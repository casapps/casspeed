# CASSPEED Specification

**Name**: casspeed

---

# PROJECT DESCRIPTION

**A free self-hosted alternative to speedtest.net with all features, no ads, no tracking, and no feature gating.**

casspeed is a comprehensive network speed testing solution that allows you to run your own speedtest server. It provides both a web interface and CLI client for measuring download/upload speeds, latency, and connection quality. Users can track their bandwidth history over time with visual graphs.

**Key Features:**
- Web-based speedtest interface with real-time graphs
- CLI client for server-side speed testing
- Historical test results tracking and visualization
- No advertisements, tracking, or feature limitations
- Self-hosted for complete privacy and control
- Multi-threaded download/upload tests
- Latency and jitter measurements
- Support for multiple concurrent tests

**Target Users:**
- Home lab enthusiasts who want to monitor their network performance
- Network administrators needing internal speedtest capabilities
- Privacy-conscious users who want self-hosted network testing
- Organizations requiring on-premises bandwidth testing
- Anyone seeking a free, open-source alternative to speedtest.net

---

# ⚠️ CRITICAL RULES - READ FIRST ⚠️

**STOP. Read this entire section before doing ANYTHING.**

## THIS IS A STRICT SPECIFICATION - NOT GUIDELINES

**EVERY SINGLE ITEM in this specification MUST be followed EXACTLY as written.**

- This is NOT a suggestion document
- This is NOT a "best practices" guide
- This is NOT open to interpretation
- There are NO exceptions unless explicitly stated
- Deviation from ANY part of this spec is a failure
- "I thought it would be better to..." is NOT acceptable
- "The standard way is..." - THIS spec IS the standard
- If the spec says X, you do X - not Y, not "improved X", not "X but slightly different"

**If something seems wrong or suboptimal in this spec, follow it anyway and flag it for review. Do NOT silently "fix" it.**

## ⚠️ CRITICAL: File Paths and Project Root ⚠️

**THIS TEMPLATE FILE CAN LIVE ANYWHERE. YOUR PROJECT FILES DO NOT.**

When using this template to build or modify a project:

| ❌ WRONG | ✅ CORRECT |
|----------|-----------|
| Create files relative to AI.md location | Create files relative to PROJECT root directory |
| `/root/Projects/github/apimgr/src/` | `{project_root}/src/` |
| Where this template lives | Where the project being built lives |

**Common Mistake Example:**
```
User: "Use AI.md to build myproject in ~/Documents/myproject"
AI (WRONG): Creates files in /root/Projects/github/apimgr/src/
AI (RIGHT): Creates files in ~/Documents/myproject/src/
```

**Rules:**
- **AI.md location** = Reference document (can be anywhere: ~/Projects/github/apimgr/, ~/, etc.)
- **Project root** = Where YOUR project lives (can be anywhere: ~/Documents/myproject, ~/myproject, /workspace/project, etc.)
- **ALL file operations** = Relative to PROJECT root, NOT template location
- **Use `git rev-parse --show-toplevel`** when in a git repo to find project root
- **Never assume** cwd or template location is the project root

## ⚠️ CRITICAL: NEVER Reference AI.md in Generated Files ⚠️

**When generating code, comments, or documentation for a project:**

| ❌ NEVER Write This | ✅ Always Write This |
|---------------------|---------------------|
| `// See AI.md for details` | `// See AI.md for details` |
| `# Based on AI.md` | `# Based on AI.md` |
| `Read AI.md` | `Read AI.md` |
| `Check AI.md` | `Check AI.md` |
| `Consult AI.md` | `Consult AI.md` |
| `From AI.md` | `From AI.md` |

**Why?** Projects don't have AI.md - they have AI.md (the project-specific spec created from AI.md). Writing "AI.md" in project files creates broken references.

**Rule:** In ALL generated code, comments, documentation, and messages, reference **AI.md**, never AI.md.

## ⚠️ CRITICAL: NEVER Overwrite AI.md (Unless Explicitly Told) ⚠️

**AI.md IS THE SOURCE OF TRUTH. DO NOT REGENERATE OR OVERWRITE IT DURING NORMAL WORK.**

**During normal development work:**

| ❌ NEVER Do This | ✅ Always Do This |
|------------------|-------------------|
| Regenerate AI.md from AI.md | Update only PART 36 in AI.md |
| Overwrite entire AI.md | Edit specific sections that changed |
| "Refresh" AI.md on your own | Keep AI.md intact, update targeted content only |
| Delete and recreate AI.md | Preserve all existing content |

**Exception:** If user explicitly says "re-read template and update AI.md", then copy AI.md → AI.md and immediately update PART 36 with current project info (see details below).

**AI.md Structure:**

```
┌─────────────────────────────────────────────────────────────────┐
│ AI.md = ENTIRE TEMPLATE (COMPLETE COPY) + PROJECT INFO         │
│                                                                 │
│ ⚠️  CRITICAL: DO NOT REMOVE ANYTHING FROM PARTS 1-35           │
│                                                                 │
│ ✓ Template sections (PARTS 1-35):  MUST STAY IDENTICAL        │
│     → Copy completely, do NOT shorten or remove ANY content    │
│     → Keep every line, every section, every word               │
│                                                                 │
│ ✓ Project-specific (PART 36):  FILL IN WITH PROJECT DETAILS   │
│     → Replace template placeholders with actual project info   │
│     → Add all endpoints, features, configurations              │
│     → This section will be LARGER than template version        │
│                                                                 │
│ Size: AI.md will be AT LEAST ~1.1MB (AI.md size)           │
│       Often LARGER due to detailed PART 36 content             │
└─────────────────────────────────────────────────────────────────┘
```

**What "Stay in Sync" Means:**

| File/Section | Must Match Reality | Update When |
|--------------|-------------------|-------------|
| **AI.md PART 36** | Actual project code/features | Code changes, features added/removed |
| **README.md** | Current functionality | Features, usage, installation changes |
| **docs/** (ReadTheDocs) | Current API/config/usage | Any user-facing changes |
| **Swagger annotations** | Actual API endpoints | Routes/handlers added/removed/changed |
| **GraphQL schema** | Actual GraphQL types/queries | Schema changes |

**Rules for Updating Documentation:**

1. **AI.md PART 36**: Update business logic, data models, features (NOT implementation patterns)
   - Add new business rules
   - Update data structures/models
   - Document new features and their purpose
   - Do NOT add route formats, HTML patterns, etc. (those are in PARTS 1-35)
2. **README.md**: Keep feature list, usage examples, and installation steps current
3. **docs/**: Update relevant .md files when config options, API routes, or behavior changes
4. **Swagger**: Add/update/remove annotations when endpoints change
5. **GraphQL**: Update schema and resolvers when types/queries change

**NEVER:**
- Regenerate AI.md from scratch
- Overwrite template sections (PARTS 1-35) in AI.md
- Let documentation drift from actual code
- Reference features in docs that don't exist in code
- Keep outdated API documentation

**Example - Adding a New Feature:**

```
✓ CORRECT:
1. Write the code (new handler, service, etc.)
2. Update AI.md PART 36 - add feature description
3. Update README.md - add feature to list
4. Update docs/api.md - document new endpoints
5. Add Swagger annotations to new handlers
6. Update GraphQL schema if applicable

✗ WRONG:
1. Write the code
2. Regenerate AI.md from AI.md (loses project-specific content!)
3. Leave README.md unchanged (documentation now lies)
```

### Exception: Refreshing AI.md from Template

**There is ONE exception to "never overwrite AI.md":**

When the user **explicitly asks** to refresh/update AI.md from the template:

```
User: "Re-read the template and update AI.md"
User: "Refresh AI.md from AI.md"
User: "Update AI.md with latest template"
```

**In this case, the workflow is:**

```
✓ CORRECT WORKFLOW:
1. Copy ENTIRE AI.md → AI.md (COMPLETE file, ~1.1MB, ALL sections)
   ⚠️  DO NOT shorten, summarize, or remove ANY sections from PARTS 1-35
   ⚠️  AI.md will be AT LEAST ~1.1MB (often larger when PART 36 is filled in)
2. Replace casspeed, casapps, CASSPEED variables
3. IMMEDIATELY update PART 36 with current project-specific info:
   - Read actual project code
   - Document actual features/endpoints/config
   - Reflect current project state
4. Delete "HOW TO USE THIS TEMPLATE" section ONLY
5. Result: COMPLETE template (PARTS 1-35 unchanged) + Current project info (PART 36)

✗ WRONG WORKFLOW:
1. Copy and shorten/summarize template (AI.md becomes tiny!)
2. Remove sections you think aren't needed (BREAKS THE SPEC!)
3. Create condensed version (NOT ALLOWED!)

⚠️  CRITICAL: AI.md is the COMPLETE project specification, not a summary!
```

**Why this is allowed:**
- AI.md gets improvements and updates over time
- Refreshing brings bug fixes, new features, better organization
- PART 36 gets repopulated with current project reality
- No information is lost if PART 36 is updated immediately

**When NOT to do this:**
- Don't refresh during normal development work
- Don't refresh just because code changed (update PART 36 only)
- Only refresh when template has significant updates

## Build & Binary Rules

| Rule | Description |
|------|-------------|
| **CGO_ENABLED=0** | ALWAYS. No exceptions. Pure Go only. |
| **Single static binary** | All assets embedded with Go `embed` package |
| **8 platforms required** | linux, darwin, windows, freebsd × amd64, arm64 |
| **Binary naming** | `{project}-{os}-{arch}` (windows adds `.exe`) |
| **NEVER use -musl suffix** | Alpine builds are NOT musl-specific |
| **Build source** | ALWAYS `src` directory |

## Docker Rules

| Rule | Description |
|------|-------------|
| **Multi-stage Dockerfile** | Builder stage (golang:alpine) + Runtime stage (alpine:latest) |
| **Dockerfile location** | `docker/Dockerfile` - NEVER in project root |
| **Default timezone** | `America/New_York` (override with `TZ` env var) |
| **Internal port** | Default `80` - app listens on `0.0.0.0:80` (override with `PORT` env var) |
| **External port** | Random `64xxx` port mapped to internal 80: `64580:80` |
| **STOPSIGNAL** | `SIGRTMIN+3` |
| **ENTRYPOINT** | `["tini", "-p", "SIGTERM", "--", "/usr/local/bin/entrypoint.sh"]` |
| **NEVER modify ENTRYPOINT/CMD** | All customization via entrypoint.sh |
| **Required packages** | `git`, `curl`, `bash`, `tini`, `tor` |
| **Tor** | Auto-enabled if `tor` binary installed (Docker image always has Tor) |

### Container Port Behavior (NON-NEGOTIABLE)

```
┌─────────────────────────────────────────────────────────────────────────┐
│  CONTAINER DEFAULT: 0.0.0.0:80                                          │
│                                                                         │
│  Inside container:  app --address 0.0.0.0 --port 80                    │
│  Docker mapping:    -p {randomport}:80  (e.g., -p 64580:80)            │
│                                                                         │
│  Override with env vars:                                                │
│    - PORT=8080      (change internal port, update docker-compose too)  │
│    - ADDRESS=...    (rarely needed, default 0.0.0.0 is correct)        │
└─────────────────────────────────────────────────────────────────────────┘
```

| Context | Address | Port | Example |
|---------|---------|------|---------|
| **Container (default)** | `0.0.0.0` | `80` | `-p 64580:80` |
| **Container (custom)** | `0.0.0.0` | `PORT` env | `PORT=8080` + `-p 64580:8080` |
| **Host (dev)** | `0.0.0.0` | Random `64xxx` | `--address 0.0.0.0 --port 64580` |
| **Host (prod)** | Specific IP | Random `64xxx` | `--address 192.168.1.100 --port 64580` |

## CI/CD Rules

| Rule | Description |
|------|-------------|
| **NEVER use Makefile in CI** | Workflows have explicit commands with all env vars |
| **GitHub/Gitea/Jenkins must match** | Same platforms, same env vars, same logic |
| **VERSION from tag** | Strip `v` prefix from semver only: `v1.2.3` → `1.2.3`, `dev` → `dev` |
| **LDFLAGS** | `-s -w -X 'main.Version=...' -X 'main.CommitID=...' -X 'main.BuildDate=...'` |
| **Docker builds on EVERY push** | Any branch push triggers Docker image build |
| **Docker tags** | Any push → `devel`, `{commit}`; beta → adds `beta`; tag → `{version}`, `latest`, `YYMM`, `{commit}` |

## Database Rules

| Rule | Description |
|------|-------------|
| **SQLite default** | `{datadir}/db/server.db` and `{datadir}/db/users.db` |
| **Password hashing** | Argon2id - NEVER bcrypt |
| **Valkey/Redis** | Every app supports it for caching/clustering |

## CLI Rules (NON-NEGOTIABLE)

```
--help                       # Show help (-h allowed)
--version                    # Show version (-v allowed)
--mode {production|development}
--config {configdir}
--data {datadir}
--log {logdir}
--pid {pidfile}
--address {listen}
--port {port}
--debug                      # Enable debug mode
--status                     # Show status and health
--service {start,restart,stop,reload,--install,--uninstall,--disable,--help}
--daemon                     # Daemonize (detach from terminal)
--maintenance {backup,restore,update,mode,setup} [optional-file-or-setting]
--update [check|yes|branch {stable|beta|daily}]
```

**Short Flag Rule:** Only `-h` (help) and `-v` (version) may have short flags. All other flags use long form only.

**These CLI commands are NON-NEGOTIABLE. Do not change, rename, or remove them.**

## Directory Structure

```
src/                        # Go source code (REQUIRED)
src/main.go                 # Server application entry point
src/config/                 # Configuration package
src/server/                 # HTTP server package
src/client/                 # CLI client (OPTIONAL - if project has CLI)
docker/                     # Docker files (REQUIRED)
docker/Dockerfile           # Multi-stage Dockerfile
docker/docker-compose.yml   # Production docker-compose
docker/rootfs/              # BUILD-TIME overlay (entrypoint.sh) - NOT runtime volumes
binaries/                   # Build output (gitignored)
releases/                   # Release artifacts (gitignored)
```

**Notes:**
- `src/client/` is only present if the project includes a CLI client. See PART 34 for CLI details.
- `docker/rootfs/` is for BUILD-TIME container overlay (copied into image). Runtime volumes (`./rootfs/config`, `./rootfs/data`) are NEVER in the repo - they exist only where docker-compose runs (production server or temp dir).

## File & Directory Naming Conventions (NON-NEGOTIABLE)

### General Rules

| Rule | Example | Avoid |
|------|---------|-------|
| **Lowercase only** | `config/`, `server.go` | `Config/`, `Server.go` |
| **Snake_case for multi-word** | `user_service.go`, `api_handler.go` | `userService.go`, `apiHandler.go` |
| **Singular directory names** | `handler/`, `model/`, `service/` | `handlers/`, `models/`, `services/` |
| **Match package name** | `config/config.go`, `server/server.go` | `config/cfg.go`, `server/srv.go` |
| **Clear intent** | `auth.go`, `middleware.go` | `a.go`, `mw.go` |

### Go Source Files (`src/`)

| Pattern | When to Use | Example |
|---------|-------------|---------|
| `{package}.go` | Main package file | `config/config.go`, `server/server.go` |
| `{feature}.go` | Feature-specific logic | `auth.go`, `session.go`, `token.go` |
| `{feature}_handler.go` | HTTP handlers for feature | `user_handler.go`, `admin_handler.go` |
| `{feature}_service.go` | Business logic for feature | `user_service.go`, `email_service.go` |
| `{feature}_model.go` | Data models for feature | `user_model.go`, `session_model.go` |
| `{feature}_test.go` | Tests for feature | `auth_test.go`, `user_handler_test.go` |
| `middleware.go` | HTTP middleware | `middleware.go` (not `mw.go`) |
| `helpers.go` | Shared utilities within package | `helpers.go` (not `utils.go`, `common.go`) |
| `errors.go` | Package-specific errors | `errors.go` |
| `types.go` | Shared types/interfaces | `types.go` |
| `constants.go` | Package constants | `constants.go` |

### Package Directory Structure (`src/`)

```
src/
├── main.go                    # Entry point (minimal - just starts server)
├── config/
│   ├── config.go              # Configuration loading & validation
│   └── bool.go                # Boolean parsing (truthy/falsy values)
├── server/
│   ├── server.go              # Server setup, routes, middleware
│   ├── middleware.go          # HTTP middleware (auth, logging, etc.)
│   ├── theme.go               # Project-wide theme detection & switching
│   ├── handler/               # HTTP handlers by domain
│   │   ├── health.go          # Health check handlers
│   │   ├── auth.go            # Authentication handlers
│   │   ├── user.go            # User management handlers
│   │   ├── admin.go           # Admin panel handlers
│   │   └── api.go             # API handlers
│   ├── service/               # Business logic by domain
│   │   ├── auth.go            # Authentication service
│   │   ├── user.go            # User service
│   │   ├── email.go           # Email service
│   │   └── scheduler.go       # Scheduled task service
│   ├── model/                 # Data models
│   │   ├── user.go            # User model
│   │   ├── session.go         # Session model
│   │   └── token.go           # Token model
│   ├── store/                 # Data access layer
│   │   ├── store.go           # Store interface
│   │   ├── sqlite.go          # SQLite implementation
│   │   └── postgres.go        # PostgreSQL implementation (if needed)
│   └── template/              # HTML templates (if not embedded)
│       ├── layout/            # Base layouts
│       ├── page/              # Full pages
│       └── partial/           # Reusable components
├── swagger/                   # OpenAPI/Swagger (REQUIRED - always relative to src/)
│   ├── swagger.go             # Swagger handler & spec generation
│   ├── annotations.go         # Swagger annotations (generated or manual)
│   └── theme.go               # Swagger UI theming (light/dark/auto)
├── graphql/                   # GraphQL API (REQUIRED - always relative to src/)
│   ├── graphql.go             # GraphQL handler & schema
│   ├── schema.go              # GraphQL schema generation
│   ├── resolvers.go           # GraphQL resolvers
│   └── theme.go               # GraphiQL theming (light/dark/auto)
├── mode/
│   └── mode.go                # Application mode (production/development)
├── paths/
│   └── paths.go               # Path resolution
├── ssl/
│   └── ssl.go                 # SSL/TLS handling
├── scheduler/
│   └── scheduler.go           # Background task scheduler
├── service/                   # Systemd service management
│   └── service.go
└── admin/                     # Admin-specific functionality
    ├── admin.go               # Admin package main
    └── handler.go             # Admin handlers
```

### When to Split Files

| Split When | Into | Example |
|------------|------|---------|
| File > 500 lines | Feature-specific files | `user.go` → `user_model.go`, `user_service.go`, `user_handler.go` |
| Multiple handlers | Handler per domain | `handler.go` → `handler/user.go`, `handler/admin.go` |
| Multiple services | Service per domain | `service.go` → `service/user.go`, `service/email.go` |
| Test file > 300 lines | Test per feature | `server_test.go` → `auth_test.go`, `user_test.go` |

### Directory Purpose (Clear Naming)

| Directory | Purpose | Contains |
|-----------|---------|----------|
| `handler/` | HTTP request handlers | Route handlers, request/response logic |
| `service/` | Business logic | Core application logic, orchestration |
| `model/` | Data structures | Structs, validation, serialization |
| `store/` | Data persistence | Database queries, CRUD operations |
| `middleware/` | HTTP middleware | Auth, logging, rate limiting, CORS |
| `template/` | HTML templates | Go templates for web UI |
| `static/` | Static assets | CSS, JS, images (embedded) |
| `migration/` | DB migrations | SQL migration files |
| `swagger/` | OpenAPI/Swagger | Spec generation, UI handler, theming (always `src/swagger/`) |
| `graphql/` | GraphQL API | Schema, resolvers, UI handler, theming (always `src/graphql/`) |

### File Content Guidelines

| File Type | Should Contain | Should NOT Contain |
|-----------|----------------|-------------------|
| `{pkg}.go` | Package init, main types, core functions | HTTP handlers, tests |
| `handler.go` | HTTP handlers only | Business logic, DB queries |
| `service.go` | Business logic only | HTTP concerns, direct DB access |
| `model.go` | Struct definitions, validation | Business logic, handlers |
| `store.go` | DB operations only | Business logic, HTTP concerns |
| `middleware.go` | Request/response middleware | Business logic |
| `helpers.go` | Small utility functions | Large features, types |
| `errors.go` | Error definitions | Error handling logic |

### Naming Anti-Patterns

| Avoid | Why | Use Instead |
|-------|-----|-------------|
| `utils.go` | Too vague | `helpers.go` or feature-specific |
| `common.go` | Too vague | `types.go`, `constants.go` |
| `misc.go` | Meaningless | Split by actual purpose |
| `stuff.go` | Meaningless | Name by content |
| `v2/` | Version in path | Use API versioning in routes |
| `new_*.go` | Temporary naming | Replace old file |
| `old_*.go` | Dead code | Delete it |
| `*.bak` | Backup files | Use git |
| `*_copy.go` | Duplicates | Delete or merge |

## Boolean Handling

Accept ALL of these (case-insensitive) → convert to `true`/`false`:

| Truthy | Falsy |
|--------|-------|
| `1`, `yes`, `true`, `on`, `enable`, `enabled` | `0`, `no`, `false`, `off`, `disable`, `disabled` |
| `y`, `t`, `yep`, `yup`, `yeah`, `aye`, `si`, `oui` | `n`, `f`, `nope`, `nah`, `nay`, `nein`, `non` |

## What NOT To Do

| NEVER | Instead |
|-------|---------|
| Use bcrypt for passwords | Use Argon2id |
| Put Dockerfile in project root | Put in `docker/Dockerfile` |
| Use .env files | Hardcode sane defaults in docker-compose |
| Run docker-compose in project dir | Use temp directory workflow |
| Skip platforms in releases | Build all 8 platforms |
| Use Makefile in CI/CD | Explicit commands with env vars |
| Modify ENTRYPOINT/CMD | Customize via entrypoint.sh |
| Use CGO | CGO_ENABLED=0 always |
| Use `strconv.ParseBool()` | Use `config.ParseBool()` for all boolean parsing |

## Project Directory Cleanliness (NON-NEGOTIABLE)

**The project directory MUST be clean, minimal, and production-ready.**

### NEVER Create These Files

| Forbidden File | Reason |
|----------------|--------|
| `SUMMARY.md` | Unnecessary - AI.md is the spec |
| `COMPLIANCE.md` | Unnecessary - compliance is in AI.md |
| `NOTES.md` | Unnecessary - notes go in AI.md |
| `CHANGELOG.md` | Use GitHub/Gitea releases instead |
| `CONTRIBUTING.md` in root | Belongs in `.github/` |
| `CODE_OF_CONDUCT.md` in root | Belongs in `.github/` |
| `SECURITY.md` in root | Belongs in `.github/` |
| `PULL_REQUEST_AI.md` in root | Belongs in `.github/` |
| `*.example.*` | No example files (defaults in binary) |
| `*.sample.*` | No sample files |
| `.env*` | No .env files |
| `TODO.md` | Use `TODO.AI.md` for AI tasks only |

### Allowed Root Files (Exhaustive List)

| File | Required | Purpose |
|------|:--------:|---------|
| `AI.md` | ✓ | Project specification |
| `TODO.AI.md` | Optional | AI task tracking (3+ tasks only) |
| `README.md` | ✓ | Public documentation |
| `LICENSE.md` | ✓ | License file |
| `Makefile` | ✓ | Build targets |
| `go.mod` | ✓ | Go module |
| `go.sum` | ✓ | Go dependencies |
| `release.txt` | ✓ | Version source of truth |
| `.gitignore` | ✓ | Git ignore rules |
| `.dockerignore` | ✓ | Docker ignore rules |
| `.gitattributes` | Optional | Git attributes |
| `Jenkinsfile` | Optional | Jenkins CI (if used) |
| `mkdocs.yml` | ✓ | MkDocs configuration |
| `.readthedocs.yaml` | ✓ | ReadTheDocs configuration |

### AI-Specific Files and Directories

| File/Directory | Required | Purpose |
|----------------|:--------:|---------|
| `.claude/` | Optional | Claude AI configuration directory |
| `.cursor/` | Optional | Cursor AI configuration directory |
| `.aider/` | Optional | Aider AI configuration directory |
| `.ai/` | Optional | Generic AI configuration directory |
| `.windsurf/` | Optional | Windsurf AI configuration directory |
| Other AI config dirs | Optional | Any AI assistant configuration directories |

**Note:** AI configuration directories are allowed in project root for tool-specific settings.

### GitHub-Specific Files (`.github/` directory)

| File | Location |
|------|----------|
| `CONTRIBUTING.md` | `.github/CONTRIBUTING.md` |
| `CODE_OF_CONDUCT.md` | `.github/CODE_OF_CONDUCT.md` |
| `SECURITY.md` | `.github/SECURITY.md` |
| `FUNDING.yml` | `.github/FUNDING.yml` |
| `ISSUE_TEMPLATE/` | `.github/ISSUE_TEMPLATE/` |
| `PULL_REQUEST_AI.md` | `.github/PULL_REQUEST_AI.md` |
| `workflows/*.yml` | `.github/workflows/` |

### Gitea-Specific Files (`.gitea/` directory)

| File | Location |
|------|----------|
| `ISSUE_TEMPLATE/` | `.gitea/ISSUE_TEMPLATE/` |
| `PULL_REQUEST_AI.md` | `.gitea/PULL_REQUEST_AI.md` |
| `workflows/*.yml` | `.gitea/workflows/` |

**RULE: If a file doesn't appear in the allowed list, it probably shouldn't exist.**

---

# TERMINOLOGY

**These terms have SPECIFIC meanings in this specification. Understand them before proceeding.**

## Core Terms

**Note:** "Project", "App", and "Application" are used interchangeably throughout this document - they all refer to the complete codebase including all files, configuration, and functionality.

| Term | Definition |
|------|------------|
| **Project / App / Application** | The server binary you are building (`casspeed`) - used interchangeably |
| **App Instance** | A single running copy of the app (one process) |
| **Server** | The machine (physical, VM, or container) running an app instance |

## Clustering Terms

| Term | Definition |
|------|------------|
| **Cluster** | Multiple app instances sharing config and state via shared database/cache |
| **Cluster Node** | An app instance participating in a cluster (synonym: cluster member) |
| **Config Sync** | Automatic propagation of settings changes across all cluster nodes |
| **Primary Node** | The elected node that handles cluster-wide tasks (leader election) |
| **Single Instance** | App running standalone without clustering (local SQLite, no shared state) |

## Extended Functionality Terms

| Term | Definition |
|------|------------|
| **Managed Node** | An EXTERNAL resource the app controls (NOT an app instance) |
| **Extended Node Function** | What the app does with managed nodes beyond config sync |
| **HA (High Availability)** | Automatic failover for critical apps - specialized, not standard |

## Managed Nodes vs Cluster Nodes

**CRITICAL DISTINCTION:**

| Type | What It Is | Example |
|------|------------|---------|
| **Cluster Node** | Instance of YOUR app | 3 copies of `jokes` running, syncing config |
| **Managed Node** | External thing your app CONTROLS | Docker hosts that Watchtower manages |

**Most apps only have cluster nodes. Managed nodes are app-specific.**

## Examples

| App | Cluster Nodes | Managed Nodes | HA |
|-----|:-------------:|:-------------:|:--:|
| Jokes API | ✓ (app instances syncing) | ✗ | ✗ |
| Watchtower-type | ✓ (app instances syncing) | ✓ (Docker hosts) | ✗ |
| DNS Server | ✓ (app instances syncing) | ✗ | ✓ |
| Monitoring App | ✓ (app instances syncing) | ✓ (monitored servers) | ✗ |

## Account Types

| Term | Definition |
|------|------------|
| **Server Admin** | Administrative account for managing the application (NOT a privileged user) |
| **Primary Admin** | The first Server Admin created during setup wizard (cannot be deleted) |
| **Additional Admin** | Server Admins added by Primary Admin or other admins |
| **OIDC/LDAP Admin** | Server Admin access via external identity provider group mapping |
| **Regular User** | End-user account that uses the application's features |

**CRITICAL:** Server Admins and Regular Users are completely separate account types stored in different database tables. A Server Admin is NOT a "privileged user."

## Other Terms

| Term | Definition |
|------|------------|
| **CLI Client** | Optional companion binary (`casspeed-cli`) for terminal access |
| **TUI** | Terminal User Interface - interactive terminal app with menus/panels |
| **Admin Panel** | Web UI at `/admin` for server administration |
| **FQDN** | Fully Qualified Domain Name (e.g., `api.example.com`) |
| **Config Dir** | Where config files live (`{configdir}`, default: `/etc/casspeed`) |
| **Data Dir** | Where runtime data lives (`{datadir}`, default: `/var/lib/casspeed`) |
| **Log Dir** | Where log files live (`{logdir}`, default: `/var/log/casspeed`) |
| **PID File** | Process ID file path (`{pidfile}`, default: `/var/run/casspeed.pid`) |

---

# AI ASSISTANT INSTRUCTIONS (READ THIS ENTIRE SECTION)

## ⚠️ STEP 1: CHECK WHICH FILE TO USE ⚠️

**BEFORE doing ANYTHING, determine which file to use:**

```bash
# Check if AI.md exists in the project directory
if [ -f "AI.md" ]; then
    # ✓ AI.md EXISTS → Use AI.md, DO NOT use AI.md
    # Exception: Only use AI.md if user explicitly says:
    #   "re-read template", "refresh from template", etc.
else
    # ✗ AI.md MISSING → Use AI.md to create AI.md
fi
```

**Decision Logic:**

| Situation | File to Use | Action |
|-----------|-------------|--------|
| **AI.md exists** | **Use AI.md** | Read AI.md for ALL project work, ignore AI.md |
| **AI.md exists** + user says "refresh from template" | **Use AI.md** | Copy AI.md → AI.md, update PART 36 |
| **AI.md missing** | **Use AI.md** | Create AI.md from AI.md |

```
┌─────────────────────────────────────────────────────────────────────────┐
│                    ⚠️  CRITICAL RULE  ⚠️                                │
│                                                                         │
│   IF AI.md EXISTS in project:                                           │
│     → Use AI.md ONLY (ignore AI.md)                              │
│     → Do NOT reference AI.md                                      │
│     → Do NOT look at AI.md                                        │
│     → Do NOT compare against AI.md                                │
│                                                                         │
│   EXCEPTION - Only use AI.md if user explicitly says:            │
│     → "Re-read the template"                                            │
│     → "Refresh AI.md from template"                                     │
│     → "Update AI.md with latest template"                               │
│                                                                         │
└─────────────────────────────────────────────────────────────────────────┘
```

## CRITICAL: AI.md vs AI.md - Know The Difference

**STOP. Understand this before doing ANYTHING.**

### The Two Files

| File | What It Is | Location | Use When? |
|------|------------|----------|-----------|
| **AI.md** | Master template (this file) | Organization/shared location | **ONLY when AI.md missing OR user says "refresh"** |
| **AI.md** | Project specification | Each project repository | **ALWAYS (if it exists)** |

### The Rule

```
┌─────────────────────────────────────────────────────────────────────────┐
│                                                                         │
│   AI.md is used to CREATE AI.md (when AI.md doesn't exist)       │
│   After AI.md exists, AI.md IS THE SPEC. Use AI.md, not AI.md    │
│                                                                         │
│   When working on a project with AI.md:                                 │
│     ✓ Read and follow AI.md (the project spec)                         │
│     ✗ Do NOT reference AI.md                                      │
│     ✗ Do NOT compare against AI.md                                │
│     ✗ Do NOT look at AI.md                                        │
│     ✗ Do NOT check AI.md for updates                              │
│                                                                         │
└─────────────────────────────────────────────────────────────────────────┘
```

### Workflow

```
AI.md (this file ~1.1MB)
    │
    │  INITIAL COPY (when AI.md doesn't exist)
    │  - Copy ENTIRE AI.md → AI.md (~1.1MB complete copy)
    │  - ⚠️  DO NOT shorten, summarize, or remove ANY sections
    │  - Replace casspeed, casapps variables
    │  - Fill in PART 36 (project-specific sections)
    │  - Delete "HOW TO USE THIS TEMPLATE" section ONLY
    │
    ▼
AI.md (project specification ~1.1MB+)
    │
    │  THIS IS NOW YOUR SPEC - DON'T OVERWRITE DURING NORMAL WORK
    │  - PARTS 1-35 MUST stay IDENTICAL to template (no removal)
    │  - PART 36 will be LARGER (filled with project details)
    │  - Read AI.md for all project work
    │  - Update ONLY PART 36 when project changes
    │  - NEVER regenerate on your own
    │  - Keep template sections (PARTS 1-35) intact and complete
    │
    │  ◄─────────────────────┐
    │                        │
    │  EXCEPTION: Template Refresh (when user explicitly requests)
    │  - User says: "Re-read template and update AI.md"
    │  - Copy ENTIRE AI.md → AI.md (complete fresh copy)
    │  - ⚠️  DO NOT shorten or summarize
    │  - Immediately update PART 36 with current project info
    │  - Result: Complete latest template + current project details
    │
    ▼
Project Implementation
    │
    │  KEEP DOCUMENTATION IN SYNC
    │  - Update AI.md PART 36 when features change (business logic only)
    │  - Implementation follows PARTS 1-35 standards (no custom patterns)
    │  - Update README.md when functionality changes
    │  - Update docs/ when API/config changes
    │  - Update Swagger annotations when routes change
    │  - Update GraphQL schema when types change
    │
    ▼
All Documentation Reflects Current Code
```

### How to Know Which File You're In

| You're in AI.md if... | You're in AI.md if... |
|-----------------------------|----------------------|
| File contains `casspeed` variables | Variables are replaced with real values |
| Has "HOW TO USE THIS TEMPLATE" section | That section is deleted |
| Located in organization/shared folder | Located in project repository |
| ~1.1MB / ~30,000 lines | ~1.1MB+ / ~29,000+ lines (at least same size, often larger) |

### What To Do

| Scenario | Action |
|----------|--------|
| **Starting work on project** | **Check if AI.md exists - if YES, use AI.md ONLY** |
| Project has AI.md | **Use AI.md only** - DO NOT open/read AI.md |
| Project missing AI.md | Create AI.md from AI.md (one-time) |
| Asked to update spec | Update AI.md PART 36 only, never overwrite entire file |
| Asked to check compliance | Check against AI.md, NOT AI.md |
| Asked for rules/requirements | Read AI.md, NOT AI.md |
| Template was updated | Does NOT affect existing AI.md files |
| Code changes | Update AI.md PART 36, README.md, docs/, Swagger, GraphQL |
| Feature added | Update all documentation to match new reality |
| Feature removed | Update all documentation to remove references |
| **User says "re-read template"** | **Copy ENTIRE AI.md → AI.md, then update PART 36** |

### Common Mistakes

| Mistake | Why It's Wrong | Correct Action |
|---------|----------------|----------------|
| **Using AI.md when AI.md exists** | **AI.md IS the project spec** | **Check if AI.md exists first, use AI.md** |
| **Looking at AI.md during project work** | **AI.md is not the project spec** | **Use AI.md only** |
| **Checking AI.md for rules** | **Rules are in AI.md (project copy)** | **Read AI.md instead** |
| Reading AI.md for project work | Project spec is AI.md | Read AI.md instead |
| "Syncing" AI.md with AI.md | AI.md is standalone after creation | Keep AI.md independent |
| Updating AI.md | Template is read-only | Ask maintainer for template changes |
| Referencing AI.md line numbers | AI.md has different line numbers | Use AI.md line numbers |
| **Shortening/summarizing AI.md** | **AI.md MUST be ≥1MB (complete PARTS 1-35)** | **Copy ENTIRE template, do NOT remove from PARTS 1-35** |
| **Removing sections from PARTS 1-35** | **Breaks the complete specification** | **Keep ALL template sections identical** |
| **Regenerating AI.md from AI.md** | **Loses all project-specific content** | **NEVER do this - update PART 36 only** |
| **Overwriting entire AI.md** | **Destroys the source of truth** | **Edit specific sections only** |
| **Leaving docs out of sync** | **Documentation lies about features** | **Update README, docs/, Swagger, GraphQL** |

---

## CRITICAL: How to Handle This Large File

**This AI.md is ~1.1MB and ~30,000 lines. You CANNOT read it all at once. Follow these procedures.**

**NOTE: This section applies when you ARE reading AI.md (to create AI.md for a new project). For existing projects, read AI.md instead - it's the complete project spec created from this template (at least ~1.1MB, often larger with project details).**

### File Size Reality

| Constraint | Value |
|------------|-------|
| File size | ~1.1MB (~1100KB) |
| Line count | ~30,000 lines |
| Read limit | ~500 lines per read |
| Full reads needed | ~60 reads (impractical) |

**You MUST read strategically, not sequentially.**

### PART Index (Quick Reference)

**⚠️ IMPORTANT: Line numbers in this index are approximate and may drift as the template is updated.**

**ALWAYS use `grep -n "^# PART" AI.md` to get exact current line numbers.**

Use this index for general navigation only. Do not rely on these line numbers for precise location.

| PART | Lines | Topic | When to Read |
|------|-------|-------|--------------|
| 0 | 1175-2238 | AI Assistant Rules | **ALWAYS READ FIRST** |
| 1 | 2239-2843 | Critical Rules | **ALWAYS READ FIRST** |
| 2 | 2844-3214 | License & Attribution | License requirements |
| 3 | 3215-3976 | Project Structure | Setting up new project |
| 4 | 3977-4142 | OS-Specific Paths | Path handling |
| 5 | 4143-5178 | Configuration | Config file work |
| 6 | 5179-5782 | Application Modes | Mode handling, debug endpoints |
| 7 | 5783-8169 | Server Binary CLI | CLI flags/commands |
| 8 | 8170-8225 | Update Command | Update feature |
| 9 | 8226-8611 | Privilege Escalation & Service | Service/privilege work |
| 10 | 8612-8629 | Service Support | Systemd/service |
| 11 | 8630-8786 | Binary Requirements | Binary building |
| 12 | 8787-9311 | Makefile | Build system |
| 13 | 9312-10420 | Testing & Development | Testing/dev workflow |
| 14 | 10421-11381 | Docker | Docker/containers |
| 15 | 11382-13545 | CI/CD Workflows | GitHub/Gitea Actions |
| 16 | 13546-13669 | Health & Versioning | Health endpoints |
| 17 | 13670-15563 | Web Frontend | Frontend/UI work |
| 18 | 15564-15802 | Server Configuration | Server settings |
| 19 | 15803-16523 | Admin Panel | Admin UI |
| 20 | 16524-17543 | API Structure | REST/GraphQL/Compatibility API |
| 21 | 17544-18221 | SSL/TLS & Let's Encrypt | SSL certificates |
| 22 | 18222-19697 | Security & Logging | Security features |
| 23 | 19698-22744 | User Management | Users/auth/sessions |
| 24 | 22745-22877 | Database & Cluster | Database work |
| 25 | 22878-23282 | Backup & Restore | Backup features |
| 26 | 23283-24616 | Email & Notifications | Email/SMTP |
| 27 | 24617-24944 | Scheduler | Background tasks |
| 28 | 24945-25017 | GeoIP | GeoIP features |
| 29 | 25018-26038 | Metrics | Metrics/monitoring |
| 30 | 26039-26631 | Tor Hidden Service | Tor support |
| 31 | 26632-26689 | Error Handling & Caching | Error/cache |
| 32 | 26690-26712 | I18N & A11Y | Internationalization |
| 33 | 26713-27429 | ReadTheDocs Documentation | Documentation |
| 34 | 27430-27992 | CLI Client | **OPTIONAL** - CLI tool |
| 35 | 27993-28926 | Custom Domains | **OPTIONAL** - user/org branded domains |
| 36 | 28927-29151 | Project-Specific Sections | Business logic only |
| FINAL | 29152-29933 | Compliance Checklist | Final verification |

### How to Read This File

**Note:** Line numbers below are approximate. Use `grep -n` for exact locations.

**Step 1: Always read these first (MANDATORY)**

```
Read lines 1-220      # Critical rules summary (includes file naming conventions)
Read lines 635-900    # HOW TO USE + AI.md vs AI.md distinction (CRITICAL)
Read lines 1170-1400  # AI rules (PART 0 start)
Read lines 2143-2400  # Critical rules (PART 1 start)
```

**Step 1b: For migrations, ALSO read:**

```
Read lines 700-710    # For Existing Projects section
```

**Step 1c: For new projects, ALSO read:**

```
Read lines 671-700    # For New Projects section
```

**Step 2: Read sections relevant to your task**

Use `grep` to find the PART you need:
```bash
grep -n "^# PART" AI.md    # List all PARTs with line numbers
grep -n "keyword" AI.md    # Find specific content
```

**Step 3: Read the specific PART completely**

Once you identify the PART, read ALL of it:
```
# Example: Working on Docker
Read lines 9921-10881  # PART 14: Docker (complete section)
```

### Reading Strategy by Task Type

| Task | Read These PARTs |
|------|------------------|
| **Migrating existing app** | 0, Migration sections (1234-1577), 1, 2, 6, 13 |
| **New project/app setup** | 0, New Project Rules (1578-1780), 1, 2, 11, 13, 35 |
| **CLI implementation** | 0, 1, 6, 7, 8 |
| **API development** | 0, 1, 15, 19, 21 |
| **Frontend/UI work** | 0, 1, 16, 18 |
| **Database work** | 0, 1, 4, 23 |
| **User/auth system** | 0, 1, 21, 22 |
| **Docker/deployment** | 0, 1, 11, 13, 14 |
| **Documentation** | 0, 1, 35 |
| **Security features** | 0, 1, 20, 21 |
| **Background tasks** | 0, 1, 26 |
| **Email features** | 0, 1, 25 |
| **Backup features** | 0, 1, 24 |
| **Debugging/profiling** | 0, 1, 5 |

### Search Before Reading

**ALWAYS search first to find exactly what you need:**

```bash
# Find specific topics
grep -n "rate limit" AI.md
grep -n "CSRF" AI.md
grep -n "server.yml" AI.md

# Find code examples
grep -n "```go" AI.md
grep -n "```yaml" AI.md

# Find tables
grep -n "^|" AI.md | head -50
```

### Common Mistakes When Reading This File

| Mistake | Consequence | Correct Approach |
|---------|-------------|------------------|
| Reading sequentially from start | Context window exhausted | Use index, read specific PARTs |
| Reading only part of a PART | Missing critical details | Read complete PART sections |
| Not re-reading before implementing | Drift from spec | Always re-read relevant PART |
| Guessing instead of searching | Wrong implementation | Use grep to find answers |
| Skipping PART 0 and 1 | Missing critical rules | ALWAYS read these first |

### When You Can't Find Information

1. **Search with grep** - use multiple keywords
2. **Check related PARTs** - information may be in adjacent sections
3. **Read the FINAL CHECKPOINT** - summary of all requirements
4. **ASK the user** - don't guess

### Memory Limitations

**You will forget details from earlier reads.** Combat this by:

1. **Re-reading before implementing** - every time
2. **Noting key values** - write down important numbers/names
3. **Cross-referencing** - check multiple sections for consistency
4. **Never relying on memory** - always verify with a fresh read

---

## CRITICAL: Specification Drift Prevention

**AI assistants have a tendency to "drift" from specifications over time.** This means gradually deviating from documented requirements, inventing new patterns, or forgetting constraints. **This is unacceptable.**

### The Problem

| Drift Type | Example | Impact |
|------------|---------|--------|
| **Pattern drift** | Using different file structure than specified | Inconsistency across projects |
| **Naming drift** | Using different variable/function names | Code doesn't match spec |
| **Feature drift** | Adding unrequested features | Over-engineering, bugs |
| **Constraint drift** | Forgetting NON-NEGOTIABLE rules | Specification violations |
| **Format drift** | Using different date/version formats | Integration failures |

### The Solution: Constant Re-verification

**You MUST re-read relevant spec sections before EVERY implementation.**

```
BEFORE writing ANY code:
1. Identify which PART(s) of the spec apply
2. Re-read those sections completely
3. Verify your planned implementation matches EXACTLY
4. If ANY deviation is needed, ASK first
5. NEVER assume you remember correctly - ALWAYS re-check
```

## Mandatory Compliance Checks

**Perform these checks at regular intervals:**

| When | Action |
|------|--------|
| **Start of session** | Read AI.md completely, identify applicable sections |
| **Before each task** | Re-read relevant PART(s) of the spec |
| **Every 3-5 changes** | Stop and verify against spec - are you drifting? |
| **Before completing task** | Full compliance check against relevant sections |
| **If uncertain** | STOP and re-read spec, or ASK user |

## What "NON-NEGOTIABLE" Means

**NON-NEGOTIABLE sections MUST be implemented EXACTLY as specified.**

| Allowed | NOT Allowed |
|---------|-------------|
| Copy spec exactly | "Improve" or "optimize" the spec |
| Ask for clarification | Assume you know better |
| Report conflicts | Silently deviate |
| Request exceptions | Make exceptions yourself |

**If you think a NON-NEGOTIABLE section is wrong:**
1. STOP implementation
2. Tell the user specifically what you think is wrong
3. Ask for explicit permission to deviate
4. Document the deviation in AI.md if approved

## Template File Rules

| Rule | Description |
|------|-------------|
| **NEVER modify template** | Template file is read-only (location varies) |
| **Identify by content** | Has unreplaced `{variables}`, "HOW TO USE" section |
| **AI.md is project spec** | Copy template → AI.md (ONE-TIME), customize for project |
| **AI.md is standalone** | Does NOT reference or sync with template after creation |
| **Keep AI.md current** | Update when project state changes (NOT template changes) |
| **Delete old files** | Merge CLAUDE.md/SPEC.md (in project) → AI.md |

## Before Starting ANY Work

1. **Locate AI.md** - this is the project specification
2. **If AI.md missing** - create from template, replace variables
3. **Read AI.md COMPLETELY** - not just relevant parts
4. **Identify applicable sections** - which PARTs apply to this task?
5. **Check TODO.AI.md** - see pending tasks
6. **Verify understanding** - if ANYTHING is unclear, ASK

## During Work

1. **Re-read spec before each implementation** - EVERY time
2. **Follow spec EXACTLY** - no "improvements" without asking
3. **Check yourself frequently** - am I drifting from spec?
4. **Update TODO.AI.md** as tasks complete
5. **If stuck or uncertain** - re-read spec or ASK, never guess

## Common Drift Mistakes to Avoid

| Mistake | Correct Approach |
|---------|------------------|
| "I'll use a better pattern" | Use the pattern in the spec |
| "This format makes more sense" | Use the format in the spec |
| "I remember the spec says..." | Re-read the spec, don't rely on memory |
| "This is obviously what they want" | Check the spec, ask if not covered |
| "I'll add this helpful feature" | Only implement what's requested |
| "The spec is outdated here" | Ask before deviating |

## Quick Reference

| File | Location | Purpose | Modify? |
|------|----------|---------|---------|
| Template | Varies (see below) | Master spec | **NEVER** |
| AI.md | Project repo | Project spec | Yes |
| TODO.AI.md | Project repo | Task tracking | Yes |
| README.md | Project repo | User docs | Yes |


# PART 0: AI ASSISTANT RULES (READ FIRST - NON-NEGOTIABLE)

**These rules govern how AI assistants work on projects using this specification.**

## CRITICAL: Specification Drift is Unacceptable

**AI assistants drift from specifications over time.** This means:
- Gradually deviating from documented requirements
- Inventing new patterns not in the spec
- Forgetting constraints after working for a while
- "Improving" things that don't need improvement

**This drift is the #1 cause of specification violations. Combat it actively.**

## CRITICAL: Always Reference The Relevant Section

**BEFORE implementing ANY feature, ALWAYS read the specific PART that covers it.**

**Rule: NEVER guess, assume, or work from memory - ALWAYS read the spec section.**

| Task | Read For Business Logic | Read For Implementation | Example |
|------|-------------------------|------------------------|---------|
| Implementing users/auth | PART 36 (if custom logic) | PART 23: User Management | "Reading PART 36 for business rules, PART 23 for implementation..." |
| Setting up UI/frontend | PART 36 (what to display) | PART 17: Web Frontend | "PART 36 defines content, PART 17 defines UI patterns..." |
| Configuring SSL | N/A | PART 21: SSL/TLS & Let's Encrypt | "Following PART 21 for SSL setup..." |
| Adding API endpoints | PART 36 (endpoint purpose) | PART 20: API Structure | "PART 36 defines what endpoints do, PART 20 defines how..." |
| Writing tests | PART 36 (what to test) | PART 13: Testing & Development | "PART 36 lists features to test, PART 13 defines test structure..." |
| Creating Dockerfile | N/A | PART 14: Docker | "Implementing per PART 14 Docker rules..." |
| Adding config options | PART 36 (what settings) | PART 5: Configuration | "PART 36 defines settings needed, PART 5 defines YAML format..." |
| CLI commands | N/A | PART 7: Server Binary CLI | "Following PART 7 for CLI structure..." |

**Workflow:**
```
1. User: "Add joke rating feature"
2. AI: Reads PART 36 for business logic (what a joke rating means, validation rules)
3. AI: Reads PART 20 for API patterns (how to structure endpoints)
4. AI: Reads PART 17 for frontend patterns (how to display ratings)
5. AI: Implements using standards from PARTS 17, 20 with logic from PART 36
6. AI: Updates PART 36 with new feature, updates README.md, docs/
```

**Key Principle:**
- **PART 36 = WHAT** (business logic, data, rules)
- **PARTS 1-35 = HOW** (implementation patterns, standards)
- **AI combines both** to build features correctly

**DO NOT:**
- Guess how features should work
- Implement based on "standard practices"
- Work from memory of the spec
- Create patterns not in the spec
- Write verbose documentation explaining what you're doing (the spec is the documentation)

**The spec defines it. TODO.AI.md tracks it. No additional documentation needed.**

## Template File vs AI.md

| File | Action | Description |
|------|--------|-------------|
| **Template file** | **NEVER MODIFY** | Read-only master (may be named AI.md, SPEC.md, etc.) |
| **AI.md** | Create/Update | Project-specific specification |
| **TODO.AI.md** | Create/Update | Task tracking |

**How to identify the AI.md:**
- Location varies: project root, org root, different org, ~/, or user-specified
- Contains unreplaced `casspeed`, `casapps` variables
- Contains "HOW TO USE THIS TEMPLATE" section
- Contains multiple "PART X:" numbered sections

**Workflow:**
1. If `AI.md` doesn't exist → Copy from template, apply migrations (see below)
2. If `AI.md` exists → Read it (it is the complete standalone spec for this project)
3. If old spec files exist in project repo → Merge into `AI.md`, DELETE old files

**Important:** AI.md is created from AI.md **once**. After creation, AI.md is the complete standalone spec and does NOT reference or sync with AI.md.

**Migration Rules (when copying AI.md → AI.md):**

| Priority | Action | Description |
|----------|--------|-------------|
| 1 | **Copy template** | Copy AI.md to project as AI.md |
| 2 | **Replace variables** | `casspeed`, `casapps` with actual values |
| 3 | **Replace references** | `AI.md` → `AI.md`, `TEMPLATE` → `AI` |
| 4 | **Update project sections** | Fill in PART 36 with actual project details |

**Variable Replacements:**
| Find | Replace With | Example |
|------|--------------|---------|
| `casspeed` | Actual project name | `jokes` |
| `casapps` | Actual org name | `apimgr` |
| `AI.md` | `AI.md` | References to this file |
| `TEMPLATE` (as document name) | `AI` | "read the TEMPLATE" → "read the AI" |

**Project-Specific Sections (PART 36) - MUST be updated:**
- Project description, purpose, and intent
- Project-specific API endpoints
- Project-specific data files and their structure
- Project-specific configuration options
- Architecture decisions and notes

## Mandatory Compliance Schedule

| When | Action | Purpose |
|------|--------|---------|
| **Session start** | Read AI.md completely | Understand full context |
| **Before EACH task** | Re-read relevant PART(s) | Prevent drift |
| **Every 3-5 changes** | Stop, verify against spec | Catch drift early |
| **Before task completion** | Full compliance check | Ensure correctness |
| **When uncertain** | Re-read spec or ASK | Never guess |

**You MUST re-read the spec before implementing. Do NOT rely on memory.**

## Before Starting Work

1. **Identify template vs AI.md** - template is read-only, AI.md is project spec
2. **NEVER modify AI.md** - location varies, but it's always read-only
3. **Read AI.md COMPLETELY** - not just parts you think are relevant
4. **If AI.md missing** - create from template (ONE-TIME), replace all variables
5. **AI.md is standalone** - does NOT sync with template after creation
6. **Check TODO.AI.md** - see pending tasks and their priority
7. **Verify understanding** - if ANYTHING is unclear, ASK first
8. **Never assume** - when in doubt, ask the user

## During Work

1. **Re-read spec before EACH implementation** - every single time
2. **Follow spec EXACTLY** - no "improvements" without explicit permission
3. **Check yourself every 3-5 changes** - am I drifting?
4. **Update TODO.AI.md** as tasks are completed
5. **Test your changes** - don't commit untested code
6. **Keep changes focused** - one feature/fix per task
7. **If uncertain** - STOP, re-read spec, or ASK

## After Work

1. **Update AI.md** if architecture or rules changed
2. **Update TODO.AI.md** with any new tasks discovered
3. **Verify compliance** - check against the FINAL CHECKPOINT
4. **NEVER modify AI.md** - changes go in AI.md only
5. **Update COMMIT_MESS** - write commit message for changes made

## Commit Message File (NON-NEGOTIABLE)

**AI assistants CANNOT run `git add`, `git commit`, or `git push`.** Instead, create/update the commit message file.

**File:** `{projectdir}/.git/COMMIT_MESS`

| Action | When |
|--------|------|
| **Create** | If file does not exist |
| **Update** | If file exists (overwrite with new message) |

**Format:**
```
{emoji} Title message (max 64 chars) {emoji}

{detailed description of changes}

- Bullet point 1
- Bullet point 2
- etc.
```

**Commit Type Emojis:**

| Emoji | Type | Use For |
|-------|------|---------|
| ✨ | feat | New feature |
| 🐛 | fix | Bug fix |
| 📝 | docs | Documentation |
| 🎨 | style | Formatting, no code change |
| ♻️ | refactor | Code refactoring |
| ⚡ | perf | Performance improvement |
| ✅ | test | Adding tests |
| 🔧 | chore | Config, build, tools |
| 🔒 | security | Security fix |
| 🗑️ | remove | Removing code/files |
| 🚀 | deploy | Deployment related |
| 📦 | deps | Dependency updates |

**Example:**
```
✨ Add GeoIP country blocking feature ✨

Implement country-based access control using ip-location-db.

- Add GeoIP database download on first run
- Add scheduler task for weekly updates
- Add deny_countries config option
- Add admin panel for country management
```

## TODO.AI.md Completion (NON-NEGOTIABLE)

**When ALL items in TODO.AI.md are completed:**

1. **Empty the TODO.AI.md file** - truncate to empty (keep the file, remove all content)
2. **Write COMMIT_MESS** with the following format:

**Title Format:**
```
✅ all todo items have been completed ✅
```

**Body Format:**
```
All tasks from TODO.AI.md have been completed.

{summary of completed tasks}

- Task 1 completed
- Task 2 completed
- etc.
```

**Example:**
```
✅ all todo items have been completed ✅

All tasks from TODO.AI.md have been completed.

Implemented core server functionality and admin panel.

- Added mode package with production/development modes
- Implemented SSL certificate handling
- Created scheduler for background tasks
- Built admin panel with authentication
```

**Rules:**
- The ✅ emoji MUST be used for todo completion commits
- Title is EXACTLY: `✅ all todo items have been completed ✅`
- Body MUST summarize what was accomplished
- Empty TODO.AI.md BEFORE writing COMMIT_MESS
- File stays empty until new tasks are added

**Rules:**
- Title line: max 64 characters (including emojis)
- Blank line after title
- Detailed description follows
- Use bullet points for multiple changes
- Be specific about what changed and why

## Common Drift Patterns to Avoid

| Drift Pattern | What You Think | What You Should Do |
|---------------|----------------|-------------------|
| Pattern improvement | "This pattern is better" | Use the pattern in spec |
| Format change | "This format is cleaner" | Use the format in spec |
| Memory reliance | "I remember it says..." | Re-read the actual spec |
| Assumption | "Obviously they want..." | Check spec, ask if unclear |
| Feature addition | "This would be helpful" | Only do what's requested |
| Spec correction | "The spec is wrong here" | Ask before any deviation |

## Attribution

| Rule | Description |
|------|-------------|
| **NEVER** | Include AI attribution in code, comments, commits, or documentation |
| **NEVER** | "authored by Claude", "generated by AI", "Co-Authored-By: Claude" |
| **ALWAYS** | Code should appear as if written by a human developer |

## Tool Access

| Access | Description |
|--------|-------------|
| Full | All tools available |
| **PROHIBITED** | `git add`, `git commit`, `git push` - AI cannot run these |
| Allowed | `git status`, `git diff`, `git log`, `git branch` (read-only) |
| **Required** | Write `.git/COMMIT_MESS` file with commit message instead |

**Since AI cannot commit, it MUST write the commit message to `.git/COMMIT_MESS` so the user can commit with:** `git commit -F .git/COMMIT_MESS`

## Prohibited Actions

| Action | Reason |
|--------|--------|
| **Modifying AI.md** | **Read-only master template - NEVER modify** |
| `git add` | AI cannot stage files - write COMMIT_MESS instead |
| `git commit` | AI cannot commit - write COMMIT_MESS instead |
| `git push` | AI cannot push - user must do this |
| Deleting files without confirmation | Destructive action |
| Changing NON-NEGOTIABLE sections | Specification violation |
| Skipping validation | Security requirement |
| Hardcoding secrets | Security vulnerability |
| Using deprecated APIs | Maintainability issue |

## Code Style Rules (NON-NEGOTIABLE)

### Comment Placement

**Comments MUST always be placed ABOVE the code they describe. NEVER inline or below.**

| Placement | Allowed |
|-----------|---------|
| Above code | YES |
| Inline (same line) | NO |
| Below code | NO |

**Correct:**
```go
// Calculate the total price including tax
total := price * (1 + taxRate)

// User configuration options
type Config struct {
    // Server port number
    Port int
    // Enable debug mode
    Debug bool
}
```

**Incorrect:**
```go
total := price * (1 + taxRate) // Calculate total price - WRONG

total := price * (1 + taxRate)
// Calculate total price - WRONG (below)

type Config struct {
    Port int  // Server port - WRONG (inline)
    Debug bool // Debug mode - WRONG (inline)
}
```

**YAML comments - same rule:**
```yaml
# Enable multi-user mode
enabled: false

# User registration mode
# Options: disabled, public, private, approval
registration:
  mode: disabled
```

### Code Quality Rules

| Rule | Description |
|------|-------------|
| **No inline comments** | Comments ALWAYS go above code, NEVER on same line |
| **No magic numbers** | Use named constants |
| **No hardcoded strings** | Use constants or config |
| **Error handling** | Always handle errors, never ignore |
| **Input validation** | Validate ALL user input |
| **SQL injection** | Use parameterized queries only |
| **XSS prevention** | Escape all output in templates |
| **CSRF protection** | All forms must have CSRF tokens |

**Comment Style (NON-NEGOTIABLE):**

```yaml
# WRONG: Inline comments
enabled: true  # Enable feature
port: 8080     # Server port

# CORRECT: Comments above
# Enable feature
enabled: true

# Server port
port: 8080
```

```go
// WRONG: Inline comments
var port = 8080  // Server port
db.Exec(query, id)  // Delete user

// CORRECT: Comments above
// Server port
var port = 8080

// Delete user
db.Exec(query, id)
```

**Rule: ALL comments go on lines ABOVE the code, NEVER inline. This prevents confusion and improves readability.**

### Formatting and Indentation (NON-NEGOTIABLE)

**ALL code, responses, and files MUST be properly formatted.**

| File Type | Indentation | Trailing Newline | Format Tool |
|-----------|-------------|------------------|-------------|
| **Go** | Tabs | Single `\n` | `gofmt`, `go fmt` |
| **HTML** | 2 spaces | Single `\n` | Manual or prettier |
| **JSON** | 2 spaces | Single `\n` | `json.MarshalIndent(data, "", "  ")` |
| **YAML** | 2 spaces | Single `\n` | Manual |
| **CSS** | 2 spaces | Single `\n` | Manual or prettier |
| **JavaScript** | 2 spaces | Single `\n` | Manual or prettier |
| **Makefile** | Tabs (required) | Single `\n` | Manual |
| **Shell scripts** | 2 spaces | Single `\n` | shellcheck/shfmt |
| **Text responses** | N/A | Single `\n` | `fmt.Fprintf(w, "%s\n", text)` |

**Universal Rules:**
- **Every file** ends with exactly ONE newline character
- **Every response** (JSON, TXT, HTML, XML) ends with exactly ONE newline
- **No trailing whitespace** on any line
- **Consistent indentation** throughout each file
- **2 spaces** is default (except Go and Makefiles which use tabs)

**Examples:**

HTML (2 spaces):
```html
<html>
  <head>
    <title>Title</title>
  </head>
</html>
⏎
```

JSON (2 spaces):
```json
{
  "name": "value"
}
⏎
```

YAML (2 spaces):
```yaml
server:
  port: 80
⏎
```

**See PART 20 (API Structure) for detailed response formatting rules.**

### File Organization

| Rule | Description |
|------|-------------|
| **One package per directory** | Standard Go convention |
| **Meaningful names** | `user.go` not `u.go` |
| **Group related code** | Keep related functions together |
| **Separate concerns** | Don't mix handlers with business logic |

## Handling Ambiguity

When the specification is unclear:

1. **Check if clarified elsewhere** - search the full spec
2. **Look for similar patterns** - how are similar features handled?
3. **Ask the user** - don't guess
4. **Document the decision** - add to AI.md for future reference

## Common Mistakes to Avoid

| Mistake | Correct Approach |
|---------|------------------|
| Implementing without reading spec | Read relevant PART first |
| Assuming default values | Check spec for defined defaults |
| Using .yaml instead of .yml | Always use `server.yml` |
| Inline comments | Comments above code only |
| Skipping admin panel | ALL settings need admin UI |
| Forgetting mobile-first | Start with mobile, expand to desktop |
| Using JavaScript alerts | Use proper notification system |
| Inline CSS | Use CSS files/classes only |

---

# MIGRATING EXISTING PROJECTS

## Migration Principles (NON-NEGOTIABLE)

**The template is the source of truth. Projects conform to the template, not the other way around.**

### What Migration Does

| Action | Description |
|--------|-------------|
| **Standardizes structure** | Reorganizes files to match template directory layout |
| **Standardizes CLI** | Updates flags, commands, help output to match spec |
| **Standardizes build** | Updates Makefile, Dockerfile, CI/CD to match spec |
| **Standardizes config** | Updates config format, paths, defaults to match spec |
| **Preserves functionality** | App's core purpose and features remain intact |

### What Projects CANNOT Change

**These are defined by the template and MUST NOT be modified by projects:**

| Element | Reason |
|---------|--------|
| **CLI flags** | `--help`, `--version`, `--config`, etc. - standardized across all apps |
| **CLI commands** | `serve`, `migrate`, `--maintenance` - same interface everywhere |
| **Flag formats** | Short/long flag patterns, output formats |
| **Makefile structure** | Targets, variables, Docker commands |
| **Makefile targets** | `build`, `release`, `docker`, `test`, `dev`, `clean` |
| **CI/CD workflows** | GitHub/Gitea/Jenkins pipeline structure |
| **Directory layout** | `src/`, `docker/`, `binaries/`, etc. |
| **Config file format** | YAML structure, standard keys |
| **Health endpoints** | `/healthz`, `/api/v1/healthz` format |
| **API response format** | JSON structure, error format, pagination |

### What Projects CAN Customize

| Element | Allowed Changes | Example |
|---------|-----------------|---------|
| **Dockerfile packages** | Add packages app needs | `RUN apk add --no-cache ffmpeg` |
| **Base image** | Change if app requires | `debian:bookworm-slim` instead of `alpine` |
| **Config values** | App-specific settings | `search.engines`, `jokes.categories` |
| **Routes** | App-specific endpoints | `/api/v1/search`, `/api/v1/jokes` |
| **Database schema** | App-specific tables | `searches`, `jokes`, `engines` |
| **Business logic** | App's core functionality | Search algorithms, joke selection |
| **UI/branding** | App-specific styling | Colors, logos, page content |

### What Migration Preserves

**The template standardizes HOW the app works, not WHAT it does:**

| App Type | Template Adds | Template Preserves |
|----------|---------------|-------------------|
| **Search engine** | Standard CLI, config, build | Search functionality, engines, algorithms |
| **Jokes API** | Standard CLI, config, build | Joke database, categories, formats |
| **Meta search** | Standard CLI, config, build | All search engines, aggregation logic |
| **Monitoring** | Standard CLI, config, build | Monitored nodes, alert rules, dashboards |

**Example - Jokes API Migration:**
```
BEFORE (non-standard)              AFTER (template-compliant)
─────────────────────              ────────────────────────────
jokes                              src/main.go
config.json                        src/config/config.go
main.go                            src/server/server.go
handlers.go                        src/server/routes.go
                                   src/service/jokes.go
run.sh                             Makefile
Dockerfile                         docker/Dockerfile

--port 8080                        --address :8080 (standard flag)
--jokes-file                       server.data.jokes_file (config)

✓ All jokes preserved
✓ All categories preserved
✓ All API endpoints preserved (with standard format)
```

## Migration Process

### Step 1: Inventory Existing Project

| Check | Document |
|-------|----------|
| **Core functionality** | What does the app DO? (preserve this) |
| **Custom config** | App-specific settings (migrate to config.yml) |
| **Custom routes** | API endpoints (keep, standardize format) |
| **Dependencies** | Required packages (add to Dockerfile) |
| **Database schema** | Tables and relationships (preserve) |

### Step 2: Create Template Structure

```bash
# Create standard directories
mkdir -p src/{config,mode,paths,scheduler,server,service,ssl}
mkdir -p docker .github/workflows binaries

# Create required files
touch AI.md README.md LICENSE.md Makefile go.mod
touch docker/Dockerfile docker-compose.yml
```

### Step 3: Migrate Code

| From | To | Action |
|------|-----|--------|
| Custom entry point | `src/main.go` | Rewrite with standard CLI |
| Config handling | `src/config/config.go` | Migrate to standard format |
| HTTP server | `src/server/server.go` | Use standard server setup |
| Routes | `src/server/routes.go` | Keep endpoints, standard handlers |
| Business logic | `src/service/*.go` | Minimal changes, organize by domain |

### Step 4: Migrate Configuration

**Old format (example):**
```json
{
  "port": 8080,
  "jokeFile": "/data/jokes.json",
  "enableLogging": true
}
```

**New format (template-compliant):**
```yaml
server:
  address: ":8080"
  mode: production

# App-specific section (preserved functionality)
jokes:
  data_file: "/var/lib/jokes/jokes.json"
  categories:
    - programming
    - dad
    - puns

logging:
  level: info
  format: json
```

### Step 5: Validate Migration

| Check | Validation |
|-------|------------|
| **CLI flags** | `--help` output matches template spec |
| **Config loading** | YAML config loads correctly |
| **Health checks** | `/healthz` returns correct format |
| **API format** | JSON responses match spec |
| **Build** | `make build` succeeds |
| **Docker** | `make docker` succeeds |
| **Functionality** | App still does what it's supposed to do |

## Migration Conflicts

### When Project Conflicts with Template

| Conflict | Resolution |
|----------|------------|
| **Project uses different flag** | Change to template flag, update docs |
| **Project uses different config format** | Migrate to YAML, template structure |
| **Project uses different directory layout** | Reorganize to template structure |
| **Project needs different base image** | Allowed - document reason in AI.md |
| **Project needs additional packages** | Allowed - add to Dockerfile |

### When Template Would Break Functionality

| Scenario | Solution |
|----------|----------|
| **App needs debian packages** | Use `debian:bookworm-slim` base image |
| **App needs specific runtime** | Add to Dockerfile, document in AI.md |
| **App has unique requirements** | Document in AI.md, request template update if common |

**Rule:** If template requirement would genuinely break the app's core functionality, document the exception in AI.md and discuss with template maintainer.

## Post-Migration Checklist

- [ ] All source code in `src/` directory
- [ ] Standard CLI flags working (`--help`, `--version`, `--config`, `--data`, `--log`, `--pid`)
- [ ] Configuration in YAML format
- [ ] Makefile with all standard targets
- [ ] Dockerfile in `docker/` directory
- [ ] CI/CD workflows in place
- [ ] Health endpoints returning correct format
- [ ] API responses in standard format
- [ ] AI.md created with project specifics
- [ ] README.md updated
- [ ] **Core functionality verified working**

---

# AI MIGRATION BEHAVIOR RULES (NON-NEGOTIABLE)

**These rules govern AI behavior during migration. Violation of these rules is unacceptable.**

## The Three Laws of Migration

1. **SPEC IS LAW** - The SPEC (AI.md) is the single source of truth. No exceptions.
2. **NO INVENTION** - Never invent, assume, or hallucinate. If not in SPEC, don't add it.
3. **VERIFY EVERYTHING** - Before every change, verify it matches SPEC exactly.

## AI MUST Follow This Process

```
┌─────────────────────────────────────────────────────────────────┐
│                    MIGRATION DECISION FLOW                       │
├─────────────────────────────────────────────────────────────────┤
│                                                                  │
│   ┌──────────────┐                                              │
│   │ Read SPEC    │ ◄─── ALWAYS start here                       │
│   └──────┬───────┘                                              │
│          │                                                       │
│          ▼                                                       │
│   ┌──────────────┐     YES    ┌──────────────┐                  │
│   │ Is it in     │ ─────────► │ Implement    │                  │
│   │ the SPEC?    │            │ EXACTLY as   │                  │
│   └──────┬───────┘            │ specified    │                  │
│          │ NO                 └──────────────┘                  │
│          ▼                                                       │
│   ┌──────────────┐     YES    ┌──────────────┐                  │
│   │ Is it        │ ─────────► │ Ask user     │                  │
│   │ required?    │            │ for guidance │                  │
│   └──────┬───────┘            └──────────────┘                  │
│          │ NO                                                    │
│          ▼                                                       │
│   ┌──────────────┐                                              │
│   │ DO NOT ADD   │ ◄─── If not in SPEC, don't add it            │
│   └──────────────┘                                              │
│                                                                  │
└─────────────────────────────────────────────────────────────────┘
```

## Common AI Deviation Patterns (NEVER DO THESE)

| Deviation | What AI Does Wrong | Correct Behavior |
|-----------|-------------------|------------------|
| **Inventing flags** | Adds `--verbose`, `--quiet` not in SPEC | Only use flags defined in SPEC |
| **Renaming things** | Changes `--config` to `--cfg` "for brevity" | Use EXACT names from SPEC |
| **Adding features** | Adds "helpful" features not requested | Only implement what SPEC defines |
| **Changing structure** | Puts files in "better" locations | Use EXACT paths from SPEC |
| **Improving code** | "Refactors" working code to be "cleaner" | Keep working code, only change what SPEC requires |
| **Different patterns** | Uses different design patterns | Use patterns shown in SPEC |
| **Assuming defaults** | Invents default values not in SPEC | Use EXACT defaults from SPEC |
| **Adding comments** | Adds "helpful" documentation not in SPEC | Only add comments shown in SPEC |
| **Changing formats** | "Improves" JSON/YAML structure | Use EXACT format from SPEC |
| **Extra validation** | Adds "safety" checks not in SPEC | Only add validation defined in SPEC |

## AI Migration Verification Protocol

**Before EVERY file change, AI MUST verify:**

```
□ Does this change match the SPEC exactly?
□ Am I using the EXACT names/paths from SPEC?
□ Am I using the EXACT code patterns from SPEC?
□ Am I adding ONLY what the SPEC defines?
□ Have I re-read the relevant SPEC section?
```

**After EVERY file change, AI MUST verify:**

```
□ Does the result match SPEC examples exactly?
□ Did I accidentally add anything not in SPEC?
□ Did I accidentally change anything the SPEC doesn't require?
□ Would this diff surprise someone who only read the SPEC?
```

## When AI Is Unsure

| Situation | Action |
|-----------|--------|
| SPEC doesn't cover this case | **ASK USER** - never assume |
| Multiple interpretations possible | **ASK USER** - never guess |
| Seems like SPEC has an error | **ASK USER** - never "fix" it |
| Better way exists | **FOLLOW SPEC** - don't improve |
| SPEC seems outdated | **FOLLOW SPEC** - ask user if concerned |
| Project has existing pattern | **FOLLOW SPEC** - migrate to SPEC pattern |

## Migration Audit Checklist

**AI must verify each item matches SPEC EXACTLY:**

### CLI Flags
```
□ --help output matches SPEC format exactly
□ --version output matches SPEC format exactly
□ All flags use SPEC names (no renames)
□ All flags have SPEC defaults (no invented defaults)
□ Only -h and -v have short forms
□ --debug flag exists and works per SPEC
```

### Directory Structure
```
□ src/ contains all Go source
□ src/config/config.go exists with SPEC format
□ src/config/bool.go exists with ParseBool
□ src/mode/mode.go exists with SPEC functions
□ src/server/ follows SPEC structure
□ docker/ contains all Docker files
□ docker/docker-compose.yml matches SPEC
□ docker/docker-compose.dev.yml matches SPEC
□ docker/docker-compose.test.yml matches SPEC
□ No extra directories not in SPEC
```

### Configuration
```
□ server.yml format matches SPEC exactly
□ All standard keys present
□ Boolean values use ParseBool
□ Paths use SPEC defaults
□ No invented configuration keys
```

### Code Patterns
```
□ Error handling matches SPEC examples
□ Logging matches SPEC format
□ HTTP handlers match SPEC structure
□ Middleware matches SPEC examples
□ No "improved" patterns
```

### Docker
```
□ Dockerfile matches SPEC multi-stage pattern
□ entrypoint.sh matches SPEC exactly
□ Environment variables match SPEC
□ Volume paths match SPEC
□ Temp directory workflow used
```

## Red Flags (AI Must Stop and Ask)

**If AI notices any of these, STOP and ask user:**

- "I think we should..." → STOP - follow SPEC instead
- "It would be better to..." → STOP - follow SPEC instead
- "Let me improve..." → STOP - follow SPEC instead
- "I'll add a helper for..." → STOP - is it in SPEC?
- "This could be cleaner if..." → STOP - follow SPEC instead
- "Let me refactor..." → STOP - only if SPEC requires it
- "I noticed the SPEC doesn't have..." → STOP - ask user
- "The existing code does X but SPEC says Y..." → Follow SPEC, ask if unsure

## Migration Success Criteria

**Migration is ONLY complete when:**

1. `grep -r "TODO\|FIXME\|XXX" src/` returns nothing migration-related
2. Every file matches a SPEC example or template
3. `--help` output is character-for-character correct
4. All tests pass
5. Build succeeds with no warnings
6. Docker build succeeds
7. User has verified core functionality works
8. No code exists that isn't defined or implied by SPEC

## Final Migration Verification

```bash
# AI should run these checks and report results:

# 1. Verify CLI
./binaries/casspeed --help
./binaries/casspeed --version

# 2. Verify build
make clean && make build

# 3. Verify Docker
make docker

# 4. Verify structure
find src -name "*.go" | head -20
ls -la docker/

# 5. Verify no deviations
# Compare key files against SPEC examples
```

**Remember: The SPEC is not a suggestion. It is the law. Follow it exactly.**

---

# AI NEW PROJECT IMPLEMENTATION RULES (NON-NEGOTIABLE)

**These rules govern AI behavior when creating new projects/apps. Same strictness as migration.**

## Terminology

**"Project" and "App" are used interchangeably throughout this document.**

| Term | Meaning |
|------|---------|
| Project | The complete codebase, including all files and configuration |
| App | Same as project - the application being built |
| Application | Same as project/app |

## The Three Laws of Implementation

1. **SPEC IS LAW** - Every section of this SPEC must be implemented. No exceptions.
2. **NO INVENTION** - Never invent, assume, or hallucinate. If not in SPEC, don't add it.
3. **COMPLETE COVERAGE** - All non-optional sections MUST be implemented fully.

## Section Implementation Requirements

### MANDATORY Sections (Must Implement ALL)

| PART | Section | Required |
|------|---------|----------|
| 0 | AI Assistant Rules | ✅ Follow always |
| 1 | Critical Rules | ✅ Follow always |
| 2 | Project Structure | ✅ Implement fully |
| 3 | OS-Specific Paths | ✅ Implement fully |
| 4 | Configuration | ✅ Implement fully |
| 5 | Application Modes & Debug | ✅ Implement fully |
| 6 | Server Binary CLI | ✅ Implement fully |
| 7 | Update Command | ✅ Implement fully |
| 8 | Privilege Escalation | ✅ Implement fully |
| 9 | Service Support | ✅ Implement fully |
| 10 | Binary Requirements | ✅ Implement fully |
| 11 | Makefile | ✅ Implement fully |
| 12 | Testing & Development | ✅ Implement fully |
| 13 | Docker | ✅ Implement fully |
| 14 | CI/CD Workflows | ✅ Implement fully |
| 15 | Health & Versioning | ✅ Implement fully |
| 16 | Web Frontend | ✅ Implement fully |
| 17 | Server Configuration | ✅ Implement fully |
| 18 | Admin Panel | ✅ Implement fully |
| 19 | API Structure | ✅ Implement fully |
| 20 | SSL/TLS & Let's Encrypt | ✅ Implement fully |
| 21 | Security & Logging | ✅ Implement fully |
| 22 | User Management | ✅ Implement fully |
| 23 | Database & Cluster | ✅ Implement fully |
| 24 | Backup & Restore | ✅ Implement fully |
| 25 | Email & Notifications | ✅ Implement fully |
| 26 | Scheduler | ✅ Implement fully |
| 27 | GeoIP | ✅ Implement fully |
| 28 | Metrics | ✅ Implement fully |
| 29 | Tor Hidden Service | ✅ Implement fully |
| 30 | Error Handling & Caching | ✅ Implement fully |
| 31 | I18N & A11Y | ✅ Implement fully |
| 32 | Project-Specific Sections | ✅ Customize for project |
| 35 | ReadTheDocs Documentation | ✅ Implement fully |
| FINAL | Compliance Checklist | ✅ Verify all items |

### OPTIONAL Sections (AI Must Decide)

| PART | Section | When to Include |
|------|---------|-----------------|
| 33 | CLI Client | If project needs command-line client tool |
| 34 | Custom Domains | If users/orgs need branded domains (see decision table below) |

### Optional Section Decision Guide

**PART 34: CLI Client**

| Include | Skip | Reason |
|---------|------|--------|
| API with complex queries | Simple web-only app | Power users need CLI access |
| DevOps/admin tools | Consumer mobile app | Automation requires CLI |
| Database management | Static content site | Bulk operations via CLI |

**PART 35: Custom Domains** (see PART 35 for full decision table)

| Include | Skip | Reason |
|---------|------|--------|
| Linktree clone | Weather API | Users want branded URLs |
| Blog platform | Jokes API | Content published under user's domain |
| SaaS application | Utility APIs | Customers need branded instances |

## AI Implementation Process

```
┌─────────────────────────────────────────────────────────────────┐
│                 NEW PROJECT IMPLEMENTATION FLOW                  │
├─────────────────────────────────────────────────────────────────┤
│                                                                  │
│   ┌──────────────────┐                                          │
│   │ 1. Read SPEC     │ ◄─── Read ALL mandatory sections         │
│   └────────┬─────────┘                                          │
│            │                                                     │
│            ▼                                                     │
│   ┌──────────────────┐                                          │
│   │ 2. Determine     │ ◄─── Decide CLI client, Custom domains   │
│   │    optional      │                                          │
│   └────────┬─────────┘                                          │
│            │                                                     │
│            ▼                                                     │
│   ┌──────────────────┐                                          │
│   │ 3. Implement     │ ◄─── Follow SPEC exactly for each PART   │
│   │    each PART     │                                          │
│   └────────┬─────────┘                                          │
│            │                                                     │
│            ▼                                                     │
│   ┌──────────────────┐                                          │
│   │ 4. Verify each   │ ◄─── Check against SPEC before next PART │
│   │    PART complete │                                          │
│   └────────┬─────────┘                                          │
│            │                                                     │
│            ▼                                                     │
│   ┌──────────────────┐                                          │
│   │ 5. Final check   │ ◄─── Run FINAL compliance checklist      │
│   └──────────────────┘                                          │
│                                                                  │
└─────────────────────────────────────────────────────────────────┘
```

## Common AI Implementation Mistakes (NEVER DO THESE)

| Mistake | What AI Does Wrong | Correct Behavior |
|---------|-------------------|------------------|
| **Skipping sections** | "This project doesn't need X" | Implement ALL mandatory sections |
| **Partial implementation** | Implements only "important" parts | Implement EVERY detail in SPEC |
| **Inventing structure** | Creates own directory layout | Use EXACT structure from SPEC |
| **Custom CLI flags** | Adds project-specific flags | Only use flags defined in SPEC |
| **Different config format** | Uses JSON instead of YAML | Use EXACT format from SPEC |
| **Skipping Docker files** | "We'll add Docker later" | Docker is mandatory, implement now |
| **Missing CI/CD** | "Not needed for MVP" | CI/CD is mandatory, implement now |
| **Custom error format** | Invents error response structure | Use EXACT format from SPEC |
| **Simplified health** | Returns just `{"status":"ok"}` | Implement FULL health response |
| **Skipping admin panel** | "Users don't need admin" | Admin panel is mandatory |

## Implementation Verification Protocol

**After implementing EACH section, verify:**

```
□ Did I implement EVERY item in this section?
□ Does my implementation match SPEC examples exactly?
□ Did I use the EXACT file names and paths?
□ Did I use the EXACT code patterns shown?
□ Did I copy configuration formats exactly?
□ Are there any TODO/FIXME comments left?
```

## New Project Completion Checklist

**Project is ONLY complete when ALL are true:**

### Structure
```
□ src/ directory with all required packages
□ docker/ directory with all required files
□ All root files present (AI.md, README.md, LICENSE.md, Makefile, go.mod)
□ No extra files/directories not in SPEC
```

### Core Features
```
□ CLI flags match SPEC exactly (--help, --version, --config, etc.)
□ Configuration in server.yml format
□ Health endpoints return SPEC format
□ API responses match SPEC format
□ Error responses match SPEC format
```

### Infrastructure
```
□ Dockerfile matches SPEC multi-stage pattern
□ docker-compose.yml, docker-compose.dev.yml, docker-compose.test.yml present
□ entrypoint.sh matches SPEC exactly
□ Makefile has all required targets
□ CI/CD workflows in place
```

### Security & Operations
```
□ Mode detection (production/development) working
□ Debug flag (--debug/DEBUG) working
□ SSL/TLS support implemented
□ User authentication implemented
□ Admin panel implemented
□ Logging in SPEC format
```

### Optional (if included)
```
□ CLI client follows SPEC (if PART 34 included)
□ Custom domains follows SPEC (if PART 35 included)
```

## What To Do When Stuck

| Situation | Action |
|-----------|--------|
| SPEC section unclear | **ASK USER** - never interpret |
| Don't know if optional applies | **ASK USER** with reasoning |
| Seems like a lot of work | **IMPLEMENT ANYWAY** - SPEC is complete |
| Project seems simple | **IMPLEMENT FULLY** - all projects need all sections |
| User says "just basic version" | **CLARIFY** - SPEC defines what basic means |

**Remember: Every project, no matter how "simple", implements the full SPEC. There is no "lite" version.**

---


# PART 1: CRITICAL RULES (NON-NEGOTIABLE)

## Working Roles

When working on this project, the following roles are assumed based on the task:

- **Senior Go Developer** - Writing production-quality Go code, making architectural decisions, following best practices, optimizing performance
- **UI/UX Designer** - Creating professional, functional, visually appealing interfaces with excellent user experience
- **Beta Tester** - Testing applications, finding bugs, edge cases, and issues before they reach users
- **User** - Thinking from the end-user perspective, ensuring things are intuitive and work as expected

These are not roleplay - they ARE these roles when the work requires it. Each project gets the full expertise of all four perspectives.

---

## CRITICAL: Specification Compliance

**STOP AND READ THIS SECTION COMPLETELY BEFORE PROCEEDING.**

### The Golden Rules

1. **Re-read this spec periodically** during work to ensure accuracy and no deviation
2. **When in doubt, check the spec** - the spec is the source of truth
3. **Never assume or guess** - ask questions if unclear
4. **Every NON-NEGOTIABLE section MUST be implemented exactly as specified**
5. **Keep AI.md in sync with the project** - always update after changes
6. **NEVER install Go on host** - ALL builds/tests/debugging use Docker containers

### Docker-Only Development (NON-NEGOTIABLE)

**The host system does NOT have Go installed. NEVER attempt to run `go` commands directly.**

| Rule | Description |
|------|-------------|
| **Host has NO Go** | Assume Go is not installed on the host system |
| **ALL builds use Docker** | `docker run ... golang:alpine go build ...` |
| **ALL tests use Docker** | `docker run ... golang:alpine go test ...` |
| **ALL debugging uses Docker** | Run binaries in containers or from /tmp |
| **NEVER run `go` directly** | Always prefix with `docker run ... golang:alpine` |

```bash
# CORRECT - Use Makefile (wraps Docker)
make dev                    # Quick build to {tempdir}/casapps.XXXXXX/casspeed
make build                  # Full build to binaries/

# ALSO CORRECT - Direct Docker (for one-offs, use random temp dir)
PROJECTORG=$(basename "$(dirname "$(pwd)")") && BUILD_DIR=$(mktemp -d "${TMPDIR:-/tmp}/${PROJECTORG}.XXXXXX") && docker run --rm -v $(pwd):/build -w /build -e CGO_ENABLED=0 golang:alpine go build -o /build/binaries/casspeed src

# WRONG - Never run go directly on host
go build -o binary/casspeed src

# WRONG - Never use predictable /tmp paths
docker run ... go build -o /tmp/casspeed src
```

**See PART 12: TESTING & DEVELOPMENT for full containerized build/test procedures.**

---

## Security-First Design (NON-NEGOTIABLE)

**Every project follows security-first design. Security MUST NOT compromise usability.**

### Core Security Principles

| Principle | Description |
|-----------|-------------|
| **Never Trust Input** | All input is validated before use - never executed directly |
| **Defense in Depth** | Multiple layers of security, not single points of failure |
| **Least Privilege** | Minimal permissions required for each operation |
| **Fail Secure** | On error, deny access rather than grant it |
| **Secure by Default** | Safe defaults, user opts-in to less secure options |
| **Suggest, Don't Block** | Recommend security features (MFA), never force them |
| **Friction-Free Security** | Security should enhance, not impede, the user experience |

**Security suggestions (not requirements):**

*For Server Admins (all projects):*
- First admin login: prompt to enable TOTP/Passkey (can skip)
- Admin panel: show security score/recommendations widget
- Periodic reminders for admins without MFA (dismissable)
- Clear benefits explained: "Protect your admin account with 2FA"

*For Users (projects with user registration):*
- Post-registration: prompt to enable TOTP/Passkey (can skip)
- First login after registration: gentle MFA setup reminder
- User settings: security section with MFA setup and recommendations
- Clear benefits: "Secure your account with two-factor authentication"
- Never block access or features for users without MFA

### Input Validation (NON-NEGOTIABLE)

**All input is SEARCHED, never EXECUTED.**

| Rule | Implementation |
|------|----------------|
| **Validate everything** | Type, length, format, range - before processing |
| **Sanitize for context** | HTML-encode for HTML, SQL-parameterize for SQL |
| **Reject unknown** | Whitelist allowed values, reject everything else |
| **No direct execution** | Never pass user input directly to shell, SQL, eval |

```go
// CORRECT - Parameterized query
db.Query("SELECT * FROM users WHERE email = ?", email)

// WRONG - SQL injection vulnerable
db.Query("SELECT * FROM users WHERE email = '" + email + "'")
```

### Attack Prevention

| Attack Type | Prevention |
|-------------|------------|
| **SQL Injection** | Parameterized queries ONLY - never string concatenation |
| **XSS** | HTML-escape all user content, CSP headers |
| **CSRF** | CSRF tokens for all state-changing forms |
| **Command Injection** | Never shell out with user input, use libraries |
| **Path Traversal** | Validate paths, use `filepath.Clean()`, reject `..` |
| **Enumeration** | Consistent timing, vague auth errors, rate limiting |
| **DDoS** | Rate limiting, request size limits, timeouts |

### Rate Limiting Defaults

| Endpoint Type | Limit | Window | Response |
|---------------|-------|--------|----------|
| **Login attempts** | 5 | 15 minutes | 429 + lockout |
| **Password reset** | 3 | 1 hour | 429 + silent (no email hint) |
| **API (authenticated)** | 100 | 1 minute | 429 + Retry-After header |
| **API (unauthenticated)** | 20 | 1 minute | 429 + Retry-After header |
| **Registration** | 5 | 1 hour | 429 |
| **File upload** | 10 | 1 hour | 429 |

### Error Message Rules

**Different audiences need different levels of detail:**

| Destination | Detail Level | Purpose |
|-------------|--------------|---------|
| **User (WebUI/API)** | Minimal, helpful | Guide user to fix issue, no internals |
| **Admin (Panel)** | Actionable | Enough to diagnose, no stack traces |
| **Console (stdout)** | Full | Debugging during development |
| **Log file** | Full + context | Structured, timestamps, request IDs |
| **Audit log** | Who/what/when | Security events, compliance |

**Error Messages by Context:**

| Error Type | User Sees | Admin Sees | Log Contains |
|------------|-----------|------------|--------------|
| **Invalid email format** | "Please enter a valid email address" | Same | `validation_error: email format invalid, input=[redacted]` |
| **Login failed (wrong password)** | "Invalid credentials" | "Login failed for user@example.com" | `auth_failure: user_id=123, ip=1.2.3.4, reason=invalid_password` |
| **Login failed (no such user)** | "Invalid credentials" | "Login attempt for unknown user" | `auth_failure: email=[redacted], ip=1.2.3.4, reason=user_not_found` |
| **Rate limited** | "Too many attempts. Try again in 5 minutes" | "Rate limit hit: login, IP 1.2.3.4" | `rate_limit: endpoint=/auth/login, ip=1.2.3.4, limit=5/15m` |
| **Database error** | "An error occurred. Please try again" | "Database connection failed" | `db_error: connection refused, host=db.local:5432, err=[full error]` |
| **Permission denied** | "Access denied" | "User lacks permission: admin.settings" | `authz_failure: user_id=123, resource=admin.settings, action=write` |
| **Internal panic** | "An unexpected error occurred" | "Internal error - check logs" | `panic: [full stack trace], request_id=abc123` |

**Console Output (Development):**
```
[ERROR] 2025-01-15 10:30:45 database connection failed
        host: localhost:5432
        error: connection refused
        stack: main.go:123 → db.go:45 → connect.go:12
```

**Log File (Production):**
```json
{
  "level": "error",
  "time": "2025-01-15T10:30:45Z",
  "request_id": "abc123",
  "component": "database",
  "message": "connection failed",
  "host": "db.local:5432",
  "error": "connection refused",
  "stack": "..."
}
```

**User Response (API):**
```json
{
  "error": "Service temporarily unavailable",
  "code": "SERVICE_ERROR",
  "retry_after": 30
}
```

**Never reveal to users:**
- Whether a username/email exists (use "If account exists, email sent")
- Database structure, table names, or query details
- Internal IP addresses, hostnames, or ports
- Stack traces or file paths
- Dependency versions or internal service names
- Specific reason for auth failures (user not found vs wrong password)

### Security vs Usability Balance

| Scenario | Security Need | Usability Solution |
|----------|---------------|-------------------|
| Strong passwords | Prevent weak passwords | Show strength meter, suggest improvements |
| Session timeout | Limit exposure | Warn before timeout, extend on activity |
| Rate limiting | Prevent abuse | Clear error message with retry time |
| CAPTCHA | Prevent bots | Only after failed attempts, not first try |
| 2FA | Account security | Remember device option (30 days) |

---

## Code Style & Naming (NON-NEGOTIABLE)

**All code must be written as if by a human - clear, readable, and maintainable.**

### Naming Conventions

| Element | Convention | Example |
|---------|------------|---------|
| **Files** | `lowercase_snake.go` | `user_handler.go`, `email_service.go` |
| **Packages** | `lowercase` (single word preferred) | `server`, `config`, `auth` |
| **Public functions/types** | `PascalCase` | `GetUserByEmail()`, `UserService` |
| **Private functions/types** | `camelCase` | `validateInput()`, `dbConnection` |
| **Constants** | `PascalCase` or `SCREAMING_SNAKE` | `MaxRetries`, `DEFAULT_TIMEOUT` |
| **Variables** | `camelCase` | `userEmail`, `isValid`, `retryCount` |
| **Interfaces** | `PascalCase` + `-er` suffix | `Reader`, `UserStore`, `Authenticator` |

### Naming Rules

| Rule | Good | Bad |
|------|------|-----|
| **Descriptive** | `getUserByEmail()` | `getUBE()`, `fetch()` |
| **No abbreviations** | `configuration` | `cfg`, `conf` |
| **Exceptions allowed** | `ID`, `URL`, `API`, `HTTP`, `HTML`, `JSON`, `SQL`, `CSS`, `JS` | |
| **Verb for functions** | `CreateUser()`, `ValidateEmail()` | `User()`, `Email()` |
| **Noun for types** | `UserService`, `EmailValidator` | `DoUser`, `Validating` |
| **Boolean prefix** | `isValid`, `hasAccess`, `canDelete` | `valid`, `access`, `delete` |

### Code Readability

| Rule | Description |
|------|-------------|
| **Self-documenting** | Code should explain itself through clear naming |
| **Comments for why** | Comment WHY, not WHAT (code shows what) |
| **Single responsibility** | Each function does one thing well |
| **Short functions** | Max ~50 lines, extract if longer |
| **Early returns** | Return early for errors, avoid deep nesting |
| **Consistent formatting** | Use `go fmt`, never manual formatting |

```go
// GOOD - Clear, self-documenting
func GetUserByEmail(email string) (*User, error) {
    if !isValidEmail(email) {
        return nil, ErrInvalidEmail
    }

    user, err := db.FindUserByEmail(email)
    if err != nil {
        return nil, fmt.Errorf("finding user: %w", err)
    }

    return user, nil
}

// BAD - Cryptic, unclear
func gUBE(e string) (*U, error) {
    if !chk(e) {
        return nil, err1
    }
    u, err := d.f(e)
    if err != nil {
        return nil, err
    }
    return u, nil
}
```

### Project Structure Naming

| Directory | Purpose | Naming |
|-----------|---------|--------|
| `src/server/` | HTTP server | `server.go`, `routes.go`, `middleware.go` |
| `src/config/` | Configuration | `config.go`, `defaults.go`, `validate.go`, `bool.go` |
| `src/service/` | Business logic | `user_service.go`, `auth_service.go` |
| `src/mode/` | Run modes | `mode.go`, `production.go`, `development.go` |
| `src/signal/` | Signal handling | `signal.go`, `signal_unix.go`, `signal_windows.go` |

---

### Required Documentation Files

| File | Location | Purpose | Modify? |
|------|----------|---------|---------|
| **Template file** | Varies (anywhere) | Master specification | **NEVER** |
| **AI.md** | Project repository | Project-specific specification | **YES** |
| **TODO.AI.md** | Project repository | Task tracking (>2 tasks) | **YES** |

**Note:** Template file may be named `AI.md`, `SPEC.md`, `CLAUDE.md`, or other. Location varies (project root, org root, ~/, etc.). Identify by content: unreplaced `{variables}`, "HOW TO USE" section, multiple PART X: sections.

### Documentation Rules (NON-NEGOTIABLE)

| Rule | Description |
|------|-------------|
| **Template is READ-ONLY** | Never modify - it is the master specification |
| **AI.md is the project spec** | Copy from template (ONE-TIME), customize for project |
| **AI.md is standalone** | Does NOT reference or sync with template after creation |
| **Keep AI.md current** | Update when project state changes (NOT template changes) |
| **Migrate old files** | Old spec files in project repo → merge into `AI.md`, DELETE |
| **TODO.AI.md for >2 tasks** | Required when doing more than 2 tasks |

**File Hierarchy:**
```
Template File (master, read-only, organization-level)
    └── AI.md (project-specific, each repository)
            └── TODO.AI.md (task tracking, each repository)
```

### README.md (NON-NEGOTIABLE)

**README.md MUST always be kept updated. Update after ANY feature change, bug fix, or configuration change.**

#### Section Order (MUST follow this order)

1. **Title & Badges** - Project name, build status, version badges
2. **About** - Brief description of what the project does
3. **Official Site** - Link to official site (if defined, e.g., `https://casspeed.casapps.us`)
4. **Features** - Key features list
5. **Production** - Production deployment instructions (Docker, binary, systemd)
6. **CLI Client** - Client CLI installation and usage (if applicable)
7. **Configuration** - Key configuration options
8. **API** - API endpoints summary (if applicable)
9. **Other** - Additional info (troubleshooting, FAQ, etc.)
10. **Development** - Development setup (ALWAYS LAST - for contributors only)
11. **License** - License info

#### README Template

```markdown
# casspeed

[![Build Status](https://jenkins.casjay.cc/buildStatus/icon?job=casapps/casspeed)](https://jenkins.casjay.cc/job/casapps/job/casspeed/)
[![GitHub release](https://img.shields.io/github/v/release/casapps/casspeed)](https://github.com/casapps/casspeed/releases)
[![License](https://img.shields.io/github/license/casapps/casspeed)](LICENSE.md)

## About

{Brief description of what the project does - 1-3 sentences}

## Official Site

https://casspeed.casapps.us

## Features

- Feature 1
- Feature 2
- Feature 3

## Production

### Docker (Recommended)

```bash
docker run -d \
  --name casspeed \
  -p 64580:80 \
  -v ./rootfs/config:/config:z \
  -v ./rootfs/data:/data:z \
  ghcr.io/casapps/casspeed:latest
```

### Docker Compose

```bash
curl -O https://raw.githubusercontent.com/casapps/casspeed/main/docker-compose.yml
docker compose up -d
```

### Binary

```bash
# Download latest release
curl -LO https://github.com/casapps/casspeed/releases/latest/download/casspeed-linux-amd64

# Make executable and run
chmod +x casspeed-linux-amd64
./casspeed-linux-amd64
```

## CLI Client

A companion CLI client is available for interacting with the server API.

### Install

```bash
# Download latest release
curl -LO https://github.com/casapps/casspeed/releases/latest/download/casspeed-cli-linux-amd64
chmod +x casspeed-cli-linux-amd64
sudo mv casspeed-cli-linux-amd64 /usr/local/bin/casspeed-cli
```

### Configure

```bash
# Connect to server (creates ~/.config/casapps/casspeed/cli.yml)
casspeed-cli --server https://api.example.com --token YOUR_API_TOKEN
```

### Usage

```bash
casspeed-cli --help
casspeed-cli [command] --help
```

## Configuration

Configuration is auto-generated on first run. Edit via admin panel at `http://{fqdn}:{port}/admin`.

Key settings:
- `server.port` - Listen port (default: random 64xxx)
- `server.mode` - production or development

## API

API documentation available at `/api/v1/` when running.

| Endpoint | Description |
|----------|-------------|
| `GET /healthz` | Health check |
| `GET /api/v1/...` | API endpoints |

## Other

### Troubleshooting

- Check logs: `docker logs casspeed`
- Health check: `curl http://{fqdn}:{port}/healthz`

## Development

**Development instructions are for contributors only.**

### Prerequisites

- Go (latest stable)
- Docker (for containerized builds)

### Build

```bash
# Clone
git clone https://github.com/casapps/casspeed
cd casspeed

# Quick dev build (outputs to OS temp dir)
make dev

# Full build (all platforms, outputs to binaries/)
make build

# Test
make test
```

### Project Structure

```
src/           # Source code
tests/         # Test files
binaries/      # Built binaries (gitignored)
```

## License

MIT - See [LICENSE.md](LICENSE.md)
```

#### README Update Rules

| When | Update README |
|------|---------------|
| New feature added | Yes - add to Features, update API if applicable |
| Bug fix | Only if it affects usage |
| Configuration change | Yes - update Configuration section |
| New CLI flag | Yes - document in appropriate section |
| Docker/deployment change | Yes - update Production section |
| Breaking change | Yes - add notice at top |

**NEVER let README become outdated. It is the first thing users see.**

---

## Development Principles (NON-NEGOTIABLE)

**EVERY principle below MUST be followed. No exceptions.**

| Principle | Description |
|-----------|-------------|
| **Validate Everything** | All input must be validated before processing |
| **Sanitize Appropriately** | Clean data where needed |
| **Save Only Valid Data** | Never persist invalid data |
| **Clear Only Invalid Data** | Don't destroy valid data |
| **Test Everything** | Comprehensive testing where applicable |
| **Show Tooltips/Docs** | Help users understand the interface |
| **Security First** | But security should never block usability |
| **Mobile First** | Responsive design for all screen sizes |
| **Sane Defaults** | Everything has sensible default values |
| **No AI/ML** | Smart logic only, no machine learning |
| **Concise Responses** | Short, descriptive, and helpful |
| **Everything Configurable** | ALL settings MUST be configurable via admin web UI |
| **Live Reload** | Configuration changes apply immediately without restart |

### Admin Web UI Configuration (NON-NEGOTIABLE)

**EVERY setting in the configuration file MUST be editable via the admin web UI.**

| Rule | Description |
|------|-------------|
| **No SSH/CLI required** | Users should NEVER need to edit config files manually |
| **Complete coverage** | 100% of `server.yml` settings available in admin panel |
| **Extend for project** | Projects MUST extend admin UI for project-specific settings |
| **Grouped logically** | Settings organized into intuitive sections |
| **Tooltips/help** | Every setting has a description explaining what it does |
| **Validation** | Real-time validation with clear error messages |
| **Defaults shown** | Show default values and current values clearly |

**Extending Admin Web UI (IF APPLICABLE):**

Not every project needs admin UI extensions - it depends on the project's nature:

| Project Type | Admin UI Extension | Example |
|--------------|-------------------|---------|
| Static data loader | Not needed | `jokes` - loads JSON, nothing to configure |
| Configurable service | Required | `weather` - API keys, update intervals, sources |
| Data with moderation | Required | User-generated content, approval workflows |
| External integrations | Required | Third-party APIs, credentials, sync settings |

**When extending, projects MUST:**
1. Add admin UI pages/sections for ALL project-specific configuration
2. Ensure project-specific settings are NOT hidden in config files only
3. Follow the same patterns as base admin UI (validation, tooltips, live reload)
4. Place project extensions in `src/server/admin/` alongside base handlers

**Rule:** If a setting exists in config, it MUST be editable in admin UI. If nothing to configure, no extension needed.

### Live Reload (NON-NEGOTIABLE)

**Configuration changes MUST apply immediately without server restart.**

| Rule | Description |
|------|-------------|
| **No restart required** | Changes take effect immediately after saving |
| **Hot reload** | Application watches for config changes and reloads |
| **Graceful** | In-flight requests complete before new config applies |
| **Feedback** | User sees confirmation that changes are active |
| **Exceptions** | Only port/address changes require restart (with clear warning) |

**What MUST live reload:**
- Branding (title, tagline, description)
- SEO settings
- Theme changes
- Email/notification settings
- Rate limiting rules
- robots.txt / security.txt
- Scheduler settings
- SSL settings (except port)
- All feature toggles

**What MAY require restart (with warning):**
- Listen address
- Port number
- Database driver change

### Sensitive Information Handling (NON-NEGOTIABLE)

**NEVER expose sensitive information unless absolutely necessary:**

- Tokens/passwords shown ONLY ONCE on generation (must be copied immediately)
- Show only on: first run, password changes, token regeneration
- Show in difficult environments: Docker, headless servers
- **NEVER log sensitive data**
- **NEVER in error messages or stack traces**
- Mask in UI: show `••••••••` or last 4 chars only

---

## Target Audience

- Self-hosted users
- SMB (Small/Medium Business)
- Enterprise
- **IMPORTANT: Assume self-hosted and SMB users are NOT tech-savvy**

---

# CHECKPOINT 1: CORE RULES VERIFICATION

Before proceeding, confirm you understand:
- [ ] All NON-NEGOTIABLE sections must be implemented exactly
- [ ] AI.md must be kept in sync with project state
- [ ] TODO.AI.md required for more than 2 tasks
- [ ] Sensitive data handling rules
- [ ] Target audience includes non-tech-savvy users

---


# PART 2: LICENSE & ATTRIBUTION (NON-NEGOTIABLE)

## Project License

**All projects MUST use the MIT License.**

| Requirement | Value |
|-------------|-------|
| License type | MIT License |
| License file | `LICENSE.md` (REQUIRED in project root) |
| Copyright holder | `casapps` or individual/organization name |
| Year | Current year or year of first publication |

## LICENSE.md Structure (NON-NEGOTIABLE)

```markdown
MIT License

Copyright (c) {YEAR} casapps

Permission is hereby granted, free of charge, to any person obtaining a copy
of this software and associated documentation files (the "Software"), to deal
in the Software without restriction, including without limitation the rights
to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
copies of the Software, and to permit persons to whom the Software is
furnished to do so, subject to the following conditions:

The above copyright notice and this permission notice shall be included in all
copies or substantial portions of the Software.

THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
SOFTWARE.

---

## Embedded Licenses

This software includes the following third-party libraries:

{LIST OF DEPENDENCIES WITH THEIR LICENSES - see below for format}
```

## Embedded License Attribution (NON-NEGOTIABLE)

**All third-party dependencies MUST have their licenses attributed in LICENSE.md.**

### Which Dependencies Require Attribution

| License Type | Attribution Required | Example Libraries |
|--------------|---------------------|-------------------|
| **MIT** | ✓ YES | Most Go libraries |
| **Apache 2.0** | ✓ YES | Many Google libraries |
| **BSD (2/3-clause)** | ✓ YES | Various libraries |
| **ISC** | ✓ YES | Similar to MIT |
| **MPL 2.0** | ✓ YES | Mozilla libraries |
| **Public Domain/Unlicense** | Optional (recommended) | CC0, WTFPL |
| **GPL/AGPL/LGPL** | ⚠️ AVOID | Copyleft licenses - do not use |

**NEVER use GPL/AGPL/LGPL licensed dependencies** - they require derivative works to be open-sourced under the same license.

### How to Identify Dependencies

For Go projects, use `go.mod` and license scanning tools:

```bash
# List all dependencies
go list -m all

# Use go-licenses tool (recommended)
go install github.com/google/go-licenses@latest
go-licenses csv ./... > licenses.csv
go-licenses save ./... --save_path=third_party_licenses
```

For Node.js projects:

```bash
# Use license-checker
npm install -g license-checker
license-checker --production --json > licenses.json
```

### Embedded License Format

**Each embedded license MUST include:**

1. **Library name and version**
2. **Copyright holder(s)**
3. **License type**
4. **Full license text**

**Template:**

```markdown
---

## Embedded Licenses

This software includes the following third-party libraries:

---

### {library-name} v{version}

**Copyright:** {copyright-holder}
**License:** {license-type}
**Repository:** https://github.com/{org}/{repo}

```
{FULL LICENSE TEXT FROM THE LIBRARY}
```

---

### {library-name-2} v{version}

**Copyright:** {copyright-holder}
**License:** {license-type}
**Repository:** https://github.com/{org}/{repo}

```
{FULL LICENSE TEXT FROM THE LIBRARY}
```

---
```

### Example Embedded License Section

```markdown
---

## Embedded Licenses

This software includes the following third-party libraries:

---

### github.com/go-chi/chi/v5 v5.0.10

**Copyright:** Copyright (c) 2015-present Peter Kieltyka (https://github.com/pkieltyka), Google Inc.
**License:** MIT License
**Repository:** https://github.com/go-chi/chi

```
MIT License

Copyright (c) 2015-present Peter Kieltyka (https://github.com/pkieltyka), Google Inc.

Permission is hereby granted, free of charge, to any person obtaining a copy of
this software and associated documentation files (the "Software"), to deal in
the Software without restriction, including without limitation the rights to
use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies
of the Software, and to permit persons to whom the Software is furnished to do
so, subject to the following conditions:

The above copyright notice and this permission notice shall be included in all
copies or substantial portions of the Software.

THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS
FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR
COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER
IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN
CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.
```

---

### github.com/mattn/go-sqlite3 v1.14.18

**Copyright:** Copyright (c) 2014 Yasuhiro Matsumoto
**License:** MIT License
**Repository:** https://github.com/mattn/go-sqlite3

```
MIT License

Copyright (c) 2014 Yasuhiro Matsumoto

Permission is hereby granted, free of charge, to any person obtaining a copy
of this software and associated documentation files (the "Software"), to deal
in the Software without restriction, including without limitation the rights
to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
copies of the Software, and to permit persons to whom the Software is
furnished to do so, subject to the following conditions:

The above copyright notice and this permission notice shall be included in all
copies or substantial portions of the Software.

THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
SOFTWARE.
```

---
```

## Maintenance Requirements (NON-NEGOTIABLE)

### When to Update LICENSE.md

| Event | Action Required |
|-------|----------------|
| **New dependency added** | Add its license to LICENSE.md embedded section |
| **Dependency removed** | Remove its license from LICENSE.md |
| **Dependency upgraded** | Verify license hasn't changed; update version number |
| **Major dependency update** | Re-check license compatibility |

### Automated License Checking

**Projects SHOULD automate license verification:**

```yaml
# .github/workflows/licenses.yml
name: License Check

on: [push, pull_request]

jobs:
  check-licenses:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
      - uses: actions/setup-go@v5
        with:
          go-version: '1.21'

      - name: Install go-licenses
        run: go install github.com/google/go-licenses@latest

      - name: Check licenses
        run: |
          # Verify no GPL/AGPL/LGPL licenses
          if go-licenses csv ./... | grep -iE 'GPL|AGPL|LGPL'; then
            echo "ERROR: Copyleft license detected!"
            exit 1
          fi

      - name: Save license report
        run: go-licenses save ./... --save_path=third_party_licenses
```

### License Verification Script

**Include in project repository:**

```bash
#!/bin/bash
# scripts/verify-licenses.sh

set -e

echo "Checking for incompatible licenses..."

# Install go-licenses if not present
if ! command -v go-licenses &> /dev/null; then
    echo "Installing go-licenses..."
    go install github.com/google/go-licenses@latest
fi

# Check for copyleft licenses
echo "Scanning dependencies..."
if go-licenses csv ./... | grep -iE 'GPL|AGPL|LGPL'; then
    echo "ERROR: Copyleft license detected!"
    echo "Remove the dependency or find an alternative."
    exit 1
fi

echo "✓ All licenses are compatible"

# Generate license report
echo "Generating license report..."
go-licenses csv ./... > licenses.csv
go-licenses save ./... --save_path=third_party_licenses

echo "✓ License report saved to licenses.csv and third_party_licenses/"
echo ""
echo "Next steps:"
echo "1. Review licenses.csv"
echo "2. Update LICENSE.md with any new dependencies"
echo "3. Commit the changes"
```

## README.md License Badge (REQUIRED)

**Every README.md MUST include a license badge:**

```markdown
[![License](https://img.shields.io/github/license/casapps/casspeed)](LICENSE.md)
```

This badge should appear in the badges section near the top of README.md.

## Docker Labels (REQUIRED)

**Dockerfile MUST include license label:**

```dockerfile
LABEL org.opencontainers.image.licenses="MIT"
```

See PART 13: DOCKER for complete label requirements.

## Go Module License Field

**go.mod does NOT have a license field**, but projects SHOULD document the license in:

1. `LICENSE.md` file (REQUIRED)
2. README.md badge (REQUIRED)
3. Package documentation comments (RECOMMENDED)

**Example package doc:**

```go
// Package jokes provides a REST API for random jokes.
//
// This software is licensed under the MIT License.
// See LICENSE.md for details.
package main
```

## Common Mistakes (AVOID)

| Mistake | Why It's Wrong | Correct Approach |
|---------|----------------|------------------|
| No LICENSE.md file | Legally ambiguous | Always include LICENSE.md |
| Missing embedded licenses | License violation | Include ALL dependency licenses |
| Using GPL dependencies | Forces project to be GPL | Use MIT/Apache/BSD alternatives |
| Outdated license attributions | Inaccurate legal compliance | Update when dependencies change |
| Only listing library names | Incomplete attribution | Include full license text |
| Mixing incompatible licenses | Legal conflicts | Verify compatibility |
| No automation | Manual errors | Use CI checks |

## License Compatibility Matrix

| Project License | Can Use Dependencies Licensed As |
|----------------|----------------------------------|
| **MIT** | MIT, Apache 2.0, BSD, ISC, Public Domain |
| **MIT** | ❌ **CANNOT use:** GPL, AGPL, LGPL |

**When in doubt:** Choose MIT/Apache 2.0/BSD licensed alternatives.

## Resources

- MIT License Template: https://opensource.org/licenses/MIT
- License Compatibility: https://www.gnu.org/licenses/license-compatibility.html
- go-licenses tool: https://github.com/google/go-licenses
- license-checker (Node.js): https://github.com/davglass/license-checker
- OSI Approved Licenses: https://opensource.org/licenses

---

**REMEMBER:**
1. Always include LICENSE.md in project root
2. Always embed third-party licenses at bottom of LICENSE.md
3. Never use GPL/AGPL/LGPL dependencies
4. Update LICENSE.md when dependencies change
5. Automate license checking in CI/CD

---

# PART 3: PROJECT STRUCTURE (NON-NEGOTIABLE)

## Project Information

| Field | Value |
|-------|-------|
| **Name** | casspeed |
| **Organization** | casapps |
| **Official Site** | https://casspeed.casapps.us |
| **Repository** | https://github.com/casapps/casspeed |
| **README** | README.md |
| **License** | MIT > LICENSE.md |
| **Embedded Licenses** | Added to bottom of LICENSE.md |

## Project Description

{Brief description of what this project does}

## Project-Specific Features

{List features unique to this project}

---

## Variables (NON-NEGOTIABLE)

| Variable | Description | Example |
|----------|-------------|---------|
| `casspeed` | Project name (inferred from path) | `jokes` |
| `casapps` | Organization name (inferred from path) | `apimgr` |
| `github` | Git hosting provider | `github`, `gitlab`, `private` |
| **Rule** | Anything in `{}` is a variable | |
| **Rule** | Anything NOT in `{}` is literal | `/etc/letsencrypt/live` is a real path |

### Inferring Variables from Path (NON-NEGOTIABLE)

**NEVER hardcode `casspeed` or `casapps` - always infer from git remote or directory path.**

**Recommended path structure:** `~/Projects/github/casapps/casspeed` (but works with any location)

```bash
# Method 1: Infer from git remote (PREFERRED - works regardless of directory location)
# github.com/apimgr/jokes.git → PROJECTORG=apimgr, PROJECTNAME=jokes
PROJECTNAME=$(git remote get-url origin 2>/dev/null | sed -E 's|.*/([^/]+)(\.git)?$|\1|')
PROJECTORG=$(git remote get-url origin 2>/dev/null | sed -E 's|.*/([^/]+)/[^/]+(\.git)?$|\1|')

# Method 2: Infer from current directory path (fallback if no git remote)
# Works with any path structure: ~/Documents/myproject, ~/myproject, etc.
PROJECTNAME=$(basename "$PWD")                    # myproject
PROJECTORG=$(basename "$(dirname "$PWD")")        # Documents (or parent dir name)

# Method 3: Combined approach (git first, fallback to path)
PROJECTNAME=$(git remote get-url origin 2>/dev/null | sed -E 's|.*/([^/]+)(\.git)?$|\1|' || basename "$PWD")
PROJECTORG=$(git remote get-url origin 2>/dev/null | sed -E 's|.*/([^/]+)/[^/]+(\.git)?$|\1|' || basename "$(dirname "$PWD")")
```

**Note:** When using path-based inference, `PROJECTORG` will be the parent directory name, which may not match the git organization unless you follow the recommended `~/Projects/github/casapps/casspeed` structure. Git remote inference is always more reliable.

### Variable Capitalization

| Format | Use Case | Example |
|--------|----------|---------|
| `casspeed` | Lowercase (filenames, paths, commands) | `jokes`, `/etc/apimgr/jokes/` |
| `{projectName}` | camelCase (Go variables, JSON keys) | `projectName := "jokes"` |
| `{Projectname}` | PascalCase (Go types, display names) | `type JokesServer struct` |
| `CASSPEED` | UPPERCASE (env vars, Makefile vars) | `PROJECTNAME=jokes` |

**Examples (assuming no git remote, inferred from path):**

| Path | `PROJECTORG` | `PROJECTNAME` | Notes |
|------|--------------|---------------|-------|
| `~/Projects/github/apimgr/jokes` | `apimgr` | `jokes` | Recommended structure |
| `~/Projects/gitlab/casapps/cassearch` | `casapps` | `cassearch` | Recommended structure |
| `~/Documents/myproject` | `Documents` | `myproject` | Simple structure - org is parent dir |
| `~/myproject` | `~` | `myproject` | Home directory - org is home |
| `/opt/projects/myproject` | `projects` | `myproject` | Custom location - org is parent dir |

**With git remote (preferred):** Variables are inferred from remote URL regardless of directory location.

## Local Project Path Structure (RECOMMENDED)

**IMPORTANT: Project root can be located ANYWHERE on your system. This section describes a RECOMMENDED organizational structure, not a requirement.**

**Recommended Format:** `~/Projects/github/casapps/casspeed`

| Component | Description | Examples |
|-----------|-------------|----------|
| `~/Projects/` | Base projects directory (recommended) | Can be `~/Projects/`, `~/Documents/`, `/opt/`, etc. |
| `github` | Git hosting provider or `local` | `github`, `gitlab`, `bitbucket`, `private`, `local` |
| `casapps` | Organization/username (inferred) | `apimgr`, `casjay`, `myorg` |
| `casspeed` | Project name (inferred) | `jokes`, `icons`, `myproject` |

**Examples of recommended structure:**
```
~/Projects/github/apimgr/jokes        # ORG=apimgr, PROJECT=jokes
~/Projects/gitlab/casjay/icons        # ORG=casjay, PROJECT=icons
~/Projects/private/myorg/myproject    # ORG=myorg, PROJECT=myproject
~/Projects/bitbucket/company/app      # ORG=company, PROJECT=app
~/Projects/local/apimgr/prototype     # ORG=apimgr, PROJECT=prototype
```

**But any of these are equally valid:**
```
~/Documents/myproject                 # Simple home directory structure
~/myproject                           # Project in home directory
/opt/projects/myproject               # System-wide location
/workspace/dev/myproject              # Custom workspace
```

### Special: `local` Provider

`~/Projects/local/casapps/casspeed` (or any other location) is used for:
- **Prototyping** - Quick experiments and proof-of-concept
- **Bootstrapping** - Initial project setup before pushing to VCS
- **Local-only development** - Projects not intended for remote hosting
- **No VCS required** - May not have git initialized
- **No Docker registry** - May not push to container registries

**Note:** The paths shown here are LOCAL development examples, not deployed paths.

---

## Directory Structure (NON-NEGOTIABLE)

**This section defines the INTERNAL structure of your project, not its location.**

**The root Project directory is**: `./` (relative paths shown below - can be located anywhere on your system)

```
./                          # Root project directory (git top-level)
├── .github/                # GitHub Actions (if using GitHub)
│   └── workflows/
│       ├── release.yml     # Stable releases
│       ├── beta.yml        # Beta releases
│       ├── daily.yml       # Daily builds
│       └── docker.yml      # Docker images
├── .gitea/                 # Gitea Actions (if using Gitea)
│   └── workflows/
│       ├── release.yml     # Stable releases
│       ├── beta.yml        # Beta releases
│       ├── daily.yml       # Daily builds
│       └── docker.yml      # Docker images
├── .claude/                # Claude AI configuration (optional)
├── .cursor/                # Cursor AI configuration (optional)
├── .aider/                 # Aider AI configuration (optional)
├── .ai/                    # Generic AI configuration (optional)
├── docs/                   # ReadTheDocs documentation ONLY (MkDocs)
│   ├── index.md            # Documentation homepage
│   ├── installation.md     # Installation guide
│   ├── configuration.md    # Configuration reference
│   ├── api.md              # API documentation
│   ├── cli.md              # CLI reference (if applicable)
│   ├── admin.md            # Admin panel guide
│   ├── development.md      # Development guide
│   ├── stylesheets/        # MkDocs theme customization
│   │   ├── dark.css        # Dark theme customization for ReadTheDocs
│   │   └── light.css       # Light theme customization for ReadTheDocs (optional)
│   └── requirements.txt    # Python dependencies for MkDocs
├── src/                    # All source files
├── scripts/                # All production/install scripts
├── tests/                  # All development/test scripts and files
│   ├── run_tests.sh        # Auto-detect and run tests (REQUIRED)
│   ├── docker.sh           # Beta testing with Docker (REQUIRED)
│   └── incus.sh            # Beta testing with Incus (REQUIRED)
├── docker/                 # Docker files
│   ├── Dockerfile          # Production Dockerfile
│   ├── Dockerfile.dev      # Development Dockerfile (optional)
│   ├── docker-compose.yml  # Production compose (NO debug)
│   ├── docker-compose.dev.yml  # Development compose
│   ├── docker-compose.test.yml # Test compose (DEBUG=true)
│   └── rootfs/             # Container filesystem overlay
│       └── usr/
│           └── local/
│               └── bin/
│                   └── entrypoint.sh  # Container entrypoint
├── rootfs/                 # Runtime volume data (gitignored)
│   ├── config/             # Config volumes per service
│   ├── data/               # Data volumes per service
│   └── db/                 # Database volumes per type
├── binaries/               # Built binaries (gitignored) - ALL binaries here
├── releases/               # Release binaries (gitignored)
├── README.md               # Production first, dev last
├── LICENSE.md              # MIT + embedded licenses
├── AI.md                   # Project specification (from AI.md)
├── TODO.AI.md              # Task tracking for >2 tasks
├── Jenkinsfile             # Jenkins pipeline
└── release.txt             # Version tracking
```

**Gitignored directories:**
- `binaries/` - All build output (host + all platforms)
- `releases/` - Release output
- `rootfs/` - Runtime volume data

### .gitignore (REQUIRED)

**Base: `gitignore --dir . default` + project-specific entries**

```gitignore
# gitignore default template
# Disable reminder in prompt
ignoredirmessage

# ignore .build_failed files
**/.build_failed*

# OS generated files
### Linux ###
*~

# temporary files which can be created if a process still has a handle open of a deleted file
.fuse_hidden*

# KDE directory preferences
.directory

# Linux trash folder which might appear on any partition or disk
.Trash-*

# .nfs files are created when an open file is removed but is still being accessed
.nfs*

### macOS ###
# General
.DS_Store?
.AppleDouble
.LSOverride

# Thumbnails
._*

# Files that might appear in the root of a volume
.DocumentRevisions-V100
.fseventsd
.Spotlight-V100
.TemporaryItems
.Trashes
.VolumeIcon.icns
.com.apple.timemachine.donotpresent

# Directories potentially created on remote AFP share
.AppleDB
.AppleDesktop
Network Trash Folder
Temporary Items
.apdisk

### macOS Patch ###
# iCloud generated files
*.icloud

### Windows ###
# Windows thumbnail cache files
Thumbs.db
Thumbs.db:encryptable
ehthumbs.db
ehthumbs_vista.db

# Dump file
*.stackdump

# Folder config file
[Dd]esktop.ini

# Recycle Bin used on file shares
$RECYCLE.BIN/

# Windows Installer files
*.cab
*.msi
*.msix
*.msm
*.msp

# misc
!*/README*
!inc/main.bash

# Windows shortcuts
*.lnk

# ignore commit message
**/.gitcommit

# ignore .bak files
**/*.bak

# ignore .no_push files
**/.no_push

# ignore .no_git files
**/.no_git

# ignore .installed files
**/.installed

# ignore work in progress files
**/*.rewrite.sh
**/*.refactor.sh

# ============================================
# PROJECT-SPECIFIC (add below default section)
# ============================================

# Build output
binaries/
releases/

# Runtime volume data (NEVER commit)
rootfs/

# IDE
.idea/
.vscode/
*.swp
*.swo

# AI config directories (keep these - they're committed, not ignored)
# .claude/
# .cursor/
# .aider/
# .ai/
# .windsurf/
```

### .dockerignore (REQUIRED)

```dockerignore
# Git
.git/
.gitignore

# GitHub/Gitea workflows
.github/
.gitea/

# Entire docker directory
docker/

# Runtime volume data (NEVER include in image)
rootfs/

# Build output
binaries/
releases/

# IDE
.idea/
.vscode/

# AI config directories
.claude/
.cursor/
.aider/
.ai/
.windsurf/

# Docs
*.md
```

**Note:** `docker/` is ignored but `COPY docker/rootfs/ /` still works because we build using host docker - files are copied from host filesystem during build, not from build context.

**RULE: Keep the base directory organized and clean - no clutter!**

## Path Convention (NON-NEGOTIABLE)

**ALL paths are ALWAYS relative to PROJECT ROOT, never the current working directory.**

**⚠️ IMPORTANT: Project root ≠ Template location ≠ Current working directory**

If you're reading this AI.md from `/root/Projects/github/apimgr/AI.md` to build a project in `~/Documents/myproject`, all file operations must be in `~/Documents/myproject/`, NOT in `/root/Projects/github/apimgr/`.

### Defining Project Root

**Project root** is the top-level directory of your project, determined by:

1. **Git repository top-level** (preferred): Run `git rev-parse --show-toplevel` to find it
2. **Directory containing project structure**: The directory with `go.mod`, `src/`, `docker/`, etc.

**Project root can be located ANYWHERE on your system:**

| Valid Project Root | Example |
|-------------------|---------|
| Structured projects dir | `~/Projects/github/casapps/myproject` |
| Documents folder | `~/Documents/myproject` |
| Home directory | `~/myproject` |
| Any arbitrary location | `/opt/projects/myproject` |
| Custom workspace | `/workspace/dev/myproject` |

**Rule: ALL file paths in code, documentation, and scripts MUST be relative to THIS project root, regardless of where it's located.**

| Path | Means | NOT |
|------|-------|-----|
| `docker/` | `{project_root}/docker/` | `{cwd}/docker/` |
| `binaries/` | `{project_root}/binaries/` | `{cwd}/binaries/` |
| `src/` | `{project_root}/src/` | `{cwd}/src/` |

**Rules:**
- Commands MUST be run from project root, OR
- Commands MUST use absolute paths, OR
- Commands MUST `cd` to project root first
- NEVER assume current directory is project root
- Scripts should determine project root programmatically

```bash
# Determine project root (in scripts)
PROJECT_ROOT="$(cd "$(dirname "${BASH_SOURCE[0]}")/.." && pwd)"

# Or for Go binaries, use os.Executable()
```

```go
// Determine project root in Go
func getProjectRoot() string {
    exe, _ := os.Executable()
    return filepath.Dir(exe)
}
```

**Example - WRONG vs RIGHT:**
```bash
# WRONG: Assumes cwd is project root
cd binaries && docker build -f .docker/Dockerfile .

# RIGHT: Explicit project root
docker build -f docker/Dockerfile -t myapp ./

# RIGHT: cd to project root first
cd /path/to/project && docker build -f docker/Dockerfile .
```

## Runtime Directory Usage (NON-NEGOTIABLE)

**Be smart about which directory to use for what purpose.**

| Directory | Purpose | Examples |
|-----------|---------|----------|
| `{config_dir}` | User-editable configuration | `server.yml`, email templates, custom themes, SSL certs |
| `{data_dir}` | Application-managed data | databases, Tor keys, caches, GeoIP databases |
| `{log_dir}` | Log files | `access.log`, `error.log`, `audit.log` |
| `{backup_dir}` | Backup files | `.tar.gz` backup archives |

**Rules:**
- If a user might edit it → `{config_dir}`
- If the application manages it → `{data_dir}`
- If it's a log → `{log_dir}`
- If it's a backup → `{backup_dir}`
- **NEVER mix purposes** - don't put user config in data_dir or vice versa

---

## Platform Support (NON-NEGOTIABLE)

### Operating Systems

| OS | Required |
|----|----------|
| Linux | YES |
| BSD (FreeBSD, OpenBSD, etc.) | YES |
| macOS (Intel and Apple Silicon) | YES |
| Windows | YES |

### Architectures

| Architecture | Required |
|--------------|----------|
| AMD64 | YES |
| ARM64 | YES |

**IMPORTANT: Be smart about implementations - code must work on ALL platforms.**

---

## Go Version (NON-NEGOTIABLE)

| Rule | Description |
|------|-------------|
| **Minimum Version** | Go 1.23+ (latest stable at time of project creation) |
| **Always Latest Stable** | Use latest stable Go version when starting new projects |
| **Build Only** | Go is only for building, not runtime (single static binary) |
| **go.mod** | Set `go 1.23` or higher in go.mod |
| **Docker** | Use `golang:alpine` for build/test/debug (always latest Go) |
| **No Pinning** | Don't pin to patch versions unless compatibility issue |

**go.mod Example:**
```
module github.com/casapps/casspeed

go 1.23

require (
    // dependencies...
)
```

## Required Go Libraries (NON-NEGOTIABLE)

**All libraries MUST be pure Go and work with `CGO_ENABLED=0`.**

### Database Drivers

| Database | Library | Driver Name | Notes |
|----------|---------|-------------|-------|
| **SQLite** | `modernc.org/sqlite` | `sqlite` | Pure Go, NO CGO |
| **PostgreSQL** | `github.com/jackc/pgx/v5/stdlib` | `pgx` | Pure Go, best performance |
| **MySQL/MariaDB** | `github.com/go-sql-driver/mysql` | `mysql` | Pure Go |
| **MSSQL** | `github.com/microsoft/go-mssqldb` | `sqlserver` | Pure Go |
| **MongoDB** | `go.mongodb.org/mongo-driver/mongo` | (native) | Pure Go, not database/sql |

### Cache/Cluster

| Purpose | Library | Notes |
|---------|---------|-------|
| **Valkey/Redis** | `github.com/redis/go-redis/v9` | Supports both Valkey and Redis |
| **Memcache** | `github.com/bradfitz/gomemcache/memcache` | Pure Go |

### Core Libraries

| Purpose | Library | Notes |
|---------|---------|-------|
| **YAML** | `gopkg.in/yaml.v3` | Config file parsing |
| **UUID** | `github.com/google/uuid` | Standard UUID generation |
| **Argon2** | `golang.org/x/crypto/argon2` | Password hashing |
| **Bcrypt** | `golang.org/x/crypto/bcrypt` | Legacy password verification |

### Authentication (REQUIRED - ALL PROJECTS)

**Every project has server admins, even apps without users (e.g., `jokes` loading JSON).**
**These libraries are REQUIRED to support admin authentication features.**

| Purpose | Library | Notes |
|---------|---------|-------|
| **TOTP** | `github.com/pquerna/otp` | Time-based 2FA codes |
| **Passkeys/WebAuthn** | `github.com/go-webauthn/webauthn` | FIDO2/WebAuthn passwordless |
| **JWT** | `github.com/golang-jwt/jwt/v5` | API token authentication |
| **OIDC** | `github.com/coreos/go-oidc/v3` | OpenID Connect client |
| **OAuth2** | `golang.org/x/oauth2` | OAuth2 flows |
| **LDAP** | `github.com/go-ldap/ldap/v3` | LDAP/Active Directory |
| **Sessions** | `github.com/gorilla/sessions` | Cookie-based sessions |

**Server Admin MFA (Recommended):**
- TOTP and Passkeys are optional but STRONGLY recommended for server admins
- Admin panel MUST support enabling/disabling TOTP and Passkeys
- Recovery keys MUST be generated when MFA is enabled
- All MFA features work regardless of whether app has regular users

### Network/HTTP

| Purpose | Library | Notes |
|---------|---------|-------|
| **Router** | `github.com/go-chi/chi/v5` | Lightweight, stdlib compatible |
| **Tor** | `github.com/cretz/bine` | Pure Go Tor controller |
| **WebSocket** | `github.com/gorilla/websocket` | WebSocket support |
| **CORS** | `github.com/rs/cors` | CORS middleware |

### Utilities

| Purpose | Library | Notes |
|---------|---------|-------|
| **Embed** | `embed` (stdlib) | Embed static files |
| **Cron** | `github.com/robfig/cron/v3` | Scheduler |
| **Rate Limit** | `golang.org/x/time/rate` | Rate limiting |
| **Validation** | `github.com/go-playground/validator/v10` | Input validation |

### SQLite Driver (NON-NEGOTIABLE)

**MUST use `modernc.org/sqlite`. NEVER use `github.com/mattn/go-sqlite3`.**

| Driver | CGO Required | Use |
|--------|--------------|-----|
| `modernc.org/sqlite` | NO | **ALWAYS USE THIS** |
| `github.com/mattn/go-sqlite3` | YES | **NEVER USE** |

**Why `modernc.org/sqlite`?**
- Pure Go implementation - no C compiler needed
- Works with `CGO_ENABLED=0` for static binaries
- Cross-compilation works without toolchain setup
- Same SQLite functionality, just pure Go

**Usage:**
```go
import (
    "database/sql"
    _ "modernc.org/sqlite"
)

func openDB(path string) (*sql.DB, error) {
    // Driver name is "sqlite" (not "sqlite3")
    return sql.Open("sqlite", path)
}
```

**go.mod:**
```
require modernc.org/sqlite v1.29.1
```

### Forbidden Libraries

| Library | Reason | Alternative |
|---------|--------|-------------|
| `github.com/mattn/go-sqlite3` | Requires CGO | `modernc.org/sqlite` |
| `github.com/lib/pq` | Outdated, less performant | `github.com/jackc/pgx/v5` |
| `github.com/ooni/go-libtor` | Requires CGO | `github.com/cretz/bine` + external Tor |
| `github.com/dgrijalva/jwt-go` | Unmaintained, security issues | `github.com/golang-jwt/jwt/v5` |
| `github.com/gorilla/mux` | Archived, no longer maintained | `github.com/go-chi/chi/v5` |
| `github.com/go-redis/redis` | Old import path | `github.com/redis/go-redis/v9` |
| Any CGO library | Breaks static builds | Find pure Go alternative |

**CGO_ENABLED=0 Rule:** All libraries must work with `CGO_ENABLED=0`. If a library requires CGO, find a pure Go alternative or don't use it.

### Example go.mod

```go
module github.com/casapps/casspeed

go 1.24

require (
	// Database drivers
	modernc.org/sqlite v1.34.5                      // SQLite (pure Go)
	github.com/jackc/pgx/v5 v5.7.2                  // PostgreSQL
	github.com/go-sql-driver/mysql v1.8.1           // MySQL/MariaDB
	github.com/microsoft/go-mssqldb v1.8.0          // MSSQL
	go.mongodb.org/mongo-driver v1.17.2             // MongoDB

	// Cache/Cluster
	github.com/redis/go-redis/v9 v9.7.0             // Valkey/Redis
	github.com/bradfitz/gomemcache v0.0.0-20230905024940-24af94b03874  // Memcache

	// Core
	gopkg.in/yaml.v3 v3.0.1                         // YAML config
	github.com/google/uuid v1.6.0                   // UUID generation
	golang.org/x/crypto v0.31.0                     // Argon2, Bcrypt

	// Authentication
	github.com/pquerna/otp v1.4.0                   // TOTP 2FA
	github.com/go-webauthn/webauthn v0.11.2         // Passkeys/WebAuthn
	github.com/golang-jwt/jwt/v5 v5.2.1             // JWT tokens
	github.com/coreos/go-oidc/v3 v3.11.0            // OIDC client
	golang.org/x/oauth2 v0.24.0                     // OAuth2 flows
	github.com/go-ldap/ldap/v3 v3.4.10              // LDAP/AD
	github.com/gorilla/sessions v1.4.0              // Cookie sessions

	// Network/HTTP
	github.com/go-chi/chi/v5 v5.2.0                 // Router
	github.com/cretz/bine v0.2.0                    // Tor controller
	github.com/gorilla/websocket v1.5.3             // WebSocket
	github.com/rs/cors v1.11.1                      // CORS middleware

	// Utilities
	github.com/robfig/cron/v3 v3.0.1                // Scheduler
	golang.org/x/time v0.8.0                        // Rate limiting
	github.com/go-playground/validator/v10 v10.23.0 // Validation
)
```

**Notes:**
- Version numbers are examples - always use latest stable versions
- Not all projects need all modules - include only what you use
- Clean up unused dependencies: `docker run --rm -v $(pwd):/build -w /build golang:alpine go mod tidy`
- MongoDB uses native driver, not database/sql
- **NEVER run `go` directly - always use `docker run ... golang:alpine go ...`**

## Password Hashing (NON-NEGOTIABLE)

**ALL passwords MUST be hashed using Argon2id. NEVER store plaintext passwords.**

### Algorithm Requirements

| Setting | Value | Reason |
|---------|-------|--------|
| **Algorithm** | Argon2id | Winner of Password Hashing Competition, memory-hard |
| **Library** | `golang.org/x/crypto/argon2` | Pure Go, CGO_ENABLED=0 compatible |
| **Fallback** | Bcrypt (cost 12+) | For legacy password verification only |

### Argon2id Parameters (OWASP 2023)

```go
import "golang.org/x/crypto/argon2"

// Recommended parameters
const (
    ArgonTime    = 3         // iterations
    ArgonMemory  = 64 * 1024 // 64 MB
    ArgonThreads = 4         // parallelism
    ArgonKeyLen  = 32        // output length in bytes
    ArgonSaltLen = 16        // salt length in bytes
)

func HashPassword(password string) (string, error) {
    // Generate random salt
    salt := make([]byte, ArgonSaltLen)
    if _, err := rand.Read(salt); err != nil {
        return "", err
    }

    // Hash password
    hash := argon2.IDKey([]byte(password), salt, ArgonTime, ArgonMemory, ArgonThreads, ArgonKeyLen)

    // Encode as string: $argon2id$v=19$m=65536,t=3,p=4$<salt>$<hash>
    return encodeArgon2Hash(salt, hash), nil
}
```

### Storage Format

Passwords stored in PHC string format:
```
$argon2id$v=19$m=65536,t=3,p=4$<base64-salt>$<base64-hash>
```

### Password Rules

| Rule | Description |
|------|-------------|
| **NEVER** | Store plaintext passwords anywhere |
| **NEVER** | Store passwords in config files (server.yml) |
| **NEVER** | Log passwords (even hashed) |
| **ALWAYS** | Use Argon2id for new passwords |
| **ALWAYS** | Store in database only |
| **ALWAYS** | Generate secure random salt per password |

### API Token Hashing

API tokens are also sensitive and MUST be hashed:

| Token Type | Storage | Hashing |
|------------|---------|---------|
| **API Token** | Database | SHA-256 hash (fast lookup needed) |
| **Session Token** | Database | SHA-256 hash |
| **Password** | Database | Argon2id (slow by design) |

```go
import "crypto/sha256"

func HashToken(token string) string {
    hash := sha256.Sum256([]byte(token))
    return hex.EncodeToString(hash[:])
}
```

**Note:** API tokens use SHA-256 (not Argon2id) because:
- Tokens are already high-entropy random strings
- Need fast lookup for every API request
- Argon2id's slowness is for weak human passwords

---

# CHECKPOINT 2: PROJECT STRUCTURE VERIFICATION

Before proceeding, confirm you understand:
- [ ] Project directory structure
- [ ] Variable syntax (`{}` = variable, no `{}` = literal)
- [ ] All 4 OSes must be supported
- [ ] Both AMD64 and ARM64 must be supported
- [ ] Always use latest stable Go

---


# PART 4: OS-SPECIFIC PATHS (NON-NEGOTIABLE)

## Linux

### Privileged (root/sudo)

| Type | Path |
|------|------|
| Binary | `/usr/local/bin/casspeed` |
| Config | `/etc/casapps/casspeed/` |
| Config File | `/etc/casapps/casspeed/server.yml` |
| Data | `/var/lib/casapps/casspeed/` |
| Logs | `/var/log/casapps/casspeed/` |
| Backup | `/mnt/Backups/casapps/casspeed/` |
| PID File | `/var/run/casapps/casspeed.pid` |
| SSL | `/etc/casapps/casspeed/ssl/` (letsencrypt/, local/) |
| Security | `/etc/casapps/casspeed/security/` (geoip/, blocklists/, cve/, trivy/) |
| SQLite DB | `/var/lib/casapps/casspeed/db/` |
| Service | `/etc/systemd/system/casspeed.service` |

### User (non-privileged)

| Type | Path |
|------|------|
| Binary | `~/.local/bin/casspeed` |
| Config | `~/.config/casapps/casspeed/` |
| Config File | `~/.config/casapps/casspeed/server.yml` |
| Data | `~/.local/share/casapps/casspeed/` |
| Logs | `~/.local/share/casapps/casspeed/logs/` |
| Backup | `~/.local/backups/casapps/casspeed/` |
| PID File | `~/.local/share/casapps/casspeed/casspeed.pid` |
| SSL | `~/.config/casapps/casspeed/ssl/` (letsencrypt/, local/) |
| Security | `~/.config/casapps/casspeed/security/` (geoip/, blocklists/, cve/, trivy/) |
| SQLite DB | `~/.local/share/casapps/casspeed/db/` |

---

## macOS

### Privileged (root/sudo)

| Type | Path |
|------|------|
| Binary | `/usr/local/bin/casspeed` |
| Config | `/Library/Application Support/casapps/casspeed/` |
| Config File | `/Library/Application Support/casapps/casspeed/server.yml` |
| Data | `/Library/Application Support/casapps/casspeed/data/` |
| Logs | `/Library/Logs/casapps/casspeed/` |
| Backup | `/Library/Backups/casapps/casspeed/` |
| PID File | `/var/run/casapps/casspeed.pid` |
| SSL | `/Library/Application Support/casapps/casspeed/ssl/` (letsencrypt/, local/) |
| Security | `/Library/Application Support/casapps/casspeed/security/` (geoip/, blocklists/, cve/, trivy/) |
| SQLite DB | `/Library/Application Support/casapps/casspeed/db/` |
| Service | `/Library/LaunchDaemons/com.casapps.casspeed.plist` |

### User (non-privileged)

| Type | Path |
|------|------|
| Binary | `~/bin/casspeed` or `/usr/local/bin/casspeed` |
| Config | `~/Library/Application Support/casapps/casspeed/` |
| Config File | `~/Library/Application Support/casapps/casspeed/server.yml` |
| Data | `~/Library/Application Support/casapps/casspeed/` |
| Logs | `~/Library/Logs/casapps/casspeed/` |
| Backup | `~/Library/Backups/casapps/casspeed/` |
| PID File | `~/Library/Application Support/casapps/casspeed/casspeed.pid` |
| SSL | `~/Library/Application Support/casapps/casspeed/ssl/` (letsencrypt/, local/) |
| Security | `~/Library/Application Support/casapps/casspeed/security/` (geoip/, blocklists/, cve/, trivy/) |
| SQLite DB | `~/Library/Application Support/casapps/casspeed/db/` |
| Service | `~/Library/LaunchAgents/com.casapps.casspeed.plist` |

---

## BSD (FreeBSD, OpenBSD, NetBSD)

### Privileged (root/sudo/doas)

| Type | Path |
|------|------|
| Binary | `/usr/local/bin/casspeed` |
| Config | `/usr/local/etc/casapps/casspeed/` |
| Config File | `/usr/local/etc/casapps/casspeed/server.yml` |
| Data | `/var/db/casapps/casspeed/` |
| Logs | `/var/log/casapps/casspeed/` |
| Backup | `/var/backups/casapps/casspeed/` |
| PID File | `/var/run/casapps/casspeed.pid` |
| SSL | `/usr/local/etc/casapps/casspeed/ssl/` (letsencrypt/, local/) |
| Security | `/usr/local/etc/casapps/casspeed/security/` (geoip/, blocklists/, cve/, trivy/) |
| SQLite DB | `/var/db/casapps/casspeed/db/` |
| Service | `/usr/local/etc/rc.d/casspeed` |

### User (non-privileged)

| Type | Path |
|------|------|
| Binary | `~/.local/bin/casspeed` |
| Config | `~/.config/casapps/casspeed/` |
| Config File | `~/.config/casapps/casspeed/server.yml` |
| Data | `~/.local/share/casapps/casspeed/` |
| Logs | `~/.local/share/casapps/casspeed/logs/` |
| Backup | `~/.local/backups/casapps/casspeed/` |
| PID File | `~/.local/share/casapps/casspeed/casspeed.pid` |
| SSL | `~/.config/casapps/casspeed/ssl/` (letsencrypt/, local/) |
| Security | `~/.config/casapps/casspeed/security/` (geoip/, blocklists/, cve/, trivy/) |
| SQLite DB | `~/.local/share/casapps/casspeed/db/` |

---

## Windows

### Privileged (Administrator)

| Type | Path |
|------|------|
| Binary | `C:\Program Files\casapps\casspeed\casspeed.exe` |
| Config | `%ProgramData%\casapps\casspeed\` |
| Config File | `%ProgramData%\casapps\casspeed\server.yml` |
| Data | `%ProgramData%\casapps\casspeed\data\` |
| Logs | `%ProgramData%\casapps\casspeed\logs\` |
| Backup | `%ProgramData%\Backups\casapps\casspeed\` |
| SSL | `%ProgramData%\casapps\casspeed\ssl\` (letsencrypt\, local\) |
| Security | `%ProgramData%\casapps\casspeed\security\` (geoip\, blocklists\, cve\, trivy\) |
| SQLite DB | `%ProgramData%\casapps\casspeed\db\` |
| Service | Windows Service Manager |

### User (non-privileged)

| Type | Path |
|------|------|
| Binary | `%LocalAppData%\casapps\casspeed\casspeed.exe` |
| Config | `%AppData%\casapps\casspeed\` |
| Config File | `%AppData%\casapps\casspeed\server.yml` |
| Data | `%LocalAppData%\casapps\casspeed\` |
| Logs | `%LocalAppData%\casapps\casspeed\logs\` |
| Backup | `%LocalAppData%\Backups\casapps\casspeed\` |
| SSL | `%AppData%\casapps\casspeed\ssl\` (letsencrypt\, local\) |
| Security | `%AppData%\casapps\casspeed\security\` (geoip\, blocklists\, cve\, trivy\) |
| SQLite DB | `%LocalAppData%\casapps\casspeed\db\` |

---

## Docker/Container

| Type | Path |
|------|------|
| Binary | `/usr/local/bin/casspeed` |
| Config | `/config/` |
| Config File | `/config/server.yml` |
| Security DBs | `/config/security/` (geoip, blocklists, cve, trivy) |
| Data | `/data/` |
| Logs | `/data/logs/` |
| SQLite DB | `/data/db/` |
| Internal Port | `80` |

---

# CHECKPOINT 3: PATH VERIFICATION

Before proceeding, confirm you understand:
- [ ] Each OS has specific paths for privileged and non-privileged users
- [ ] Config file is ALWAYS `server.yml` (not .yaml)
- [ ] Docker uses simplified paths (/config, /data)
- [ ] All paths follow the casapps/casspeed pattern

---

# PART 5: CONFIGURATION (NON-NEGOTIABLE)

## YAML Comment Style (NON-NEGOTIABLE)

**CRITICAL: ALL comments in YAML files MUST go ABOVE the setting, NEVER inline.**

**WRONG:**
```yaml
enabled: true  # Enable feature
port: 8080     # Server port
```

**CORRECT:**
```yaml
# Enable feature
enabled: true

# Server port
port: 8080
```

**Reason:** Inline comments create confusion, make YAML harder to parse visually, and can cause issues with some YAML parsers. Comments above are clear and unambiguous.

**This applies to:**
- `server.yml` configuration
- `docker-compose.yml` files
- All YAML in the project
- All code examples in documentation

## Configuration Storage

**Configuration can be stored in `server.yml` OR database, depending on mode.**

### Terminology

| Term | Meaning |
|------|---------|
| **server.yml** | YAML configuration file on disk |
| **Configuration** | Settings (stored in server.yml OR database) |
| **Database** | SQLite (local) or PostgreSQL/MySQL (remote) |
| **Server Address** | The bind address for the server (e.g., `[::]`, `0.0.0.0`, `127.0.0.1`) |
| **FQDN** | Fully Qualified Domain Name (e.g., `api.example.com`) |
| **Node ID** | Unique identifier for a cluster node (default: hostname) |

**IMPORTANT:** We use "Server Address" (bind address), NOT "Server Name". The server address is where the server listens; the FQDN is how clients reach it.

### Configuration Source of Truth

| Mode | Source of Truth | server.yml Role |
|------|-----------------|-----------------|
| **Single Instance (SQLite)** | server.yml | Primary configuration |
| **Cluster Mode (Remote DB)** | Database | Bootstrap only (connection settings) |

### Single Instance Mode

```
server.yml (source of truth)
     │
     ▼
Application reads config
     │
     ▼
Admin panel writes to server.yml
```

- All settings stored in `server.yml`
- Admin panel edits `server.yml` directly
- SQLite databases for credentials/sessions only

### Cluster Mode

```
server.yml (cache + backup)
     │
     └─ Contains: database connection + cached config

Database (source of truth)
     │
     ▼
Application reads config from DB
     │
     ▼
Admin panel writes to database
     │
     ▼
Changes synced to server.yml cache
     │
     ▼
All nodes see changes immediately
```

- Database is source of truth
- `server.yml` is cache AND backup
- Admin panel writes to database
- Changes automatically synced to local `server.yml`
- If database unavailable → read-only mode using cached config

### server.yml as Cache/Backup (NON-NEGOTIABLE)

**When using external database, server.yml becomes a local cache and backup.**

```
Normal Operation:
┌──────────────┐         ┌──────────────┐
│   Database   │◄───────►│  server.yml  │
│ (source of   │  sync   │   (cache)    │
│   truth)     │         │              │
└──────────────┘         └──────────────┘
       │
       ▼
  Application
  reads from DB

Database Unavailable:
┌──────────────┐         ┌──────────────┐
│   Database   │    ✗    │  server.yml  │
│   (DOWN)     │         │   (backup)   │
└──────────────┘         └──────────────┘
                               │
                               ▼
                         Application
                         READ-ONLY MODE
                         uses cached config
```

### Config Sync (Database → server.yml)

**Every config change in database is synced to local server.yml:**

```go
func onConfigChange(db *sql.DB, key string, value interface{}) {
    // 1. Write to database (source of truth)
    writeToDatabase(db, key, value)

    // 2. Sync to local server.yml (cache)
    syncToLocalConfig(key, value)

    // 3. Update last_sync timestamp
    updateSyncTimestamp()
}
```

**Sync happens:**
- Immediately after any config change
- On application startup (DB → server.yml)
- Periodically (every 5 minutes) to catch any drift

### Maintenance Mode (NON-NEGOTIABLE)

**Only TWO types of errors are truly critical:**
1. Database connection error
2. Cannot write to files (disk full, permissions, etc.)

**All other errors are recoverable. The server ALWAYS attempts self-healing.**

### Critical Error Detection

| Error Type | Detection | Self-Healing Attempt |
|------------|-----------|---------------------|
| **Database connection** | Connection refused, timeout, auth failed | Retry with backoff, check credentials |
| **Database write** | Write failed, transaction error | Retry, check permissions, check disk |
| **File read** | Permission denied, file not found | Check permissions, recreate if possible |
| **File write** | Permission denied, disk full | Check permissions, check disk space, cleanup |

### Mode States

| State | Condition | Behavior |
|-------|-----------|----------|
| **Normal** | All systems healthy | Full functionality |
| **Maintenance** | Critical error detected | Read-only + admin guidance |
| **Starting** | Application starting up | Checking systems |

### Maintenance Mode

**When a critical error occurs, the application enters maintenance mode:**

| Aspect | Behavior |
|--------|----------|
| **Public API** | Read-only operations only |
| **Admin panel** | Accessible with fix instructions |
| **Writes** | Rejected with 503 |
| **Self-healing** | Continuously attempting in background |
| **Recovery** | Automatic when issue resolved |

### Self-Healing Process

```
Critical Error Detected
         │
         ▼
Enter Maintenance Mode
         │
         ├──────────────────────────────────────┐
         ▼                                      │
Attempt Self-Healing                            │
         │                                      │
         ├─► Database connection failed         │
         │   1. Retry connection (3x backoff)   │
         │   2. Check if host reachable         │
         │   3. Verify credentials              │
         │   4. Test with simple query          │
         │                                      │
         ├─► File write failed                  │
         │   1. Check disk space                │
         │   2. Check directory permissions     │
         │   3. Attempt to create test file     │
         │   4. Try alternate location          │
         │                                      │
         ├─► Disk full                          │
         │   1. Cleanup old logs                │
         │   2. Cleanup temp files              │
         │   3. Cleanup old backups             │
         │   4. Report space freed              │
         │                                      │
         ▼                                      │
Self-Healing Successful?                        │
    │                                           │
    ├─► YES: Exit Maintenance Mode ─────────────┘
    │        Resume Normal Operation
    │
    └─► NO: Continue in Maintenance Mode
            Retry every 30 seconds
            Show fix instructions in admin UI
```

### Admin Panel in Maintenance Mode

**The admin panel remains accessible and provides guidance for fixing issues.**

#### Maintenance Dashboard (`/admin`)

```
┌─────────────────────────────────────────────────────────────┐
│  ⚠️  MAINTENANCE MODE                                        │
│                                                             │
│  The application is running in read-only maintenance mode   │
│  due to a critical error. Self-healing is in progress.      │
│                                                             │
├─────────────────────────────────────────────────────────────┤
│                                                             │
│  Error: Database Connection Failed                          │
│  ─────────────────────────────────────────                  │
│  Host: db.example.com:5432                                  │
│  Error: connection refused                                  │
│  Last successful connection: 5 minutes ago                  │
│                                                             │
│  Self-Healing Status: Retrying... (attempt 15)              │
│                                                             │
├─────────────────────────────────────────────────────────────┤
│                                                             │
│  📋 Suggested Actions:                                      │
│                                                             │
│  1. Check if database server is running                     │
│     └─ ssh db.example.com "systemctl status postgresql"     │
│                                                             │
│  2. Verify network connectivity                             │
│     └─ ping db.example.com                                  │
│     └─ telnet db.example.com 5432                           │
│                                                             │
│  3. Check database credentials                              │
│     └─ Verify password in server.yml or environment         │
│                                                             │
│  4. Check database logs                                     │
│     └─ ssh db.example.com "tail /var/log/postgresql/*.log"  │
│                                                             │
│  [Test Connection]  [View Full Diagnostics]                 │
│                                                             │
└─────────────────────────────────────────────────────────────┘
```

#### Error-Specific Guidance

**Database Connection Failed:**

| Check | Command/Action | What to Look For |
|-------|----------------|------------------|
| Server running | `systemctl status postgresql` | Active (running) |
| Network | `ping db.example.com` | Response |
| Port open | `telnet db.example.com 5432` | Connected |
| Credentials | Check server.yml | Correct password |
| Max connections | Check DB logs | "too many connections" |
| Firewall | Check iptables/ufw | Port 5432 allowed |

**Disk Full:**

| Check | Command/Action | What to Look For |
|-------|----------------|------------------|
| Disk space | `df -h` | Usage % |
| Large files | `du -sh /var/log/*` | Oversized logs |
| Old backups | Check backup directory | Old files to delete |
| Temp files | Check /tmp | Cleanup candidates |

**Auto-cleaned:**
- Logs older than retention policy
- Temp files older than 24 hours
- Old backup files (keeps last 5)

**Permission Denied:**

| Check | Command/Action | What to Look For |
|-------|----------------|------------------|
| Directory owner | `ls -la /path/to/dir` | Correct user:group |
| Directory perms | `stat /path/to/dir` | Write permission |
| SELinux/AppArmor | `getenforce` / `aa-status` | Blocking access |
| Disk mounted | `mount` | Read-only mount |

### API Responses in Maintenance Mode

**All write operations return:**

```json
{
  "error": "Service in maintenance mode",
  "code": "MAINTENANCE_MODE",
  "status": 503,
  "message": "Server is in maintenance mode due to: Database connection failed",
  "reason": "database_connection",
  "self_healing": true,
  "retry_after": 30
}
```

**Headers:**
```
Retry-After: 30
X-Maintenance-Mode: true
X-Maintenance-Reason: database_connection
```

### /healthz in Maintenance Mode

```json
{
  "status": "maintenance",
  "version": "1.0.0",
  "mode": "maintenance",
  "uptime": "2d 5h 30m",
  "maintenance": {
    "reason": "database_connection",
    "message": "Database connection failed",
    "since": "2025-01-15T10:30:00Z",
    "self_healing": {
      "enabled": true,
      "attempts": 15,
      "last_attempt": "2025-01-15T10:35:00Z",
      "next_attempt": "2025-01-15T10:35:30Z"
    }
  },
  "checks": {
    "database": "error",
    "disk": "ok",
    "config": "ok"
  }
}
```

### Recovery (Automatic)

**When self-healing succeeds:**

```
1. Self-healing attempt succeeds
         │
         ▼
2. Verify server is stable
   - Run health checks
   - Verify read/write works
         │
         ▼
3. Log: "Issue resolved, exiting maintenance mode"
         │
         ▼
4. Exit maintenance mode
   - Set mode = normal
   - Remove maintenance banner
   - Re-enable write operations
         │
         ▼
5. Send notification (if email configured)
   - "Server recovered from maintenance mode"
   - Include duration and cause
         │
         ▼
6. Resume normal operation
```

### Maintenance Mode Config

```yaml
server:
  maintenance:
    # Self-healing settings
    self_healing:
      enabled: true
      retry_interval: 30
      # seconds between retry attempts
      max_attempts: 0
      # 0 = unlimited (keep trying forever)

    # Auto-cleanup thresholds
    cleanup:
      disk_threshold: 90
      # Start cleanup when disk > 90% full
      log_retention_days: 7
      # Delete logs older than 7 days during cleanup
      backup_keep_count: 5
      # Keep last 5 backups during cleanup

    # Notifications
    notify:
      on_enter: true
      # Notify when entering maintenance mode
      on_exit: true
      # Notify when exiting maintenance mode
```

### What Goes Where

| Setting | Single Instance | Cluster Mode | Read-Only Fallback |
|---------|-----------------|--------------|-------------------|
| Database connection | server.yml | server.yml | server.yml |
| Admin credentials | Local SQLite | Remote DB | Cached in server.yml |
| Server settings | server.yml | Remote DB | Cached in server.yml |
| Branding/SEO | server.yml | Remote DB | Cached in server.yml |
| SSL settings | server.yml | Remote DB | Cached in server.yml |
| User accounts | Local SQLite | Remote DB | ❌ Unavailable |
| Sessions | Local SQLite | Remote DB | ❌ Unavailable |
| API tokens | Local SQLite | Remote DB | ❌ Unavailable |

### server.yml Structure (Cluster Mode with Cache)

```yaml
# Database connection (always present)
server:
  database:
    driver: postgres
    host: db.example.com
    port: 5432
    name: myapp
    username: myapp
    password: ${DB_PASSWORD}
    sslmode: require

# Cached configuration (synced from database)
# Used as backup when database unavailable
_cache:
  last_sync: "2025-01-15T10:30:00Z"

  admin:
    email: admin@example.com
    # Note: password NOT cached (security)

  branding:
    title: "My Application"
    tagline: "The best app ever"

  ssl:
    enabled: true
    letsencrypt:
      enabled: true
      email: admin@example.com

  # ... all other settings cached here
```

### Database Schema for Configuration

**Configuration Table (in remote database):**

| Column | Type | Description |
|--------|------|-------------|
| `key` | String | Config key (e.g., "branding.title") |
| `value` | JSON | Config value |
| `updated_at` | Timestamp | Last update time |
| `updated_by` | String | Node ID or "admin" |

**Example data:**

| key | value | updated_at |
|-----|-------|------------|
| `branding.title` | `"My Application"` | 2025-01-15 10:30:00 |
| `branding.tagline` | `"The best app"` | 2025-01-15 10:30:00 |
| `ssl.enabled` | `true` | 2025-01-15 09:00:00 |
| `ssl.letsencrypt.enabled` | `true` | 2025-01-15 09:00:00 |
| `rate_limit.enabled` | `true` | 2025-01-14 15:00:00 |
| `rate_limit.requests` | `120` | 2025-01-14 15:00:00 |

**Cluster State Table:**

| Column | Type | Description |
|--------|------|-------------|
| `key` | String | State key |
| `value` | JSON | State value |
| `node_id` | String | Node that owns this state (or NULL for global) |
| `updated_at` | Timestamp | Last update |

**Example state data:**

| key | value | node_id | updated_at |
|-----|-------|---------|------------|
| `cluster.id` | `"cluster_abc123"` | NULL | 2025-01-10 |
| `cluster.name` | `"Production"` | NULL | 2025-01-10 |
| `encryption.key` | `"encrypted..."` | NULL | 2025-01-10 |
| `tor.onion_address` | `"abc...xyz.onion"` | `node-1` | 2025-01-15 |
| `tor.onion_address` | `"def...uvw.onion"` | `node-2` | 2025-01-15 |

### Full Database Schema Summary

**Server Tables (srv_* prefix in remote DB, or server.db in SQLite):**

| Table | Purpose |
|-------|---------|
| `config` / `srv_config` | Configuration key-value pairs |
| `config_meta` / `srv_config_meta` | Config metadata (defaults, restart flags) |
| `admin_sessions` / `srv_admin_sessions` | Admin web sessions |
| `rate_limits` / `srv_rate_limits` | Rate limiting counters |
| `audit_log` / `srv_audit_log` | Admin actions, config changes |
| `scheduler_tasks` / `srv_scheduler_tasks` | Scheduled task definitions |
| `scheduler_history` / `srv_scheduler_history` | Task execution history |
| `backups` / `srv_backups` | Backup metadata |

**User Tables (usr_* prefix in remote DB, or users.db in SQLite):**

| Table | Purpose |
|-------|---------|
| `admins` / `usr_admins` | Admin accounts |
| `users` / `usr_users` | Regular user accounts |
| `api_keys` / `usr_api_keys` | API keys |
| `password_resets` / `usr_password_resets` | Password reset tokens |
| `email_verifications` / `usr_email_verifications` | Email verification tokens |
| `totp_secrets` / `usr_totp_secrets` | TOTP 2FA secrets |
| `passkeys` / `usr_passkeys` | WebAuthn/FIDO2 credentials |
| `trusted_devices` / `usr_trusted_devices` | Remembered 2FA devices |
| `user_sessions` / `usr_user_sessions` | User web sessions |
| `custom_domains` / `usr_custom_domains` | User/org custom domains with SSL (optional) |
| `custom_domain_audit` / `usr_custom_domain_audit` | Custom domain audit log (optional) |

## Boolean Handling (NON-NEGOTIABLE)

**ALL boolean parsing in the application MUST use `config.ParseBool()` or `config.IsTruthy()`.**

This applies to:
- Environment variables (`DEBUG`, `ENABLE_*`, etc.)
- Configuration file values (YAML, JSON, TOML)
- CLI flag values
- API request parameters
- Form inputs
- Query string parameters

**Accept ALL of these values for booleans (case-insensitive):**

| Truthy | Falsy |
|--------|-------|
| `1` | `0` |
| `yes` | `no` |
| `true` | `false` |
| `enable` | `disable` |
| `enabled` | `disabled` |
| `on` | `off` |
| `yep` | `nope` |
| `yup` | `nah` |
| `yeah` | `nay` |
| `affirmative` | `negative` |
| `aye` | `nein` |
| `si` | `non` |
| `oui` | `niet` |
| `da` | `iie` |
| `hai` | `lie` |
| `totally` | `noway` |
| `sure` | `never` |
| `ok` | `deny` |
| `accept` | `reject` |
| `allow` | `block` |
| `grant` | `revoke` |
| `y` | `n` |
| `t` | `f` |

**Rules:**
- Case-insensitive: `YES`, `yes`, `Yes` all → `true`
- Internally convert all to `true` or `false`
- Empty string or unset → use default value
- Invalid value → error (don't silently default)

**Go Implementation (`src/config/bool.go`):**

```go
package config

import (
	"fmt"
	"strings"
)

// Truthy values (case-insensitive)
var truthyValues = map[string]bool{
	"1": true, "y": true, "t": true,
	"yes": true, "true": true, "on": true, "ok": true,
	"enable": true, "enabled": true,
	"yep": true, "yup": true, "yeah": true,
	"aye": true, "si": true, "oui": true, "da": true, "hai": true,
	"affirmative": true, "accept": true, "allow": true, "grant": true,
	"sure": true, "totally": true,
}

// Falsy values (case-insensitive)
var falsyValues = map[string]bool{
	"0": true, "n": true, "f": true,
	"no": true, "false": true, "off": true,
	"disable": true, "disabled": true,
	"nope": true, "nah": true, "nay": true,
	"nein": true, "non": true, "niet": true, "iie": true, "lie": true,
	"negative": true, "reject": true, "block": true, "revoke": true,
	"deny": true, "never": true, "noway": true,
}

// ParseBool parses a string into a boolean using truthy/falsy values.
// Returns the parsed value and nil on success.
// Returns false and an error for invalid values.
// Empty string returns the provided default value.
func ParseBool(s string, defaultVal bool) (bool, error) {
	s = strings.TrimSpace(strings.ToLower(s))

	if s == "" {
		return defaultVal, nil
	}

	if truthyValues[s] {
		return true, nil
	}

	if falsyValues[s] {
		return false, nil
	}

	return false, fmt.Errorf("invalid boolean value: %q", s)
}

// MustParseBool parses a string into a boolean, panics on invalid value.
// Use only during initialization where invalid config should halt startup.
func MustParseBool(s string, defaultVal bool) bool {
	val, err := ParseBool(s, defaultVal)
	if err != nil {
		panic(err)
	}
	return val
}

// IsTruthy returns true if the string is a truthy value.
// Returns false for empty, invalid, or falsy values (no error).
func IsTruthy(s string) bool {
	return truthyValues[strings.TrimSpace(strings.ToLower(s))]
}

// IsFalsy returns true if the string is a falsy value.
// Returns false for empty, invalid, or truthy values (no error).
func IsFalsy(s string) bool {
	return falsyValues[strings.TrimSpace(strings.ToLower(s))]
}
```

**Usage Examples:**

```go
// Environment variables
debug := config.MustParseBool(os.Getenv("DEBUG"), false)
enableTor := config.MustParseBool(os.Getenv("ENABLE_TOR"), true)

// Config file values (after YAML/JSON unmarshal to string)
sslEnabled, err := config.ParseBool(cfg.SSL.Enabled, false)
if err != nil {
    return fmt.Errorf("invalid ssl.enabled value: %w", err)
}

// CLI flags (custom parsing)
if config.IsTruthy(flagValue) {
    enableFeature()
}

// API request parameters
func handleRequest(w http.ResponseWriter, r *http.Request) {
    includeDeleted, _ := config.ParseBool(r.URL.Query().Get("include_deleted"), false)
    // ...
}

// Form inputs
func handleForm(w http.ResponseWriter, r *http.Request) {
    newsletter, _ := config.ParseBool(r.FormValue("subscribe_newsletter"), false)
    // ...
}

// JSON API body
type CreateUserRequest struct {
    Email    string `json:"email"`
    IsAdmin  string `json:"is_admin"`  // Accept string for flexible input
    Verified string `json:"verified"`
}

func (req *CreateUserRequest) Parse() (*User, error) {
    isAdmin, err := config.ParseBool(req.IsAdmin, false)
    if err != nil {
        return nil, fmt.Errorf("invalid is_admin: %w", err)
    }
    verified, err := config.ParseBool(req.Verified, false)
    if err != nil {
        return nil, fmt.Errorf("invalid verified: %w", err)
    }
    return &User{Email: req.Email, IsAdmin: isAdmin, Verified: verified}, nil
}
```

**NEVER use `strconv.ParseBool()` directly** - it only accepts `true/false/1/0/t/f`. Always use `config.ParseBool()` for consistent behavior across the application.

## Environment Variables (NON-NEGOTIABLE)

### Runtime Variables (Always Checked)

| Variable | Description |
|----------|-------------|
| `DOMAIN` | FQDN override (highest priority for hostname resolution) |
| `MODE` | `production` (default) or `development` |
| `DATABASE_DRIVER` | `file`, `sqlite`, `mariadb`, `mysql`, `postgres`, `mssql`, `mongodb` |
| `DATABASE_URL` | Database connection string |
| `SMTP_HOST` | SMTP server hostname (if set, skips autodetect) |
| `SMTP_PORT` | SMTP server port (default: 587) |
| `SMTP_USERNAME` | SMTP authentication username |
| `SMTP_PASSWORD` | SMTP authentication password |
| `SMTP_FROM_NAME` | Sender name (default: app title) |
| `SMTP_FROM_EMAIL` | Sender email (default: `no-reply@{fqdn}`) |
| `SMTP_TLS` | TLS mode: `auto`, `starttls`, `tls`, `none` (default: `auto`) |

**URL Variable Resolution (Reverse Proxy Preferred):**
- `{fqdn}`: Reverse Proxy Headers → `DOMAIN` → `os.Hostname()` → `$HOSTNAME` → Global IP → `localhost`
- `{proto}`: `X-Forwarded-Proto` → `X-Forwarded-Ssl` → TLS detection → `http`
- `{port}`: `X-Forwarded-Port` → Host header → Server port → Proto default

**Note:** Loopback addresses avoided; global IPs preferred. See PART 5 for full details.

### Init-Only Variables (First Run Only)

| Variable | Description |
|----------|-------------|
| `CONFIG_DIR` | Configuration directory |
| `DATA_DIR` | Data directory |
| `LOG_DIR` | Log directory |
| `DATABASE_DIR` | SQLite database directory (changeable) |
| `BACKUP_DIR` | Backup directory (changeable) |
| `PORT` | Server port |
| `LISTEN` | Listen address |
| `APPLICATION_NAME` | Application title |
| `APPLICATION_TAGLINE` | Application description |

**Init-only variables are used ONCE during first run, then ignored.**

---

## Configuration File (NON-NEGOTIABLE)

### Design Rules

| Rule | Description |
|------|-------------|
| **Clean & Intuitive** | Easy to read and understand |
| **Everything Configurable** | If it has a setting, it's in the config |
| **Sane Defaults** | Built-in defaults (no 1000-line configs) |
| **Comprehensive** | All options present (commented/defaulted) |
| **Comments** | Single-line, under 140 characters |

### Location

| User Type | Path |
|-----------|------|
| Root | `/etc/casapps/casspeed/server.yml` |
| Regular | `~/.config/casapps/casspeed/server.yml` |

### Migration

**If `server.yaml` found, auto-migrate to `server.yml` on startup.**

## Port Rules (NON-NEGOTIABLE)

**Default port is a random unused port in the 64000-64999 range.**

### Port Selection Logic

| Scenario | Port | Behavior |
|----------|------|----------|
| First run (no config) | Random 64xxx | Auto-select unused port in 64000-64999, **save to config** |
| Config specifies port | Use specified | Use exact port from config |
| Port in use | Error | Fail with clear error message |
| Privileged port (<1024) | Requires root | Warn if not running as root |

**IMPORTANT: Once a port is selected (randomly or specified), it is saved to `server.yml` and persists across restarts. The random selection only happens on first run when no port is configured.**

### Why Random 64xxx?

| Reason | Description |
|--------|-------------|
| **Avoid conflicts** | Most services use well-known ports; 64xxx is rarely used |
| **No root required** | Ports >1024 don't need root privileges |
| **Self-hosted friendly** | Users can run multiple instances without conflict |
| **Reverse proxy ready** | Designed to run behind nginx/caddy/traefik |

### Special Port Handling

| Port | Special Behavior |
|------|------------------|
| `80` | Enable Let's Encrypt HTTP-01 challenge |
| `443` | Enable Let's Encrypt TLS-ALPN-01 challenge, auto-enable SSL |
| `0` | Let OS assign any available port |
| `64000-64999` | Default range for random selection |

### Port Display Rules

| Rule | Description |
|------|-------------|
| Strip `:80` | Don't show port for HTTP on 80 |
| Strip `:443` | Don't show port for HTTPS on 443 |
| Always show others | Show port for all non-standard ports |

### Dual Port Support

**Applications can listen on two ports simultaneously for HTTP and HTTPS:**

| Format | Description | Example |
|--------|-------------|---------|
| Single | One port (HTTP; exception: port 443 = HTTPS-only; `ssl.enabled` overrides) | `8090` |
| Dual | HTTP port, HTTPS port (comma-separated) | `8090,8443` |

**Dual Port Behavior:**

| HTTP Port | HTTPS Port | Behavior |
|-----------|------------|----------|
| Any | Any | Both ports active, HTTP redirects to HTTPS optional |
| 80 | 443 | Let's Encrypt challenges enabled, standard web ports |
| 64xxx | 64xxx+1 | Common pattern for random ports |

```yaml
# Single port (HTTP by default; exception: port 443 = HTTPS-only mode; ssl.enabled overrides)
server:
  port: 8090

# Single port with ssl.enabled override (HTTPS on non-443 port)
# Forces HTTPS on port 8090
server:
  port: 8090
  ssl:
    enabled: true

# Dual port (HTTP on 8090, HTTPS on 8443)
server:
  port: "8090,8443"
  ssl:
    enabled: true

# Standard web ports
server:
  port: "80,443"
  ssl:
    enabled: true
    letsencrypt:
      enabled: true
```

### Configuration

```yaml
server:
  # Port options:
  # - Omit or empty: Random port in 64000-64999 range
  # - Single number: Use that exact port
  # - Dual (HTTP,HTTPS): "8090,8443" format
  # - 0: Let OS assign any available port
  port: 64580
```

### Admin Panel

Port can be changed via `/admin/server/settings`, but **requires server restart** (with warning shown to user).

### Example Structure

```yaml
# =============================================================================
# SERVER CONFIGURATION
# =============================================================================

server:
  # Default: random unused port in 64xxx range
  port: {random}
  # Auto-detected from host
  fqdn: {hostname}
  # [::] = all interfaces IPv4/IPv6
  address: "[::]"
  # production or development
  mode: production

  # Branding & SEO - see PART 17 for full details
  branding:
    title: "casspeed"
    tagline: ""
    description: ""
  seo:
    keywords: []

  # System user/group
  user: {auto}
  group: {auto}

  # PID file
  pidfile: true

  # Daemonize on start (detach from terminal)
  # Default: false (modern service managers prefer foreground)
  daemonize: false

  # Admin Panel
  admin:
    email: admin@{fqdn}
    # Note: username, password, and token are stored in database (admins table)
    # NOT in this config file for security

  # SSL/TLS
  ssl:
    enabled: false
    # cert/key: Optional manual override paths (leave empty for auto-detection)
    # Auto-detection order:
    #   /etc/letsencrypt/live/domain/ → system manages (certbot)
    #   /etc/letsencrypt/live/{fqdn}/ → system manages (certbot)
    #   {config_dir}/ssl/letsencrypt/{fqdn}/ → app manages (auto-renew)
    #   {config_dir}/ssl/local/{fqdn}/ → user manages (no auto-renew)
    cert: ""   # Manual cert path (optional)
    key: ""    # Manual key path (optional)
    min_version: "TLS1.2"  # TLS1.2, TLS1.3

    letsencrypt:
      enabled: false
      email: admin@{fqdn}
      challenge: http-01  # http-01, tls-alpn-01, dns-01
      staging: false      # Use staging server for testing

  # Scheduler - manages all background tasks
  scheduler:
    enabled: true
    # Built-in tasks with sane defaults (all enabled by default)
    tasks:
      # Security database updates
      geoip_update:
        enabled: true
        # Weekly: Sunday 3:00 AM
        schedule: "0 3 * * 0"
        retry_on_fail: true
        retry_delay: 1h
      blocklist_update:
        enabled: true
        # Daily: 4:00 AM
        schedule: "0 4 * * *"
        retry_on_fail: true
        retry_delay: 1h
      cve_update:
        enabled: true
        # Daily: 5:00 AM
        schedule: "0 5 * * *"
        retry_on_fail: true
        retry_delay: 1h

      # Maintenance tasks
      log_rotation:
        enabled: true
        # Daily: midnight
        schedule: "0 0 * * *"
        max_age: 30d
        max_size: 100MB
      session_cleanup:
        enabled: true
        # Hourly
        schedule: "@hourly"
      backup:
        enabled: true
        # Daily: 2:00 AM
        schedule: "0 2 * * *"
        # Keep max 4 backups (storage management)
        retention: 4

      # SSL certificate management (only when app manages certs)
      ssl_renewal:
        enabled: true
        # Daily: 3:00 AM (after backup at 2:00)
        schedule: "0 3 * * *"
        # Renew 7 days before expiry
        renew_before: 7d

      # Health checks
      health_check:
        enabled: true
        # Every 5 minutes
        schedule: "*/5 * * * *"

      # Tor maintenance
      tor_health:
        enabled: true
        # Every 10 minutes
        schedule: "*/10 * * * *"

  rate_limit:
    enabled: true
    requests: 120
    window: 60

  # Database
  database:
    driver: file

# =============================================================================
# FRONTEND CONFIGURATION
# =============================================================================

web:
  ui:
    theme: dark
  cors: "*"
```

---

# CHECKPOINT 4: CONFIGURATION VERIFICATION

Before proceeding, confirm you understand:
- [ ] Config file is `server.yml` (not .yaml)
- [ ] Boolean handling uses `config.ParseBool()` - NEVER `strconv.ParseBool()`
- [ ] All boolean inputs accept truthy/falsy values (yes, enable, oui, etc.)
- [ ] Environment variables: some runtime, some init-only
- [ ] Config auto-created on first run with sane defaults

---


# PART 6: APPLICATION MODES (NON-NEGOTIABLE)

## Mode and Debug Detection Priority

**Mode:**
1. `--mode` CLI flag (highest priority)
2. `MODE` environment variable
3. Default: `production`

**Debug:**
1. `--debug` CLI flag (highest priority)
2. `DEBUG` environment variable (truthy values)
3. Default: `false`

## Three Operational States

| State | Mode | Debug | Use Case |
|-------|------|-------|----------|
| **Production** | `production` | `false` | Live deployment, no debugging |
| **Production + Debug** | `production` | `true` | Live debugging (temporary) |
| **Development** | `development` | `false` | Local development, sensible defaults |
| **Development + Debug** | `development` | `true` | Full debugging, all features |

## Production Mode (Default)

| Setting | Behavior |
|---------|----------|
| Logging | `info` level, minimal output |
| Debug endpoints | **Disabled** (`/debug/*` returns 404) |
| pprof endpoints | **Disabled** |
| Error messages | Generic (no stack traces) |
| Panic recovery | Graceful (logs error, returns 500) |
| Template caching | Enabled |
| Static file caching | Enabled |
| Rate limiting | Enforced |
| Security headers | All enabled |
| Sensitive data | Never shown |
| Request logging | Minimal (status, duration) |

## Development Mode

**Enables sensible debugging for local development, but NOT full debug endpoints.**

| Setting | Behavior |
|---------|----------|
| Logging | `debug` level, verbose |
| Debug endpoints | **Disabled** (use `--debug` to enable) |
| pprof endpoints | **Disabled** (use `--debug` to enable) |
| Error messages | Detailed (stack traces in logs) |
| Panic recovery | Verbose (full stack in response) |
| Template caching | Disabled (hot reload) |
| Static file caching | Disabled (hot reload) |
| Rate limiting | Relaxed/disabled |
| Security headers | Relaxed (CORS permissive) |
| Sensitive data | Can be shown (with warning) |
| Request logging | Verbose (headers, body preview) |

## Debug Flag (`--debug` / `DEBUG=true`)

**Enables ALL debug features regardless of mode. Use sparingly in production.**

| Setting | Behavior |
|---------|----------|
| **Admin authentication** | **BYPASSED** (for manual dev only - NOT for automated tests) |
| Debug endpoints | **Enabled** (`/debug/*`) |
| pprof endpoints | **Enabled** (`/debug/pprof/*`) |
| expvar endpoints | **Enabled** (`/debug/vars`) |
| Request/response logging | Full (headers, body, timing) |
| Database query logging | Enabled (queries, timing, rows) |
| Cache operation logging | Enabled (hits, misses, evictions) |
| Memory profiling | Enabled |
| Goroutine monitoring | Enabled |

**Console output when debug enabled:**
```
🔒 Running in mode: production [debugging]
🔧 Running in mode: development [debugging]
```

## Mode Shortcuts

| Shortcut | Mode |
|----------|------|
| `--mode dev` | development |
| `--mode development` | development |
| `--mode prod` | production |
| `--mode production` | production |

## Debug Endpoints (`--debug` / `DEBUG=true` Only)

**Debug endpoints are ONLY available when `--debug` flag or `DEBUG=true` is set. Otherwise returns 404.**

### pprof Endpoints

| Endpoint | Purpose |
|----------|---------|
| `/debug/pprof/` | Index page with all profiles |
| `/debug/pprof/heap` | Heap memory profile |
| `/debug/pprof/goroutine` | Goroutine stack traces |
| `/debug/pprof/allocs` | Memory allocation profile |
| `/debug/pprof/block` | Blocking profile |
| `/debug/pprof/mutex` | Mutex contention profile |
| `/debug/pprof/threadcreate` | Thread creation profile |
| `/debug/pprof/cmdline` | Command line arguments |
| `/debug/pprof/profile` | CPU profile (30s default) |
| `/debug/pprof/symbol` | Symbol lookup |
| `/debug/pprof/trace` | Execution trace |

### Debug API Endpoints

| Endpoint | Method | Purpose |
|----------|--------|---------|
| `/debug/vars` | GET | Runtime variables (expvar) |
| `/debug/config` | GET | Current configuration (sanitized) |
| `/debug/routes` | GET | All registered routes |
| `/debug/cache` | GET | Cache statistics |
| `/debug/db` | GET | Database statistics |
| `/debug/scheduler` | GET | Scheduler task status |

### Debug Implementation

```go
// src/server/debug.go
package server

import (
    "expvar"
    "net/http"
    "net/http/pprof"
    "runtime"

    "github.com/go-chi/chi/v5"
)

// registerDebugRoutes registers debug endpoints (--debug/DEBUG=true only)
func (s *Server) registerDebugRoutes(r chi.Router) {
    if !s.config.IsDebug() {
        return // No debug routes unless --debug or DEBUG=true
    }

    r.Route("/debug", func(r chi.Router) {
        // pprof endpoints
        r.HandleFunc("/pprof/", pprof.Index)
        r.HandleFunc("/pprof/cmdline", pprof.Cmdline)
        r.HandleFunc("/pprof/profile", pprof.Profile)
        r.HandleFunc("/pprof/symbol", pprof.Symbol)
        r.HandleFunc("/pprof/trace", pprof.Trace)
        r.Handle("/pprof/heap", pprof.Handler("heap"))
        r.Handle("/pprof/goroutine", pprof.Handler("goroutine"))
        r.Handle("/pprof/allocs", pprof.Handler("allocs"))
        r.Handle("/pprof/block", pprof.Handler("block"))
        r.Handle("/pprof/mutex", pprof.Handler("mutex"))
        r.Handle("/pprof/threadcreate", pprof.Handler("threadcreate"))

        // expvar
        r.Handle("/vars", expvar.Handler())

        // Custom debug endpoints
        r.Get("/config", s.handleDebugConfig)
        r.Get("/routes", s.handleDebugRoutes)
        r.Get("/cache", s.handleDebugCache)
        r.Get("/db", s.handleDebugDB)
        r.Get("/scheduler", s.handleDebugScheduler)
        r.Get("/memory", s.handleDebugMemory)
        r.Get("/goroutines", s.handleDebugGoroutines)
    })
}

// handleDebugConfig returns sanitized configuration
func (s *Server) handleDebugConfig(w http.ResponseWriter, r *http.Request) {
    // Return config with sensitive values redacted
    sanitized := s.config.Sanitized()
    respondJSON(w, http.StatusOK, sanitized)
}

// handleDebugRoutes returns all registered routes
func (s *Server) handleDebugRoutes(w http.ResponseWriter, r *http.Request) {
    routes := []map[string]string{}

    walkFunc := func(method string, route string, handler http.Handler, middlewares ...func(http.Handler) http.Handler) error {
        routes = append(routes, map[string]string{
            "method": method,
            "route":  route,
        })
        return nil
    }

    if err := chi.Walk(s.router, walkFunc); err != nil {
        respondError(w, http.StatusInternalServerError, "Failed to walk routes")
        return
    }

    respondJSON(w, http.StatusOK, map[string]any{
        "count":  len(routes),
        "routes": routes,
    })
}

// handleDebugMemory returns memory statistics
func (s *Server) handleDebugMemory(w http.ResponseWriter, r *http.Request) {
    var m runtime.MemStats
    runtime.ReadMemStats(&m)

    respondJSON(w, http.StatusOK, map[string]any{
        "alloc_mb":       m.Alloc / 1024 / 1024,
        "total_alloc_mb": m.TotalAlloc / 1024 / 1024,
        "sys_mb":         m.Sys / 1024 / 1024,
        "num_gc":         m.NumGC,
        "heap_objects":   m.HeapObjects,
        "goroutines":     runtime.NumGoroutine(),
    })
}

// handleDebugGoroutines returns goroutine count and stack traces
func (s *Server) handleDebugGoroutines(w http.ResponseWriter, r *http.Request) {
    buf := make([]byte, 1024*1024) // 1MB buffer
    n := runtime.Stack(buf, true)   // true = all goroutines

    w.Header().Set("Content-Type", "text/plain; charset=utf-8")
    w.WriteHeader(http.StatusOK)
    w.Write(buf[:n])
}

// handleDebugCache returns cache statistics
func (s *Server) handleDebugCache(w http.ResponseWriter, r *http.Request) {
    stats := s.cache.Stats()
    respondJSON(w, http.StatusOK, stats)
}

// handleDebugDB returns database statistics
func (s *Server) handleDebugDB(w http.ResponseWriter, r *http.Request) {
    stats := s.db.Stats()
    respondJSON(w, http.StatusOK, map[string]any{
        "open_connections":  stats.OpenConnections,
        "in_use":            stats.InUse,
        "idle":              stats.Idle,
        "wait_count":        stats.WaitCount,
        "wait_duration_ms":  stats.WaitDuration.Milliseconds(),
        "max_idle_closed":   stats.MaxIdleClosed,
        "max_lifetime_closed": stats.MaxLifetimeClosed,
    })
}

// handleDebugScheduler returns scheduler task status
func (s *Server) handleDebugScheduler(w http.ResponseWriter, r *http.Request) {
    tasks := s.scheduler.Status()
    respondJSON(w, http.StatusOK, tasks)
}
```

### Debug Logging

```go
// src/server/debug_log.go
package server

import (
    "log/slog"
    "net/http"
    "time"
)

// debugLog logs detailed request information (--debug/DEBUG=true only)
func (s *Server) debugLog(r *http.Request, status int, duration time.Duration, size int) {
    if !s.config.IsDebug() {
        return
    }

    slog.Debug("request",
        "method", r.Method,
        "path", r.URL.Path,
        "query", r.URL.RawQuery,
        "status", status,
        "duration_ms", duration.Milliseconds(),
        "size", size,
        "remote_addr", r.RemoteAddr,
        "user_agent", r.UserAgent(),
        "referer", r.Referer(),
        "request_id", r.Header.Get("X-Request-ID"),
    )
}

// debugLogDB logs database queries (--debug/DEBUG=true only)
func (s *Server) debugLogDB(query string, args []any, duration time.Duration, err error) {
    if !s.config.IsDebug() {
        return
    }

    attrs := []any{
        "query", query,
        "duration_ms", duration.Milliseconds(),
    }

    if len(args) > 0 {
        attrs = append(attrs, "args", args)
    }

    if err != nil {
        attrs = append(attrs, "error", err.Error())
        slog.Debug("db query failed", attrs...)
    } else {
        slog.Debug("db query", attrs...)
    }
}

// debugLogCache logs cache operations (--debug/DEBUG=true only)
func (s *Server) debugLogCache(op string, key string, hit bool, duration time.Duration) {
    if !s.config.IsDebug() {
        return
    }

    slog.Debug("cache",
        "operation", op,
        "key", key,
        "hit", hit,
        "duration_us", duration.Microseconds(),
    )
}
```

### Debug Middleware

```go
// src/server/middleware_debug.go
package server

import (
    "bytes"
    "io"
    "net/http"
    "time"
)

// debugMiddleware logs detailed request/response info (--debug/DEBUG=true only)
func (s *Server) debugMiddleware(next http.Handler) http.Handler {
    if !s.config.IsDebug() {
        return next // No-op unless debug enabled
    }

    return http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {
        start := time.Now()

        // Capture request body for logging (limit to 10KB)
        var requestBody []byte
        if r.Body != nil && r.ContentLength > 0 && r.ContentLength < 10*1024 {
            requestBody, _ = io.ReadAll(r.Body)
            r.Body = io.NopCloser(bytes.NewBuffer(requestBody))
        }

        // Wrap response writer to capture status and size
        rw := &responseWriter{ResponseWriter: w, status: http.StatusOK}

        // Process request
        next.ServeHTTP(rw, r)

        // Log after request completes
        s.debugLog(r, rw.status, time.Since(start), rw.size)
    })
}

type responseWriter struct {
    http.ResponseWriter
    status int
    size   int
}

func (rw *responseWriter) WriteHeader(status int) {
    rw.status = status
    rw.ResponseWriter.WriteHeader(status)
}

func (rw *responseWriter) Write(b []byte) (int, error) {
    n, err := rw.ResponseWriter.Write(b)
    rw.size += n
    return n, err
}
```

### expvar Registration

```go
// src/server/expvar.go
package server

import (
    "expvar"
    "runtime"
    "time"
)

var (
    requestCount    = expvar.NewInt("requests_total")
    requestDuration = expvar.NewFloat("requests_duration_seconds")
    errorCount      = expvar.NewInt("errors_total")
    goroutineCount  = expvar.NewInt("goroutines")
    startTime       = time.Now()
)

func init() {
    // Publish uptime
    expvar.Publish("uptime_seconds", expvar.Func(func() any {
        return time.Since(startTime).Seconds()
    }))

    // Publish goroutine count
    expvar.Publish("goroutines", expvar.Func(func() any {
        return runtime.NumGoroutine()
    }))

    // Publish memory stats
    expvar.Publish("memory", expvar.Func(func() any {
        var m runtime.MemStats
        runtime.ReadMemStats(&m)
        return map[string]uint64{
            "alloc":       m.Alloc,
            "total_alloc": m.TotalAlloc,
            "sys":         m.Sys,
            "heap_alloc":  m.HeapAlloc,
            "heap_sys":    m.HeapSys,
        }
    }))
}

// recordRequest records a request for expvar
func recordRequest(duration time.Duration) {
    requestCount.Add(1)
    requestDuration.Add(duration.Seconds())
}

// recordError records an error for expvar
func recordError() {
    errorCount.Add(1)
}
```

### Using pprof (Commands)

```bash
# CPU profile (30 seconds)
go tool pprof http://localhost:64580/debug/pprof/profile

# Heap memory
go tool pprof http://localhost:64580/debug/pprof/heap

# Goroutines
go tool pprof http://localhost:64580/debug/pprof/goroutine

# Allocations
go tool pprof http://localhost:64580/debug/pprof/allocs

# Blocking profile (requires runtime.SetBlockProfileRate)
go tool pprof http://localhost:64580/debug/pprof/block

# Mutex contention (requires runtime.SetMutexProfileFraction)
go tool pprof http://localhost:64580/debug/pprof/mutex

# Execution trace (download and view)
curl -o trace.out http://localhost:64580/debug/pprof/trace?seconds=5
go tool trace trace.out

# Web UI for profiles
go tool pprof -http=:8081 http://localhost:64580/debug/pprof/heap
```

### Debug Configuration

```yaml
server:
  # Application mode
  mode: development  # Enables all debug features

  # Debug-specific settings (only apply in development mode)
  debug:
    # Enable pprof endpoints
    pprof: true

    # Log all SQL queries
    log_queries: true

    # Log cache operations
    log_cache: true

    # Log request/response bodies (up to max_body_log_size)
    log_bodies: false
    max_body_log_size: 10240  # 10KB

    # Block profiling rate (0 = disabled)
    block_profile_rate: 1

    # Mutex profiling fraction (0 = disabled)
    mutex_profile_fraction: 1

    # Enable runtime/debug endpoints
    runtime_endpoints: true
```

### Debug Mode Detection

```go
// src/mode/mode.go
package mode

import (
    "os"
    "runtime"
    "strings"

    "github.com/casapps/casspeed/src/config"
)

var (
    currentMode = Production
    debugEnabled = false
)

type Mode int

const (
    Production Mode = iota
    Development
)

func (m Mode) String() string {
    switch m {
    case Development:
        return "development"
    default:
        return "production"
    }
}

// Set sets the application mode
func Set(m string) {
    switch strings.ToLower(m) {
    case "dev", "development":
        currentMode = Development
    default:
        currentMode = Production
    }
    updateProfilingSettings()
}

// SetDebug enables or disables debug mode
func SetDebug(enabled bool) {
    debugEnabled = enabled
    updateProfilingSettings()
}

// updateProfilingSettings enables/disables profiling based on debug flag
func updateProfilingSettings() {
    if debugEnabled {
        // Enable profiling when debug is on
        runtime.SetBlockProfileRate(1)
        runtime.SetMutexProfileFraction(1)
    } else {
        // Disable profiling when debug is off
        runtime.SetBlockProfileRate(0)
        runtime.SetMutexProfileFraction(0)
    }
}

// Current returns the current mode
func Current() Mode {
    return currentMode
}

// IsDevelopment returns true if in development mode
func IsDevelopment() bool {
    return currentMode == Development
}

// IsProduction returns true if in production mode
func IsProduction() bool {
    return currentMode == Production
}

// IsDebug returns true if debug mode is enabled (--debug or DEBUG=true)
func IsDebug() bool {
    return debugEnabled
}

// ModeString returns mode string with debug suffix if enabled
func ModeString() string {
    s := currentMode.String()
    if debugEnabled {
        s += " [debugging]"
    }
    return s
}

// FromEnv sets mode and debug from environment variables
func FromEnv() {
    if m := os.Getenv("MODE"); m != "" {
        Set(m)
    }
    if config.IsTruthy(os.Getenv("DEBUG")) {
        SetDebug(true)
    }
}
```

---


# PART 7: SERVER BINARY CLI (NON-NEGOTIABLE)

**These are the command-line flags for the SERVER binary (`casspeed`), NOT the CLI client (`casspeed-cli`).**

## Two Different Binaries

| Binary | Default Name | Purpose | Flags |
|--------|--------------|---------|-------|
| **Server** | `casspeed` | Runs the HTTP server | `--config`, `--data`, `--log`, `--port`, `--mode`, etc. |
| **CLI Client** | `casspeed-cli` | Connects to server | `--server`, `--token`, `--output`, `--tui`, etc. |

**Shared flags:** `--help` and `--version` (both binaries support these)

**Binary naming rules:**
- Both binaries can be renamed by users
- Show ACTUAL binary name in user-facing places:
  - `--help` and `--version` output
  - Web UI titles, headers, command examples
  - Error messages showing "run X --help"
  - Any documentation/instructions shown to user
- Hardcode `casspeed` for internal identifiers:
  - User-Agent header
  - Default paths (`/etc/casapps/casspeed/`)
  - Config keys, database tables
  - API identifiers
- Hardcode `casspeed-cli` for: CLI client User-Agent

**Get actual binary name:**
```go
binaryName := filepath.Base(os.Args[0])
```

**Example:**
```
# User renames jokes to myapp
$ myapp --help
Usage: myapp [options]              # Shows actual name

# Web UI shows:
"myapp Admin Panel"                 # Shows actual name
"Run: myapp --status"               # Shows actual name

# But internally:
User-Agent: jokes/1.0.0             # Hardcoded project name
Default config: /etc/apimgr/jokes/  # Hardcoded project name
```

**For CLI client flags, see PART 34.**

**THESE SERVER COMMANDS CANNOT BE CHANGED. This is the complete command set.**

## Server Binary Commands

```bash
--help                       # Show help (can be run by anyone)
--version                    # Show version (can be run by anyone)
--mode {production|development}  # Set application mode
--config {configdir}         # Set config directory
--data {datadir}             # Set data directory
--log {logdir}               # Set log directory
--pid {pidfile}              # Set PID file path
--address {listen}           # Set listen address
--port {port}                # Set the port
--status                     # Show status and health
--service {start,restart,stop,reload,--install,--uninstall,--disable,--help}
--daemon                     # Daemonize (detach from terminal)
--debug                      # Enable debug mode (verbose logging, debug endpoints)
--maintenance {backup,restore,update,mode,setup} [optional-file-or-setting]
--update [check|yes|branch {stable|beta|daily}]  # Check/perform updates
```

## Directory Flags (NON-NEGOTIABLE)

**All directory flags MUST create directories if they don't exist.**

| Flag | Type | Default (Linux root) | Default (Linux user) |
|------|------|----------------------|----------------------|
| `--config` | Directory | `/etc/casapps/casspeed/` | `~/.config/casapps/casspeed/` |
| `--data` | Directory | `/var/lib/casapps/casspeed/` | `~/.local/share/casapps/casspeed/` |
| `--log` | Directory | `/var/log/casapps/casspeed/` | `~/.local/share/casapps/casspeed/logs/` |
| `--pid` | File | `/var/run/casapps/casspeed.pid` | `~/.local/share/casapps/casspeed/casspeed.pid` |

### Directory Validation Rules

| Rule | Description |
|------|-------------|
| **Create if missing** | All directories are created with proper permissions if they don't exist |
| **Permissions (root)** | Directories: `0755`, Files: `0644`, PID: `0644` |
| **Permissions (user)** | Directories: `0700`, Files: `0600`, PID: `0600` |
| **Parent dirs** | Create parent directories as needed (`mkdir -p` equivalent) |
| **Validate writable** | Fail fast if directory is not writable |
| **Log on create** | Log directory creation at INFO level |

### Implementation

```go
// EnsureDir creates directory with proper permissions if it doesn't exist
func EnsureDir(path string, isRoot bool) error {
    perm := os.FileMode(0700)
    if isRoot {
        perm = 0755
    }

    if err := os.MkdirAll(path, perm); err != nil {
        return fmt.Errorf("failed to create directory %s: %w", path, err)
    }

    // Verify writable
    testFile := filepath.Join(path, ".write-test")
    if err := os.WriteFile(testFile, []byte{}, 0600); err != nil {
        return fmt.Errorf("directory %s is not writable: %w", path, err)
    }
    os.Remove(testFile)

    return nil
}

// EnsurePIDFile creates PID file directory and validates path
func EnsurePIDFile(path string, isRoot bool) error {
    dir := filepath.Dir(path)
    return EnsureDir(dir, isRoot)
}
```

### PID File Handling (NON-NEGOTIABLE)

**Stale PID detection is REQUIRED.** A crash or kill -9 leaves stale PID files.

```go
// CheckPIDFile checks if PID file exists and if the process is still running
// Returns: (isRunning bool, pid int, err error)
func CheckPIDFile(pidPath string) (bool, int, error) {
    data, err := os.ReadFile(pidPath)
    if os.IsNotExist(err) {
        return false, 0, nil // No PID file, not running
    }
    if err != nil {
        return false, 0, fmt.Errorf("reading pid file: %w", err)
    }

    pid, err := strconv.Atoi(strings.TrimSpace(string(data)))
    if err != nil {
        // Corrupt PID file - remove it
        os.Remove(pidPath)
        return false, 0, nil
    }

    // Check if process is running
    if !isProcessRunning(pid) {
        // Stale PID file - remove it
        os.Remove(pidPath)
        return false, 0, nil
    }

    // Process exists - verify it's actually our process (not PID reuse)
    if !isOurProcess(pid) {
        // PID was reused by another process - remove stale file
        os.Remove(pidPath)
        return false, 0, nil
    }

    return true, pid, nil
}

// Process checking is platform-dependent - see pid_unix.go and pid_windows.go

// --- pid_unix.go ---
//go:build !windows
// +build !windows

// isProcessRunning checks if a process with given PID exists (Unix)
func isProcessRunning(pid int) bool {
    process, err := os.FindProcess(pid)
    if err != nil {
        return false
    }
    // On Unix, FindProcess always succeeds - need to send signal 0
    err = process.Signal(syscall.Signal(0))
    return err == nil
}

// isOurProcess verifies the process is actually our binary (Unix)
func isOurProcess(pid int) bool {
    // Read /proc/{pid}/exe symlink (Linux)
    exePath, err := os.Readlink(fmt.Sprintf("/proc/%d/exe", pid))
    if err != nil {
        // On macOS/BSD, use ps command
        return isOurProcessDarwin(pid)
    }
    return strings.Contains(filepath.Base(exePath), "casspeed")
}

// isOurProcessDarwin checks process on macOS/BSD
func isOurProcessDarwin(pid int) bool {
    cmd := exec.Command("ps", "-p", strconv.Itoa(pid), "-o", "comm=")
    output, err := cmd.Output()
    if err != nil {
        return false
    }
    return strings.Contains(string(output), "casspeed")
}

// --- pid_windows.go ---
//go:build windows
// +build windows

// isProcessRunning checks if a process with given PID exists (Windows)
func isProcessRunning(pid int) bool {
    // On Windows, FindProcess succeeds for any valid PID
    // Use OpenProcess with PROCESS_QUERY_LIMITED_INFORMATION to check
    process, err := os.FindProcess(pid)
    if err != nil {
        return false
    }
    // Try to get exit code - fails if process doesn't exist or no permission
    // But for our own processes, this should work
    var exitCode uint32
    handle := windows.Handle(uintptr(process.Pid))
    err = windows.GetExitCodeProcess(handle, &exitCode)
    return err == nil && exitCode == windows.STILL_ACTIVE
}

// isOurProcess verifies the process is actually our binary (Windows)
func isOurProcess(pid int) bool {
    // Use Windows API to get process image name
    handle, err := windows.OpenProcess(windows.PROCESS_QUERY_LIMITED_INFORMATION, false, uint32(pid))
    if err != nil {
        return false
    }
    defer windows.CloseHandle(handle)

    var buf [windows.MAX_PATH]uint16
    var size uint32 = windows.MAX_PATH
    err = windows.QueryFullProcessImageName(handle, 0, &buf[0], &size)
    if err != nil {
        return false
    }
    exePath := windows.UTF16ToString(buf[:size])
    return strings.Contains(strings.ToLower(filepath.Base(exePath)), "casspeed")
}

// WritePIDFile writes current process PID to file
func WritePIDFile(pidPath string) error {
    // Check for existing running instance first
    running, existingPID, err := CheckPIDFile(pidPath)
    if err != nil {
        return err
    }
    if running {
        return fmt.Errorf("already running (pid %d)", existingPID)
    }

    // Write our PID
    pid := os.Getpid()
    return os.WriteFile(pidPath, []byte(strconv.Itoa(pid)), 0644)
}

// RemovePIDFile removes PID file on shutdown
func RemovePIDFile(pidPath string) error {
    return os.Remove(pidPath)
}
```

**Startup Flow:**

```
1. Check if PID file exists
   ├─► No  → Create PID file, start server
   └─► Yes → Read PID from file
             ├─► Process running AND is our binary → Exit "already running"
             ├─► Process running BUT different binary → Remove stale, start
             └─► Process not running → Remove stale, start
```

**Shutdown Flow:**

```
1. Receive SIGTERM/SIGINT
2. Graceful shutdown (close connections, flush logs)
3. Remove PID file
4. Exit
```

**Important:**
- Always remove PID file in signal handlers
- Use defer + signal handler for cleanup
- Check for stale PIDs on EVERY startup
- Verify process identity to handle PID reuse

### Daemonization (--daemon flag)

**By default, the server runs in foreground.** Modern service managers (systemd, launchd) prefer this.

**`--service start` ignores `daemonize` setting** - it auto-detects the service manager and does the right thing.

| Start Method | Daemonize Behavior |
|--------------|-------------------|
| `--service start` (systemd) | Always foreground (ignores config) |
| `--service start` (launchd) | Always foreground (ignores config) |
| `--service start` (runit/s6) | Always foreground (ignores config) |
| `--service start` (container) | Always foreground (ignores config) |
| `--service start` (SysV init) | Always daemonize (ignores config) |
| `--service start` (rc.d/BSD) | Always daemonize (ignores config) |
| Manual start (no --service) | Respects `--daemon` flag and config |

**Container Detection (always foreground):**
- `/.dockerenv` exists
- `container` env var set
- Parent process is: `tini`, `dumb-init`, `s6-svscan`, `runsv`, `runsvdir`
- Parent process is `casspeed` (self - entrypoint wrapper)

**Manual Start Priority Order:**
1. `--daemon` CLI flag (highest)
2. `server.daemonize` config setting
3. Default: `false` (foreground)

| Flag/Config | Behavior |
|-------------|----------|
| (default) | Run in foreground |
| `--daemon` or `daemonize: true` | Fork, detach from terminal, run in background |

**Service Manager Detection:**

```go
// detectServiceManager returns the active service manager
func detectServiceManager() string {
    // Check for container environment first
    if _, err := os.Stat("/.dockerenv"); err == nil {
        return "container"
    }
    if os.Getenv("container") != "" {
        return "container"
    }

    // Check parent process name for container init systems
    parentName := getParentProcessName()
    switch parentName {
    case "tini", "dumb-init", "s6-svscan", "runsv", "runsvdir":
        return "container"
    case "casspeed":
        // Parent is our own binary - likely container entrypoint
        return "container"
    }

    // Check parent process / init system
    ppid := os.Getppid()

    // systemd: parent is systemd or PPID=1 with systemd running
    if ppid == 1 {
        if _, err := os.Stat("/run/systemd/system"); err == nil {
            return "systemd"
        }
    }
    // Also check INVOCATION_ID (set by systemd)
    if os.Getenv("INVOCATION_ID") != "" {
        return "systemd"
    }

    // launchd: macOS with PPID=1
    if runtime.GOOS == "darwin" && ppid == 1 {
        return "launchd"
    }

    // runit: check for SVDIR
    if os.Getenv("SVDIR") != "" {
        return "runit"
    }

    // s6: check for S6_* vars
    if os.Getenv("S6_LOGGING") != "" {
        return "s6"
    }

    // SysV init: /etc/init.d script, no systemd
    if ppid == 1 {
        if _, err := os.Stat("/etc/init.d"); err == nil {
            if _, err := os.Stat("/run/systemd/system"); os.IsNotExist(err) {
                return "sysv"
            }
        }
    }

    // rc.d (BSD): check for rc.subr
    if _, err := os.Stat("/etc/rc.subr"); err == nil {
        return "rcd"
    }

    return "manual"
}

// getParentProcessName returns the name of the parent process
func getParentProcessName() string {
    ppid := os.Getppid()

    // Linux: read /proc/{ppid}/comm
    if data, err := os.ReadFile(fmt.Sprintf("/proc/%d/comm", ppid)); err == nil {
        return strings.TrimSpace(string(data))
    }

    // macOS/BSD: use ps command
    cmd := exec.Command("ps", "-p", strconv.Itoa(ppid), "-o", "comm=")
    if output, err := cmd.Output(); err == nil {
        return strings.TrimSpace(string(output))
    }

    return ""
}

// shouldDaemonize determines if we should daemonize based on context
func shouldDaemonize(isServiceStart bool, daemonFlag bool, configDaemonize bool) bool {
    if isServiceStart {
        // Service start - detect manager and ignore config
        switch detectServiceManager() {
        case "systemd", "launchd", "runit", "s6", "docker", "container":
            return false // Always foreground
        case "sysv", "rcd":
            return true // Always daemonize
        default:
            return false // Unknown, default to foreground
        }
    }

    // Manual start - respect flag and config
    if daemonFlag {
        return true
    }
    return configDaemonize
}
```

**When to use `--daemon` (manual start only):**
- Starting from terminal without service manager
- Running from cron/at
- Quick testing without terminal lock

**When NOT to use `--daemon`:**
- Any `--service start` scenario (auto-detected)
- Docker/containers (use entrypoint)
- systemd/launchd/runit/s6 (they manage it)

**Daemonization Process (Unix):**

```go
// Daemonize forks the process and detaches from terminal
func Daemonize() error {
    // Already daemonized? Check if parent is init (PID 1)
    if os.Getppid() == 1 {
        return nil
    }

    // Fork by re-executing ourselves with a marker env var
    if os.Getenv("_DAEMON_CHILD") != "" {
        // We are the child - continue execution
        return nil
    }

    // Prepare to re-exec as daemon
    execPath, err := os.Executable()
    if err != nil {
        return fmt.Errorf("getting executable path: %w", err)
    }

    // Build command with same args (minus --daemon to prevent loop)
    args := filterDaemonFlag(os.Args[1:])

    cmd := exec.Command(execPath, args...)
    cmd.Env = append(os.Environ(), "_DAEMON_CHILD=1")

    // Detach from terminal
    cmd.Stdin = nil
    cmd.Stdout = nil
    cmd.Stderr = nil
    cmd.SysProcAttr = &syscall.SysProcAttr{
        Setsid: true, // Create new session (detach from controlling terminal)
    }

    if err := cmd.Start(); err != nil {
        return fmt.Errorf("starting daemon: %w", err)
    }

    // Parent exits, child continues
    fmt.Printf("Daemon started with PID %d\n", cmd.Process.Pid)
    os.Exit(0)
    return nil
}

// filterDaemonFlag removes --daemon from args to prevent infinite loop
func filterDaemonFlag(args []string) []string {
    filtered := make([]string, 0, len(args))
    for _, arg := range args {
        if arg != "--daemon" && arg != "-d" {
            filtered = append(filtered, arg)
        }
    }
    return filtered
}
```

**Daemonization (Windows):**

```go
//go:build windows
// +build windows

// Windows does NOT support traditional Unix daemonization
// Instead, use Windows Services (golang.org/x/sys/windows/svc)

func Daemonize() error {
    // On Windows, --daemon flag is ignored with a warning
    // Use Windows Service (--service install/start) instead
    fmt.Fprintln(os.Stderr, "Warning: --daemon is not supported on Windows")
    fmt.Fprintln(os.Stderr, "Use --service install && --service start for Windows Service")
    return nil // Continue in foreground
}
```

**Platform Support Summary:**

| Feature | Unix (Linux/macOS/BSD) | Windows |
|---------|------------------------|---------|
| `--daemon` flag | Forks and detaches | Ignored (use --service) |
| setsid() | Creates new session | Not supported |
| Config reload | File watcher (auto) | File watcher (auto) |
| SIGTERM/SIGINT | Full support | os.Interrupt only |
| SIGUSR1/SIGUSR2 | Supported | Not supported |
| PID file | /var/run or XDG | AppData or program dir |
| Service manager | systemd/launchd/runit | Windows SCM |

**Startup with --daemon (Unix only):**

```
1. Parse --daemon flag
2. If --daemon:
   ├─► Fork child process with _DAEMON_CHILD=1
   ├─► Child: setsid() to create new session
   ├─► Child: Close stdin/stdout/stderr
   ├─► Parent: Print "Daemon started with PID {pid}"
   └─► Parent: Exit 0
3. Child continues normal startup (PID file, server, etc.)
```

**Console Output (Unix):**

```bash
$ ./myapp --daemon
Daemon started with PID 12345

$ ./myapp --status
myapp is running (PID 12345)
```

**Console Output (Windows):**

```cmd
C:\> myapp.exe --daemon
Warning: --daemon is not supported on Windows
Use --service install && --service start for Windows Service
[Server starts in foreground]
```

### Signal Handling & Graceful Shutdown (NON-NEGOTIABLE)

**All signals MUST be handled properly for graceful shutdown. Implementation MUST be platform-dependent.**

**Unix (Linux, macOS, FreeBSD):**

| Signal | Number | Action | Description |
|--------|--------|--------|-------------|
| `SIGTERM` | 15 | Graceful shutdown | Default kill signal, clean exit |
| `SIGINT` | 2 | Graceful shutdown | Ctrl+C, clean exit |
| `SIGQUIT` | 3 | Graceful shutdown | Ctrl+\, clean exit |
| `SIGHUP` | 1 | Ignored | Config auto-reloads via file watcher |
| `SIGUSR1` | 10 | Reopen logs | Log rotation |
| `SIGUSR2` | 12 | Status dump | Dump status to log |
| `SIGRTMIN+3` | 37 | Graceful shutdown | Docker STOPSIGNAL |

**Windows:**

| Signal | Action | Description |
|--------|--------|-------------|
| `os.Interrupt` | Graceful shutdown | Ctrl+C, Ctrl+Break |
| `os.Kill` | Immediate exit | Cannot be caught (for reference) |
| Windows Service Control | Graceful shutdown | SERVICE_CONTROL_STOP from SCM |

**IMPORTANT:** Windows does NOT support SIGHUP, SIGUSR1, SIGUSR2, SIGQUIT. Use build tags to separate platform code.

**Graceful Shutdown Sequence:**

```
1. Signal received (SIGTERM/SIGINT/SIGQUIT/SIGRTMIN+3)
2. Stop accepting new connections
3. Set shutdown flag (health checks return 503)
4. Wait for in-flight requests (with timeout)
5. Close database connections
6. Flush logs and metrics
7. Stop child processes (Tor, etc.) with SIGTERM
8. Wait for children (with timeout)
9. Remove PID file
10. Exit 0
```

**Shutdown Timeouts:**

| Phase | Timeout | Action if exceeded |
|-------|---------|-------------------|
| In-flight requests | 30s | Force close connections |
| Child processes | 10s | SIGKILL children |
| Database flush | 5s | Log warning, continue |
| Log flush | 2s | Skip, exit anyway |

**Implementation (Platform-Dependent with Build Tags):**

**File: `src/signal/signal_unix.go`**

```go
//go:build !windows
// +build !windows

package signal

import (
    "log"
    "net/http"
    "os"
    "os/signal"
    "syscall"
)

// setupSignalHandler configures graceful shutdown (Unix)
func setupSignalHandler(server *http.Server, pidFile string) {
    sigChan := make(chan os.Signal, 1)
    signal.Notify(sigChan,
        syscall.SIGTERM,  // kill (default)
        syscall.SIGINT,   // Ctrl+C
        syscall.SIGQUIT,  // Ctrl+\
        syscall.SIGUSR1,  // Reopen logs
        syscall.SIGUSR2,  // Status dump
    )

    // Handle SIGRTMIN+3 (Docker STOPSIGNAL) - signal 37
    signal.Notify(sigChan, syscall.Signal(37))

    // Ignore SIGHUP - config reloads automatically via file watcher
    signal.Ignore(syscall.SIGHUP)

    go func() {
        for sig := range sigChan {
            switch sig {
            case syscall.SIGUSR1:
                log.Println("Received SIGUSR1, reopening logs...")
                reopenLogs()

            case syscall.SIGUSR2:
                log.Println("Received SIGUSR2, dumping status...")
                dumpStatus()

            default:
                // Graceful shutdown (SIGTERM, SIGINT, SIGQUIT, SIGRTMIN+3)
                log.Printf("Received %v, starting graceful shutdown...", sig)
                gracefulShutdown(server, pidFile)
            }
        }
    }()
}

// killProcess sends signal to process (Unix)
func killProcess(pid int, graceful bool) error {
    process, err := os.FindProcess(pid)
    if err != nil {
        return err
    }
    if graceful {
        return process.Signal(syscall.SIGTERM)
    }
    return process.Signal(syscall.SIGKILL)
}
```

**File: `src/signal/signal_windows.go`**

```go
//go:build windows
// +build windows

package signal

import (
    "log"
    "net/http"
    "os"
    "os/signal"
)

// setupSignalHandler configures graceful shutdown (Windows)
// Windows only supports os.Interrupt (Ctrl+C, Ctrl+Break)
func setupSignalHandler(server *http.Server, pidFile string) {
    sigChan := make(chan os.Signal, 1)
    signal.Notify(sigChan, os.Interrupt)

    go func() {
        for sig := range sigChan {
            log.Printf("Received %v, starting graceful shutdown...", sig)
            gracefulShutdown(server, pidFile)
        }
    }()
}

// killProcess terminates process (Windows)
// Windows doesn't have graceful signals - uses TerminateProcess
func killProcess(pid int, graceful bool) error {
    process, err := os.FindProcess(pid)
    if err != nil {
        return err
    }
    // Windows: Kill() calls TerminateProcess - no graceful option
    return process.Kill()
}

// NOTE: For Windows Services, use golang.org/x/sys/windows/svc
// to handle SERVICE_CONTROL_STOP properly
```

**File: `src/signal/signal.go`** (shared, platform-independent)

```go
package signal

import (
    "context"
    "log"
    "net/http"
    "os"
    "time"
)

// gracefulShutdown performs orderly shutdown (cross-platform)
func gracefulShutdown(server *http.Server, pidFile string) {
    // Set shutdown flag for health checks
    setShuttingDown(true)

    // Create context with timeout
    ctx, cancel := context.WithTimeout(context.Background(), 30*time.Second)
    defer cancel()

    // Stop accepting new connections, wait for in-flight
    if err := server.Shutdown(ctx); err != nil {
        log.Printf("HTTP server shutdown error: %v", err)
    }

    // Stop child processes (Tor, etc.) - platform-specific
    stopChildProcesses(10 * time.Second)

    // Close database connections
    closeDatabase(5 * time.Second)

    // Flush logs
    flushLogs(2 * time.Second)

    // Remove PID file
    if pidFile != "" {
        os.Remove(pidFile)
    }

    log.Println("Graceful shutdown complete")
    os.Exit(0)
}
```

**Child Process Handling (Unix) - in `signal_unix.go`:**

```go
// stopChildProcesses sends SIGTERM to children, SIGKILL after timeout (Unix)
func stopChildProcesses(timeout time.Duration) {
    for _, pid := range getChildPIDs() {
        process, err := os.FindProcess(pid)
        if err != nil {
            continue
        }

        // Send SIGTERM (graceful)
        process.Signal(syscall.SIGTERM)
    }

    // Wait with timeout, then SIGKILL
    deadline := time.Now().Add(timeout)
    for _, pid := range getChildPIDs() {
        process, _ := os.FindProcess(pid)
        for time.Now().Before(deadline) {
            if err := process.Signal(syscall.Signal(0)); err != nil {
                break // Process exited
            }
            time.Sleep(100 * time.Millisecond)
        }
        // Force kill if still running
        process.Signal(syscall.SIGKILL)
    }
}
```

**Child Process Handling (Windows) - in `signal_windows.go`:**

```go
// stopChildProcesses terminates children (Windows)
// Windows cannot send graceful signals - immediate termination only
func stopChildProcesses(timeout time.Duration) {
    for _, pid := range getChildPIDs() {
        process, err := os.FindProcess(pid)
        if err != nil {
            continue
        }
        // Windows: Kill() is immediate termination (TerminateProcess)
        process.Kill()
    }
}
```

**Smart Config Reload (NON-NEGOTIABLE):**

The app automatically watches config files and hot-reloads what it can. Settings that require restart trigger admin UI notification.

**Hot-Reloadable (auto-applied on file change):**

| Setting Category | Examples |
|------------------|----------|
| Rate limits | `ratelimit.*` |
| CORS settings | `cors.*` |
| Branding/SEO | `branding.*`, `seo.*` |
| Logging level | `logging.level` |
| Notification settings | `notifications.*`, `smtp.*` |
| Security headers | `security.headers.*` |
| Allowed origins | `cors.allowed_origins` |

**Requires Restart (admin UI shows notification):**

| Setting | Why |
|---------|-----|
| `server.port` | Bound socket cannot change |
| `server.address` | Bound socket cannot change |
| `ssl.*` | TLS listener must be recreated |
| `server.daemonize` | Process mode cannot change |
| `database.*` | Connection pool must be recreated |
| `tor.*` | Child process must be restarted |

**Implementation:**

```go
// ConfigManager manages config from both file AND database (admin WebUI)
// Changes from either source trigger hot-reload or restart notification
type ConfigManager struct {
    configPath      string
    db              *sql.DB
    lastFileModTime time.Time
    lastDBVersion   int64         // Config version in database
    pendingRestart  bool          // True if restart-required settings changed
    restartSettings []string      // Which settings need restart
    mu              sync.RWMutex
}

func (m *ConfigManager) Start() {
    go func() {
        ticker := time.NewTicker(5 * time.Second)
        for range ticker.C {
            m.checkFileChanges()
            m.checkDBChanges()
        }
    }()
}

// checkFileChanges watches config file for external edits
func (m *ConfigManager) checkFileChanges() {
    info, err := os.Stat(m.configPath)
    if err != nil || info.ModTime() == m.lastFileModTime {
        return
    }
    m.lastFileModTime = info.ModTime()

    newConfig, err := loadConfigFromFile(m.configPath)
    if err != nil {
        log.Printf("Config file parse error: %v", err)
        return
    }

    m.applyConfigChanges(newConfig, "file")

    // Sync file changes to database so admin UI sees them
    m.syncToDatabase(newConfig)
}

// checkDBChanges watches database for admin WebUI changes
func (m *ConfigManager) checkDBChanges() {
    var version int64
    err := m.db.QueryRow("SELECT version FROM config_meta WHERE id = 1").Scan(&version)
    if err != nil || version == m.lastDBVersion {
        return
    }
    m.lastDBVersion = version

    newConfig, err := loadConfigFromDB(m.db)
    if err != nil {
        log.Printf("Config DB load error: %v", err)
        return
    }

    m.applyConfigChanges(newConfig, "database")

    // Sync database changes to file so file reflects current state
    m.syncToFile(newConfig)
}

// applyConfigChanges handles both file and database config changes
func (m *ConfigManager) applyConfigChanges(newConfig *Config, source string) {
    changes := compareConfigs(currentConfig, newConfig)
    if len(changes) == 0 {
        return
    }

    hotReloadable, needsRestart := categorizeChanges(changes)

    // Apply hot-reloadable settings immediately
    if len(hotReloadable) > 0 {
        applyHotReloadSettings(newConfig, hotReloadable)
        log.Printf("Hot-reloaded from %s: %v", source, hotReloadable)
    }

    // Flag restart-required settings
    if len(needsRestart) > 0 {
        m.mu.Lock()
        m.pendingRestart = true
        m.restartSettings = needsRestart
        m.mu.Unlock()
        log.Printf("Restart required for: %v (changed via %s)", needsRestart, source)
    }
}

// syncToDatabase writes file config to database
func (m *ConfigManager) syncToDatabase(cfg *Config) {
    // Update config table, bump version
    _, err := m.db.Exec(`
        UPDATE config SET value = ? WHERE key = ?
        -- ... for each setting
    `)
    if err == nil {
        m.db.Exec("UPDATE config_meta SET version = version + 1 WHERE id = 1")
    }
}

// syncToFile writes database config to file
func (m *ConfigManager) syncToFile(cfg *Config) {
    data, _ := yaml.Marshal(cfg)
    os.WriteFile(m.configPath, data, 0644)
    // Update lastFileModTime to prevent re-reading our own write
    info, _ := os.Stat(m.configPath)
    m.lastFileModTime = info.ModTime()
}
```

**Database Schema (NON-NEGOTIABLE):**

All projects use SQLite with two database files:
- `server.db` - Server state (config, sessions, rate limits, audit, scheduler)
- `users.db` - User data (admins, users, API keys) - separate for easy backup/restore

| Database | Table | Purpose |
|----------|-------|---------|
| `server.db` | `config` | Key-value config storage |
| `server.db` | `config_meta` | Config version tracking |
| `server.db` | `sessions` | Admin WebUI login sessions |
| `server.db` | `rate_limits` | Sliding window rate limit counters |
| `server.db` | `audit_log` | Admin actions, config changes, security events |
| `server.db` | `scheduler_tasks` | Background task definitions |
| `server.db` | `scheduler_history` | Task run history |
| `server.db` | `backups` | Backup metadata and history |
| `users.db` | `admins` | Server admin accounts (WebUI access) |
| `users.db` | `users` | Regular app users (if project has users) |
| `users.db` | `api_keys` | API authentication keys |
| `users.db` | `password_resets` | Password reset tokens |
| `users.db` | `email_verifications` | Email verification tokens |
| `users.db` | `totp_secrets` | 2FA TOTP secrets and backup codes |

**Why two databases?**
- `users.db` can be backed up/restored independently
- User data is more sensitive, may have different retention policies
- Easier to migrate users between instances
- `server.db` can be recreated from config file if needed

**Database Modes:**

| Mode | Database | Cache | Use Case |
|------|----------|-------|----------|
| Single Instance | SQLite (default) | memory (default) | Development, small deployments |
| Cluster | 1+ remote databases | 1× Valkey/Redis | Multiple instances, shared state, HA |

**Cluster minimum requirements:**
- 1× remote database (PostgreSQL, MySQL, MariaDB, or MSSQL)
- 1× Valkey/Redis instance (does NOT need to be a cluster)

**Supported Databases:**

| Database | Notes |
|----------|-------|
| **PostgreSQL** | Recommended for production. Read replicas supported. SSL/TLS recommended. |
| **MySQL/MariaDB** | Full support. Read replicas supported. UTF8MB4 required. |
| **MSSQL** | Full support. Windows environments. |
| **SQLite** | Embedded, zero config. Default. See below. |
| **MongoDB** | Project-specific only. See below. |

**MongoDB (Project-Specific Use):**

MongoDB is available but NOT used for standard schema (config, sessions, admins, api_keys, etc.). Use for project-specific application data only.

**Good for:**
- Document/JSON-heavy data (logs, events, analytics)
- Flexible schemas that change frequently
- Geospatial data and queries
- Time-series data
- Projects migrating from existing MongoDB

**Example use cases:**
- `quotes` - storing quote collections with varying metadata
- `jokes` - joke database with categories, tags, nested data
- `analytics` - event tracking, user behavior logs
- `search` - document indexing alongside Elasticsearch

**Configuration (when needed):**

```yaml
# Project-specific MongoDB connection (NOT for standard schema)
mongodb:
  url: ${MONGODB_URL}  # mongodb://user:pass@host:27017/dbname
  database: myapp
  # Replica set for HA
  replica_set: rs0
  # Connection pool
  max_pool_size: 100
  min_pool_size: 10
```

**Standard schema still uses relational DB (SQLite/PostgreSQL/MySQL/MSSQL).**

**SQLite Details:**

| Feature | Description |
|---------|-------------|
| **Zero configuration** | No server, no setup, just works |
| **Embedded** | Database is a file, ships with app |
| **Automatic backups** | Scheduled backups to `{backup_dir}` |
| **Local cache mode** | Can cache remote DB data for offline/fast access |

**Good for:**
- Development and testing
- Single server deployments
- Small to medium traffic (< 100 concurrent users)
- Appliances and embedded systems
- Edge deployments with intermittent connectivity
- Desktop applications

**NOT good for:**
- Multiple app instances (no shared state)
- High write concurrency (SQLite locks on write)
- Large datasets (> 10GB, consider PostgreSQL)

**SQLite as Local Cache (with remote DB):**

```yaml
database:
  # Primary: remote database
  primary:
    driver: postgres
    url: ${DATABASE_URL}

  # Local SQLite cache for fast reads and offline resilience
  cache:
    enabled: true
    path: ${DATA_DIR}/db/cache.db
    sync_interval: 30s     # Sync from remote
    offline_mode: true     # Continue working if remote unavailable
    max_age: 1h            # Max cache age before forcing remote
```

When enabled:
- Reads check local cache first
- Writes go to remote, then update local cache
- If remote unavailable, serve from cache (read-only mode)
- Background sync keeps cache fresh

**Multiple Connections & Mixed Mode:**

Supports multiple database connections of different types with automatic sync:

```yaml
database:
  # Primary database (required)
  primary:
    driver: postgres
    url: ${DATABASE_URL}

  # Additional databases (optional, for redundancy/failover)
  replicas:
    - name: mariadb-1
      driver: mysql
      url: mysql://user:pass@mariadb1.example.com:3306/myapp
      priority: 1        # Failover priority (lower = higher priority)
      read_only: true    # Read replica

    - name: mariadb-2
      driver: mysql
      url: mysql://user:pass@mariadb2.example.com:3306/myapp
      priority: 2
      read_only: true

    - name: postgres-backup
      driver: postgres
      url: postgres://user:pass@pg-backup.example.com:5432/myapp
      priority: 3
      read_only: false   # Can be promoted to primary

    - name: mssql-legacy
      driver: mssql
      url: sqlserver://user:pass@mssql.example.com:1433?database=myapp
      priority: 10
      sync: true         # Sync data to this DB

  # Sync settings
  sync:
    enabled: true        # Auto-sync between all databases
    interval: 5s         # Sync check interval

  # Failover settings
  failover:
    enabled: true
    health_check: 10s    # Health check interval
    threshold: 3         # Failed checks before failover
```

**Failover Priority:**
- Lower number = higher priority
- Primary always tried first
- On primary failure, try replicas in priority order
- Auto-promote read-write replica if primary down

**Automatic Sync:**
- Changes written to primary, synced to all replicas
- Conflict resolution: primary wins
- Sync uses Valkey/Redis pub/sub for real-time updates

See **PART 17: SERVER CONFIGURATION** for Valkey/Redis setup.
See **PART 23: DATABASE & CLUSTER** for full cluster configuration.

**SQLite vs Remote - Key Differences:**

| Feature | SQLite | PostgreSQL/MySQL |
|---------|--------|------------------|
| Files | `server.db`, `users.db` | Single DB, prefixed tables (`srv_*`, `usr_*`) |
| Timestamps | `strftime('%s','now')` | `EXTRACT(EPOCH FROM NOW())` / `UNIX_TIMESTAMP()` |
| Auto-increment | `AUTOINCREMENT` | `SERIAL` / `AUTO_INCREMENT` |
| Upsert | `ON CONFLICT DO UPDATE` | `ON CONFLICT DO UPDATE` / `ON DUPLICATE KEY` |
| Boolean | `INTEGER (0/1)` | `BOOLEAN` / `TINYINT(1)` |

**Automatic Detection:**

```go
// If database.url provided → remote, otherwise SQLite
func OpenDatabase(cfg *Config) (*Database, error) {
    if cfg.Database.URL != "" {
        return openRemoteDB(cfg.Database.Driver, cfg.Database.URL)
    }
    // Default to SQLite
    return openSQLite(cfg.DataDir)
}
```

```sql
-- ============================================================================
-- SERVER.DB - Server state and operations
-- ============================================================================

-- Config key-value storage (mirrors YAML structure as flat keys)
CREATE TABLE IF NOT EXISTS config (
    key         TEXT PRIMARY KEY,              -- Dot notation: "server.port", "ssl.enabled"
    value       TEXT NOT NULL,                 -- JSON-encoded value (string, number, bool, array)
    type        TEXT NOT NULL DEFAULT 'string', -- string, number, bool, array, object
    updated_at  INTEGER NOT NULL DEFAULT (strftime('%s', 'now'))
);

-- Config metadata for change detection
CREATE TABLE IF NOT EXISTS config_meta (
    id          INTEGER PRIMARY KEY CHECK (id = 1),  -- Single row
    version     INTEGER NOT NULL DEFAULT 1,          -- Incremented on any change
    updated_at  INTEGER NOT NULL DEFAULT (strftime('%s', 'now'))
);

-- Initialize metadata row
INSERT OR IGNORE INTO config_meta (id, version) VALUES (1, 1);

-- Trigger to auto-increment version on config change
CREATE TRIGGER IF NOT EXISTS config_version_bump
AFTER INSERT OR UPDATE OR DELETE ON config
BEGIN
    UPDATE config_meta SET
        version = version + 1,
        updated_at = strftime('%s', 'now')
    WHERE id = 1;
END;

-- Index for fast lookups by prefix (e.g., all "ssl.*" settings)
CREATE INDEX IF NOT EXISTS idx_config_key_prefix ON config(key);

-- ----------------------------------------------------------------------------
-- Admin Sessions (admin WebUI login sessions)
-- NOTE: admin_id is a logical FK to users.db admins table (cross-DB, not enforced)
-- ----------------------------------------------------------------------------
CREATE TABLE IF NOT EXISTS admin_sessions (
    id          TEXT PRIMARY KEY,              -- Session token (secure random)
    admin_id    INTEGER NOT NULL,              -- Logical FK to admins.id in users.db
    ip_address  TEXT NOT NULL,
    user_agent  TEXT,
    created_at  INTEGER NOT NULL DEFAULT (strftime('%s', 'now')),
    expires_at  INTEGER NOT NULL,              -- Unix timestamp (default: 30 days)
    last_active INTEGER NOT NULL DEFAULT (strftime('%s', 'now'))
);

CREATE INDEX IF NOT EXISTS idx_admin_sessions_admin ON admin_sessions(admin_id);
CREATE INDEX IF NOT EXISTS idx_admin_sessions_expires ON admin_sessions(expires_at);

-- Cleanup expired sessions (run via scheduler)
-- DELETE FROM admin_sessions WHERE expires_at < strftime('%s', 'now');

-- ----------------------------------------------------------------------------
-- Rate Limiting (sliding window counters)
-- ----------------------------------------------------------------------------
CREATE TABLE IF NOT EXISTS rate_limits (
    key         TEXT PRIMARY KEY,              -- "ip:1.2.3.4:login" or "key:abc12345:global" (prefix, not hash)
    count       INTEGER NOT NULL DEFAULT 1,
    window_start INTEGER NOT NULL DEFAULT (strftime('%s', 'now')),
    updated_at  INTEGER NOT NULL DEFAULT (strftime('%s', 'now'))
);

CREATE INDEX IF NOT EXISTS idx_rate_limits_window ON rate_limits(window_start);

-- Cleanup old rate limit entries (run periodically)
-- DELETE FROM rate_limits WHERE window_start < strftime('%s', 'now') - 3600;

-- ----------------------------------------------------------------------------
-- Audit Log (admin actions, config changes, security events)
-- ----------------------------------------------------------------------------
CREATE TABLE IF NOT EXISTS audit_log (
    id          INTEGER PRIMARY KEY AUTOINCREMENT,
    timestamp   INTEGER NOT NULL DEFAULT (strftime('%s', 'now')),
    level       TEXT NOT NULL DEFAULT 'info',  -- info, warning, error, security
    category    TEXT NOT NULL,                 -- auth, config, admin, api, system
    action      TEXT NOT NULL,                 -- login, logout, config_change, user_create, etc.
    actor_type  TEXT,                          -- admin, api_key, system, anonymous
    actor_id    TEXT,                          -- admin ID, API key ID, or null
    actor_ip    TEXT,
    target_type TEXT,                          -- user, config, api_key, etc.
    target_id   TEXT,
    details     TEXT,                          -- JSON with additional context
    success     INTEGER NOT NULL DEFAULT 1     -- 1=success, 0=failure
);

CREATE INDEX IF NOT EXISTS idx_audit_timestamp ON audit_log(timestamp);
CREATE INDEX IF NOT EXISTS idx_audit_category ON audit_log(category);
CREATE INDEX IF NOT EXISTS idx_audit_actor ON audit_log(actor_type, actor_id);

-- ----------------------------------------------------------------------------
-- Scheduler (background task tracking)
-- ----------------------------------------------------------------------------
CREATE TABLE IF NOT EXISTS scheduler_tasks (
    id          TEXT PRIMARY KEY,              -- Task name: "backup", "geoip_update", "cleanup"
    enabled     INTEGER NOT NULL DEFAULT 1,
    schedule    TEXT NOT NULL,                 -- Cron expression: "0 2 * * *"
    last_run    INTEGER,                       -- Unix timestamp
    next_run    INTEGER,                       -- Unix timestamp
    last_status TEXT,                          -- success, failed, running
    last_error  TEXT,                          -- Error message if failed
    run_count   INTEGER NOT NULL DEFAULT 0,
    fail_count  INTEGER NOT NULL DEFAULT 0
);

CREATE TABLE IF NOT EXISTS scheduler_history (
    id          INTEGER PRIMARY KEY AUTOINCREMENT,
    task_id     TEXT NOT NULL,
    started_at  INTEGER NOT NULL,
    finished_at INTEGER,
    status      TEXT NOT NULL,                 -- running, success, failed
    error       TEXT,
    duration_ms INTEGER
);

CREATE INDEX IF NOT EXISTS idx_scheduler_history_task ON scheduler_history(task_id);
CREATE INDEX IF NOT EXISTS idx_scheduler_history_started ON scheduler_history(started_at);

-- Keep only last 100 runs per task (run periodically via scheduler)
-- DELETE FROM scheduler_history WHERE id NOT IN (
--     SELECT id FROM (
--         SELECT id, ROW_NUMBER() OVER (PARTITION BY task_id ORDER BY started_at DESC) as rn
--         FROM scheduler_history
--     ) WHERE rn <= 100
-- );

-- ----------------------------------------------------------------------------
-- Backups (backup history and metadata)
-- ----------------------------------------------------------------------------
CREATE TABLE IF NOT EXISTS backups (
    id          INTEGER PRIMARY KEY AUTOINCREMENT,
    filename    TEXT NOT NULL UNIQUE,          -- "backup-2025-01-15-103045.tar.gz"
    filepath    TEXT NOT NULL,                 -- Full path
    size_bytes  INTEGER NOT NULL,
    type        TEXT NOT NULL DEFAULT 'auto',  -- auto, manual, pre_update
    created_at  INTEGER NOT NULL DEFAULT (strftime('%s', 'now')),
    checksum    TEXT,                          -- SHA256
    notes       TEXT
);

CREATE INDEX IF NOT EXISTS idx_backups_created ON backups(created_at);

-- ============================================================================
-- USERS.DB - User accounts and authentication
-- ============================================================================

-- ----------------------------------------------------------------------------
-- Server Admins (admin WebUI access)
-- ----------------------------------------------------------------------------
CREATE TABLE IF NOT EXISTS admins (
    id          INTEGER PRIMARY KEY AUTOINCREMENT,
    username    TEXT NOT NULL UNIQUE,
    password    TEXT NOT NULL,                 -- Argon2id hash
    email       TEXT,
    role        TEXT NOT NULL DEFAULT 'admin', -- superadmin, admin, readonly
    enabled     INTEGER NOT NULL DEFAULT 1,
    api_token_hash TEXT,                       -- SHA-256 hash of API token (prefix: adm_)
    created_at  INTEGER NOT NULL DEFAULT (strftime('%s', 'now')),
    updated_at  INTEGER NOT NULL DEFAULT (strftime('%s', 'now')),
    last_login  INTEGER,
    failed_attempts INTEGER NOT NULL DEFAULT 0,
    locked_until INTEGER,                      -- Account lockout timestamp
    -- OIDC/LDAP sync fields (null for local accounts)
    source      TEXT NOT NULL DEFAULT 'local', -- local, oidc:{provider}, ldap
    external_id TEXT,                          -- Provider's user ID
    groups      TEXT,                          -- JSON array of group memberships
    last_sync   INTEGER                        -- Last OIDC/LDAP sync timestamp
);

CREATE UNIQUE INDEX IF NOT EXISTS idx_admins_username ON admins(username);

-- ----------------------------------------------------------------------------
-- Regular Users (app users - ONLY if project has user accounts)
-- ----------------------------------------------------------------------------
CREATE TABLE IF NOT EXISTS users (
    id          INTEGER PRIMARY KEY AUTOINCREMENT,
    username    TEXT NOT NULL UNIQUE,
    email       TEXT UNIQUE,
    password    TEXT NOT NULL,                 -- Argon2id hash
    display_name TEXT,
    avatar_url  TEXT,
    role        TEXT NOT NULL DEFAULT 'user',  -- user, moderator, premium, etc.
    enabled     INTEGER NOT NULL DEFAULT 1,
    verified    INTEGER NOT NULL DEFAULT 0,    -- Email verified
    created_at  INTEGER NOT NULL DEFAULT (strftime('%s', 'now')),
    updated_at  INTEGER NOT NULL DEFAULT (strftime('%s', 'now')),
    last_login  INTEGER,
    failed_attempts INTEGER NOT NULL DEFAULT 0,
    locked_until INTEGER,                      -- Account lockout timestamp
    metadata    TEXT                           -- JSON for app-specific data
);

CREATE UNIQUE INDEX IF NOT EXISTS idx_users_username ON users(username);
CREATE UNIQUE INDEX IF NOT EXISTS idx_users_email ON users(email);

-- ----------------------------------------------------------------------------
-- API Keys (for API authentication)
-- ----------------------------------------------------------------------------
CREATE TABLE IF NOT EXISTS api_keys (
    id          INTEGER PRIMARY KEY AUTOINCREMENT,
    key_hash    TEXT NOT NULL UNIQUE,          -- SHA256 of the key (never store plaintext)
    key_prefix  TEXT NOT NULL,                 -- First 8 chars for identification: "abc12345..."
    name        TEXT NOT NULL,                 -- Friendly name: "Production API"
    owner_type  TEXT NOT NULL,                 -- admin, user
    owner_id    INTEGER NOT NULL,              -- FK to admins or users
    scopes      TEXT,                          -- JSON array: ["read", "write", "admin"]
    rate_limit  INTEGER,                       -- Override default rate limit (requests/min)
    enabled     INTEGER NOT NULL DEFAULT 1,
    created_at  INTEGER NOT NULL DEFAULT (strftime('%s', 'now')),
    expires_at  INTEGER,                       -- Null = never expires
    last_used   INTEGER,
    use_count   INTEGER NOT NULL DEFAULT 0
);

CREATE UNIQUE INDEX IF NOT EXISTS idx_api_keys_hash ON api_keys(key_hash);
CREATE INDEX IF NOT EXISTS idx_api_keys_prefix ON api_keys(key_prefix);
CREATE INDEX IF NOT EXISTS idx_api_keys_owner ON api_keys(owner_type, owner_id);

-- ----------------------------------------------------------------------------
-- Password Reset Tokens
-- ----------------------------------------------------------------------------
CREATE TABLE IF NOT EXISTS password_resets (
    id          INTEGER PRIMARY KEY AUTOINCREMENT,
    token_hash  TEXT NOT NULL UNIQUE,          -- SHA256 of token
    user_type   TEXT NOT NULL,                 -- admin, user
    user_id     INTEGER NOT NULL,
    created_at  INTEGER NOT NULL DEFAULT (strftime('%s', 'now')),
    expires_at  INTEGER NOT NULL,
    used_at     INTEGER
);

CREATE INDEX IF NOT EXISTS idx_password_resets_expires ON password_resets(expires_at);

-- Cleanup expired/used tokens (run periodically via scheduler)
-- DELETE FROM password_resets WHERE expires_at < strftime('%s', 'now') OR used_at IS NOT NULL;

-- ----------------------------------------------------------------------------
-- Email Verification Tokens (for user email verification)
-- ----------------------------------------------------------------------------
CREATE TABLE IF NOT EXISTS email_verifications (
    id          INTEGER PRIMARY KEY AUTOINCREMENT,
    token_hash  TEXT NOT NULL UNIQUE,          -- SHA256 of token
    user_type   TEXT NOT NULL,                 -- admin, user
    user_id     INTEGER NOT NULL,
    email       TEXT NOT NULL,                 -- Email being verified
    created_at  INTEGER NOT NULL DEFAULT (strftime('%s', 'now')),
    expires_at  INTEGER NOT NULL,
    verified_at INTEGER
);

CREATE INDEX IF NOT EXISTS idx_email_verifications_expires ON email_verifications(expires_at);

-- Cleanup expired/used tokens (run periodically via scheduler)
-- DELETE FROM email_verifications WHERE expires_at < strftime('%s', 'now') OR verified_at IS NOT NULL;

-- ----------------------------------------------------------------------------
-- TOTP Secrets (for 2FA - admin only by default)
-- ----------------------------------------------------------------------------
CREATE TABLE IF NOT EXISTS totp_secrets (
    id          INTEGER PRIMARY KEY AUTOINCREMENT,
    user_type   TEXT NOT NULL,                 -- admin (users can be added per-project)
    user_id     INTEGER NOT NULL UNIQUE,       -- One TOTP per user
    secret      TEXT NOT NULL,                 -- Encrypted TOTP secret
    enabled     INTEGER NOT NULL DEFAULT 0,    -- 0=setup pending, 1=active
    backup_codes TEXT,                         -- JSON array of hashed backup codes
    created_at  INTEGER NOT NULL DEFAULT (strftime('%s', 'now')),
    last_used   INTEGER
);

CREATE UNIQUE INDEX IF NOT EXISTS idx_totp_user ON totp_secrets(user_type, user_id);

-- ----------------------------------------------------------------------------
-- User Sessions (app user login sessions - ONLY if project has user accounts)
-- ----------------------------------------------------------------------------
CREATE TABLE IF NOT EXISTS user_sessions (
    id          TEXT PRIMARY KEY,              -- Session token (secure random)
    user_id     INTEGER NOT NULL,              -- FK to users.id
    ip_address  TEXT NOT NULL,
    user_agent  TEXT,
    created_at  INTEGER NOT NULL DEFAULT (strftime('%s', 'now')),
    expires_at  INTEGER NOT NULL,              -- Unix timestamp (default: 7 days)
    last_active INTEGER NOT NULL DEFAULT (strftime('%s', 'now'))
);

CREATE INDEX IF NOT EXISTS idx_user_sessions_user ON user_sessions(user_id);
CREATE INDEX IF NOT EXISTS idx_user_sessions_expires ON user_sessions(expires_at);

-- Cleanup expired sessions (run via scheduler)
-- DELETE FROM user_sessions WHERE expires_at < strftime('%s', 'now');

-- ----------------------------------------------------------------------------
-- Passkeys (WebAuthn/FIDO2 credentials)
-- ----------------------------------------------------------------------------
CREATE TABLE IF NOT EXISTS passkeys (
    id              TEXT PRIMARY KEY,              -- WebAuthn credential ID (base64url)
    user_type       TEXT NOT NULL,                 -- admin, user
    user_id         INTEGER NOT NULL,              -- FK to admins or users
    name            TEXT NOT NULL,                 -- User-friendly name: "MacBook Pro Touch ID"
    public_key      TEXT NOT NULL,                 -- WebAuthn public key (base64)
    sign_count      INTEGER NOT NULL DEFAULT 0,    -- Signature counter (replay protection)
    transports      TEXT,                          -- JSON array: ["usb", "nfc", "ble", "internal"]
    aaguid          TEXT,                          -- Authenticator AAGUID
    created_at      INTEGER NOT NULL DEFAULT (strftime('%s', 'now')),
    last_used       INTEGER
);

CREATE INDEX IF NOT EXISTS idx_passkeys_user ON passkeys(user_type, user_id);

-- ----------------------------------------------------------------------------
-- Trusted Devices (skip 2FA for remembered devices)
-- ----------------------------------------------------------------------------
CREATE TABLE IF NOT EXISTS trusted_devices (
    id          TEXT PRIMARY KEY,              -- Device token (secure random)
    user_type   TEXT NOT NULL,                 -- admin, user
    user_id     INTEGER NOT NULL,              -- FK to admins or users
    device_hash TEXT NOT NULL,                 -- SHA256(user_agent + ip partial)
    name        TEXT,                          -- "Chrome on Windows" (auto-detected)
    created_at  INTEGER NOT NULL DEFAULT (strftime('%s', 'now')),
    expires_at  INTEGER NOT NULL,              -- 30 days from creation
    last_used   INTEGER
);

CREATE INDEX IF NOT EXISTS idx_trusted_devices_user ON trusted_devices(user_type, user_id);
CREATE INDEX IF NOT EXISTS idx_trusted_devices_expires ON trusted_devices(expires_at);

-- Cleanup expired trusted devices (run via scheduler)
-- DELETE FROM trusted_devices WHERE expires_at < strftime('%s', 'now');
```

**Example Config Data:**

```sql
-- Flat key-value pairs (dot notation matches YAML structure)
INSERT INTO config (key, value, type) VALUES
    ('server.port', '8080', 'number'),
    ('server.address', '"0.0.0.0"', 'string'),
    ('ssl.enabled', 'true', 'bool'),
    ('ssl.cert', '""', 'string'),                    -- Empty = auto-detect
    ('ssl.key', '""', 'string'),                     -- Empty = auto-detect
    ('ssl.min_version', '"TLS1.2"', 'string'),
    ('cors.allowed_origins', '["https://example.com","https://api.example.com"]', 'array'),
    ('ratelimit.requests_per_minute', '60', 'number'),
    ('branding.site_name', '"My App"', 'string');
```

**Config Load/Save Helpers:**

```go
// loadConfigFromDB loads config from database into struct
func loadConfigFromDB(db *sql.DB) (*Config, error) {
    rows, err := db.Query("SELECT key, value, type FROM config")
    if err != nil {
        return nil, err
    }
    defer rows.Close()

    cfg := &Config{}
    for rows.Next() {
        var key, value, typ string
        rows.Scan(&key, &value, &typ)

        // Parse JSON value and set on config struct
        if err := setConfigValue(cfg, key, value, typ); err != nil {
            log.Printf("Config key %s parse error: %v", key, err)
        }
    }
    return cfg, nil
}

// saveConfigToDB saves config struct to database
func saveConfigToDB(db *sql.DB, cfg *Config) error {
    tx, _ := db.Begin()
    defer tx.Rollback()

    // Flatten config struct to key-value pairs
    pairs := flattenConfig(cfg)

    stmt, _ := tx.Prepare(`
        INSERT INTO config (key, value, type, updated_at)
        VALUES (?, ?, ?, strftime('%s', 'now'))
        ON CONFLICT(key) DO UPDATE SET
            value = excluded.value,
            type = excluded.type,
            updated_at = strftime('%s', 'now')
    `)
    defer stmt.Close()

    for _, p := range pairs {
        stmt.Exec(p.Key, p.Value, p.Type)
    }

    return tx.Commit()
}

// flattenConfig converts nested struct to flat key-value pairs
func flattenConfig(cfg *Config) []ConfigPair {
    // Uses reflection to walk struct and build dot-notation keys
    // server.port, ssl.enabled, cors.allowed_origins, etc.
    return flattenStruct(reflect.ValueOf(cfg), "")
}
```

**Config Priority (NON-NEGOTIABLE):**

```
1. CLI flags (highest priority)
2. Environment variables
3. Database (admin WebUI changes)
4. Config file (config.yml)
5. Defaults (lowest priority)
```

On startup, merge all sources. Database and file stay in sync via ConfigManager.

```go
// Settings that require restart
var restartRequiredSettings = []string{
    "server.port",
    "server.address",
    "ssl.enabled",
    "ssl.cert",
    "ssl.key",
    "ssl.min_version",
    "server.daemonize",
    "database.path",
    "tor.enabled",
}

func categorizeChanges(changes []string) (hotReload, needsRestart []string) {
    for _, setting := range changes {
        requiresRestart := false
        for _, rs := range restartRequiredSettings {
            if strings.HasPrefix(setting, rs) {
                requiresRestart = true
                break
            }
        }
        if requiresRestart {
            needsRestart = append(needsRestart, setting)
        } else {
            hotReload = append(hotReload, setting)
        }
    }
    return
}
```

**Admin UI Restart Notification:**

```go
// GET /admin/api/status returns pending restart info
func adminStatusHandler(w http.ResponseWriter, r *http.Request) {
    status := map[string]interface{}{
        "running":         true,
        "pending_restart": configManager.PendingRestart(),
        "restart_reason":  configManager.RestartSettings(),
    }
    json.NewEncoder(w).Encode(status)
}
```

**Admin UI displays:**
```
┌─────────────────────────────────────────────────────────┐
│ ⚠️  Restart Required                                    │
│                                                         │
│ The following settings require a restart to take effect:│
│ • server.port                                           │
│ • ssl.enabled                                           │
│                                                         │
│ [Restart Now]  [Dismiss]                                │
└─────────────────────────────────────────────────────────┘
```

**Health Check Endpoint (`/healthz`):**

```go
// GET /healthz - used by load balancers, orchestrators, monitoring
func healthHandler(w http.ResponseWriter, r *http.Request) {
    w.Header().Set("Content-Type", "application/json")

    status := struct {
        Status         string   `json:"status"`
        PendingRestart bool     `json:"pending_restart,omitempty"`
        RestartReason  []string `json:"restart_reason,omitempty"`
    }{
        Status: "ok",
    }

    // Check shutdown state
    if isShuttingDown() {
        status.Status = "shutting_down"
        w.WriteHeader(http.StatusServiceUnavailable)
        json.NewEncoder(w).Encode(status)
        return
    }

    // Check pending restart (config changed, needs restart)
    if configManager.PendingRestart() {
        status.Status = "restart_required"
        status.PendingRestart = true
        status.RestartReason = configManager.RestartSettings()
        // Still return 200 - service is running, just needs restart
        // Orchestrators can watch pending_restart field
    }

    w.WriteHeader(http.StatusOK)
    json.NewEncoder(w).Encode(status)
}

// ConfigManager helper methods
func (m *ConfigManager) PendingRestart() bool {
    m.mu.RLock()
    defer m.mu.RUnlock()
    return m.pendingRestart
}

func (m *ConfigManager) RestartSettings() []string {
    m.mu.RLock()
    defer m.mu.RUnlock()
    return m.restartSettings
}

func (m *ConfigManager) ClearPendingRestart() {
    m.mu.Lock()
    defer m.mu.Unlock()
    m.pendingRestart = false
    m.restartSettings = nil
}
```

**Health Check Responses:**

```json
// Normal operation
{"status": "ok"}

// Restart required (service running but config changed)
{"status": "restart_required", "pending_restart": true, "restart_reason": ["ssl.enabled", "server.port"]}

// Shutting down
{"status": "shutting_down"}
```

**Orchestrator Integration:**

```yaml
# Kubernetes - check pending_restart for rolling updates
livenessProbe:
  httpGet:
    path: /healthz
    port: 8080
  # Don't fail on restart_required - service is still live

# Custom controller can watch for pending_restart and trigger rollout
```

**Console Output:**

```
$ kill -TERM $(cat /var/run/myapp.pid)

[INFO] 2025-01-15 10:30:45 Received SIGTERM, starting graceful shutdown...
[INFO] 2025-01-15 10:30:45 Stopping HTTP server...
[INFO] 2025-01-15 10:30:46 Waiting for 3 in-flight requests...
[INFO] 2025-01-15 10:30:47 HTTP server stopped
[INFO] 2025-01-15 10:30:47 Stopping Tor process (PID 12346)...
[INFO] 2025-01-15 10:30:48 Tor stopped
[INFO] 2025-01-15 10:30:48 Closing database connections...
[INFO] 2025-01-15 10:30:48 Flushing logs...
[INFO] 2025-01-15 10:30:48 Removing PID file...
[INFO] 2025-01-15 10:30:48 Graceful shutdown complete
```

### Environment Variable Fallbacks (NON-NEGOTIABLE)

**Server binary directory flags accept corresponding environment variables as fallbacks.**

**Priority order:** Server binary CLI flag > Environment variable > Default

| CLI Flag | Env Variable | Description |
|----------|--------------|-------------|
| `--config` | `CONFIG_DIR` | Configuration directory |
| `--data` | `DATA_DIR` | Data directory |
| `--log` | `LOG_DIR` | Log directory |
| `--pid` | `PID_FILE` | PID file path |
| `--port` | `PORT` | Listen port |
| `--address` | `LISTEN` | Listen address |
| `--mode` | `MODE` | Application mode (production/development) |
| (none) | `DATABASE_DIR` | SQLite database directory (defaults to `{datadir}/db/`, changeable) |
| (none) | `BACKUP_DIR` | Backup directory (defaults to `{datadir}/backup/`, changeable) |

**External backup mounts:** In production, `BACKUP_DIR` should typically point to external storage (NAS, separate disk, etc.) rather than staying under `{datadir}`. Example: `BACKUP_DIR=/mnt/Backups/casapps/casspeed`. The default `{datadir}/backup/` is for development/testing only.

**Implementation:**

```go
// GetConfigDir returns config directory from flag, env, or default
func GetConfigDir(flagValue string) string {
    if flagValue != "" {
        return flagValue
    }
    if envValue := os.Getenv("CONFIG_DIR"); envValue != "" {
        return envValue
    }
    return defaultConfigDir() // OS-specific default
}

// GetDatabaseDir returns database directory (always under data dir)
// This ensures SQLite is NEVER in {datadir} root, always in {datadir}/db/
func GetDatabaseDir(dataDir string) string {
    if envValue := os.Getenv("DATABASE_DIR"); envValue != "" {
        return envValue
    }
    return filepath.Join(dataDir, "db")
}
```

**Container defaults (set by entrypoint.sh):**

```bash
# Configurable paths (via env vars or CLI flags)
export CONFIG_DIR="/config"
export DATA_DIR="/data"
export LOG_DIR="/data/logs"
export DATABASE_DIR="/data/db"
export BACKUP_DIR="/data/backup"

# Fixed subdirectories (always under DATA_DIR)
TOR_DATA_DIR="${DATA_DIR}/tor"
```

### Docker Compose Mapping

**Directory flags enable clean volume mounts:**

```yaml
services:
  casspeed:
    image: ghcr.io/casapps/casspeed:latest
    command:
      - --config=/config
      - --data=/data
      - --log=/logs
      - --pid=/run/casspeed.pid
      - --port=8080
    volumes:
      - config:/config:ro          # Config (read-only)
      - data:/data                 # Data (read-write)
      - logs:/logs                 # Logs (read-write)
      - /var/run:/run                # PID file
    ports:
      - "8080:8080"
```

**Minimal compose (uses container defaults):**

```yaml
services:
  casspeed:
    image: ghcr.io/casapps/casspeed:latest
    volumes:
      - casspeed-data:/data
    ports:
      - "8080:8080"

volumes:
  casspeed-data:
```

### Commands Anyone Can Run (No Privileges)

- `--help`
- `--version`
- `--status`
- `--update check`

## Display Rules (NON-NEGOTIABLE)

| Rule | Description |
|------|-------------|
| Never show | `0.0.0.0`, `127.0.0.1`, `localhost` |
| Always show | Valid FQDN, host, or IP |
| Show only | One address, the most relevant |

## URL & FQDN Detection (NON-NEGOTIABLE)

**CRITICAL: Never hardcode host, IP, or port in project code. Always detect dynamically.**

### URL Display Rules

| Rule | Description |
|------|-------------|
| **NEVER hardcode** | `localhost`, `127.0.0.1`, `0.0.0.0`, `[::1]`, any static host/IP |
| **NEVER display** | `GET /api/`, `POST /api/` without full URL |
| **ALWAYS use** | `{proto}://{fqdn}:{port}/path` format |
| **ALWAYS detect** | `{proto}`, `{fqdn}`, `{port}` from request context |
| **ALWAYS strip** | `:80` for HTTP, `:443` for HTTPS |
| **Default proto** | `http` if not detected |

### URL Format Examples

| WRONG | RIGHT |
|-------|-------|
| `GET /api/v1/resource/random` | `https://api.example.com/api/v1/resource/random` |
| `POST /api/v1/admin/server/settings` | `https://api.example.com/api/v1/admin/server/settings` |
| `http://localhost:8080/api` | `http://192.168.1.100:64580/api` |
| `http://0.0.0.0:80/healthz` | `https://myserver.example.com/healthz` |

### URL Variables (NON-NEGOTIABLE)

**Three variables for building URLs: `{proto}`, `{fqdn}`, `{port}`**

All templates, Swagger/OpenAPI, GraphQL, email links, etc. MUST use these resolved variables.

| Variable | Description | Example |
|----------|-------------|---------|
| `{proto}` | Protocol (http/https) | `https` |
| `{fqdn}` | Fully qualified domain name | `api.example.com` |
| `{port}` | Port number (ALWAYS stripped if 80/443) | `8080` or empty |

**URL Format:** `{proto}://{fqdn}/path` or `{proto}://{fqdn}:{port}/path`

**Port Stripping (NON-NEGOTIABLE):**
- `:80` and `:443` are NEVER included in URLs
- `{port}` returns empty string for 80/443
- Only non-standard ports appear in URLs

### Resolution Order (Reverse Proxy Preferred)

**We prefer to run behind a reverse proxy. Reverse proxy headers take priority.**

**`{fqdn}` Resolution:**

| Priority | Source | Description |
|----------|--------|-------------|
| 1 | **Reverse Proxy Headers** | `X-Forwarded-Host`, `X-Real-Host`, `X-Original-Host` |
| 2 | **DOMAIN env var** | Comma-separated list (first is primary) |
| 3 | **os.Hostname()** | Go's hostname function |
| 4 | **$HOSTNAME env var** | Shell fallback |
| 5 | **Public IPv6** | First public IPv6 (excludes private/link-local) |
| 6 | **Public IPv4** | First public IPv4 (excludes 10/8, 172.16/12, 192.168/16) |
| 7 | **localhost** | Last resort |

**Public IP Detection (Go 1.17+):**
- Uses `ip.IsGlobalUnicast() && !ip.IsPrivate()`
- IPv4 excludes: `10.0.0.0/8`, `172.16.0.0/12`, `192.168.0.0/16`, `169.254.0.0/16`, `127.0.0.0/8`
- IPv6 excludes: `::1`, `fe80::/10` (link-local), `fc00::/7` (unique local)

**DOMAIN Environment Variable (Comma-Separated List):**

```bash
# Single domain
DOMAIN=myapp.com

# Multiple domains (first is primary)
DOMAIN=myapp.com,www.myapp.com,api.myapp.com
```

| Behavior | Description |
|----------|-------------|
| First domain is primary | Used as `{fqdn}` and `GetBaseDomain()` |
| Auto-infer wildcard | Same base domain → `*.myapp.com` |
| Skip learning | If DOMAIN set, no need to learn from requests |
| CORS auto-configured | All listed domains added to allowed origins |
| Validate on startup | Invalid domains cause startup warning |

**Examples:**

```bash
# Explicit list - skips learning
DOMAIN=myapp.com,www.myapp.com,api.myapp.com
# Result: fqdn=myapp.com, wildcard=*.myapp.com

# Single domain - still learns subdomains from requests
DOMAIN=myapp.com
# Result: fqdn=myapp.com, wildcard learned if www/api seen

# Not set - full auto-detection
# Result: learned from reverse proxy headers
```

**`{proto}` Resolution:**

| Priority | Source | Description |
|----------|--------|-------------|
| 1 | `X-Forwarded-Proto` | `https` or `http` |
| 2 | `X-Forwarded-Ssl` | `on` → https |
| 3 | `X-Url-Scheme` | `https` or `http` |
| 4 | **TLS on connection** | If TLS → https |
| 5 | **Default** | `http` |

**`{port}` Resolution:**

| Priority | Source | Description |
|----------|--------|-------------|
| 1 | `X-Forwarded-Port` | Port from proxy |
| 2 | **Host header port** | `example.com:8080` → 8080 |
| 3 | **Server listen port** | Actual port server is on |
| 4 | **Proto default** | https → 443, http → 80 |

**Reverse Proxy Headers (All Checked):**

| Header | Provides |
|--------|----------|
| `X-Forwarded-Host` | `{fqdn}` |
| `X-Forwarded-Proto` | `{proto}` |
| `X-Forwarded-Port` | `{port}` |
| `X-Forwarded-Ssl` | `{proto}` (on=https) |
| `X-Real-Host` | `{fqdn}` (fallback) |
| `X-Original-Host` | `{fqdn}` (fallback) |
| `X-Url-Scheme` | `{proto}` (fallback) |
| `X-Forwarded-For` | Request IP (for logging) |
| `X-Real-IP` | Request IP (fallback) |

### Smart FQDN Detection (Live Reload)

**App automatically detects and learns domain patterns from reverse proxy headers:**

When reverse proxy headers are detected, the app:
1. **Live reloads** URL variables immediately (no restart required)
2. **Infers wildcard domains** from observed patterns
3. **Updates cached values** for Swagger/GraphQL/templates

**Domain Learning Algorithm:**

```
Observation History:
  Request 1: myapp.com
  Request 2: www.myapp.com
  Request 3: api.myapp.com
  Request 4: myapp.com

Inference:
  Base domain: myapp.com
  Pattern: *.myapp.com (wildcard detected)
  Primary FQDN: myapp.com (most frequent non-www)
```

**Detection Rules:**

| Scenario | Detection | Result |
|----------|-----------|--------|
| Same domain repeated | Stable | Use as `{fqdn}` |
| www + apex seen | Wildcard | Infer `*.domain.com`, use apex as primary |
| Multiple subdomains | Wildcard | Infer `*.domain.com`, use most common |
| Conflicting domains | Warning | Log warning, use most recent |
| IP then domain | Upgrade | Switch to domain, log detection |

**Live Reload Triggers:**

| Trigger | Action |
|---------|--------|
| First reverse proxy header detected | Reload all URL vars |
| Domain change detected | Reload, log change |
| Proto change (http→https) | Reload, log upgrade |
| Conflicting headers | Log warning, use priority order |

**Configuration:**

```yaml
server:
  url_detection:
    # Enable smart domain learning
    learning: true
    # Minimum requests before inferring wildcard
    min_samples: 3
    # Time window for pattern analysis (duration)
    sample_window: 5m
    # Log domain changes to application log
    log_changes: true
    # Allow live reload without restart
    live_reload: true
```

**Sane Defaults:**
- Learning enabled
- 3 samples minimum for wildcard inference
- 5 minute sample window
- Log all domain changes
- Live reload enabled

**Usage in Code:**

```go
// GetURLVars returns resolved URL variables from request
// Checks reverse proxy headers first, triggers live reload on detection
// Port is empty string for 80/443 (always stripped)
func GetURLVars(r *http.Request) (proto, fqdn, port string)

// BuildURL constructs full URL with automatic port stripping
// :80 and :443 are NEVER included
func BuildURL(r *http.Request, path string) string {
    proto, fqdn, port := GetURLVars(r)
    if port == "" {
        return fmt.Sprintf("%s://%s%s", proto, fqdn, path)
    }
    return fmt.Sprintf("%s://%s:%s%s", proto, fqdn, port, path)
}

// GetBaseDomain returns inferred base domain from learning
// Returns: "myapp.com" even if accessed via "www.myapp.com"
func GetBaseDomain() string

// GetWildcardDomain returns inferred wildcard if detected
// Returns: "*.myapp.com" or empty if no wildcard pattern
func GetWildcardDomain() string
```

**Usage in Templates/Swagger/GraphQL:**

| Component | Base URL Source |
|-----------|-----------------|
| HTML templates | `BuildURL(r, "/path")` |
| Swagger/OpenAPI | `servers[0].url` = `BuildURL(r, "")` |
| GraphQL | `BuildURL(r, "/graphql")` |
| Email links | `BuildURL(r, "/verify")` |
| CORS origins | Auto-include `GetWildcardDomain()` if detected |
| OAuth callbacks | `BuildURL(r, "/auth/callback")` |

### FQDN/Host Validation Rules

**Uses `golang.org/x/net/publicsuffix` for proper TLD validation.**

**go.mod:**
```
require golang.org/x/net v0.33.0
```

This properly handles complex suffixes like `.co.uk`, `.com.au`, `.org.uk`, etc.

**Production Mode (Strict):**

| Valid | Invalid |
|-------|---------|
| `api.example.com` | `localhost` |
| `my.server.domain.co.uk` | `dev.local` |
| `app.company.com.au` | `app.test` |
| `server.company.io` | `192.168.1.1` (IP address) |
| | `myhost` (single-label) |

**Development Mode (Relaxed):**

| Valid | Invalid |
|-------|---------|
| `api.example.com` | `192.168.1.1` (IP address) |
| `localhost` | `myhost` (single-label, not localhost) |
| `dev.local` | `devbox` (single-label) |
| `app.test` | |
| `staging.internal` | |

**Validation Requirements:**

| Mode | Rules |
|------|-------|
| **Production** | Must have valid public suffix (ICANN TLD), no IPs, no dev TLDs |
| **Development** | Must have dot OR be localhost, no IPs, dev TLDs allowed |

**Internal/Dev-Only TLDs (blocked in production):**
- `localhost` (literal)
- `.localhost`, `.test`, `.example`, `.invalid` (RFC 6761)
- `.local`, `.lan`, `.internal`, `.home`, `.localdomain`
- `.home.arpa`, `.intranet`, `.corp`, `.private`
- `casspeed` - dynamic (e.g., `app.jokes`, `dev.quotes`, `my.api`)

**Overlay Network TLDs (App-Managed, not set in DOMAIN):**
- `.onion` - Tor hidden services (RFC 7686) - app generates/manages
- `.i2p` - I2P eepsites - app generates/manages
- `.exit` - Tor exit notation - app generates/manages

These are NOT set via `DOMAIN` env var. App handles registration and displays them in console.

**Go Implementation:**
```go
import (
    "net"
    "strings"

    "golang.org/x/net/publicsuffix"
)

var devOnlyTLDs = map[string]bool{
    "localhost": true, "test": true, "example": true, "invalid": true,
    "local": true, "lan": true, "internal": true, "home": true,
    "localdomain": true, "home.arpa": true, "intranet": true,
    "corp": true, "private": true,
}

func IsValidHost(host string, devMode bool, projectName string) bool {
    lower := strings.ToLower(strings.TrimSpace(host))

    // Reject empty
    if lower == "" {
        return false
    }

    // Reject IP addresses always
    if net.ParseIP(lower) != nil {
        return false
    }

    // Handle localhost
    if lower == "localhost" {
        return devMode
    }

    // Must contain at least one dot
    if !strings.Contains(lower, ".") {
        return false
    }

    // Overlay network TLDs - valid but app-managed (not set via DOMAIN)
    // These are checked here for internal validation, not for DOMAIN env var
    if strings.HasSuffix(lower, ".onion") ||
       strings.HasSuffix(lower, ".i2p") ||
       strings.HasSuffix(lower, ".exit") {
        return true
    }

    // Check dynamic project-specific TLD (e.g., app.jokes, dev.quotes, quotes, jokes, casspeed)
    if projectName != "" && strings.HasSuffix(lower, "."+strings.ToLower(projectName)) {
        return devMode // Project TLDs only valid in dev mode
    }

    // Get the public suffix (TLD or eTLD like co.uk)
    suffix, icann := publicsuffix.PublicSuffix(lower)

    // Check if it's a dev-only TLD
    if devOnlyTLDs[suffix] {
        return devMode // Dev TLDs only valid in dev mode
    }

    // In production, require valid ICANN TLD
    if !devMode && !icann {
        return false
    }

    // Verify we have at least eTLD+1 (not just the suffix itself)
    etldPlusOne, err := publicsuffix.EffectiveTLDPlusOne(lower)
    if err != nil {
        return false
    }

    // Host must be at least eTLD+1 (e.g., "domain.co.uk" not just "co.uk")
    return len(etldPlusOne) > 0
}
```

**Example Results (projectName = "jokes"):**

| Host | Production | Development | Reason |
|------|------------|-------------|--------|
| `my.server.domain.co.uk` | ✓ | ✓ | Valid eTLD+1: `domain.co.uk` |
| `api.example.com` | ✓ | ✓ | Valid eTLD+1: `example.com` |
| `app.company.com.au` | ✓ | ✓ | Valid eTLD+1: `company.com.au` |
| `dev.local` | ✗ | ✓ | Dev TLD `.local` |
| `app.test` | ✗ | ✓ | Dev TLD `.test` |
| `app.jokes` | ✗ | ✓ | Dynamic dev TLD `jokes` |
| `my.app.jokes` | ✗ | ✓ | Dynamic dev TLD `jokes` |
| `localhost` | ✗ | ✓ | Dev only |
| `co.uk` | ✗ | ✗ | No eTLD+1 (suffix only) |
| `192.168.1.1` | ✗ | ✗ | IP address |
| `myhost` | ✗ | ✗ | No dot (single-label) |

**Note:** DOMAIN and HOSTNAME environment variables MUST pass host validation for the current mode. Invalid values are skipped silently and detection continues to next source.

### SSL/Let's Encrypt FQDN Requirements

When requesting SSL certificates (Let's Encrypt), the FQDN must be **publicly resolvable**. This uses the same validation as production mode - no internal/dev-only TLDs allowed.

**Go Implementation for SSL validation:**
```go
func IsValidSSLHost(host string) bool {
    lower := strings.ToLower(host)

    // .onion addresses cannot use Let's Encrypt (not publicly resolvable)
    // Tor provides end-to-end encryption, so SSL is optional for .onion
    if strings.HasSuffix(lower, ".onion") {
        return false
    }

    // SSL always requires production-valid host (devMode=false)
    return IsValidHost(host, false)
}
```

**Behavior:**
- SSL with Let's Encrypt: Must pass production-mode validation (no dev TLDs)
- .onion addresses: Cannot use Let's Encrypt (Tor provides encryption)
- If Let's Encrypt requested with invalid host: Log warning, skip cert request, continue without SSL
- Self-signed certs: Can use any valid host for current mode

### Reverse Proxy Header Support (All Headers Supported)

**Protocol Detection (`{proto}`):**
- `X-Forwarded-Proto` - Standard: "https" or "http"
- `X-Forwarded-Ssl` - "on" = https, "off" = http
- `X-Url-Scheme` - Alternative: "https" or "http"
- `Front-End-Https` - Microsoft: "on" = https

**Host Detection (`{fqdn}`):**
- `X-Forwarded-Host` - Standard: "example.com" or "example.com:8080"
- `X-Real-Host` - nginx: "example.com"
- `X-Original-Host` - Alternative

**Port Detection (`{port}`):**
- `X-Forwarded-Port` - Standard: "443" or "8080"
- `X-Real-Port` - nginx alternative

**Client IP Detection (for logging, rate limiting, GeoIP):**
- `X-Forwarded-For` - Standard: may contain chain "client, proxy1, proxy2"
- `X-Real-IP` - nginx: single IP
- `CF-Connecting-IP` - Cloudflare
- `True-Client-IP` - Akamai/Cloudflare Enterprise
- `X-Client-IP` - Alternative

**Request ID (for tracing):**
- `X-Request-ID` - Standard
- `X-Correlation-ID` - Alternative
- `X-Trace-ID` - Distributed tracing

### Request ID Handling (NON-NEGOTIABLE)

**Every request MUST have a Request ID for tracing and debugging.**

| Scenario | Behavior |
|----------|----------|
| Client sends `X-Request-ID` | Use client's ID (validate format) |
| No Request ID header | Generate new UUID |
| Invalid format | Generate new UUID, log warning |

**Request ID Rules:**

| Rule | Description |
|------|-------------|
| **Format** | UUID v4 (e.g., `550e8400-e29b-41d4-a716-446655440000`) |
| **Generation** | Use secure random UUID generator |
| **Propagation** | Include in all outgoing requests to downstream services |
| **Response** | Return `X-Request-ID` in response headers |
| **Logging** | Include `{request_id}` in all log entries for the request |

**Go Implementation:**
```go
func RequestIDMiddleware(next http.Handler) http.Handler {
    return http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {
        // Check for existing request ID from client or upstream proxy
        requestID := r.Header.Get("X-Request-ID")
        if requestID == "" {
            requestID = r.Header.Get("X-Correlation-ID")
        }
        if requestID == "" {
            requestID = r.Header.Get("X-Trace-ID")
        }

        // Generate new ID if none provided or invalid
        if requestID == "" || !isValidUUID(requestID) {
            requestID = uuid.New().String()
        }

        // Add to response headers
        w.Header().Set("X-Request-ID", requestID)

        // Add to request context for logging and downstream calls
        ctx := context.WithValue(r.Context(), "request_id", requestID)
        next.ServeHTTP(w, r.WithContext(ctx))
    })
}
```

### Auth Token Headers (All Headers Supported)

**Standard Authorization:**
- `Authorization` - Standard: `Bearer {token}`, `Basic {base64}`, `Digest {credentials}`

**API Key Headers:**
- `X-API-Key` - Common API key header
- `X-Api-Key` - Case variant (treat as same)
- `API-Key` - Alternative without X- prefix
- `ApiKey` - No hyphen variant

**Custom Token Headers:**
- `X-Auth-Token` - Custom auth token
- `X-Access-Token` - Access token header
- `X-Token` - Short form
- `Token` - Minimal form

**Session/CSRF Headers:**
- `X-CSRF-Token` - CSRF protection token
- `X-XSRF-Token` - Angular variant
- `X-Session-ID` - Session identifier

**Service-to-Service:**
- `X-Service-Token` - Internal service auth
- `X-Internal-Token` - Internal API calls

**Priority Order (first found wins):**
1. `Authorization` header (standard, preferred)
2. `X-API-Key` / `API-Key`
3. `X-Auth-Token` / `X-Access-Token`
4. `X-Token` / `Token`
5. Query parameter `?token=` (least preferred, avoid in production)

### Implementation Requirements

1. **Request Context Helper**: Create a helper function that extracts `{proto}`, `{fqdn}`, `{port}` from each request
2. **URL Builder**: Create a helper that builds full URLs: `{proto}://{fqdn}:{port}/path` (strip :80/:443)
3. **Never Import** hardcoded URLs into templates - always pass detected values
4. **API Response URLs**: All URLs in API responses must be absolute, using detected values
5. **Swagger/OpenAPI**: Server URL must be detected, not hardcoded

---


# PART 8: UPDATE COMMAND (NON-NEGOTIABLE)

## --update Command

```bash
--update [command]
```

**Alias:** `--maintenance update` is an alias for `--update yes`

## Commands

| Command | Description |
|---------|-------------|
| `yes` (default) | Check and perform in-place update with restart |
| `check` | Check for updates without installing (no privileges required) |
| `branch {stable\|beta\|daily}` | Set update branch |

### Exit Codes

| Code | Meaning |
|------|---------|
| 0 | Successful update or no update available |
| 1 | Error |

**HTTP 404 from GitHub API means no updates available (already current).**

### Update Branches

| Branch | Release Type | Tag Pattern | Example |
|--------|--------------|-------------|---------|
| `stable` (default) | Release | `v*`, `*.*.*` | `v1.0.0` |
| `beta` | Pre-release | `*-beta` | `202512051430-beta` |
| `daily` | Pre-release | `YYYYMMDDHHMMSS` | `20251205143022` |

### Examples

```bash
# Check for updates (no privileges required)
casspeed --update check

# Perform update (these are equivalent)
casspeed --update
casspeed --update yes
casspeed --maintenance update

# Switch channels
casspeed --update branch beta
casspeed --update branch daily
casspeed --update branch stable
```

---



# PART 9: PRIVILEGE ESCALATION & SERVICE (NON-NEGOTIABLE)

## Overview

Application user creation **REQUIRES** privilege escalation. If the user cannot escalate privileges, the application runs as the current user with user-level directories.

## Escalation Detection by OS

### Linux
```
Escalation Methods (in order):
1. Already root (EUID == 0)
2. sudo (if user is in sudoers/wheel group)
3. su (if user knows root password)
4. pkexec (PolicyKit, if available)
5. doas (OpenBSD-style, if configured)
```

### macOS
```
Escalation Methods (in order):
1. Already root (EUID == 0)
2. sudo (user must be in admin group)
3. osascript with administrator privileges (GUI prompt)
```

### BSD
```
Escalation Methods (in order):
1. Already root (EUID == 0)
2. doas (OpenBSD default, others if configured)
3. sudo (if installed and configured)
4. su (if user knows root password)
```

### Windows
```
Escalation Methods (in order):
1. Already Administrator (elevated token)
2. UAC prompt (requires GUI)
3. runas (command line, requires admin password)
```

## User Creation Logic

```
ON --service --install:

1. Check if can escalate privileges
   ├─ YES: Continue with privileged installation
   │   ├─ Create system user/group (UID/GID 100-999)
   │   ├─ Use system directories (/etc, /var/lib, /var/log)
   │   ├─ Install service (systemd/launchd/rc.d/Windows Service)
   │   └─ Set ownership to created user
   │
   └─ NO: Fall back to user installation
       ├─ Skip user creation (run as current user)
       ├─ Use user directories (~/.config, ~/.local/share)
       ├─ Skip system service installation
       └─ Offer alternative (cron, user systemd, launchctl user agent)
```

## System User Requirements (NON-NEGOTIABLE)

| Requirement | Value |
|-------------|-------|
| Username | `casspeed` |
| Group | `casspeed` |
| UID/GID | **Must match** - same value for both UID and GID |
| UID/GID Range | 100-999 (system user range) |
| Shell | `/sbin/nologin` or `/usr/sbin/nologin` |
| Home | Config directory (`/etc/casapps/casspeed`) or data directory (`/var/lib/casapps/casspeed`) |
| Type | System user (no password, no login) |
| Gecos | `casspeed service account` |

### UID/GID Selection Logic

**The UID and GID MUST be the same value.** Find an unused ID where both UID and GID are available:

```
1. Start at 999 (top of system range)
2. Check if UID is unused (not in /etc/passwd)
3. Check if GID is unused (not in /etc/group)
4. If both available → use this value for both UID and GID
5. If either taken → decrement and repeat
6. Stop at 100 (bottom of system range)
7. If no ID found → error (system has no available IDs)
```

### Go Implementation

```go
func findAvailableSystemID() (int, error) {
    // Start from top of system range, work down
    for id := 999; id >= 100; id-- {
        // Check if UID is available
        if _, err := user.LookupId(strconv.Itoa(id)); err == nil {
            continue
            // UID exists, try next
        }

        // Check if GID is available
        if _, err := user.LookupGroupId(strconv.Itoa(id)); err == nil {
            continue
            // GID exists, try next
        }

        // Both available
        return id, nil
    }
    return 0, fmt.Errorf("no available UID/GID in system range 100-999")
}
```

### Platform-Specific Commands

**Linux:**
```bash
# Create group with specific GID
groupadd --system --gid {id} casspeed

# Create user with matching UID, same primary group
useradd --system --uid {id} --gid {id} \
  --home-dir /etc/casapps/casspeed \
  --shell /sbin/nologin \
  --comment "casspeed service account" \
  casspeed
```

### macOS Service Account (NON-NEGOTIABLE)

**macOS services (launchd) MUST NOT run as logged-in user or root.**

| Option | Security | Recommendation |
|--------|----------|----------------|
| root | HIGH privileges - dangerous | NO |
| Logged-in User | User privileges - insecure | NO |
| `_www` | Web server account | NO (wrong purpose) |
| **Dedicated service user** | Minimal privileges, isolated | **RECOMMENDED** |

**Default: Dedicated system user with matching UID/GID**

macOS uses `dscl` (Directory Service Command Line) to create system users. The user is hidden from login screen and has no shell access.

**macOS UID/GID Ranges:**

| Range | Purpose |
|-------|---------|
| 0-99 | System accounts (reserved) |
| 100-499 | System services (use this range) |
| 500+ | Regular users |

**Create Service Account:**
```bash
# Find available ID in 100-499 range (same logic as Linux but different range)
# Start at 499, work down until both UID and GID are available

# Create group with specific GID
dscl . -create /Groups/casspeed
dscl . -create /Groups/casspeed PrimaryGroupID {id}
dscl . -create /Groups/casspeed Password "*"

# Create user with matching UID
dscl . -create /Users/casspeed
dscl . -create /Users/casspeed UniqueID {id}
dscl . -create /Users/casspeed PrimaryGroupID {id}
dscl . -create /Users/casspeed UserShell /usr/bin/false
dscl . -create /Users/casspeed RealName "casspeed service account"
dscl . -create /Users/casspeed NFSHomeDirectory /usr/local/var/casapps/casspeed
dscl . -create /Users/casspeed Password "*"

# Hide user from login window
dscl . -create /Users/casspeed IsHidden 1
```

**launchd plist with UserName:**
```xml
<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE plist PUBLIC "-//Apple//DTD PLIST 1.0//EN" "http://www.apple.com/DTDs/PropertyList-1.0.dtd">
<plist version="1.0">
<dict>
    <key>Label</key>
    <string>casapps.casspeed</string>

    <key>ProgramArguments</key>
    <array>
        <string>/usr/local/bin/casspeed</string>
    </array>

    <!-- Run as dedicated service user, NOT root -->
    <key>UserName</key>
    <string>casspeed</string>

    <key>GroupName</key>
    <string>casspeed</string>

    <key>RunAtLoad</key>
    <true/>

    <key>KeepAlive</key>
    <true/>

    <key>WorkingDirectory</key>
    <string>/usr/local/var/casapps/casspeed</string>

    <key>StandardOutPath</key>
    <string>/usr/local/var/log/casapps/casspeed/stdout.log</string>

    <key>StandardErrorPath</key>
    <string>/usr/local/var/log/casapps/casspeed/stderr.log</string>
</dict>
</plist>
```

**macOS Directory Structure:**

| Directory | Path | Purpose |
|-----------|------|---------|
| Binary | `/usr/local/bin/casspeed` | Executable |
| Config | `/usr/local/etc/casapps/casspeed/` | Configuration files |
| Data | `/usr/local/var/casapps/casspeed/` | Application data |
| Logs | `/usr/local/var/log/casapps/casspeed/` | Log files |
| launchd plist | `/Library/LaunchDaemons/casapps.casspeed.plist` | Service definition |

**Go Implementation (macOS):**
```go
// +build darwin

func findAvailableMacOSSystemID() (int, error) {
    // macOS system services use 100-499 range
    for id := 499; id >= 100; id-- {
        // Check if UID is available
        if _, err := user.LookupId(strconv.Itoa(id)); err == nil {
            continue
        }

        // Check if GID is available
        if _, err := user.LookupGroupId(strconv.Itoa(id)); err == nil {
            continue
        }

        return id, nil
    }
    return 0, fmt.Errorf("no available UID/GID in macOS system range 100-499")
}

func createMacOSServiceUser(name string, id int, homeDir string) error {
    commands := [][]string{
        // Create group
        {"dscl", ".", "-create", "/Groups/" + name},
        {"dscl", ".", "-create", "/Groups/" + name, "PrimaryGroupID", strconv.Itoa(id)},
        {"dscl", ".", "-create", "/Groups/" + name, "Password", "*"},
        // Create user
        {"dscl", ".", "-create", "/Users/" + name},
        {"dscl", ".", "-create", "/Users/" + name, "UniqueID", strconv.Itoa(id)},
        {"dscl", ".", "-create", "/Users/" + name, "PrimaryGroupID", strconv.Itoa(id)},
        {"dscl", ".", "-create", "/Users/" + name, "UserShell", "/usr/bin/false"},
        {"dscl", ".", "-create", "/Users/" + name, "RealName", name + " service account"},
        {"dscl", ".", "-create", "/Users/" + name, "NFSHomeDirectory", homeDir},
        {"dscl", ".", "-create", "/Users/" + name, "Password", "*"},
        {"dscl", ".", "-create", "/Users/" + name, "IsHidden", "1"},
    }

    for _, cmd := range commands {
        if err := exec.Command(cmd[0], cmd[1:]...).Run(); err != nil {
            return fmt.Errorf("failed to run %v: %w", cmd, err)
        }
    }
    return nil
}
```

**FreeBSD:**
```bash
# Create user and group with matching ID
pw groupadd -n casspeed -g {id}
pw useradd -n casspeed -u {id} -g {id} \
  -d /var/lib/casapps/casspeed \
  -s /usr/sbin/nologin \
  -c "casspeed service account"
```

### Windows Service Account (NON-NEGOTIABLE)

**Windows services MUST NOT run as logged-in user or Administrator.**

| Option | Security | Recommendation |
|--------|----------|----------------|
| Local System | HIGH privileges - dangerous | NO |
| Administrator | HIGH privileges - dangerous | NO |
| Logged-in User | User privileges - insecure | NO |
| Local Service | Limited privileges | OK for network-less services |
| Network Service | Limited + network access | OK for network services |
| **Virtual Service Account** | Minimal privileges, isolated | **RECOMMENDED** |
| Managed Service Account | Domain-managed, auto-password | Enterprise environments |

**Default: Virtual Service Account (VSA)**

Virtual Service Accounts are automatically managed by Windows, require no password management, and have minimal privileges. They are created automatically when the service is installed.

**Service Account Format:** `NT SERVICE\casspeed`

```powershell
# Create service with Virtual Service Account (automatic)
New-Service -Name "casspeed" `
  -BinaryPathName "C:\Program Files\casapps\casspeed\casspeed.exe" `
  -DisplayName "casspeed" `
  -Description "casspeed service" `
  -StartupType Automatic

# Service automatically runs as NT SERVICE\casspeed
# No user creation needed - Windows manages it
```

**Directory Permissions:**
```powershell
# Grant Virtual Service Account access to config/data directories
$acl = Get-Acl "C:\ProgramData\casapps\casspeed"
$rule = New-Object System.Security.AccessControl.FileSystemAccessRule(
    "NT SERVICE\casspeed",
    "FullControl",
    "ContainerInherit,ObjectInherit",
    "None",
    "Allow"
)
$acl.SetAccessRule($rule)
Set-Acl "C:\ProgramData\casapps\casspeed" $acl
```

**Go Implementation (Windows):**
```go
// +build windows

import "golang.org/x/sys/windows/svc/mgr"

func installWindowsService() error {
    m, err := mgr.Connect()
    if err != nil {
        return err
    }
    defer m.Disconnect()

    exePath, _ := os.Executable()

    // Create service - runs as Virtual Service Account by default
    // when ServiceStartName is empty or "NT SERVICE\{name}"
    s, err := m.CreateService(
        "casspeed",
        exePath,
        mgr.Config{
            DisplayName:     "casspeed",
            Description:     "casspeed service",
            StartType:       mgr.StartAutomatic,
            ServiceStartName: "", // Empty = Virtual Service Account
        },
    )
    if err != nil {
        return err
    }
    defer s.Close()

    return nil
}
```

**Windows Directory Structure:**

| Directory | Path | Purpose |
|-----------|------|---------|
| Binary | `C:\Program Files\casapps\casspeed\` | Executable |
| Config | `C:\ProgramData\casapps\casspeed\config\` | Configuration files |
| Data | `C:\ProgramData\casapps\casspeed\data\` | Application data |
| Logs | `C:\ProgramData\casapps\casspeed\logs\` | Log files |

### Home Directory Selection

| Directory | Use When |
|-----------|----------|
| Config dir (`/etc/casapps/casspeed`) | Default - user needs access to config files |
| Data dir (`/var/lib/casapps/casspeed`) | When data dir contains user-writable content |

**Note:** Home directory must exist before user creation. Create directories first, then user, then set ownership.

---


# PART 10: SERVICE SUPPORT (NON-NEGOTIABLE)

## Built-in Service Support

**ALL projects MUST have built-in service support for ALL service managers:**

| Service Manager | OS |
|-----------------|-----|
| systemd | Linux |
| runit | Linux |
| Windows Service Manager | Windows |
| launchd | macOS |
| rc.d | BSD |

---



# PART 11: BINARY REQUIREMENTS (NON-NEGOTIABLE)

## Single Static Binary

| Requirement | Description |
|-------------|-------------|
| Type | **SINGLE STATIC BINARY** |
| Assets | Embedded using Go's `embed` package |
| Dependencies | None at runtime |
| Build | **CGO_ENABLED=0** |
| Libraries | Pure Go only (no CGO) |

## Default Behavior

| Behavior | Description |
|----------|-------------|
| No arguments | Initialize (if needed) and start server |
| First run | Auto-create config with defaults |
| First run | Auto-create required directories |
| Signals | Proper handling (SIGTERM, SIGINT, SIGHUP) |
| PID file | Enabled by default |

## Embedded Assets

| Asset Type | Location |
|------------|----------|
| Templates | `src/server/templates/` |
| Static files | `src/server/static/` |
| Application data | `src/data/` (JSON files) |

## External Data (NOT Embedded)

**Security databases are NEVER embedded in the binary.** They are downloaded on first run and kept updated via the built-in scheduler.

| Data Type | Location | Source | Update Frequency |
|-----------|----------|--------|------------------|
| GeoIP (ASN) | `{config_dir}/security/geoip/` | ip-location-db | Daily |
| GeoIP (Country) | `{config_dir}/security/geoip/` | ip-location-db | Daily |
| GeoIP (City) | `{config_dir}/security/geoip/` | ip-location-db | Daily |
| GeoIP (WHOIS) | `{config_dir}/security/geoip/` | ip-location-db | Daily |
| IP Blocklists | `{config_dir}/security/blocklists/` | Configurable sources | Daily |
| Domain Blocklists | `{config_dir}/security/blocklists/` | Configurable sources | Daily |
| CVE databases | `{config_dir}/security/cve/` | NVD/NIST feeds | Daily |
| Trivy DB | `{config_dir}/security/trivy/` | Aqua Security | Daily |

**Why NOT Embedded:**
- Security data changes frequently (daily/weekly updates)
- Embedding would require new binary releases for data updates
- Allows immediate security updates without redeployment
- Reduces binary size significantly

**Download Behavior:**
1. On first run, check if data exists in `{config_dir}/security/`
2. If missing, download from configured sources
3. If download fails, log warning and continue (graceful degradation)
4. Scheduler keeps data updated automatically

### Default Data Sources

```yaml
# Data source configuration (in server.yml)
data:
  # Base directory for all security databases
  security_dir: "{config_dir}/security"

  geoip:
    # ip-location-db (https://github.com/sapics/ip-location-db)
    # Free, no API key required, daily updates, CC0/PDDL licensed
    provider: "ip-location-db"
    databases:
      asn:
        enabled: true
        url: "https://cdn.jsdelivr.net/npm/@ip-location-db/asn-mmdb/asn.mmdb"
        file: "asn.mmdb"
      country:
        enabled: true
        url: "https://cdn.jsdelivr.net/npm/@ip-location-db/geo-whois-asn-country-mmdb/geo-whois-asn-country.mmdb"
        file: "country.mmdb"
      city:
        enabled: true
        url: "https://cdn.jsdelivr.net/npm/@ip-location-db/dbip-city-mmdb/dbip-city-ipv4.mmdb"
        file: "city.mmdb"
      whois:
        enabled: true
        url: "https://cdn.jsdelivr.net/npm/@ip-location-db/geo-whois-asn-country-mmdb/geo-whois-asn-country.mmdb"
        file: "whois.mmdb"

  blocklists:
    # Default blocklist sources (configurable)
    sources:
      - name: "firehol_level1"
        url: "https://iplists.firehol.org/files/firehol_level1.netset"
        type: ip
        enabled: true
      - name: "spamhaus_drop"
        url: "https://www.spamhaus.org/drop/drop.txt"
        type: ip
        enabled: true
      - name: "abuse_ch_urlhaus"
        url: "https://urlhaus.abuse.ch/downloads/text/"
        type: domain
        # Optional
        enabled: false

  cve:
    # NVD (NIST National Vulnerability Database)
    source: "https://nvd.nist.gov/feeds/json/cve/1.1"
    # Only download CVEs relevant to project dependencies
    filter_by_cpe: true

  trivy:
    # Aqua Trivy vulnerability database (optional, for container scanning)
    enabled: false
    source: "https://ghcr.io/aquasecurity/trivy-db"
```

### Security Directory Structure

```
{config_dir}/security/
├── geoip/
│   ├── asn.mmdb                 # ASN lookups (AS number, organization)
│   ├── country.mmdb             # Country code lookups
│   ├── city.mmdb                # City, region, coordinates, timezone
│   ├── whois.mmdb               # WHOIS data (registrant, org)
│   └── .last_updated            # Timestamp file
├── blocklists/
│   ├── firehol_level1.txt
│   ├── spamhaus_drop.txt
│   └── .last_updated
├── cve/
│   ├── nvd.json
│   └── .last_updated
└── trivy/
    ├── db.tar.gz
    └── .last_updated
```

### GeoIP Database Details (ip-location-db)

| Database | File | Contains | Use Case |
|----------|------|----------|----------|
| ASN | `asn.mmdb` | AS number, AS organization | Network provider identification |
| Country | `country.mmdb` | Country code (ISO 3166-1) | Geo-blocking, compliance |
| City | `city.mmdb` | City, region, postal, lat/lon, timezone | Location-based features |
| WHOIS | `whois.mmdb` | Registrant info, combined with ASN | Abuse detection, attribution |

**Benefits of ip-location-db:**
- No API key or account required (unlike MaxMind)
- Daily updates via jsDelivr CDN
- CC0/PDDL licensed (no restrictions)
- MMDB format (same as MaxMind, compatible with existing Go libraries)
- IPv4 and IPv6 support

---


# PART 12: MAKEFILE (NON-NEGOTIABLE)

**Four targets only. DO NOT ADD MORE.**

## Targets

| Target | Description | Output |
|--------|-------------|--------|
| `build` | Build all platforms + host binary | `binaries/` |
| `release` | GitHub release with source archive | `releases/` |
| `docker` | Build and push container to ghcr.io | ghcr.io |
| `test` | Run all tests | - |

## Versioning (NON-NEGOTIABLE)

### Version File: `release.txt`

- If `VERSION` env var is set, use it (highest priority)
- If `release.txt` exists, read version from it
- If `release.txt` does not exist, create with current app version
- Auto-increment patch version on each release
- Semantic versioning: `MAJOR.MINOR.PATCH` (e.g., `1.2.3`)

### Version Tag `v` Prefix Rules (NON-NEGOTIABLE)

**CRITICAL: Only add `v` prefix to NUMERIC semantic versions, NEVER to text versions.**

**Rule: Add `v` prefix ONLY if tag is a NUMBER (semantic version X.Y.Z), NEVER if it's TEXT.**

**When creating git tags:**
- ✓ Numeric versions: `git tag v0.2.0` or `git tag 0.2.0` (both become v0.2.0)
- ✓ Text versions: `git tag dev` or `git tag beta` (stay as dev, beta - NO v)
- ✗ NEVER create: `git tag vdev`, `git tag vbeta` (wrong!)

**When extracting VERSION variable from tag:**
- Git tag `v1.2.3` → VERSION=`1.2.3` (strip v for internal use)
- Git tag `dev` → VERSION=`dev` (no v to strip)
- Git tag `beta` → VERSION=`beta` (no v to strip)

| Tag Input | Type | Add `v`? | Display As | Why |
|-----------|------|----------|------------|-----|
| `0.2.0` | Number (semver) | ✓ YES | `v0.2.0` | Numeric version gets v |
| `1.2.3` | Number (semver) | ✓ YES | `v1.2.3` | Numeric version gets v |
| `v1.2.0` | Number (has v) | ✗ NO | `v1.2.0` | Already has v |
| `1.2.3-rc1` | Number (semver+suffix) | ✓ YES | `v1.2.3-rc1` | Numeric version gets v |
| `dev` | Text | ✗ NO | `dev` | Text version NO v |
| `beta` | Text | ✗ NO | `beta` | Text version NO v |
| `daily` | Text | ✗ NO | `daily` | Text version NO v |
| `20251218060432` | Timestamp | ✗ NO | `20251218060432` | Not semver NO v |
| `20251218060432-beta` | Timestamp+text | ✗ NO | `20251218060432-beta` | Not semver NO v |

**Examples of WRONG:**
- ❌ `vdev` - NEVER add v to text
- ❌ `vbeta` - NEVER add v to text
- ❌ `v20251218` - NEVER add v to timestamps
- ❌ `vv0.3.0` - NEVER double the v prefix

**Examples of CORRECT:**
- ✓ `dev` - Text version, no v
- ✓ `beta` - Text version, no v
- ✓ `v0.2.0` - Numeric version, has v (input: 0.2.0 or v0.2.0)
- ✓ `v1.2.3` - Numeric version, has v (input: 1.2.3 or v1.2.3)
- ✓ `20251218-beta` - Timestamp+text, no v

```bash
# Shell function to format version tag (prevents vv prefix, only adds v to numbers)
format_version_tag() {
    local tag="$1"

    # Step 1: If already starts with v, return as-is (prevents vv0.3.0)
    if [[ "$tag" == v* ]]; then
        echo "$tag"
        return
    fi

    # Step 2: If it's a semantic version (starts with digit.digit.digit), add v
    # Matches: 0.2.0, 1.2.3, 10.5.2-rc1
    # Does NOT match: dev, beta, daily, 20251218
    if [[ "$tag" =~ ^[0-9]+\.[0-9]+\.[0-9]+ ]]; then
        echo "v$tag"        # 0.2.0 → v0.2.0
    else
        echo "$tag"         # dev → dev (no v)
    fi
}

# Usage examples:
# format_version_tag "0.2.0"         → "v0.2.0"
# format_version_tag "v0.2.0"        → "v0.2.0" (not vv0.2.0)
# format_version_tag "dev"           → "dev" (not vdev)
# format_version_tag "beta"          → "beta" (not vbeta)
# format_version_tag "20251218-beta" → "20251218-beta" (not v...)
```

### Version Priority

1. `VERSION` environment variable (if set)
2. `release.txt` file (if exists)
3. Create `release.txt` with `0.1.0` (first release)

## Binary Naming (NON-NEGOTIABLE)

| Context | Name | Example |
|---------|------|---------|
| Host Build | `binaries/casspeed` | `binaries/jokes` |
| Distribution | `casspeed-{os}-{arch}` | `jokes-linux-amd64` |
| Local/Testing | `$(mktemp -d "${TMPDIR:-/tmp}/${PROJECTORG}.XXXXXX")/casspeed` | Org-prefixed temp dir |

**If built with musl → strip binary before release. Final name has NO `-musl` suffix.**

## Build Matrix

| OS | Architectures |
|----|---------------|
| Linux | amd64, arm64 |
| macOS (Darwin) | amd64, arm64 |
| Windows | amd64, arm64 |
| FreeBSD | amd64, arm64 |

## Makefile Implementation

```makefile
# Infer PROJECTNAME and PROJECTORG from git remote or directory path (NEVER hardcode)
PROJECTNAME := $(shell git remote get-url origin 2>/dev/null | sed -E 's|.*/([^/]+)(\.git)?$$|\1|' || basename "$$(pwd)")
PROJECTORG := $(shell git remote get-url origin 2>/dev/null | sed -E 's|.*/([^/]+)/[^/]+(\.git)?$$|\1|' || basename "$$(dirname "$$(pwd)")")

# Version: env var > release.txt > default
VERSION ?= $(shell cat release.txt 2>/dev/null || echo "0.1.0")

# Build info - use TZ env var or system timezone
# Format: "Thu Dec 17, 2025 at 18:19:24 EST"
BUILD_DATE := $(shell date +"%%a %%b %%d, %%Y at %%H:%%M:%%S %%Z")
COMMIT_ID := $(shell git rev-parse --short HEAD 2>/dev/null || echo "unknown")
# COMMIT_ID used directly - no VCS_REF alias

# Linker flags to embed build info
LDFLAGS := -s -w \
	-X 'main.Version=$(VERSION)' \
	-X 'main.CommitID=$(COMMIT_ID)' \
	-X 'main.BuildDate=$(BUILD_DATE)'

# Directories
BINDIR := binaries
RELDIR := releases

# Go module cache (persistent across builds)
GOCACHE := $(HOME)/.cache/go-build
GOMODCACHE := $(HOME)/go/pkg/mod

# Build targets
PLATFORMS := linux/amd64 linux/arm64 darwin/amd64 darwin/arm64 windows/amd64 windows/arm64 freebsd/amd64 freebsd/arm64

# Docker
REGISTRY := ghcr.io/$(PROJECTORG)/$(PROJECTNAME)
GO_DOCKER := docker run --rm \
	-v $(PWD):/build \
	-v $(GOCACHE):/root/.cache/go-build \
	-v $(GOMODCACHE):/go/pkg/mod \
	-w /build \
	-e CGO_ENABLED=0 \
	golang:alpine

.PHONY: build release docker test dev clean

# =============================================================================
# BUILD - Build all platforms + host binary (via Docker with cached modules)
# =============================================================================
build: clean
	@mkdir -p $(BINDIR)
	@echo "Building version $(VERSION)..."
	@mkdir -p $(GOCACHE) $(GOMODCACHE)

	# Download modules first (cached)
	@echo "Downloading Go modules..."
	@$(GO_DOCKER) go mod download

	# Build for host OS/ARCH
	@echo "Building host binary..."
	@$(GO_DOCKER) sh -c "GOOS=$$(go env GOOS) GOARCH=$$(go env GOARCH) \
		go build -ldflags \"$(LDFLAGS)\" -o $(BINDIR)/$(PROJECTNAME) src"

	# Build all platforms
	@for platform in $(PLATFORMS); do \
		OS=$${platform%/*}; \
		ARCH=$${platform#*/}; \
		OUTPUT=$(BINDIR)/$(PROJECTNAME)-$$OS-$$ARCH; \
		[ "$$OS" = "windows" ] && OUTPUT=$$OUTPUT.exe; \
		echo "Building $$OS/$$ARCH..."; \
		$(GO_DOCKER) sh -c "GOOS=$$OS GOARCH=$$ARCH \
			go build -ldflags \"$(LDFLAGS)\" \
			-o $$OUTPUT src" || exit 1; \
	done

	@echo "Build complete: $(BINDIR)/"

# =============================================================================
# RELEASE - Manual local release (stable only)
# =============================================================================
release: build
	@mkdir -p $(RELDIR)
	@echo "Preparing release $(VERSION)..."

	# Create version.txt
	@echo "$(VERSION)" > $(RELDIR)/version.txt

	# Copy binaries to releases (strip if needed)
	@for f in $(BINDIR)/$(PROJECTNAME)-*; do \
		[ -f "$$f" ] || continue; \
		strip "$$f" 2>/dev/null || true; \
		cp "$$f" $(RELDIR)/; \
	done

	# Create source archive (exclude VCS and build artifacts)
	@tar --exclude='.git' --exclude='.github' --exclude='.gitea' \
		--exclude='binaries' --exclude='releases' --exclude='*.tar.gz' \
		-czf $(RELDIR)/$(PROJECTNAME)-$(VERSION)-source.tar.gz .

	# Delete existing release/tag if exists
	@gh release delete $(VERSION) --yes 2>/dev/null || true
	@git tag -d $(VERSION) 2>/dev/null || true
	@git push origin :refs/tags/$(VERSION) 2>/dev/null || true

	# Create new release (stable)
	@gh release create $(VERSION) $(RELDIR)/* \
		--title "$(PROJECTNAME) $(VERSION)" \
		--notes "Release $(VERSION)" \
		--latest

	@echo "Release complete: $(VERSION)"

# =============================================================================
# DOCKER - Build and push container to ghcr.io
# =============================================================================
# Uses multi-stage Dockerfile - Go compilation happens inside Docker
# No pre-built binaries needed
docker:
	@echo "Building Docker image $(VERSION)..."

	# Ensure buildx is available
	@docker buildx version > /dev/null 2>&1 || (echo "docker buildx required" && exit 1)

	# Create/use builder
	@docker buildx create --name $(PROJECTNAME)-builder --use 2>/dev/null || \
		docker buildx use $(PROJECTNAME)-builder

	# Build and push multi-arch (multi-stage Dockerfile handles Go compilation)
	@docker buildx build \
		-f docker/Dockerfile \
		--platform linux/amd64,linux/arm64 \
		--build-arg VERSION="$(VERSION)" \
		--build-arg BUILD_DATE="$(BUILD_DATE)" \
		--build-arg COMMIT_ID="$(COMMIT_ID)" \
		-t $(REGISTRY):$(VERSION) \
		-t $(REGISTRY):latest \
		--push \
		.

	@echo "Docker push complete: $(REGISTRY):$(VERSION)"

# =============================================================================
# TEST - Run all tests (via Docker with cached modules)
# =============================================================================
test:
	@echo "Running tests in Docker..."
	@mkdir -p $(GOCACHE) $(GOMODCACHE)
	@$(GO_DOCKER) go mod download
	@$(GO_DOCKER) go test -v -cover ./...
	@echo "Tests complete"

# =============================================================================
# DEV - Quick build for local development/testing (to random temp dir)
# =============================================================================
# Fast: host platform only, no ldflags, random temp dir for isolation
dev:
	@mkdir -p $(GOCACHE) $(GOMODCACHE)
	@BUILD_DIR=$$(mktemp -d "$${TMPDIR:-/tmp}/$(PROJECTORG).XXXXXX") && \
		echo "Quick dev build..." && \
		$(GO_DOCKER) go build -o $$BUILD_DIR/$(PROJECTNAME) src && \
		echo "Built: $$BUILD_DIR/$(PROJECTNAME)" && \
		echo "Test:  docker run --rm -v $$BUILD_DIR:/app alpine:latest /app/$(PROJECTNAME) --help"

# =============================================================================
# CLEAN - Remove build artifacts
# =============================================================================
clean:
	@rm -rf $(BINDIR) $(RELDIR)
```

## Embedded Build Info (NON-NEGOTIABLE)

Every binary MUST have these values embedded at build time:

| Variable | Example | Description |
|----------|---------|-------------|
| `Version` | `1.2.3` | Semantic version from release.txt |
| `CommitID` | `a1b2c3d` | Git short commit hash |
| `BuildDate` | `Thu Dec 17, 2025 at 18:19:24 EST` | Build timestamp with timezone |

**Go code requirement** (in `main.go` or `version.go`):

```go
// Build info - set via -ldflags at build time
var (
    Version   = "dev"
    CommitID  = "unknown"
    BuildDate = "unknown"
)
```

**Build date format:** Uses build system timezone or `TZ` env var.

## Go Module Caching

All Docker builds use persistent Go module caching to avoid re-downloading dependencies:

| Cache | Host Path | Container Path |
|-------|-----------|----------------|
| Build cache | `~/.cache/go-build` | `/root/.cache/go-build` |
| Module cache | `~/go/pkg/mod` | `/go/pkg/mod` |

**Benefits:**
- First build downloads modules once
- Subsequent builds use cached modules
- Shared across all projects on the same machine
- Significantly faster builds after first run

## Target Details

### `make build`

1. Creates cache directories if needed
2. Downloads Go modules (cached)
3. Creates `binaries/` directory
4. Builds host binary: `binaries/casspeed`
5. Builds all platform binaries: `binaries/casspeed-{os}-{arch}`
6. Uses `CGO_ENABLED=0` for static binaries
7. Embeds Version, CommitID, BuildDate via `-ldflags`
8. All builds via Docker (`golang:alpine`)

### `make release`

1. Runs `build` first
2. Creates `releases/version.txt` with current version
3. Strips binaries (removes symbols)
4. Creates source archive (excludes `.git`, `.github`, `.gitea`, `binaries/`, `releases/`)
5. Deletes existing GitHub release/tag if exists
6. Creates new GitHub release marked as `--latest`
7. Uses `gh` CLI - **manual local release only**

### `make docker`

1. Uses `docker buildx` for multi-arch builds
2. Multi-stage Dockerfile handles Go compilation (no pre-built binaries)
3. Context is project root, Dockerfile at `docker/Dockerfile`
4. Builds for `linux/amd64` and `linux/arm64`
5. Pushes to `ghcr.io/{org}/casspeed:{version}` and `:latest`
6. Passes VERSION, BUILD_DATE, COMMIT_ID as build args
7. Layer caching: Go modules cached in builder stage

### `make test`

1. Downloads Go modules (cached)
2. Runs tests inside Docker container (`golang:alpine`)
3. Mounts project directory to `/build`
4. Runs `go test` with coverage
5. Tests all packages (`./...`)
6. Container removed after completion (`--rm`)

### `make dev`

1. Quick build for local development/testing
2. Builds host platform only (fastest)
3. No `-ldflags` (version info not embedded)
4. Outputs to `{tempdir}/casapps.XXXXXX/casspeed` (isolated, org-identifiable)
5. Uses Docker (`golang:alpine`) - keeps host clean
6. Easy cleanup: `rm -rf "${TMPDIR:-/tmp}"/${PROJECTORG}.*/` or auto-deleted on reboot

**When to use:**

| Command | Use Case |
|---------|----------|
| `make dev` | Quick iteration during development |
| `make build` | Full build for testing all platforms |
| `make test` | Run test suite |

## Directory Rules (NON-NEGOTIABLE)

| Rule | Description |
|------|-------------|
| **NEVER symlink** | Never symlink between `binaries/` and `releases/` |
| **NEVER copy** | Never copy files between `binaries/` and `releases/` |
| **binaries/** | Build output only - temporary, gitignored |
| **releases/** | Release artifacts only - packaged for distribution |
| **version.txt** | Every release includes `version.txt` with current version |

## Release Artifacts (NON-NEGOTIABLE)

**Every GitHub release MUST include these files:**

### Server Binaries (Always)

| File | Description |
|------|-------------|
| `casspeed-linux-amd64` | Linux AMD64 server binary |
| `casspeed-linux-arm64` | Linux ARM64 server binary |
| `casspeed-darwin-amd64` | macOS AMD64 server binary |
| `casspeed-darwin-arm64` | macOS ARM64 (Apple Silicon) server binary |
| `casspeed-windows-amd64.exe` | Windows AMD64 server binary |
| `casspeed-windows-arm64.exe` | Windows ARM64 server binary |
| `casspeed-freebsd-amd64` | FreeBSD AMD64 server binary |
| `casspeed-freebsd-arm64` | FreeBSD ARM64 server binary |

### CLI Binaries (If Project Has CLI)

| File | Description |
|------|-------------|
| `casspeed-linux-amd64-cli` | Linux AMD64 CLI binary |
| `casspeed-linux-arm64-cli` | Linux ARM64 CLI binary |
| `casspeed-darwin-amd64-cli` | macOS AMD64 CLI binary |
| `casspeed-darwin-arm64-cli` | macOS ARM64 (Apple Silicon) CLI binary |
| `casspeed-windows-amd64-cli.exe` | Windows AMD64 CLI binary |
| `casspeed-windows-arm64-cli.exe` | Windows ARM64 CLI binary |
| `casspeed-freebsd-amd64-cli` | FreeBSD AMD64 CLI binary |
| `casspeed-freebsd-arm64-cli` | FreeBSD ARM64 CLI binary |

### Metadata Files (Always)

| File | Description | Example Content |
|------|-------------|-----------------|
| `version.txt` | Version string only | `1.2.3`, `20251218060432-beta`, `20251218060432` |
| `casspeed-{version}-source.tar.gz` | Source code archive | Excludes `.git`, `.github`, `binaries/`, `releases/` |

### version.txt Content

| Release Type | version.txt Content |
|--------------|---------------------|
| Stable | `1.2.3` (semver without `v` prefix) |
| Beta | `20251205143022-beta` (timestamp-beta) |
| Daily | `20251218060432` (timestamp only) |

## Release Types

### Stable Release

| Property | Value |
|----------|-------|
| Trigger | Git tag push with semver pattern (`v*`, `*.*.*`) |
| Version format | Semantic (`X.Y.Z`) - NUMBERS only |
| Git tag | `v1.2.3`, `v0.2.0`, or `1.2.3` (numeric versions) |
| Release name | `v{version}` (always with v: `v1.2.3`, `v0.2.0`) |
| version.txt | `{version}` (without `v`: `1.2.3`, `0.2.0`) |
| GitHub release | Yes, marked as latest |

**Examples:**
- Git tag `v1.2.3` → Release `v1.2.3`, version.txt `1.2.3`
- Git tag `0.2.0` → Release `v0.2.0`, version.txt `0.2.0`

### Beta Release

| Property | Value |
|----------|-------|
| Trigger | Push to `beta` branch |
| Version format | `{YYYYMMDDHHMMSS}-beta` - TEXT, NO `v` prefix |
| Release name | `{YYYYMMDDHHMMSS}-beta` (e.g., `20251205143022-beta`) |
| version.txt | `{YYYYMMDDHHMMSS}-beta` |
| GitHub release | Yes, marked as pre-release |

**Example:**
- Beta build → Release `20251205143022-beta`, version.txt `20251205143022-beta`
- NO `v` prefix (not a semantic version)

### Daily Build

| Property | Value |
|----------|-------|
| Trigger | Daily schedule (3am UTC) + push to main/master |
| Version format | `{YYYYMMDDHHMMSS}` - TIMESTAMP, NO `v` prefix |
| Release name | `daily` (single rolling release) |
| version.txt | `{YYYYMMDDHHMMSS}` (e.g., `20251218060432`) |
| GitHub release | Yes, **replaces previous daily** |
| Max releases | **1** (always overwrites previous daily) |

**Example:**
- Daily build → Release name `daily`, version.txt `20251218060432`
- NO `v` prefix (not a semantic version)

**Daily Build Rules:**
- Only ONE daily release exists at any time
- Each daily build **deletes and replaces** the previous `daily` release
- Prevents accumulation of thousands of releases

## Version Tag Summary (Quick Reference)

| Release Type | Git Tag | Has `v` Prefix? | Release Name | version.txt |
|--------------|---------|-----------------|--------------|-------------|
| **Stable** | `v1.2.3` or `1.2.3` | ✓ YES (numbers) | `v1.2.3` | `1.2.3` |
| **Stable** | `v0.2.0` or `0.2.0` | ✓ YES (numbers) | `v0.2.0` | `0.2.0` |
| **Beta** | (branch push) | ✗ NO (timestamp) | `20251205-beta` | `20251205-beta` |
| **Daily** | (branch push) | ✗ NO (timestamp) | `daily` | `20251218` |
| **Dev** | `dev` | ✗ NO (text) | `dev` | `dev` |

**NEVER:**
- ❌ `vdev`, `vbeta`, `vdaily` (text versions never get v)
- ❌ `v20251218` (timestamps never get v)
- ❌ `vv1.2.3` (don't double the v)

## Version Files

| File | Purpose | When Updated |
|------|---------|--------------|
| `release.txt` | Source of truth for stable version | Manual |
| `releases/version.txt` | Included in release archive | During release build |

## Release Summary

| Type | Method | Version Example | Max Releases |
|------|--------|-----------------|--------------|
| Stable | CI/CD (tag) or `make release` (local) | `1.2.3` | Unlimited |
| Beta | CI/CD only | `20251205143022-beta` | Unlimited |
| Daily | CI/CD only | `20251218060432` | **1** (rolling) |

**Note:** `make release` is for manual local releases only. All automated releases use CI/CD (GitHub Actions, Gitea Actions, or GitLab CI depending on git host).

---


# PART 13: TESTING & DEVELOPMENT (NON-NEGOTIABLE)

## NEVER Use Project Directory for Testing (NON-NEGOTIABLE)

**ALL testing, debugging, and runtime data MUST use temp directories. NEVER the project directory.**

| FORBIDDEN | REASON |
|-----------|--------|
| `data/` | Project directory - will pollute repo |
| `config/` | Project directory - will pollute repo |
| `test-data/` | Project directory - will pollute repo |
| `logs/` | Project directory - will pollute repo |
| `{project_path}/anything` | NEVER write test data to project |

**The project directory is for SOURCE CODE ONLY. All runtime/test data goes to the OS temp directory.**

## NEVER Create Example Files (NON-NEGOTIABLE)

**Do NOT create example/sample configuration files in the repository.**

| FORBIDDEN | REASON |
|-----------|--------|
| `server.example.yml` | Unnecessary - defaults are in binary |
| `server.sample.yml` | Unnecessary - defaults are in binary |
| `.env` | We don't use .env files |
| `.env.example` | We don't use .env files |
| `.env.sample` | We don't use .env files |
| `.env.local` | We don't use .env files |
| `config.example.json` | Unnecessary |
| `*.example.*` | No example files of any kind |
| `*.sample.*` | No sample files of any kind |

**If docker-compose.yml needs env vars → hardcode with sane defaults. NEVER use .env files.**

**Why no example files?**

| Reason | Description |
|--------|-------------|
| **Self-documenting** | Binary generates default config on first run |
| **Always current** | Embedded defaults are always in sync with code |
| **No maintenance** | Example files become outdated and misleading |
| **Cleaner repo** | Less clutter in repository |

**How users get configuration:**

1. Run binary - it auto-generates `server.yml` with defaults on first run
2. Admin panel shows all settings with descriptions
3. Documentation in AI.md describes all options

## Temporary Directory Structure (NON-NEGOTIABLE)

**CRITICAL: NEVER use `/tmp` root directory directly. ALWAYS use `/tmp/casapps/casspeed-XXXXXX` structure.**

**FORBIDDEN:**
- ❌ `/tmp/myfile` - Root tmp directory
- ❌ `/tmp/casspeed` - Missing org prefix
- ❌ `mktemp -d` - No org/project structure
- ❌ `/tmp/test-data` - Generic paths

**REQUIRED:**
- ✓ `/tmp/casapps/casspeed-XXXXXX/` - Full structure
- ✓ `/tmp/apimgr/jokes-aB3xY9/` - Org + project + random
- ✓ `mktemp -d "${TMPDIR:-/tmp}/${PROJECTORG}/$CASSPEED-XXXXXX"` - Proper command

**See "Inferring Variables from Path" section for how to detect `ORG` and `PROJECT`.**

### Creating Temp Directories

**Always use `casapps/casspeed-` structure for identifiable temp dirs:**

| Language | How to Create Prefixed Temp Dir |
|----------|--------------------------------|
| Shell | `mkdir -p "${TMPDIR:-/tmp}/${PROJECTORG}" && mktemp -d "${TMPDIR:-/tmp}/${PROJECTORG}/$CASSPEED-XXXXXX"` |
| Go | `os.MkdirAll(filepath.Join(os.TempDir(), projectOrg), 0755); os.MkdirTemp(filepath.Join(os.TempDir(), projectOrg), projectName+"-")` |
| Python | `os.makedirs(f"{tempfile.gettempdir()}/{project_org}", exist_ok=True); tempfile.mkdtemp(prefix=f"{project_name}-", dir=f"{tempfile.gettempdir()}/{project_org}")` |

**Result:** `/tmp/apimgr/jokes-aB3xY9` or `/tmp/casapps/linktree-k9mN2p` (identifiable by org and project)

### Directory Structure

| Purpose | Path Pattern | Example |
|---------|--------------|---------|
| Dev/Test runtime | `{tempdir}/casapps/casspeed-XXXXXX/` | `/tmp/apimgr/jokes-aB3xY9/` |
| Config volume | `{tempdir}/casapps/casspeed-XXXXXX/rootfs/config/` | `/tmp/apimgr/jokes-aB3xY9/rootfs/config/` |
| Data volume | `{tempdir}/casapps/casspeed-XXXXXX/rootfs/data/` | `/tmp/apimgr/jokes-aB3xY9/rootfs/data/` |

### OS Temp Directories

| OS | Default Temp Dir | Env Var |
|----|------------------|---------|
| Linux | `/tmp` | `$TMPDIR` |
| macOS | `/var/folders/.../T/` | `$TMPDIR` |
| Windows | `C:\Users\{user}\AppData\Local\Temp` | `%TEMP%` |
| FreeBSD | `/tmp` | `$TMPDIR` |

### Rules

| Rule | Description |
|------|-------------|
| **NEVER** | Use project directory for test/runtime data |
| **NEVER** | Hardcode `/tmp` - use `os.TempDir()` or `mktemp` |
| **NEVER** | Use bare `mktemp -d` without org prefix |
| **ALWAYS** | Use `casapps.` prefix for all temp dirs |
| **ALWAYS** | Detect org from git remote or directory path |

### Cleanup

```bash
# Find all temp dirs for this org
ls -la "${TMPDIR:-/tmp}"/${PROJECTORG}.*/

# Clean all temp dirs for this org
rm -rf "${TMPDIR:-/tmp}"/${PROJECTORG}.*/
```

### Correct vs Incorrect

| WRONG | RIGHT | Why |
|-------|-------|-----|
| `/tmp/` | `/tmp/casapps/casspeed-XXXXXX/` | NEVER use root tmp |
| `/tmp/myfile` | `/tmp/apimgr/jokes-aB3xY9/myfile` | Always use org/project structure |
| `/tmp/jokes` | `/tmp/apimgr/jokes-kL9mN2/` | Missing org, missing random suffix |
| `/tmp/test-data/` | `/tmp/apimgr/jokes-Qw5rT1/test-data/` | Generic path not allowed |
| `mktemp -d` | `mktemp -d "${TMPDIR:-/tmp}/${PROJECTORG}/$CASSPEED-XXXXXX"` | Must include org/project |
| `os.TempDir()` alone | `os.MkdirTemp(filepath.Join(os.TempDir(), projectOrg), projectName+"-")` | Must nest under org |
| Hardcoded org name | Detect from git remote or path | Auto-detect, never hardcode |

**Rule: ALL temp directories MUST be under `/tmp/casapps/casspeed-XXXXXX/` - no exceptions.**

### Summary: Temp Directory Rules

**The ONLY acceptable temp directory pattern:**
```
/tmp/casapps/casspeed-XXXXXX/
```

**Breaking it down:**
- `/tmp/` or `$TMPDIR` - OS temp directory base
- `casapps/` - Organization directory (apimgr, casapps, etc.)
- `casspeed-XXXXXX` - Project directory with random suffix

**Examples of CORRECT paths:**
- `/tmp/apimgr/jokes-aB3xY9/` ✓
- `/tmp/casapps/linktree-k9mN2p/` ✓
- `/tmp/myorg/myproject-Qw5rT1/` ✓

**Examples of WRONG paths:**
- `/tmp/jokes/` ❌ (missing org)
- `/tmp/myfile` ❌ (no structure at all)
- `/tmp/test-data/` ❌ (generic path)
- `/tmp/apimgr/` ❌ (no project directory)

**Why this structure:**
- Prevents conflicts between projects
- Makes cleanup easy (`rm -rf /tmp/casapps.*`)
- Identifies which project created temp files
- Prevents pollution of root `/tmp` directory
- Multiple projects can run simultaneously

## Container Usage (NON-NEGOTIABLE)

**⚠️ NEVER RUN BINARIES DIRECTLY ON THE HOST. ALWAYS USE CONTAINERS. ⚠️**

**ALL builds, tests, and binary execution MUST use containers. The host is for orchestration only.**

| Rule | Description |
|------|-------------|
| **Host has NO Go** | Go is NOT installed on the host - don't even try |
| **NEVER run binaries on host** | All binaries run inside containers, never directly |
| **NEVER** | Run `go build` directly on host |
| **NEVER** | Run `go test` directly on host |
| **NEVER** | Run `binaries/casspeed` on host |
| **NEVER** | Run `$BUILD_DIR/casspeed` on host |
| **ALWAYS** | Build inside container, run inside container |

### Container Types

| Purpose | Tool | Image | When to Use |
|---------|------|-------|-------------|
| **Building** | Docker | `golang:alpine` | Compiling Go code |
| **Container testing** | Docker | `alpine:latest` | Quick tests, CI/CD |
| **Full OS testing** | Incus | `debian:latest` | Systemd, services, integration |

### Testing Strategy

**Two types of tests are REQUIRED:**

| Test Type | Files | Run With | Tests |
|-----------|-------|----------|-------|
| **Go Unit Tests** | `*_test.go` | `go test` | Function/package logic, no server |
| **Integration Tests** | `tests/*.sh` | Shell scripts | Full server, API endpoints, auth |

**Go Unit Tests (`*_test.go`):**
- Test individual functions and packages
- No server running required
- Fast, run frequently during development
- Run with `docker run ... golang:alpine go test ./...`

**Integration Tests (`tests/*.sh`):**
- Test complete running server
- Test API endpoints, .txt extension, Accept headers
- Test authentication, admin routes
- Test project-specific functionality (from PART 36)
- Run with `./tests/run_tests.sh`

### Testing Requirements Summary

**BOTH types of tests are REQUIRED for all projects:**

1. **Go Unit Tests** (`*_test.go`) - Test package logic
2. **Integration Tests** (`tests/*.sh`) - Test full running application

**Integration tests MUST be comprehensive:**
- ✓ Test ALL project-specific endpoints (PART 36)
- ✓ If project has CRUD → Test full CRUD (Create, Read, Update, Delete)
- ✓ Test both API endpoints (`/api/v1/*`) AND frontend routes (`/**`)
- ✓ Test API .txt extension (for simplicity)
- ✓ Test Accept headers (application/json, text/plain, text/html)
- ✓ Test frontend smart detection (browser → HTML, CLI → text)
- ✓ Test authentication (admin, user if applicable)

**Example: User management project MUST test:**
```bash
# API CRUD (JSON)
POST   /api/v1/users           # Create user (API JSON)
GET    /api/v1/users/1         # Read user (API JSON)
PUT    /api/v1/users/1         # Update user (API JSON)
DELETE /api/v1/users/1         # Delete user (API)

# API .txt extension (for simplicity)
GET    /api/v1/users/1.txt     # Read user (API plain text)

# Frontend routes (smart detection)
curl /users                    # CLI → plain text (smart detection)
browser /users                 # Browser → HTML page (smart detection)
curl -H "Accept: text/plain" /users/1   # Plain text (Accept header)
curl -H "Accept: text/html" /users/1    # HTML (Accept header)
```

**Example: Jokes API (read-only) MUST test:**
```bash
# API endpoints
GET /api/v1/jokes/random             # Random joke (JSON)
GET /api/v1/jokes/random.txt         # Random joke (text)
GET /api/v1/jokes/programming        # Category filter (JSON)
GET /api/v1/jokes/search?q=bug       # Search (JSON)

# Frontend endpoints (smart detection)
curl /jokes/random                   # CLI auto-detects → text
curl /jokes                          # CLI → text list
curl -H "Accept: text/html" /jokes   # Browser → HTML
```

**Example: Weather API (external integration) MUST test:**
```bash
# API endpoints with location params
GET /api/v1/weather/current/New%20York        # Current weather (JSON)
GET /api/v1/weather/current/New%20York.txt    # Current weather (text)
GET /api/v1/weather/forecast/10001            # ZIP code forecast (JSON)
GET /api/v1/weather/alerts/40.7128,-74.0060   # Lat/long alerts (JSON)

# Test caching behavior
GET /api/v1/weather/current/Chicago           # First call (cache miss)
GET /api/v1/weather/current/Chicago           # Second call (cache hit, faster)

# Frontend (smart detection)
curl /weather/Chicago                # CLI → text
curl /weather/forecast/90210         # CLI → text forecast
```

**Example: Link Shortener (URL mapping) MUST test:**
```bash
# API CRUD for short links
POST   /api/v1/links -d '{"url":"https://example.com/long/url"}'  # Create
GET    /api/v1/links/abc123         # Get link details (JSON)
PUT    /api/v1/links/abc123 -d '{"url":"https://new.com"}'        # Update
DELETE /api/v1/links/abc123         # Delete

# Redirect resolution
GET /abc123                          # Should redirect to destination
GET /abc123/stats                    # Link statistics (JSON or HTML)

# Frontend (smart detection)
curl /links                          # User's links list (text)
curl /links/abc123                   # Link details (text)
```

### Go Unit Test Requirements

**Every package with logic SHOULD have unit tests:**

| Package | Test File | What to Test |
|---------|-----------|--------------|
| `config/` | `config_test.go` | Config loading, validation, defaults |
| `server/` | `server_test.go` | Route registration, middleware |
| `server/handler/` | `*_handler_test.go` | Handler logic (mock requests) |
| `mode/` | `mode_test.go` | Mode detection, behavior |
| `ssl/` | `ssl_test.go` | Certificate loading, validation |
| `paths/` | `paths_test.go` | Path resolution |

**What to test in unit tests:**
- ✓ Function inputs/outputs
- ✓ Edge cases and error handling
- ✓ Validation logic
- ✓ Data transformations
- ✓ Business logic without dependencies

**What NOT to test in unit tests:**
- ✗ Full HTTP requests (use integration tests)
- ✗ Database operations (use integration tests)
- ✗ External services (use integration tests)
- ✗ Authentication flows (use integration tests)

**Running Go tests:**
```bash
# Run all unit tests (via Docker)
make test

# Or directly:
docker run --rm -v $(pwd):/build -w /build golang:alpine go test -v -cover ./...

# Run specific package tests
docker run --rm -v $(pwd):/build -w /build golang:alpine go test -v ./src/config/

# Run with coverage
docker run --rm -v $(pwd):/build -w /build golang:alpine go test -cover ./...
```

**When to run which tests:**

| When | Run This | Purpose |
|------|----------|---------|
| **During development** | `make test` (Go unit tests) | Fast feedback, verify logic |
| **Before committing** | `make test` + `./tests/run_tests.sh` | Verify all tests pass |
| **Before release** | `make test` + `./tests/incus.sh` | Full systemd testing |
| **In CI/CD** | Both Go tests and integration tests | Automated verification |

**Test Execution Order:**
```bash
1. make test                    # Go unit tests (fast)
2. ./tests/run_tests.sh         # Integration tests (slower, full coverage)
```

### Integration Testing Strategy

**Preferred: Incus with Debian** (if available)
- Full systemd support
- Complete OS environment
- Service installation testing
- Full integration tests

**Fallback: Docker with golang:alpine**
- When Incus not available
- CI/CD environments
- Quick validation tests

### Incus vs Docker

| Aspect | Incus (Preferred) | Docker (Fallback) |
|--------|-------------------|-------------------|
| **Use for** | Full OS/systemd testing | Container/app testing |
| **Image** | `debian:latest` | `golang:alpine` or `alpine:latest` |
| **Init system** | Full systemd | None (single process) |
| **Best for** | Service install, integration | Quick tests, CI/CD |
| **Startup** | ~5s | Fast (~1s) |
| **Availability** | May not be installed | Always available |

### Testing Workflow

```bash
# 1. Build in Docker (always use Docker for builds)
BUILD_DIR=$(mktemp -d "${TMPDIR:-/tmp}/${PROJECTORG}.XXXXXX")
docker run --rm -v $(pwd):/build -w /build -e CGO_ENABLED=0 \
  golang:alpine go build -o /build/binaries/casspeed src

# 2. Test (prefer Incus, fallback to Docker)
if command -v incus &>/dev/null; then
  # PREFERRED: Full OS test in Incus (debian + systemd)
  echo "Testing with Incus (Debian + systemd)..."
  incus launch images:debian/12 test-casspeed
  incus file push binaries/casspeed test-casspeed/usr/local/bin/
  incus exec test-casspeed -- chmod +x /usr/local/bin/casspeed
  incus exec test-casspeed -- casspeed --help
  incus exec test-casspeed -- casspeed --service --install
  incus exec test-casspeed -- systemctl status casspeed
  incus delete test-casspeed --force
else
  # FALLBACK: Quick test in Docker (alpine, no systemd)
  echo "Incus not available, testing with Docker..."
  docker run --rm -v $(pwd)/binaries:/app alpine:latest \
    /app/casspeed --help
fi
```

### Why Containerized Everything?

| Reason | Description |
|--------|-------------|
| **Clean system** | No Go, no binaries, no artifacts on host |
| **Isolation** | Each test runs in fresh environment |
| **Reproducible** | Same results across all machines |
| **Full OS testing** | Incus provides real systemd for service tests |
| **No pollution** | Host system stays pristine |

### Test Scripts (tests/ directory)

**ALL projects MUST have these test scripts in `tests/` directory:**

| Script | Purpose | Container | Tests |
|--------|---------|-----------|-------|
| `tests/run_tests.sh` | Auto-detect runtime and run tests | Auto-detect | Runs incus.sh or docker.sh |
| `tests/docker.sh` | Beta testing with Docker | `alpine:latest` | Full integration tests |
| `tests/incus.sh` | Beta testing with Incus | `debian:latest` | Full integration + systemd tests |

**docker.sh and incus.sh MUST:**
1. Build binary using Docker (golang:alpine) in temp directory
2. Copy binary to test container
3. Run full beta test suite:
   - Version and help checks
   - Binary info verification
   - Start server and test API endpoints
   - Test API .txt extension (for simplicity)
   - Test frontend smart detection (browser → HTML, CLI → text)
   - Test Accept headers (application/json, text/plain, text/html)
   - Test project-specific endpoints (from PART 36)
   - Test admin authentication (see "Testing Admin Routes")
4. Clean up on exit

#### tests/docker.sh

**Purpose:** Full integration testing in Docker Alpine container

```bash
#!/usr/bin/env bash
set -euo pipefail

# Detect project info
PROJECTNAME=$(basename "$PWD")
PROJECTORG=$(basename "$(dirname "$PWD")")

# Create temp directory for build
BUILD_DIR=$(mktemp -d "${TMPDIR:-/tmp}/${PROJECTORG}.XXXXXX")
trap "rm -rf $BUILD_DIR" EXIT

echo "Building binary in Docker..."
docker run --rm \
  -v "$(pwd):/build" \
  -w /build \
  -e CGO_ENABLED=0 \
  golang:alpine go build -o "$BUILD_DIR/$CASSPEED" src

echo "Testing in Docker (Alpine)..."
docker run --rm \
  -v "$BUILD_DIR:/app" \
  alpine:latest sh -c "
    set -e
    chmod +x /app/$CASSPEED

    echo '=== Version Check ==='
    /app/$CASSPEED --version

    echo '=== Help Check ==='
    /app/$CASSPEED --help

    echo '=== Binary Info ==='
    ls -lh /app/$CASSPEED
    file /app/$CASSPEED

    echo '=== Starting Server for API Tests ==='
    /app/$CASSPEED --port 64580 &
    SERVER_PID=\$!
    sleep 3

    echo '=== API Endpoint Tests ==='
    # Test JSON response (default)
    curl -f http://localhost:64580/api/v1/healthz || echo 'FAILED: /api/v1/healthz'

    # Test .txt extension (plain text)
    curl -f http://localhost:64580/api/v1/healthz.txt || echo 'FAILED: /api/v1/healthz.txt'

    # Test Accept header: application/json
    curl -f -H 'Accept: application/json' http://localhost:64580/healthz || echo 'FAILED: Accept JSON'

    # Test Accept header: text/plain
    curl -f -H 'Accept: text/plain' http://localhost:64580/healthz || echo 'FAILED: Accept text/plain'

    echo '=== Project-Specific Endpoint Tests ==='
    # MUST test ALL endpoints from PART 36 - both API and frontend
    # Test FULL CRUD if project has CRUD operations
    #
    # Example for jokes API (API routes with .txt extension):
    #   curl -f http://localhost:64580/api/v1/jokes/random || echo 'FAILED: API JSON'
    #   curl -f http://localhost:64580/api/v1/jokes/random.txt || echo 'FAILED: API .txt'
    #   curl -f -H 'Accept: text/plain' http://localhost:64580/api/v1/jokes/random || echo 'FAILED: API Accept text'
    #
    # Example for jokes frontend (smart detection, no .txt - test with text for simplicity):
    #   JOKE=\$(curl -s http://localhost:64580/jokes/random)  # CLI auto-detects text
    #   if echo "\$JOKE" | grep -q "Why"; then echo '✓ Frontend text works'; else echo 'FAILED: Frontend text'; fi
    #   # Optional: verify HTML is served to browsers
    #   curl -f -s -I -H 'Accept: text/html' http://localhost:64580/jokes/random | grep -q 'text/html' || echo 'FAILED: Frontend HTML'
    #
    # Example for user CRUD (full test suite):
    #   # API CRUD
    #   curl -f -X POST -H 'Content-Type: application/json' -d '{\"username\":\"test\"}' http://localhost:64580/api/v1/users || echo 'FAILED: CREATE user API'
    #   curl -f http://localhost:64580/api/v1/users/1 || echo 'FAILED: READ user API JSON'
    #   curl -f http://localhost:64580/api/v1/users/1.txt || echo 'FAILED: READ user API .txt'
    #   curl -f -X PUT -H 'Content-Type: application/json' -d '{\"email\":\"new@test.com\"}' http://localhost:64580/api/v1/users/1 || echo 'FAILED: UPDATE user API'
    #   curl -f -X DELETE http://localhost:64580/api/v1/users/1 || echo 'FAILED: DELETE user API'
    #   # Frontend (smart detection - test with text for simplicity)
    #   USERS=\$(curl -s http://localhost:64580/users)  # CLI auto-detects text
    #   if echo "\$USERS" | grep -q "testuser"; then echo '✓ Frontend user list'; else echo 'FAILED: Frontend user list'; fi
    #   USER=\$(curl -s http://localhost:64580/users/1)  # CLI auto-detects text
    #   if echo "\$USER" | grep -q "testuser"; then echo '✓ Frontend user profile'; else echo 'FAILED: Frontend user'; fi
    #
    # Test ALL project-specific endpoints defined in PART 36

    echo '=== Stopping Server ==='
    kill \$SERVER_PID
    wait \$SERVER_PID 2>/dev/null || true

    echo '=== All tests passed ==='
"

echo "Docker tests completed successfully"
```

#### tests/incus.sh

**Purpose:** Full integration + systemd testing in Incus Debian container

```bash
#!/usr/bin/env bash
set -euo pipefail

# Check if incus is available
if ! command -v incus &>/dev/null; then
    echo "ERROR: incus not found. Install incus or use tests/docker.sh"
    exit 1
fi

# Detect project info
PROJECTNAME=$(basename "$PWD")
PROJECTORG=$(basename "$(dirname "$PWD")")
CONTAINER_NAME="test-$CASSPEED-$$"

# Create temp directory for build
BUILD_DIR=$(mktemp -d "${TMPDIR:-/tmp}/${PROJECTORG}.XXXXXX")
trap "rm -rf $BUILD_DIR; incus delete $CONTAINER_NAME --force 2>/dev/null || true" EXIT

echo "Building binary in Docker..."
docker run --rm \
  -v "$(pwd):/build" \
  -w /build \
  -e CGO_ENABLED=0 \
  golang:alpine go build -o "$BUILD_DIR/$CASSPEED" src

echo "Launching Incus container (Debian + systemd)..."
incus launch images:debian/12 "$CONTAINER_NAME"

# Wait for container to be ready
sleep 2

echo "Copying binary to container..."
incus file push "$BUILD_DIR/$CASSPEED" "$CONTAINER_NAME/usr/local/bin/"
incus exec "$CONTAINER_NAME" -- chmod +x "/usr/local/bin/$CASSPEED"

echo "Running tests in Incus..."
incus exec "$CONTAINER_NAME" -- bash -c "
    set -e

    echo '=== Version Check ==='
    $CASSPEED --version

    echo '=== Help Check ==='
    $CASSPEED --help

    echo '=== Binary Info ==='
    ls -lh /usr/local/bin/$CASSPEED
    file /usr/local/bin/$CASSPEED

    echo '=== Service Install Test ==='
    $CASSPEED --service --install

    echo '=== Service Status ==='
    systemctl status $CASSPEED || true

    echo '=== Service Start Test ==='
    systemctl start $CASSPEED
    sleep 2
    systemctl status $CASSPEED

    echo '=== API Endpoint Tests ==='
    # Test JSON response (default)
    curl -f http://localhost:80/api/v1/healthz || echo 'FAILED: /api/v1/healthz'

    # Test .txt extension (plain text)
    curl -f http://localhost:80/api/v1/healthz.txt || echo 'FAILED: /api/v1/healthz.txt'

    # Test Accept header: application/json
    curl -f -H 'Accept: application/json' http://localhost:80/healthz || echo 'FAILED: Accept JSON'

    # Test Accept header: text/plain
    curl -f -H 'Accept: text/plain' http://localhost:80/healthz || echo 'FAILED: Accept text/plain'

    echo '=== Project-Specific Endpoint Tests ==='
    # MUST test ALL endpoints from PART 36 - both API and frontend
    # Test FULL CRUD if project has CRUD operations
    #
    # Example for jokes API (API routes with .txt extension):
    #   curl -f http://localhost:80/api/v1/jokes/random || echo 'FAILED: API JSON'
    #   curl -f http://localhost:80/api/v1/jokes/random.txt || echo 'FAILED: API .txt'
    #   curl -f -H 'Accept: text/plain' http://localhost:80/api/v1/jokes/random || echo 'FAILED: API Accept text'
    #
    # Example for jokes frontend (smart detection, no .txt - test with text for simplicity):
    #   JOKE=\$(curl -s http://localhost:80/jokes/random)  # CLI auto-detects text
    #   if echo "\$JOKE" | grep -q "Why"; then echo '✓ Frontend text works'; else echo 'FAILED: Frontend text'; fi
    #   # Optional: verify HTML is served to browsers
    #   curl -f -s -I -H 'Accept: text/html' http://localhost:80/jokes/random | grep -q 'text/html' || echo 'FAILED: Frontend HTML'
    #
    # Example for user CRUD (full test suite):
    #   # API CRUD
    #   curl -f -X POST -H 'Content-Type: application/json' -d '{\"username\":\"test\"}' http://localhost:80/api/v1/users || echo 'FAILED: CREATE user API'
    #   curl -f http://localhost:80/api/v1/users/1 || echo 'FAILED: READ user API JSON'
    #   curl -f http://localhost:80/api/v1/users/1.txt || echo 'FAILED: READ user API .txt'
    #   curl -f -X PUT -H 'Content-Type: application/json' -d '{\"email\":\"new@test.com\"}' http://localhost:80/api/v1/users/1 || echo 'FAILED: UPDATE user API'
    #   curl -f -X DELETE http://localhost:80/api/v1/users/1 || echo 'FAILED: DELETE user API'
    #   # Frontend (smart detection - test with text for simplicity)
    #   USERS=\$(curl -s http://localhost:80/users)  # CLI auto-detects text
    #   if echo "\$USERS" | grep -q "testuser"; then echo '✓ Frontend user list'; else echo 'FAILED: Frontend user list'; fi
    #   USER=\$(curl -s http://localhost:80/users/1)  # CLI auto-detects text
    #   if echo "\$USER" | grep -q "testuser"; then echo '✓ Frontend user profile'; else echo 'FAILED: Frontend user'; fi
    #
    # Test ALL project-specific endpoints defined in PART 36

    echo '=== Service Stop Test ==='
    systemctl stop $CASSPEED

    echo '=== All tests passed ==='
"

echo "Incus tests completed successfully"
```

#### tests/run_tests.sh

**Purpose:** Automatic test runner - detects available container runtime and runs appropriate test

```bash
#!/usr/bin/env bash
set -euo pipefail

# Detect available container runtime and run appropriate test
if command -v incus &>/dev/null; then
    echo "Incus detected - running full systemd tests..."
    exec "$(dirname "$0")/incus.sh"
elif command -v docker &>/dev/null; then
    echo "Docker detected - running container tests..."
    exec "$(dirname "$0")/docker.sh"
else
    echo "ERROR: Neither incus nor docker found"
    echo "Please install one of the following:"
    echo "  - Incus (preferred): https://linuxcontainers.org/incus/"
    echo "  - Docker (fallback): https://docker.com/"
    exit 1
fi
```

**Test Script Rules:**

| Rule | Requirement |
|------|-------------|
| **Location** | `tests/run_tests.sh`, `tests/docker.sh`, `tests/incus.sh` |
| **Permissions** | Executable (`chmod +x tests/*.sh`) |
| **Build method** | ALWAYS use Docker (golang:alpine) |
| **Build location** | ALWAYS use temp directory |
| **API endpoint testing** | MUST test .txt extension and Accept headers on API routes |
| **Frontend testing** | MUST test smart detection (CLI → text, browser → HTML) |
| **Content negotiation** | Test JSON, text/plain, and text/html responses |
| **Project-specific tests** | MUST test ALL endpoints from PART 36 (CRUD, API, frontend) |
| **Admin authentication** | Test setup token, login, and rejection (no bypass) |
| **Cleanup** | ALWAYS use `trap` for cleanup |
| **Exit codes** | 0 = success, non-zero = failure |
| **Output** | Clear progress messages with `echo` |
| **Error handling** | `set -euo pipefail` at top |

## Testing Admin Routes (NON-NEGOTIABLE)

**Admin routes (`/admin/**`) require authentication. Tests MUST verify authentication works.**

**CRITICAL: Do NOT bypass authentication in tests - TEST that it works!**

### Proper Admin Testing Approach

**Tests should verify the authentication system, not skip it:**

```bash
#!/usr/bin/env bash
set -euo pipefail

echo '=== Admin Authentication Tests ==='

# Start server normally (authentication required)
/app/$CASSPEED --port 64580 &
SERVER_PID=$!
sleep 3

# 1. Test that unauthenticated access is REJECTED
echo "Testing unauthenticated access is blocked..."
HTTP_CODE=$(curl -s -o /dev/null -w "%{http_code}" http://localhost:64580/admin)
if [ "$HTTP_CODE" = "302" ] || [ "$HTTP_CODE" = "401" ]; then
    echo "✓ Unauthenticated access properly rejected"
else
    echo "✗ FAILED: Admin routes not protected (got HTTP $HTTP_CODE)"
    kill $SERVER_PID
    exit 1
fi

# 2. Get setup token from server logs
SETUP_TOKEN=$(grep -oP 'Setup Token.*:\s*\K[a-f0-9]+' /tmp/server.log | head -1)

if [ -z "$SETUP_TOKEN" ]; then
    echo "✗ FAILED: No setup token found in logs"
    kill $SERVER_PID
    exit 1
fi

echo "✓ Setup token found: ${SETUP_TOKEN:0:8}..."

# 3. Test admin routes WITH authentication (setup token)
echo "Testing admin access with setup token..."
HTTP_CODE=$(curl -s -o /dev/null -w "%{http_code}" \
    -H "X-Setup-Token: $SETUP_TOKEN" \
    http://localhost:64580/admin)

if [ "$HTTP_CODE" = "200" ]; then
    echo "✓ Admin access works with setup token"
else
    echo "✗ FAILED: Admin access with token returned HTTP $HTTP_CODE"
    kill $SERVER_PID
    exit 1
fi

# 4. Complete setup wizard (create admin account)
echo "Creating admin account via API..."
curl -s -X POST \
    -H "X-Setup-Token: $SETUP_TOKEN" \
    -H "Content-Type: application/json" \
    -d '{"username":"testadmin","password":"TestPass123!"}' \
    http://localhost:64580/api/v1/admin/setup

# 5. Test login with created admin
echo "Testing admin login..."
SESSION=$(curl -s -X POST \
    -H "Content-Type: application/json" \
    -d '{"username":"testadmin","password":"TestPass123!"}' \
    http://localhost:64580/api/v1/admin/login | jq -r '.session_token')

if [ -z "$SESSION" ] || [ "$SESSION" = "null" ]; then
    echo "✗ FAILED: Admin login failed"
    kill $SERVER_PID
    exit 1
fi

echo "✓ Admin login successful"

# 6. Test admin routes with valid session
echo "Testing admin routes with session..."
curl -s -H "Authorization: Bearer $SESSION" \
    http://localhost:64580/api/v1/admin/users > /dev/null

echo "✓ Admin routes work with authentication"

# 7. Test that invalid credentials are rejected
echo "Testing invalid credentials are rejected..."
INVALID=$(curl -s -X POST \
    -H "Content-Type: application/json" \
    -d '{"username":"testadmin","password":"wrongpassword"}' \
    -w "%{http_code}" \
    http://localhost:64580/api/v1/admin/login)

if echo "$INVALID" | grep -q "401\|403"; then
    echo "✓ Invalid credentials properly rejected"
else
    echo "✗ FAILED: Invalid credentials not rejected"
    kill $SERVER_PID
    exit 1
fi

# Cleanup
kill $SERVER_PID
wait $SERVER_PID 2>/dev/null || true

echo '=== All admin authentication tests passed ==='
```

### Debug Mode - ONLY for Manual Development

**Debug mode auth bypass exists ONLY for quick manual testing during development:**

```go
// In admin middleware
func AdminAuthMiddleware(next http.Handler) http.Handler {
    return http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {
        // Debug mode: bypass authentication ONLY for manual dev work
        // NEVER use this in automated tests!
        if os.Getenv("DEBUG") == "true" || config.IsDebug() {
            log.Println("[DEBUG] Admin auth bypassed (debug mode - manual dev only)")
            next.ServeHTTP(w, r)
            return
        }

        // Normal: require valid admin session
        session := validateAdminSession(r)
        if session == nil {
            http.Redirect(w, r, "/admin/login", http.StatusSeeOther)
            return
        }

        next.ServeHTTP(w, r)
    })
}
```

**Debug bypass is for:**
- ✓ Quick manual UI testing during development
- ✓ Exploring admin panel while coding
- ✓ Debugging admin routes interactively

**Debug bypass is NOT for:**
- ✗ Automated test scripts
- ✗ Beta testing
- ✗ CI/CD pipelines
- ✗ Verifying authentication works

### Admin Testing Rules

| Rule | Requirement |
|------|-------------|
| **Test authentication** | Tests MUST verify auth works, not bypass it |
| **Use setup token** | First-run setup token for initial admin access |
| **Create test admin** | Create admin account via setup API |
| **Test login flow** | Verify credentials, sessions, and access control |
| **Test rejection** | Verify unauthenticated and invalid credentials are rejected |
| **Debug mode** | ONLY for manual development, NEVER in automated tests |

### Container Images

| Purpose | Image | Required Packages | Why |
|---------|-------|-------------------|-----|
| Building Go | `golang:alpine` | `git`, `bash` | Latest Go, dependencies need git |
| Container runtime | `alpine:latest` | `git`, `bash`, `curl`, `tini`, `tor` | Minimal, all runtime tools included |
| Full OS runtime | `debian:latest` (Incus) | Full OS | Complete systemd, realistic environment |

### Common Docker Commands

**All Go commands MUST be run through Docker. Here are the patterns:**

```bash
# Set project path to YOUR actual project location (examples shown below)
# Use git top-level if in a git repo: PROJECT_PATH="$(git rev-parse --show-toplevel)"
# Or use absolute path to your project directory
PROJECT_PATH="/root/Projects/github/apimgr/casspeed"  # Example 1
# PROJECT_PATH="~/Documents/myproject"                     # Example 2
# PROJECT_PATH="~/myproject"                               # Example 3
# PROJECT_PATH="/workspace/dev/myproject"                  # Example 4

# Build (outputs to binaries/ which can be mounted into test containers)
docker run --rm -v $PROJECT_PATH:/build -w /build -e CGO_ENABLED=0 \
  golang:alpine go build -o /build/binaries/casspeed src

# Run tests
docker run --rm -v $PROJECT_PATH:/build -w /build \
  golang:alpine go test ./...

# Run specific test
docker run --rm -v $PROJECT_PATH:/build -w /build \
  golang:alpine go test -v src/server/...

# Tidy modules
docker run --rm -v $PROJECT_PATH:/build -w /build \
  golang:alpine go mod tidy

# Download dependencies
docker run --rm -v $PROJECT_PATH:/build -w /build \
  golang:alpine go mod download

# Check formatting
docker run --rm -v $PROJECT_PATH:/build -w /build \
  golang:alpine go fmt ./...

# Run vet
docker run --rm -v $PROJECT_PATH:/build -w /build \
  golang:alpine go vet ./...

# Interactive shell (for debugging)
docker run --rm -it -v $PROJECT_PATH:/build -w /build \
  golang:alpine sh
```

## Build and Test (NON-NEGOTIABLE)

**Build outputs to `binaries/`, test by running in container.**

```bash
# Build
docker run --rm -v $(pwd):/build -w /build -e CGO_ENABLED=0 \
  golang:alpine go build -o /build/binaries/casspeed src

# Test in Docker (quick)
docker run --rm -v $(pwd)/binaries:/app alpine:latest /app/casspeed --help

# Test in Incus (full OS with systemd)
incus launch images:debian/12 test-casspeed
incus file push binaries/casspeed test-casspeed/usr/local/bin/
incus exec test-casspeed -- casspeed --help
incus delete test-casspeed --force
```

### Testing with Config/Data

```bash
# Create prefixed temp dir for test data
TEST_DIR=$(mktemp -d "${TMPDIR:-/tmp}/${PROJECTORG}.XXXXXX")
mkdir -p $TEST_DIR/{config,data,logs}

# Build to binaries/
docker run --rm -v $(pwd):/build -w /build -e CGO_ENABLED=0 \
  golang:alpine go build -o /build/binaries/casspeed src

# Quick test in Docker
docker run --rm -v $(pwd)/binaries:/app alpine:latest /app/casspeed --help
docker run --rm -v $(pwd)/binaries:/app alpine:latest /app/casspeed --version

# Full test with config/data in Docker
docker run --rm \
  -v $(pwd)/binaries:/app \
  -v $TEST_DIR:/test \
  alpine:latest /app/casspeed \
    --config /test/config \
    --data /test/data \
    --log /test/logs

# Cleanup
rm -rf $TEST_DIR
```

### Full OS Testing with Incus

**For testing systemd services, use Incus with Debian:**

```bash
# Create prefixed temp dir
TEST_DIR=$(mktemp -d "${TMPDIR:-/tmp}/${PROJECTORG}.XXXXXX")
mkdir -p $TEST_DIR/{config,data,logs}

# Build
docker run --rm -v $(pwd):/build -w /build -e CGO_ENABLED=0 \
  golang:alpine go build -o /build/binaries/casspeed src

# Launch Incus container
incus launch images:debian/12 test-casspeed

# Push binary and test data
incus file push binaries/casspeed test-casspeed/usr/local/bin/
incus exec test-casspeed -- mkdir -p /etc/casapps/casspeed /var/lib/casapps/casspeed

# Test
incus exec test-casspeed -- casspeed --help
incus exec test-casspeed -- casspeed --version
incus exec test-casspeed -- casspeed --service --install
incus exec test-casspeed -- systemctl status casspeed

# Cleanup
incus delete test-casspeed --force
rm -rf $TEST_DIR
```

**NEVER run binaries directly on host - always use Docker or Incus containers!**

## Process Management (NON-NEGOTIABLE)

**STRICT RULES: Only kill/remove the EXACT process or container being worked on. NEVER anything else.**

### FORBIDDEN Commands (NEVER Use)

| Command | Reason |
|---------|--------|
| `pkill -f {pattern}` | Too broad, kills unrelated processes |
| `pkill {name}` | Too broad without `-x` flag |
| `killall {name}` | Too broad, may kill unrelated processes |
| `kill -9 {pid}` | Use graceful `kill {pid}` first |
| `docker kill` | Use `docker stop` for graceful shutdown |
| `docker rm $(docker ps -aq)` | Removes ALL containers |
| `docker rm $(docker ps -q)` | Removes ALL running containers |
| `docker rmi $(docker images -q)` | Removes ALL images |
| `docker system prune` | Cleans ALL unused resources |
| `docker container prune` | Removes ALL stopped containers |
| `docker image prune` | Removes ALL dangling images |
| `docker volume prune` | Removes ALL unused volumes |
| `docker network prune` | Removes ALL unused networks |
| `rm -rf /` | Catastrophic |
| `rm -rf /*` | Catastrophic |
| `rm -rf ~` | Destroys home directory |
| `rm -rf .` | Dangerous in wrong directory |
| `rm -rf *` | Dangerous without proper scoping |

### Process Termination Rules

| Rule | Description |
|------|-------------|
| **Identify first** | ALWAYS get exact PID before killing |
| **Graceful first** | Use `kill {pid}` (SIGTERM), wait, then `kill -9 {pid}` only if needed |
| **One at a time** | Kill ONE specific PID, never patterns |
| **Verify PID** | Confirm PID belongs to the project process |
| **Document** | Log what was killed and why |

**Kill Process Flow:**
```
1. pgrep -la casspeed           # List matching processes
2. Verify the PID is correct          # CHECK before killing
3. kill {pid}                         # Graceful termination (SIGTERM)
4. sleep 5                            # Wait for graceful shutdown
5. pgrep -la casspeed           # Check if still running
6. kill -9 {pid}                      # Force kill ONLY if still running
```

### Docker Container Rules

| Rule | Description |
|------|-------------|
| **ONLY this project** | Only stop/remove containers named `casspeed` |
| **NEVER other containers** | Even if they look related or unused |
| **NEVER images not ours** | Only remove `casapps/casspeed:*` images |
| **NEVER base images** | Never remove `golang`, `alpine`, `ubuntu`, etc. |
| **NEVER volumes** | Unless explicitly part of this project |

**Docker Cleanup Flow:**
```
1. docker ps -a --filter name=casspeed     # List ONLY this project's containers
2. Verify output shows ONLY casspeed       # CHECK before removing
3. docker stop casspeed                    # Stop gracefully
4. docker rm casspeed                      # Remove container

# For images:
1. docker images casapps/casspeed     # List ONLY this project's images
2. Verify output shows ONLY our images          # CHECK before removing
3. docker rmi casapps/casspeed:tag    # Remove SPECIFIC tag
```

### Allowed Commands (Project-Scoped ONLY)

| Command | Description |
|---------|-------------|
| `kill {specific-pid}` | Kill exact PID only (after verification) |
| `pkill -x casspeed` | Exact binary name match only |
| `docker stop casspeed` | Stop specific container by name |
| `docker rm casspeed` | Remove specific container by name |
| `docker rmi casapps/casspeed:tag` | Remove specific image:tag |
| `rm -rf $BUILD_DIR` | Remove temp build dir (from mktemp) |
| `rm -rf $TEST_DIR` | Remove temp test dir (from mktemp) |

### Before ANY Kill/Remove Operation

1. **List first**: See exactly what will be affected
2. **Verify**: Confirm it's the correct process/container/file
3. **Be specific**: Use exact names, PIDs, or paths - NEVER patterns
4. **Ask if unsure**: When in doubt, ask the user
5. **Document**: Log what was removed and why

## File Cleanup Rules (NON-NEGOTIABLE)

**Always be explicit and project-scoped when deleting files.**

### Safe Cleanup Commands

| Purpose | Command |
|---------|---------|
| Temp build dir | `rm -rf $BUILD_DIR` (saved from mktemp) |
| Temp test dir | `rm -rf $TEST_DIR` (saved from mktemp) |
| All mktemp dirs | Cleaned automatically on reboot |
| Project binaries | `rm -rf binaries/casspeed*` |
| Project releases | `rm -rf releases/casspeed*` |

**Note:** Always use `mktemp -d "${TMPDIR:-/tmp}/${PROJECTORG}.XXXXXX"` and save the path to a variable for cleanup. Temp dirs are auto-cleaned on reboot.

### NEVER Delete Without Confirmation

| Item | Why |
|------|-----|
| User data directories | Irreversible data loss |
| Config files | User customizations lost |
| Database files | Data loss |
| SSL certificates | Service disruption |
| Git repositories | Code loss |
| Anything outside project scope | Affects other systems |

### Cleanup Checklist

Before running any `rm -rf`:

1. **Echo first**: `echo "Would delete: /path/to/delete"` - verify the path
2. **Check pwd**: `pwd` - make sure you're in the right directory
3. **List first**: `ls -la /path/to/delete` - see what will be deleted
4. **Be specific**: Use full paths, not relative paths with wildcards
5. **Ask if unsure**: When in doubt, ask the user before deleting

---


# PART 14: DOCKER (NON-NEGOTIABLE)

## Docker Directory Structure (NON-NEGOTIABLE)

All Docker-related files MUST be in `docker/`:

```
docker/
├── Dockerfile              # Production Dockerfile
├── Dockerfile.dev          # Development Dockerfile (optional)
├── docker-compose.yml      # Production compose (NO debug options)
├── docker-compose.dev.yml  # Development compose (DEBUG commented)
├── docker-compose.test.yml # Test compose (DEBUG=true enabled)
└── rootfs/                 # Container filesystem overlay
    └── usr/
        └── local/
            └── bin/
                └── entrypoint.sh  # Container entrypoint (REQUIRED)
```

**Build Context:**
- Docker build context is project root (`.`)
- Dockerfile specified with `-f docker/Dockerfile`
- Multi-stage build: Go binary compiled in builder stage
- rootfs copied from `docker/rootfs/`

**Rules:**
- NEVER place Dockerfile or docker-compose.yml in project root
- ALWAYS use `docker/` directory for all Docker files
- ALWAYS use `entrypoint.sh` for container startup
- ALWAYS use multi-stage build (no pre-built binaries needed)
- rootfs structure mirrors container filesystem

## Dockerfile Requirements

| Requirement | Value |
|-------------|-------|
| Location | `docker/Dockerfile` |
| **Build type** | **Multi-stage** (builder + runtime) |
| Builder stage | `golang:alpine` |
| Runtime stage | `alpine:latest` |
| Meta labels | All OCI labels (see below) |
| Required packages | git, curl, bash, tini, **tor** |
| Binary location | `/usr/local/bin/casspeed` |
| Entrypoint script | `/usr/local/bin/entrypoint.sh` |
| Init system | **tini** |
| Internal port | **80** |
| **ENV MODE** | **development** (allows localhost, .local, .test, etc.) |

### Container Paths (NON-NEGOTIABLE)

| Path | Purpose |
|------|---------|
| `/config` | Configuration directory (server.yml, templates, SSL certs) |
| `/config/security` | Security databases (geoip, blocklists, cve, trivy) |
| `/data` | Data directory (databases, Tor keys, caches) |
| `/data/db` | SQLite databases (server.db, users.db) |
| `/data/logs` | Log files (access.log, error.log, audit.log, etc.) |
| `/data/tor` | Tor data (hidden service keys) |
| `/data/backup` | Backup archives |
| `/usr/local/bin/casspeed` | Application binary |
| `/root/Dockerfile` | Build reference and backup |

### OCI Meta Labels (Required)

All Dockerfiles MUST include these labels:

| Label | Value |
|-------|-------|
| `maintainer` | `{maintainer_name} <{maintainer_email}>` |
| `org.opencontainers.image.vendor` | `casapps` |
| `org.opencontainers.image.authors` | `casapps` |
| `org.opencontainers.image.title` | `casspeed` |
| `org.opencontainers.image.base.name` | `casspeed` |
| `org.opencontainers.image.description` | `Containerized version of casspeed` |
| `org.opencontainers.image.licenses` | License (e.g., `MIT`) |
| `org.opencontainers.image.created` | `${BUILD_DATE}` (ARG) |
| `org.opencontainers.image.version` | `${VERSION}` (ARG) |
| `org.opencontainers.image.schema-version` | `${VERSION}` (ARG) |
| `org.opencontainers.image.revision` | `${COMMIT_ID}` (ARG) |
| `org.opencontainers.image.url` | `https://github.com/casapps/casspeed` |
| `org.opencontainers.image.source` | `https://github.com/casapps/casspeed` |
| `org.opencontainers.image.documentation` | `https://github.com/casapps/casspeed` |
| `org.opencontainers.image.vcs-type` | `Git` |
| `com.github.containers.toolbox` | `false` |

### Multi-Arch Manifest Annotations (NON-NEGOTIABLE)

**For multi-arch images, OCI labels MUST also be set as manifest annotations.**

Container registries (GHCR, Docker Hub, etc.) read metadata from the manifest index for multi-arch images, not from individual image configs. Without manifest annotations, registry pages show no description.

| Where | How | What For |
|-------|-----|----------|
| Dockerfile `LABEL` | Image config | Single-arch images, `docker inspect` |
| Workflow `labels:` | Image config | Per-architecture metadata |
| Workflow `annotations:` | Manifest index | Registry display, multi-arch images |

**The `manifest:` prefix tells buildx to apply annotations to the manifest list:**

```yaml
annotations: |
  manifest:org.opencontainers.image.description=My app description
  manifest:org.opencontainers.image.title=myapp
  manifest:org.opencontainers.image.version=1.0.0
```

See the docker.yml workflow for the complete list of required annotations.

### Dockerfile Rules (NON-NEGOTIABLE)

| Rule | Description |
|------|-------------|
| **NEVER modify ENTRYPOINT** | Always use entrypoint.sh for customization |
| **NEVER modify CMD** | Pass commands to entrypoint.sh instead |
| **STOPSIGNAL** | Use `SIGRTMIN+3` for proper shutdown |
| **ENTRYPOINT format** | `[ "tini", "-p", "SIGTERM", "--", "/usr/local/bin/entrypoint.sh" ]` |
| **HEALTHCHECK timing** | Start: 10m, Interval: 5m, Timeout: 15s |
| **Customization** | ALL customization via entrypoint.sh |

### Dockerfile Example (Multi-Stage)

**Location:** `docker/Dockerfile`

```dockerfile
# =============================================================================
# Build Stage - Compile Go binary
# =============================================================================
FROM golang:alpine AS builder

# Install git and bash (git: required for go mod download; bash: for build scripts)
RUN apk add --no-cache git bash

ARG TARGETARCH
ARG VERSION=dev
ARG BUILD_DATE
ARG COMMIT_ID

WORKDIR /build

# Copy go.mod first for layer caching
COPY go.mod go.sum ./
RUN go mod download

# Copy source and build
COPY . .
RUN CGO_ENABLED=0 GOOS=linux GOARCH=${TARGETARCH} go build \
    -ldflags "-s -w -X 'main.Version=${VERSION}' -X 'main.CommitID=${COMMIT_ID}' -X 'main.BuildDate=${BUILD_DATE}'" \
    -o /build/binary/casspeed src

# =============================================================================
# Runtime Stage - Minimal Alpine image
# =============================================================================
FROM alpine:latest

# ARGs for build-time values (set by docker build --build-arg)
ARG VERSION=dev
ARG BUILD_DATE
ARG COMMIT_ID
ARG LICENSE=MIT

# Static Labels
LABEL maintainer="{maintainer_name} <{maintainer_email}>" \
      org.opencontainers.image.vendor="casapps" \
      org.opencontainers.image.authors="casapps" \
      org.opencontainers.image.title="casspeed" \
      org.opencontainers.image.base.name="casspeed" \
      org.opencontainers.image.description="Containerized version of casspeed" \
      org.opencontainers.image.url="https://github.com/casapps/casspeed" \
      org.opencontainers.image.source="https://github.com/casapps/casspeed" \
      org.opencontainers.image.documentation="https://github.com/casapps/casspeed" \
      org.opencontainers.image.vcs-type="Git" \
      com.github.containers.toolbox="false"

# Dynamic Labels (from ARGs)
LABEL org.opencontainers.image.licenses="${LICENSE}" \
      org.opencontainers.image.created="${BUILD_DATE}" \
      org.opencontainers.image.version="${VERSION}" \
      org.opencontainers.image.schema-version="${VERSION}" \
      org.opencontainers.image.revision="${COMMIT_ID}"

# Install required packages including Tor
RUN apk add --no-cache \
    git \
    curl \
    bash \
    tini \
    tor

# Create directories with proper structure
RUN mkdir -p /config /config/security /data/db /data/logs /data/tor /data/backup

# Copy binary from builder stage (multi-stage build)
COPY --from=builder /build/binary/casspeed /usr/local/bin/casspeed

# Copy BUILD-TIME overlay (entrypoint.sh) from docker/rootfs/ into image
# Note: This is docker/rootfs/ (build context), NOT runtime ./rootfs/ volumes
COPY docker/rootfs/ /

# Copy Dockerfile to image (for reference and backup)
COPY docker/Dockerfile /root/Dockerfile

# Make all binaries/scripts in /usr/local/bin executable (755)
RUN chmod 755 /usr/local/bin/*

# Set environment
# Note: Tor auto-enabled because tor binary is installed above
ENV MODE=development \
    TZ=America/New_York

# Expose internal port (always 80)
EXPOSE 80

# Stop signal for graceful shutdown
STOPSIGNAL SIGRTMIN+3

# Health check (long start period for services that need initialization)
HEALTHCHECK --start-period=10m --interval=5m --timeout=15s --retries=3 \
    CMD /usr/local/bin/casspeed --status || exit 1

# Use tini as init with signal propagation
# -p SIGTERM: propagate SIGTERM to child processes
ENTRYPOINT [ "tini", "-p", "SIGTERM", "--", "/usr/local/bin/entrypoint.sh" ]
```

**Multi-Stage Build Benefits:**
- Self-contained - no pre-built binaries required
- Layer caching - `go.mod` copied first for faster rebuilds
- `TARGETARCH` automatically set by docker buildx (`amd64` or `arm64`)
- Works perfectly with `docker buildx --platform linux/amd64,linux/arm64`

**Notes:**
- **NEVER modify ENTRYPOINT or CMD** - all customization goes in `entrypoint.sh`
- `STOPSIGNAL SIGRTMIN+3` allows entrypoint.sh to handle shutdown gracefully
- `tini -p SIGTERM` propagates SIGTERM to all child processes
- docker.yml workflow needs NO binary build step - just docker buildx

### Entrypoint Script (REQUIRED)

**Location:** `docker/rootfs/usr/local/bin/entrypoint.sh`

```bash
#!/usr/bin/env bash
set -e

# =============================================================================
# Container Entrypoint Script
# Handles service startup, signal handling, and graceful shutdown
# =============================================================================

APP_NAME="casspeed"
APP_BIN="/usr/local/bin/${APP_NAME}"

# Container defaults (exported for app to use)
# Timezone - default to America/New_York
export TZ="${TZ:-America/New_York}"

# Configurable paths (via env vars or CLI flags)
export CONFIG_DIR="/config"
export DATA_DIR="/data"
export LOG_DIR="/data/logs"
export DATABASE_DIR="/data/db"
export BACKUP_DIR="/data/backup"

# Fixed subdirectories (always under DATA_DIR, not exported)
TOR_DATA_DIR="${DATA_DIR}/tor"

# Tor auto-detection: if tor binary is installed, Tor is enabled
# Docker image always installs tor, so always enabled in containers
TOR_INSTALLED=$(command -v tor >/dev/null 2>&1 && echo "true" || echo "false")

# Array to track background PIDs
declare -a PIDS=()

# -----------------------------------------------------------------------------
# Logging
# -----------------------------------------------------------------------------
log() {
    echo "[entrypoint] $(date '+%Y-%m-%d %H:%M:%S') $*"
}

log_error() {
    echo "[entrypoint] $(date '+%Y-%m-%d %H:%M:%S') ERROR: $*" >&2
}

# Check if value is truthy (case-insensitive)
# Usage: if is_truthy "$DEBUG"; then ...
is_truthy() {
    local val="${1:-false}"
    val="${val,,}"  # lowercase
    [[ "$val" =~ ^(1|y|t|yes|true|on|ok|enable|enabled|sure|yep|yup|yeah|aye|si|oui|da|hai|affirmative|accept|allow|totally)$ ]]
}

# -----------------------------------------------------------------------------
# Signal handling
# -----------------------------------------------------------------------------
cleanup() {
    log "Received shutdown signal, stopping services..."

    # Stop services in reverse order
    for ((i=${#PIDS[@]}-1; i>=0; i--)); do
        pid="${PIDS[i]}"
        if kill -0 "$pid" 2>/dev/null; then
            log "Stopping PID $pid..."
            kill -TERM "$pid" 2>/dev/null || true
        fi
    done

    # Wait for processes to exit (max 30 seconds)
    local timeout=30
    while [ $timeout -gt 0 ]; do
        local running=0
        for pid in "${PIDS[@]}"; do
            if kill -0 "$pid" 2>/dev/null; then
                running=1
                break
            fi
        done
        [ $running -eq 0 ] && break
        sleep 1
        ((timeout--))
    done

    # Force kill any remaining
    for pid in "${PIDS[@]}"; do
        if kill -0 "$pid" 2>/dev/null; then
            log "Force killing PID $pid..."
            kill -9 "$pid" 2>/dev/null || true
        fi
    done

    log "Shutdown complete"
    exit 0
}

# Trap signals for graceful shutdown
# SIGRTMIN+3 (37) is the Docker STOPSIGNAL
# SIGTERM is propagated by tini -p SIGTERM
trap cleanup SIGTERM SIGINT SIGQUIT
trap cleanup SIGRTMIN+3 2>/dev/null || trap cleanup 37

# -----------------------------------------------------------------------------
# Directory setup
# -----------------------------------------------------------------------------
# Container directory structure:
#   $CONFIG_DIR          - configuration files (mounted: ./rootfs/config)
#   $CONFIG_DIR/security - TLS certs, keys
#   $DATA_DIR            - all persistent data (mounted: ./rootfs/data)
#   $DATABASE_DIR        - SQLite databases (changeable, defaults to $DATA_DIR/db)
#   $LOG_DIR             - application and service logs
#   $TOR_DATA_DIR        - Tor hidden service data (fixed: $DATA_DIR/tor)
#   $BACKUP_DIR          - backup files (changeable, defaults to $DATA_DIR/backup)
# -----------------------------------------------------------------------------
setup_directories() {
    log "Setting up directories..."
    mkdir -p "$CONFIG_DIR" "$CONFIG_DIR/security" \
             "$DATABASE_DIR" "$LOG_DIR" "$TOR_DATA_DIR" "$BACKUP_DIR"

    # Fix permissions for Tor (runs as tor user)
    if [ "$TOR_INSTALLED" = "true" ]; then
        chown -R tor:tor "$TOR_DATA_DIR"
        chmod 700 "$TOR_DATA_DIR"
    fi
}

# -----------------------------------------------------------------------------
# Start Tor (auto-detected: if tor binary installed, it's enabled)
# -----------------------------------------------------------------------------
start_tor() {
    if [ "$TOR_INSTALLED" != "true" ]; then
        log "Tor not installed, skipping..."
        return 0
    fi

    log "Starting Tor hidden service..."

    # Create torrc if not exists
    if [ ! -f "$CONFIG_DIR/torrc" ]; then
        cat > "$CONFIG_DIR/torrc" <<EOF
DataDirectory ${TOR_DATA_DIR}
HiddenServiceDir ${TOR_DATA_DIR}/hidden_service
HiddenServicePort 80 127.0.0.1:80
Log notice file ${LOG_DIR}/tor.log
EOF
    fi

    # Start Tor in background
    tor -f "$CONFIG_DIR/torrc" &
    PIDS+=($!)
    log "Tor started (PID: ${PIDS[-1]})"

    # Wait for .onion address
    local timeout=60
    while [ $timeout -gt 0 ]; do
        if [ -f "${TOR_DATA_DIR}/hidden_service/hostname" ]; then
            local onion_addr
            onion_addr=$(cat "${TOR_DATA_DIR}/hidden_service/hostname")
            log "Tor hidden service: ${onion_addr}"
            break
        fi
        sleep 1
        ((timeout--))
    done
}

# -----------------------------------------------------------------------------
# Start main application
# -----------------------------------------------------------------------------
start_app() {
    log "Starting ${APP_NAME}..."

    # Container defaults: 0.0.0.0:80 (override with ADDRESS/PORT env vars)
    local listen_addr="${ADDRESS:-0.0.0.0}"
    local listen_port="${PORT:-80}"
    local debug_flag=""

    # Enable debug mode if DEBUG is truthy (see Boolean Values table)
    if is_truthy "$DEBUG"; then
        debug_flag="--debug"
        log "Debug mode enabled"
    fi

    # Run the main application with container directory paths
    # Uses exported env vars that match volume mounts in docker-compose.yml
    # App can also read DATABASE_DIR, BACKUP_DIR env vars directly
    "$APP_BIN" \
        --address "$listen_addr" \
        --port "$listen_port" \
        --config "$CONFIG_DIR" \
        --data "$DATA_DIR" \
        --log "$LOG_DIR" \
        --pid "$DATA_DIR/${APP_NAME}.pid" \
        $debug_flag \
        "$@" &
    PIDS+=($!)
    log "${APP_NAME} started on ${listen_addr}:${listen_port} (PID: ${PIDS[-1]})"
}

# -----------------------------------------------------------------------------
# Wait for services
# -----------------------------------------------------------------------------
wait_for_services() {
    log "All services started, waiting..."

    # Wait for any process to exit
    while true; do
        for pid in "${PIDS[@]}"; do
            if ! kill -0 "$pid" 2>/dev/null; then
                log_error "Process $pid exited unexpectedly"
                cleanup
            fi
        done
        sleep 5
    done
}

# -----------------------------------------------------------------------------
# Main
# -----------------------------------------------------------------------------
main() {
    log "Container starting..."
    log "MODE: ${MODE:-development}"
    log "DEBUG: ${DEBUG:-false}"
    log "TZ: ${TZ:-America/New_York}"
    log "ADDRESS: ${ADDRESS:-0.0.0.0}"
    log "PORT: ${PORT:-80}"
    log "TOR_INSTALLED: ${TOR_INSTALLED}"

    setup_directories
    start_tor
    start_app "$@"
    wait_for_services
}

main "$@"
```

### Entrypoint Features

| Feature | Description |
|---------|-------------|
| **Timezone** | Default `America/New_York`, override with `TZ` env var |
| **Port binding** | Default `0.0.0.0:80`, override with `ADDRESS`/`PORT` env vars |
| **Signal handling** | Graceful shutdown on SIGTERM/SIGINT/SIGQUIT/SIGRTMIN+3 |
| **Docker STOPSIGNAL** | Handles SIGRTMIN+3 (signal 37) from Docker |
| **Multi-service** | Can start Tor + main app + additional services |
| **Ordered startup** | Services start in defined order |
| **Ordered shutdown** | Services stop in reverse order |
| **Process monitoring** | Detects unexpected process exits |
| **Timeout handling** | Force kill after 30s if graceful shutdown fails |
| **Directory setup** | Creates required directories on startup |
| **Logging** | Timestamped log messages |

### Why SIGRTMIN+3?

| Reason | Description |
|--------|-------------|
| **Systemd compatibility** | SIGRTMIN+3 is used by systemd for clean shutdown |
| **Container orchestration** | Works well with Docker, Podman, Kubernetes |
| **Graceful multi-process** | Allows entrypoint.sh to coordinate shutdown of all services |
| **Avoids race conditions** | Gives time for proper cleanup before forced termination |

### Environment Variables (Entrypoint)

| Variable | Default | Description |
|----------|---------|-------------|
| `TZ` | `America/New_York` | Timezone for app and scheduler |
| `MODE` | `development` | `production` (strict) or `development` (relaxed) |
| `DEBUG` | `false` | Enable ALL debug features (pprof, expvar, detailed logging) |
| `ADDRESS` | `0.0.0.0` | Listen address |
| `PORT` | `80` | Listen port (update docker-compose ports: to match) |

**MODE vs DEBUG:**
- `MODE=development`: Relaxed security, verbose logging, no caching (sensible for local dev)
- `MODE=production`: Strict security, minimal logging, caching enabled
- `DEBUG=true`: Enables debug endpoints (`/debug/*`), regardless of MODE

**Note:** Boolean env vars accept all truthy/falsy values (see Boolean Values table). Examples: `DEBUG=yes`, `DEBUG=enable`, `DEBUG=1`, `DEBUG=oui`.

**Note:** Tor is auto-enabled if the `tor` binary is installed. No `ENABLE_TOR` flag needed. Docker image always includes Tor.

## Docker Compose Requirements (NON-NEGOTIABLE)

**Location:** `docker/docker-compose.yml`

| Requirement | Value |
|-------------|-------|
| `build:` | **NEVER include** |
| `version:` | **NEVER include** |
| `name:` | `casspeed` |
| Container name | `casspeed` |
| Network | Custom `casspeed` with `external: false` |
| Environment variables | **Hardcode with sane defaults** (NEVER use .env files) |
| **environment: MODE** | **production** (strict host validation) |

### Two `rootfs/` Contexts (CRITICAL - Understand This)

**There are TWO completely different `rootfs/` directories - do not confuse them:**

| Context | Location | Purpose | In Repo? |
|---------|----------|---------|----------|
| **Build-time** | `docker/rootfs/` | Container overlay (entrypoint.sh) | YES |
| **Runtime** | `./rootfs/` in docker-compose | Volume mounts (config, data) | NEVER |

**Build-time `docker/rootfs/`** (in repo):
```
docker/
├── Dockerfile           # COPY rootfs/ / ← copies into container image
├── docker-compose.yml
└── rootfs/              # BUILD overlay - committed to git
    └── usr/local/bin/
        └── entrypoint.sh
```

**Runtime `./rootfs/`** (never in repo):
```
# Production (server admin's choice of location):
/path/to/deployment/
├── docker-compose.yml   # copied from repo
└── rootfs/              # RUNTIME - created on server
    ├── config/
    └── data/

# Development (temp dir):
$TEMP_DIR/
├── docker-compose.yml   # copied from repo
└── rootfs/              # RUNTIME - created in temp
    ├── config/
    └── data/
```

**Why same name works:** The `./rootfs/` path in docker-compose.yml is relative to where docker-compose runs from, not where it lives in the repo. Dockerfile's `COPY rootfs/ /` uses build context (`docker/`).

### Volume Paths (Host Side)

**Docker-compose.yml uses only 2 volumes:**

| Volume Mount | Purpose |
|--------------|---------|
| `./rootfs/config:/config:z` | Configuration files |
| `./rootfs/data:/data:z` | All persistent data (db, logs, cache, etc.) |

**Container internal structure:**

| Container Path | Contents |
|----------------|----------|
| `/config/` | Configuration files |
| `/config/security/` | TLS certs, keys |
| `/data/db/` | SQLite databases (server.db, users.db) |
| `/data/logs/` | Application and service logs |
| `/data/tor/` | Tor hidden service data |
| `/data/backup/` | Backup files |
| `/data/cache/` | Cache files (if used) |

**Rules:**
- Production volumes use `:z` suffix (SELinux shared label)
- Development volumes omit `:z` (not needed in temp dir)
- `docker/rootfs/` is for container overlay (entrypoint.sh) - NOT for runtime volumes
- NEVER create runtime `rootfs/` in the project repo

### Running Docker Compose (NON-NEGOTIABLE)

**NEVER run docker compose in the project directory.**

**Always use temp directory workflow:**
1. Create unique temp dir with apimgr prefix
2. Copy `docker/docker-compose.yml` to temp dir
3. Create `rootfs/` structure in temp dir
4. Run docker compose from temp dir
5. Data lives in temp dir, isolated from project

```bash
# Setup (uses OS temp dir: {ostempdir}/casapps/casspeed-XXXXXX/)
# Set PROJECT_ROOT to your actual project location
PROJECT_ROOT="$(git rev-parse --show-toplevel)"  # Use git top-level
# Or use absolute path: PROJECT_ROOT="/path/to/your/project"
mkdir -p "${TMPDIR:-/tmp}/${PROJECTORG}"
TEMP_DIR=$(mktemp -d "${TMPDIR:-/tmp}/${PROJECTORG}/$CASSPEED-XXXXXX")
mkdir -p "$TEMP_DIR/rootfs/config" "$TEMP_DIR/rootfs/data"

# Copy docker-compose.yml
cp "$PROJECT_ROOT/docker/docker-compose.yml" "$TEMP_DIR/"

# Run from temp dir - ./rootfs/ resolves to $TEMP_DIR/rootfs/
cd "$TEMP_DIR" && docker compose up -d

# Stop and cleanup
cd "$TEMP_DIR" && docker compose down
rm -rf "$TEMP_DIR"
```

**Example paths:**
```
/tmp/apimgr/jokes-aB3xY9/           # jokes project
/tmp/apimgr/weather-k9mN2p/         # weather project
/tmp/casapps/linktree-Qw5rT1/       # different org
```

**Why temp dir:**
- Project directory stays clean
- Data isolated from source code
- Multiple instances possible
- Safe cleanup

**NEVER:**
- Run docker compose in project directory
- Run docker compose with `--project-directory` pointing to project root
- Mount volumes to `{project_root}/rootfs/`

### Port Mapping (NON-NEGOTIABLE)

| Mode | Format | Example |
|------|--------|---------|
| Development | `{randomport}:80` | `64580:80` |
| Production | `172.17.0.1:{randomport}:80` | `172.17.0.1:64580:80` |

**Rules:**
- Internal port defaults to `80` (override with `PORT` env var)
- External port is random unused port in `64xxx` range
- Production binds to Docker bridge IP (`172.17.0.1`) for security
- Development binds to all interfaces for easier access
- If changing internal port, update docker-compose port mapping to match

### Environment Variables (NON-NEGOTIABLE)

**ALL environment variables MUST be hardcoded with sane defaults. NEVER require .env files.**

| Rule | Description |
|------|-------------|
| **NEVER** | Use `${VAR}` or `${VAR:-default}` syntax requiring .env |
| **NEVER** | Create `.env`, `.env.example`, `.env.sample` files |
| **ALWAYS** | Hardcode values directly in docker-compose.yml |
| **ALWAYS** | Use sane, working defaults |

**Why hardcoded defaults?**
- Works out of the box - no setup required
- No confusion about required variables
- No outdated .env.example files
- Users can override by editing docker-compose.yml directly

### Docker Compose (Development)

**Location:** `docker/docker-compose.dev.yml`

**Development mode with optional debug. MUST use temp directory workflow.**

```yaml
name: casspeed-dev

services:
  casspeed:
    image: ghcr.io/casapps/casspeed:latest
    container_name: casspeed-dev
    restart: unless-stopped
    environment:
      # Development: relaxed security, verbose logging, no caching
      # Does NOT enable debug endpoints - uncomment DEBUG=true for that
      - MODE=development
      - TZ=America/New_York
      # DEBUG: Uncomment to enable pprof, expvar, detailed request logging
      # - DEBUG=true
    ports:
      # Development: accessible from all interfaces
      - "64580:80"
    volumes:
      # TEMP DIR WORKFLOW: ./rootfs/ resolves to $TEMP_DIR/rootfs/
      # NEVER run from project directory - always use temp dir workflow
      - ./rootfs/config:/config
      - ./rootfs/data:/data
    networks:
      - casspeed-dev

networks:
  casspeed-dev:
    name: casspeed-dev
    external: false
```

**Run:**
```bash
mkdir -p "${TMPDIR:-/tmp}/casapps"
TEMP_DIR=$(mktemp -d "${TMPDIR:-/tmp}/casapps/casspeed-XXXXXX")
mkdir -p "$TEMP_DIR/rootfs/config" "$TEMP_DIR/rootfs/data"
cp docker/docker-compose.dev.yml "$TEMP_DIR/docker-compose.yml"
cd "$TEMP_DIR" && docker compose up -d
```

### Docker Compose (Production)

**Location:** `docker/docker-compose.yml`

**Production has NO debug options. Debug must be set via CLI if needed.**

```yaml
name: casspeed

services:
  casspeed:
    image: ghcr.io/casapps/casspeed:latest
    container_name: casspeed
    restart: unless-stopped
    environment:
      # Production: strict security, minimal logging, caching enabled
      # NO debug options - debug must be explicitly set via CLI if needed
      - MODE=production
      - TZ=America/New_York
      # DOMAIN (optional - auto-detects from reverse proxy headers)
      # - DOMAIN=myapp.com,www.myapp.com
      # SMTP (optional - autodetects if not set)
      # - SMTP_HOST=smtp.example.com
      # - SMTP_PORT=587
      # - SMTP_USERNAME=user
      # - SMTP_PASSWORD=pass
    ports:
      # Production: bound to Docker bridge only (reverse proxy handles external)
      - "172.17.0.1:64580:80"
    volumes:
      # TEMP DIR WORKFLOW: ./rootfs/ resolves to $TEMP_DIR/rootfs/
      # NEVER run from project directory - always use temp dir workflow
      - ./rootfs/config:/config:z
      - ./rootfs/data:/data:z
    networks:
      - casspeed

networks:
  casspeed:
    name: casspeed
    external: false
```

**Run:**
```bash
mkdir -p "${TMPDIR:-/tmp}/casapps"
TEMP_DIR=$(mktemp -d "${TMPDIR:-/tmp}/casapps/casspeed-XXXXXX")
mkdir -p "$TEMP_DIR/rootfs/config" "$TEMP_DIR/rootfs/data"
cp docker/docker-compose.yml "$TEMP_DIR/"
cd "$TEMP_DIR" && docker compose up -d
```

### Docker Compose (Test)

**Location:** `docker/docker-compose.test.yml`

**For running tests in CI/CD or locally. Debug enabled for test visibility. MUST use temp directory workflow.**

```yaml
name: casspeed-test

services:
  casspeed:
    image: ghcr.io/casapps/casspeed:latest
    container_name: casspeed-test
    restart: "no"
    environment:
      - MODE=development
      - DEBUG=true
      - TZ=America/New_York
    ports:
      - "64581:80"
    volumes:
      # TEMP DIR WORKFLOW: ./rootfs/ resolves to $TEMP_DIR/rootfs/
      # NEVER run from project directory - always use temp dir workflow
      - ./rootfs/config:/config
      - ./rootfs/data:/data
    networks:
      - casspeed-test

networks:
  casspeed-test:
    name: casspeed-test
    external: false
```

**Run:**
```bash
mkdir -p "${TMPDIR:-/tmp}/casapps"
TEMP_DIR=$(mktemp -d "${TMPDIR:-/tmp}/casapps/casspeed-XXXXXX")
mkdir -p "$TEMP_DIR/rootfs/config" "$TEMP_DIR/rootfs/data"
cp docker/docker-compose.test.yml "$TEMP_DIR/docker-compose.yml"
cd "$TEMP_DIR" && docker compose up --abort-on-container-exit
rm -rf "$TEMP_DIR"  # Cleanup after tests
```

### Docker Compose with Database Example

**Location:** `docker/docker-compose.yml`

```yaml
name: casspeed

services:
  casspeed:
    image: ghcr.io/casapps/casspeed:latest
    container_name: casspeed
    restart: unless-stopped
    depends_on:
      - postgres
    environment:
      # Tor auto-enabled (tor binary installed in image)
      - MODE=production
      - TZ=America/New_York
      # DOMAIN (optional - containers behind reverse proxy auto-detect from headers)
      # Only set if NOT behind reverse proxy, comma-separated list supported
      # - DOMAIN=myapp.com,www.myapp.com,api.myapp.com
      - DB_HOST=postgres
      - DB_PORT=5432
      - DB_NAME=casspeed
      - DB_USER=casspeed
      - DB_PASS=casspeed
    ports:
      # Production: bound to Docker bridge only (reverse proxy handles external)
      - "172.17.0.1:64580:80"
    volumes:
      - ./rootfs/config:/config:z
      - ./rootfs/data:/data:z
    networks:
      - casspeed

  postgres:
    image: postgres:alpine
    container_name: casspeed-postgres
    restart: unless-stopped
    environment:
      - POSTGRES_DB=casspeed
      - POSTGRES_USER=casspeed
      - POSTGRES_PASSWORD=casspeed
      - TZ=America/New_York
    volumes:
      - ./rootfs/data/db/postgres:/var/lib/postgresql/data:z
    networks:
      - casspeed

networks:
  casspeed:
    name: casspeed
    external: false
```

**Run:** Use temp directory workflow (see "Running Docker Compose" section above).

## Container Configuration

| Setting | Value |
|---------|-------|
| Internal port | **80** (always) |
| Config dir | `/config` |
| Security dir | `/config/security` (geoip, blocklists, cve, trivy) |
| Data dir | `/data` |
| Database dir | `/data/db` (server.db, users.db) |
| Log dir | `/data/logs` |
| Tor data dir | `/data/tor` |
| Backup dir | `/data/backup` |
| Binary | `/usr/local/bin/casspeed` |
| HEALTHCHECK | `{binary} --status` |

**Path Mapping (Container vs Host):**

| Container Path | Host Path | Purpose |
|----------------|-----------|---------|
| `/config` | `./rootfs/config` | Configuration files |
| `/data` | `./rootfs/data` | All persistent data |
| `/data/db/` | (inside /data) | SQLite databases |
| `/data/logs/` | (inside /data) | Log files |

## Tor in Container

**Tor is included in the container image and auto-enabled (no configuration needed).**

| Behavior | Description |
|----------|-------------|
| Auto-detection | Tor starts automatically if `tor` binary is installed |
| Always enabled | Docker image includes `tor`, so always enabled in containers |
| Data persistence | Tor keys stored in `/data/tor/site/` (survives container restart) |
| .onion address | Persists across container restarts via volume mount |

## Container Detection

**Assume running in container if tini init system (PID 1) is detected.**

| When in Container | Behavior |
|-------------------|----------|
| Show setup token | On first run - one-time setup token displayed in console for `/admin` access |
| Defaults | Use container-appropriate defaults |
| Logging | Log to stdout/stderr (captured by container runtime) |
| Tor | Application manages Tor process internally |

## Image Tags (NON-NEGOTIABLE)

### Release Tags (Production)

| Tag | Description | Example |
|-----|-------------|---------|
| `ghcr.io/casapps/casspeed:latest` | Latest stable release | `ghcr.io/myorg/myapp:latest` |
| `ghcr.io/casapps/casspeed:{version}` | Specific version | `ghcr.io/myorg/myapp:1.2.3` |
| `ghcr.io/casapps/casspeed:{YYMM}` | Year/month tag | `ghcr.io/myorg/myapp:2512` |
| `ghcr.io/casapps/casspeed:{commit}` | Git commit (7 char) | `ghcr.io/myorg/myapp:abc1234` |

### Development Tags (Local)

| Tag | Description | Example |
|-----|-------------|---------|
| `casspeed:dev` | Local development build | `myapp:dev` |
| `casspeed:test` | Local test build | `myapp:test` |

### Registry

| Environment | Registry |
|-------------|----------|
| Release | `ghcr.io` (GitHub Container Registry) |
| Development | Local Docker daemon only |

### Tag Rules

1. **Release builds** MUST push to `ghcr.io/casapps/casspeed`
2. **Development builds** MUST use local-only tags (no registry prefix)
3. **NEVER push `:dev` or `:test` tags to ghcr.io**
4. All release images built for `linux/amd64` AND `linux/arm64`

---


# PART 15: CI/CD WORKFLOWS (NON-NEGOTIABLE)

**All projects MUST have CI/CD workflows appropriate for their git hosting platform.**

| Git Host | CI System | Config Location | Self-Hosted |
|----------|-----------|-----------------|-------------|
| GitHub | GitHub Actions | `.github/workflows/*.yml` | No (github.com only) |
| Gitea | Gitea Actions | `.gitea/workflows/*.yml` | Yes |
| Forgejo | Forgejo Actions | `.forgejo/workflows/*.yml` | Yes (self-hosted only) |
| GitLab | GitLab CI | `.gitlab-ci.yml` | Yes |

**Note:** Forgejo is a fork of Gitea - Forgejo Actions are compatible with Gitea Actions. Use `.forgejo/workflows/` for Forgejo or `.gitea/workflows/` (both work).

# GITHUB ACTIONS

**GitHub Actions only works with github.com (no self-hosted option).**

## Workflow Files

| File | Trigger | Purpose |
|------|---------|---------|
| `release.yml` | Tag push (`v*`, `*.*.*`) | Production releases |
| `beta.yml` | Push to `beta` branch | Beta releases |
| `daily.yml` | Daily at 3am UTC + push to main/master | Daily builds |
| `docker.yml` | Version tag, push to main/master/beta | Docker images |

## Build Info Variables

All workflows MUST set these environment variables:

```yaml
# Set in "Set build info" step, NOT as static env:
#   echo "VERSION=${GITHUB_REF_NAME#v}" >> $GITHUB_ENV
#   echo "COMMIT_ID=$(git rev-parse --short HEAD)" >> $GITHUB_ENV
#   echo "BUILD_DATE=$(date +"%a %b %d, %Y at %H:%M:%S %Z")" >> $GITHUB_ENV
# Then use in build step:
#   LDFLAGS="-s -w -X 'main.Version=${{ env.VERSION }}' -X 'main.CommitID=${{ env.COMMIT_ID }}' -X 'main.BuildDate=${{ env.BUILD_DATE }}'"
```

## Release Workflow (Stable)

**File:** `.github/workflows/release.yml`

```yaml
name: Release

on:
  push:
    tags:
      - 'v*'
      - '[0-9]*.[0-9]*.[0-9]*'

env:
  PROJECTNAME: casspeed

jobs:
  build:
    runs-on: ubuntu-latest
    strategy:
      matrix:
        include:
          - goos: linux
            goarch: amd64
          - goos: linux
            goarch: arm64
          - goos: darwin
            goarch: amd64
          - goos: darwin
            goarch: arm64
          - goos: windows
            goarch: amd64
            ext: .exe
          - goos: windows
            goarch: arm64
            ext: .exe
          - goos: freebsd
            goarch: amd64
          - goos: freebsd
            goarch: arm64

    steps:
      - uses: actions/checkout@v4

      - name: Set up Go
        uses: actions/setup-go@v5
        with:
          go-version: 'stable'

      - name: Set build info
        run: |
          echo "VERSION=${GITHUB_REF_NAME#v}" >> $GITHUB_ENV
          echo "COMMIT_ID=$(git rev-parse --short HEAD)" >> $GITHUB_ENV
          echo "BUILD_DATE=$(date +"%a %b %d, %Y at %H:%M:%S %Z")" >> $GITHUB_ENV

      - name: Build server
        env:
          GOOS: ${{ matrix.goos }}
          GOARCH: ${{ matrix.goarch }}
          CGO_ENABLED: 0
        run: |
          LDFLAGS="-s -w -X 'main.Version=${{ env.VERSION }}' -X 'main.CommitID=${{ env.COMMIT_ID }}' -X 'main.BuildDate=${{ env.BUILD_DATE }}'"
          go build -ldflags "${LDFLAGS}" -o ${{ env.PROJECTNAME }}-${{ matrix.goos }}-${{ matrix.goarch }}${{ matrix.ext }} src

      # CLI build - only if src/client/ directory exists
      - name: Build CLI
        if: hashFiles('src/client/') != ''
        env:
          GOOS: ${{ matrix.goos }}
          GOARCH: ${{ matrix.goarch }}
          CGO_ENABLED: 0
        run: |
          LDFLAGS="-s -w -X 'main.Version=${{ env.VERSION }}' -X 'main.CommitID=${{ env.COMMIT_ID }}' -X 'main.BuildDate=${{ env.BUILD_DATE }}'"
          go build -ldflags "${LDFLAGS}" -o ${{ env.PROJECTNAME }}-${{ matrix.goos }}-${{ matrix.goarch }}-cli${{ matrix.ext }} src/client

      - name: Upload server artifact
        uses: actions/upload-artifact@v4
        with:
          name: ${{ env.PROJECTNAME }}-${{ matrix.goos }}-${{ matrix.goarch }}
          path: ${{ env.PROJECTNAME }}-${{ matrix.goos }}-${{ matrix.goarch }}${{ matrix.ext }}

      - name: Upload CLI artifact
        if: hashFiles('src/client/') != ''
        uses: actions/upload-artifact@v4
        with:
          name: ${{ env.PROJECTNAME }}-${{ matrix.goos }}-${{ matrix.goarch }}-cli
          path: ${{ env.PROJECTNAME }}-${{ matrix.goos }}-${{ matrix.goarch }}-cli${{ matrix.ext }}

  release:
    needs: build
    runs-on: ubuntu-latest
    permissions:
      contents: write

    steps:
      - uses: actions/checkout@v4

      - name: Download all artifacts
        uses: actions/download-artifact@v4
        with:
          path: binaries
          merge-multiple: true

      - name: Set version
        run: |
          TAG="${GITHUB_REF_NAME}"
          # VERSION for version.txt (strip v if present)
          echo "VERSION=${TAG#v}" >> $GITHUB_ENV
          # RELEASE_TAG: add v prefix only if semver without v
          if [[ "$TAG" == v* ]]; then
            echo "RELEASE_TAG=$TAG" >> $GITHUB_ENV
          elif [[ "$TAG" =~ ^[0-9]+\.[0-9]+\.[0-9]+ ]]; then
            echo "RELEASE_TAG=v$TAG" >> $GITHUB_ENV
          else
            echo "RELEASE_TAG=$TAG" >> $GITHUB_ENV
          fi

      - name: Create version.txt
        run: echo "${{ env.VERSION }}" > binaries/version.txt

      - name: Create source archive
        run: |
          tar --exclude='.git' --exclude='.github' --exclude='.gitea' \
            --exclude='binaries' --exclude='releases' --exclude='*.tar.gz' \
            -czf binaries/${{ env.PROJECTNAME }}-${{ env.VERSION }}-source.tar.gz .

      - name: Create Release
        uses: softprops/action-gh-release@v1
        with:
          tag_name: ${{ env.RELEASE_TAG }}
          files: binaries/*
          generate_release_notes: true
          make_latest: true
```

## Beta Workflow

**File:** `.github/workflows/beta.yml`

```yaml
name: Beta Release

on:
  push:
    branches:
      - beta

env:
  PROJECTNAME: casspeed

jobs:
  build:
    runs-on: ubuntu-latest
    strategy:
      matrix:
        include:
          - goos: linux
            goarch: amd64
          - goos: linux
            goarch: arm64

    steps:
      - uses: actions/checkout@v4

      - name: Set up Go
        uses: actions/setup-go@v5
        with:
          go-version: 'stable'

      - name: Set build info
        run: |
          echo "VERSION=$(date -u +"%Y%m%d%H%M%S")-beta" >> $GITHUB_ENV
          echo "COMMIT_ID=$(git rev-parse --short HEAD)" >> $GITHUB_ENV
          echo "BUILD_DATE=$(date +"%a %b %d, %Y at %H:%M:%S %Z")" >> $GITHUB_ENV

      - name: Build server
        env:
          GOOS: ${{ matrix.goos }}
          GOARCH: ${{ matrix.goarch }}
          CGO_ENABLED: 0
        run: |
          LDFLAGS="-s -w -X 'main.Version=${{ env.VERSION }}' -X 'main.CommitID=${{ env.COMMIT_ID }}' -X 'main.BuildDate=${{ env.BUILD_DATE }}'"
          go build -ldflags "${LDFLAGS}" -o ${{ env.PROJECTNAME }}-${{ matrix.goos }}-${{ matrix.goarch }} src

      # CLI build - only if src/client/ directory exists
      - name: Build CLI
        if: hashFiles('src/client/') != ''
        env:
          GOOS: ${{ matrix.goos }}
          GOARCH: ${{ matrix.goarch }}
          CGO_ENABLED: 0
        run: |
          LDFLAGS="-s -w -X 'main.Version=${{ env.VERSION }}' -X 'main.CommitID=${{ env.COMMIT_ID }}' -X 'main.BuildDate=${{ env.BUILD_DATE }}'"
          go build -ldflags "${LDFLAGS}" -o ${{ env.PROJECTNAME }}-${{ matrix.goos }}-${{ matrix.goarch }}-cli src/client

      - name: Upload server artifact
        uses: actions/upload-artifact@v4
        with:
          name: ${{ env.PROJECTNAME }}-${{ matrix.goos }}-${{ matrix.goarch }}
          path: ${{ env.PROJECTNAME }}-${{ matrix.goos }}-${{ matrix.goarch }}

      - name: Upload CLI artifact
        if: hashFiles('src/client/') != ''
        uses: actions/upload-artifact@v4
        with:
          name: ${{ env.PROJECTNAME }}-${{ matrix.goos }}-${{ matrix.goarch }}-cli
          path: ${{ env.PROJECTNAME }}-${{ matrix.goos }}-${{ matrix.goarch }}-cli

  release:
    needs: build
    runs-on: ubuntu-latest
    permissions:
      contents: write

    steps:
      - uses: actions/checkout@v4

      - name: Download all artifacts
        uses: actions/download-artifact@v4
        with:
          path: binaries
          merge-multiple: true

      - name: Set version
        run: echo "VERSION=$(date -u +"%Y%m%d%H%M%S")-beta" >> $GITHUB_ENV

      - name: Create version.txt
        run: echo "${{ env.VERSION }}" > binaries/version.txt

      - name: Create Release
        uses: softprops/action-gh-release@v1
        with:
          tag_name: ${{ env.VERSION }}
          files: binaries/*
          prerelease: true
          generate_release_notes: true
```

## Daily Workflow

**File:** `.github/workflows/daily.yml`

```yaml
name: Daily Build

on:
  schedule:
    - cron: '0 3 * * *'  # 3am UTC daily
  push:
    branches:
      - main
      - master
  workflow_dispatch:

env:
  PROJECTNAME: casspeed

jobs:
  build:
    runs-on: ubuntu-latest
    strategy:
      matrix:
        include:
          - goos: linux
            goarch: amd64
          - goos: linux
            goarch: arm64

    steps:
      - uses: actions/checkout@v4

      - name: Set up Go
        uses: actions/setup-go@v5
        with:
          go-version: 'stable'

      - name: Set build info
        run: |
          echo "VERSION=$(date -u +"%Y%m%d%H%M%S")" >> $GITHUB_ENV
          echo "COMMIT_ID=$(git rev-parse --short HEAD)" >> $GITHUB_ENV
          echo "BUILD_DATE=$(date +"%a %b %d, %Y at %H:%M:%S %Z")" >> $GITHUB_ENV

      - name: Build server
        env:
          GOOS: ${{ matrix.goos }}
          GOARCH: ${{ matrix.goarch }}
          CGO_ENABLED: 0
        run: |
          LDFLAGS="-s -w -X 'main.Version=${{ env.VERSION }}' -X 'main.CommitID=${{ env.COMMIT_ID }}' -X 'main.BuildDate=${{ env.BUILD_DATE }}'"
          go build -ldflags "${LDFLAGS}" -o ${{ env.PROJECTNAME }}-${{ matrix.goos }}-${{ matrix.goarch }} src

      # CLI build - only if src/client/ directory exists
      - name: Build CLI
        if: hashFiles('src/client/') != ''
        env:
          GOOS: ${{ matrix.goos }}
          GOARCH: ${{ matrix.goarch }}
          CGO_ENABLED: 0
        run: |
          LDFLAGS="-s -w -X 'main.Version=${{ env.VERSION }}' -X 'main.CommitID=${{ env.COMMIT_ID }}' -X 'main.BuildDate=${{ env.BUILD_DATE }}'"
          go build -ldflags "${LDFLAGS}" -o ${{ env.PROJECTNAME }}-${{ matrix.goos }}-${{ matrix.goarch }}-cli src/client

      - name: Upload server artifact
        uses: actions/upload-artifact@v4
        with:
          name: ${{ env.PROJECTNAME }}-${{ matrix.goos }}-${{ matrix.goarch }}
          path: ${{ env.PROJECTNAME }}-${{ matrix.goos }}-${{ matrix.goarch }}

      - name: Upload CLI artifact
        if: hashFiles('src/client/') != ''
        uses: actions/upload-artifact@v4
        with:
          name: ${{ env.PROJECTNAME }}-${{ matrix.goos }}-${{ matrix.goarch }}-cli
          path: ${{ env.PROJECTNAME }}-${{ matrix.goos }}-${{ matrix.goarch }}-cli

  release:
    needs: build
    runs-on: ubuntu-latest
    permissions:
      contents: write

    steps:
      - uses: actions/checkout@v4

      - name: Download all artifacts
        uses: actions/download-artifact@v4
        with:
          path: binaries
          merge-multiple: true

      - name: Set version
        run: echo "VERSION=$(date -u +"%Y%m%d%H%M%S")" >> $GITHUB_ENV

      - name: Create version.txt
        run: echo "${{ env.VERSION }}" > binaries/version.txt

      - name: Delete previous daily release
        run: |
          gh release delete daily --yes 2>/dev/null || true
          git push origin :refs/tags/daily 2>/dev/null || true
        env:
          GH_TOKEN: ${{ github.token }}

      - name: Create Release
        uses: softprops/action-gh-release@v1
        with:
          tag_name: daily
          name: "Daily Build ${{ env.VERSION }}"
          files: binaries/*
          prerelease: true
          body: "Daily build: ${{ env.VERSION }}"
```

## Docker Workflow

### Triggers and Tags

| Trigger | Image Tags |
|---------|------------|
| **Any push** (all branches) | `devel`, `{COMMIT_ID}` |
| Push to beta branch | `devel`, `beta`, `{COMMIT_ID}` |
| Version tag (`v*`, `*.*.*`) | `{version}`, `latest`, `YYMM`, `{COMMIT_ID}` |

**Notes:**
- `{COMMIT_ID}` = short SHA (7 characters) from `git rev-parse --short HEAD`
- `YYMM` = year/month (e.g., `2512`)
- Built for `linux/amd64` and `linux/arm64` using `docker buildx`
- Registry: `ghcr.io`
- `devel` tag is updated on EVERY push (any branch)
- `latest` tag only updated on version tags (releases)

**File:** `.github/workflows/docker.yml`

```yaml
name: Docker Build

on:
  push:
    branches: ['**']  # ALL branches
    tags:
      - 'v*'
      - '*.*.*'
  workflow_dispatch:

env:
  PROJECTNAME: casspeed
  REGISTRY: ghcr.io
  IMAGE_NAME: ${{ github.repository }}

jobs:
  build:
    runs-on: ubuntu-latest
    permissions:
      contents: read
      packages: write

    steps:
      - uses: actions/checkout@v4

      - name: Set up QEMU
        uses: docker/setup-qemu-action@v3

      - name: Set up Docker Buildx
        uses: docker/setup-buildx-action@v3

      - name: Log in to Container Registry
        uses: docker/login-action@v3
        with:
          registry: ${{ env.REGISTRY }}
          username: ${{ github.actor }}
          password: ${{ secrets.GITHUB_TOKEN }}

      - name: Set build info
        run: |
          echo "COMMIT_ID=$(git rev-parse --short HEAD)" >> $GITHUB_ENV
          echo "YYMM=$(date +"%y%m")" >> $GITHUB_ENV
          if [[ "${{ github.ref }}" == refs/tags/* ]]; then
            VERSION="${GITHUB_REF#refs/tags/}"
            echo "VERSION=${VERSION#v}" >> $GITHUB_ENV  # Strip 'v' prefix
            echo "IS_TAG=true" >> $GITHUB_ENV
          else
            echo "VERSION=$(git rev-parse --short HEAD)" >> $GITHUB_ENV
            echo "IS_TAG=false" >> $GITHUB_ENV
          fi
          echo "BUILD_DATE=$(date +"%a %b %d, %Y at %H:%M:%S %Z")" >> $GITHUB_ENV

      - name: Determine tags
        id: tags
        run: |
          TAGS="${{ env.REGISTRY }}/${{ env.IMAGE_NAME }}:${{ env.COMMIT_ID }}"

          if [[ "${{ env.IS_TAG }}" == "true" ]]; then
            # Release tag - version, latest, YYMM
            TAGS="$TAGS,${{ env.REGISTRY }}/${{ env.IMAGE_NAME }}:${{ env.VERSION }}"
            TAGS="$TAGS,${{ env.REGISTRY }}/${{ env.IMAGE_NAME }}:latest"
            TAGS="$TAGS,${{ env.REGISTRY }}/${{ env.IMAGE_NAME }}:${{ env.YYMM }}"
          else
            # All pushes get devel tag
            TAGS="$TAGS,${{ env.REGISTRY }}/${{ env.IMAGE_NAME }}:devel"

            # Beta branch also gets beta tag
            if [[ "${{ github.ref }}" == refs/heads/beta ]]; then
              TAGS="$TAGS,${{ env.REGISTRY }}/${{ env.IMAGE_NAME }}:beta"
            fi
          fi

          echo "tags=$TAGS" >> $GITHUB_OUTPUT

      - name: Build and push
        uses: docker/build-push-action@v5
        with:
          context: .
          file: docker/Dockerfile
          platforms: linux/amd64,linux/arm64
          push: true
          tags: ${{ steps.tags.outputs.tags }}
          build-args: |
            VERSION="${{ env.VERSION }}"
            BUILD_DATE="${{ env.BUILD_DATE }}"
            COMMIT_ID="${{ env.COMMIT_ID }}"
          # OCI Image Labels (applied to image config)
          labels: |
            org.opencontainers.image.vendor="casapps"
            org.opencontainers.image.authors="casapps"
            org.opencontainers.image.title="${{ env.PROJECTNAME }}"
            org.opencontainers.image.base.name="${{ env.PROJECTNAME }}"
            org.opencontainers.image.description="Containerized version of ${{ env.PROJECTNAME }}"
            org.opencontainers.image.licenses=MIT
            org.opencontainers.image.version="${{ env.VERSION }}"
            org.opencontainers.image.created="${{ env.BUILD_DATE }}"
            org.opencontainers.image.revision="${{ env.COMMIT_ID }}"
            org.opencontainers.image.url="${{ github.server_url }}/${{ github.repository }}"
            org.opencontainers.image.source="${{ github.server_url }}/${{ github.repository }}"
            org.opencontainers.image.documentation="${{ github.server_url }}/${{ github.repository }}"
          # OCI Annotations for multi-arch manifest (required for registry display)
          annotations: |
            manifest:org.opencontainers.image.vendor=casapps
            manifest:org.opencontainers.image.authors=casapps
            manifest:org.opencontainers.image.title=${{ env.PROJECTNAME }}
            manifest:org.opencontainers.image.description=Containerized version of ${{ env.PROJECTNAME }}
            manifest:org.opencontainers.image.licenses=MIT
            manifest:org.opencontainers.image.version=${{ env.VERSION }}
            manifest:org.opencontainers.image.created=${{ env.BUILD_DATE }}
            manifest:org.opencontainers.image.revision=${{ env.COMMIT_ID }}
            manifest:org.opencontainers.image.url=${{ github.server_url }}/${{ github.repository }}
            manifest:org.opencontainers.image.source=${{ github.server_url }}/${{ github.repository }}
            manifest:org.opencontainers.image.documentation=${{ github.server_url }}/${{ github.repository }}
```

**Labels vs Annotations:**

| Type | Purpose | Where Applied |
|------|---------|---------------|
| `labels` | Image metadata | Image config (per-arch) |
| `annotations` | Manifest metadata | Multi-arch manifest index |

**Note:** For multi-arch images, registries (GHCR, Docker Hub) read annotations from the manifest index, not from individual image configs. The `manifest:` prefix tells buildx to apply annotations to the manifest list.

---

# GITEA / FORGEJO ACTIONS

**For projects hosted on Gitea or Forgejo (cloud or self-hosted), use these equivalent workflows.**

Forgejo is a community fork of Gitea - workflows are fully compatible between them.

| Platform | Directory | Variables | Self-Hosted |
|----------|-----------|-----------|-------------|
| Gitea | `.gitea/workflows/` | `GITEA_*`, `${{ gitea.* }}` | Yes (gitea.com + self-hosted) |
| Forgejo | `.forgejo/workflows/` | `FORGEJO_*`, `${{ forgejo.* }}` | Yes (self-hosted only) |

**Compatibility:** Forgejo also reads `.gitea/workflows/` and accepts `GITEA_*` variables for backwards compatibility.

Key differences from GitHub Actions:
- Directory: `.gitea/workflows/` or `.forgejo/workflows/`
- Use `gitea.com/actions/*` actions or compatible GitHub Actions
- Registry: Auto-detected from server URL (works with self-hosted)
- Some GitHub-specific variables have Gitea/Forgejo equivalents (see mapping table below)

## Self-Hosted Configuration

**Gitea:**

| Setting | Value |
|---------|-------|
| Gitea version | 1.19+ (Actions support) |
| Enable Actions | Site Administration → Actions → Enable Actions |
| Runner | Register runner via `act_runner` |
| Container Registry | Enable in Site Administration → Packages |
| Token | User Settings → Applications → Generate Access Token |

**Forgejo:**

| Setting | Value |
|---------|-------|
| Forgejo version | 1.21+ (Actions support) |
| Enable Actions | Site Administration → Actions → Enable Actions |
| Runner | Register runner via `forgejo-runner` (or `act_runner`) |
| Container Registry | Enable in Site Administration → Packages |
| Token | User Settings → Applications → Generate Access Token |

For self-hosted runners, change `runs-on: ubuntu-latest` to your runner label.

## Workflow Files

| File | Trigger | Purpose |
|------|---------|---------|
| `release.yml` | Tag push (`v*`, `*.*.*`) | Production releases |
| `beta.yml` | Push to `beta` branch | Beta releases |
| `daily.yml` | Daily at 3am UTC + push to main/master | Daily builds |
| `docker.yml` | Version tag, push to main/master/beta | Docker images |

## Release Workflow (Stable)

**File:** `.gitea/workflows/release.yml`

```yaml
name: Release

on:
  push:
    tags:
      - 'v*'
      - '[0-9]*.[0-9]*.[0-9]*'

env:
  PROJECTNAME: casspeed

jobs:
  build:
    runs-on: ubuntu-latest
    strategy:
      matrix:
        include:
          - goos: linux
            goarch: amd64
          - goos: linux
            goarch: arm64
          - goos: darwin
            goarch: amd64
          - goos: darwin
            goarch: arm64
          - goos: windows
            goarch: amd64
            ext: .exe
          - goos: windows
            goarch: arm64
            ext: .exe
          - goos: freebsd
            goarch: amd64
          - goos: freebsd
            goarch: arm64

    steps:
      - uses: actions/checkout@v4

      - name: Set up Go
        uses: actions/setup-go@v5
        with:
          go-version: 'stable'

      - name: Set build info
        run: |
          echo "VERSION=${GITEA_REF_NAME#v}" >> $GITEA_ENV
          echo "COMMIT_ID=$(git rev-parse --short HEAD)" >> $GITEA_ENV
          echo "BUILD_DATE=$(date +"%a %b %d, %Y at %H:%M:%S %Z")" >> $GITEA_ENV

      - name: Build server
        env:
          GOOS: ${{ matrix.goos }}
          GOARCH: ${{ matrix.goarch }}
          CGO_ENABLED: 0
        run: |
          LDFLAGS="-s -w -X 'main.Version=${{ env.VERSION }}' -X 'main.CommitID=${{ env.COMMIT_ID }}' -X 'main.BuildDate=${{ env.BUILD_DATE }}'"
          go build -ldflags "${LDFLAGS}" -o ${{ env.PROJECTNAME }}-${{ matrix.goos }}-${{ matrix.goarch }}${{ matrix.ext }} src

      # CLI build - only if src/client/ directory exists
      - name: Build CLI
        if: hashFiles('src/client/') != ''
        env:
          GOOS: ${{ matrix.goos }}
          GOARCH: ${{ matrix.goarch }}
          CGO_ENABLED: 0
        run: |
          LDFLAGS="-s -w -X 'main.Version=${{ env.VERSION }}' -X 'main.CommitID=${{ env.COMMIT_ID }}' -X 'main.BuildDate=${{ env.BUILD_DATE }}'"
          go build -ldflags "${LDFLAGS}" -o ${{ env.PROJECTNAME }}-${{ matrix.goos }}-${{ matrix.goarch }}-cli${{ matrix.ext }} src/client

      - name: Upload server artifact
        uses: actions/upload-artifact@v4
        with:
          name: ${{ env.PROJECTNAME }}-${{ matrix.goos }}-${{ matrix.goarch }}
          path: ${{ env.PROJECTNAME }}-${{ matrix.goos }}-${{ matrix.goarch }}${{ matrix.ext }}

      - name: Upload CLI artifact
        if: hashFiles('src/client/') != ''
        uses: actions/upload-artifact@v4
        with:
          name: ${{ env.PROJECTNAME }}-${{ matrix.goos }}-${{ matrix.goarch }}-cli
          path: ${{ env.PROJECTNAME }}-${{ matrix.goos }}-${{ matrix.goarch }}-cli${{ matrix.ext }}

  release:
    needs: build
    runs-on: ubuntu-latest
    permissions:
      contents: write

    steps:
      - uses: actions/checkout@v4

      - name: Download all artifacts
        uses: actions/download-artifact@v4
        with:
          path: binaries
          merge-multiple: true

      - name: Set version
        run: |
          TAG="${GITEA_REF_NAME}"
          # VERSION for version.txt (strip v if present)
          echo "VERSION=${TAG#v}" >> $GITEA_ENV
          # RELEASE_TAG: add v prefix only if semver without v
          if [[ "$TAG" == v* ]]; then
            echo "RELEASE_TAG=$TAG" >> $GITEA_ENV
          elif [[ "$TAG" =~ ^[0-9]+\.[0-9]+\.[0-9]+ ]]; then
            echo "RELEASE_TAG=v$TAG" >> $GITEA_ENV
          else
            echo "RELEASE_TAG=$TAG" >> $GITEA_ENV
          fi

      - name: Create version.txt
        run: echo "${{ env.VERSION }}" > binaries/version.txt

      - name: Create source archive
        run: |
          tar --exclude='.git' --exclude='.github' --exclude='.gitea' \
            --exclude='binaries' --exclude='releases' --exclude='*.tar.gz' \
            -czf binaries/${{ env.PROJECTNAME }}-${{ env.VERSION }}-source.tar.gz .

      - name: Create Release
        uses: softprops/action-gh-release@v1
        with:
          tag_name: ${{ env.RELEASE_TAG }}
          files: binaries/*
          generate_release_notes: true
          make_latest: true
```

## Beta Workflow

**File:** `.gitea/workflows/beta.yml`

```yaml
name: Beta Release

on:
  push:
    branches:
      - beta

env:
  PROJECTNAME: casspeed

jobs:
  build:
    runs-on: ubuntu-latest
    strategy:
      matrix:
        include:
          - goos: linux
            goarch: amd64
          - goos: linux
            goarch: arm64

    steps:
      - uses: actions/checkout@v4

      - name: Set up Go
        uses: actions/setup-go@v5
        with:
          go-version: 'stable'

      - name: Set build info
        run: |
          echo "VERSION=$(date -u +"%Y%m%d%H%M%S")-beta" >> $GITEA_ENV
          echo "COMMIT_ID=$(git rev-parse --short HEAD)" >> $GITEA_ENV
          echo "BUILD_DATE=$(date +"%a %b %d, %Y at %H:%M:%S %Z")" >> $GITEA_ENV

      - name: Build server
        env:
          GOOS: ${{ matrix.goos }}
          GOARCH: ${{ matrix.goarch }}
          CGO_ENABLED: 0
        run: |
          LDFLAGS="-s -w -X 'main.Version=${{ env.VERSION }}' -X 'main.CommitID=${{ env.COMMIT_ID }}' -X 'main.BuildDate=${{ env.BUILD_DATE }}'"
          go build -ldflags "${LDFLAGS}" -o ${{ env.PROJECTNAME }}-${{ matrix.goos }}-${{ matrix.goarch }} src

      # CLI build - only if src/client/ directory exists
      - name: Build CLI
        if: hashFiles('src/client/') != ''
        env:
          GOOS: ${{ matrix.goos }}
          GOARCH: ${{ matrix.goarch }}
          CGO_ENABLED: 0
        run: |
          LDFLAGS="-s -w -X 'main.Version=${{ env.VERSION }}' -X 'main.CommitID=${{ env.COMMIT_ID }}' -X 'main.BuildDate=${{ env.BUILD_DATE }}'"
          go build -ldflags "${LDFLAGS}" -o ${{ env.PROJECTNAME }}-${{ matrix.goos }}-${{ matrix.goarch }}-cli src/client

      - name: Upload server artifact
        uses: actions/upload-artifact@v4
        with:
          name: ${{ env.PROJECTNAME }}-${{ matrix.goos }}-${{ matrix.goarch }}
          path: ${{ env.PROJECTNAME }}-${{ matrix.goos }}-${{ matrix.goarch }}

      - name: Upload CLI artifact
        if: hashFiles('src/client/') != ''
        uses: actions/upload-artifact@v4
        with:
          name: ${{ env.PROJECTNAME }}-${{ matrix.goos }}-${{ matrix.goarch }}-cli
          path: ${{ env.PROJECTNAME }}-${{ matrix.goos }}-${{ matrix.goarch }}-cli

  release:
    needs: build
    runs-on: ubuntu-latest
    permissions:
      contents: write

    steps:
      - uses: actions/checkout@v4

      - name: Download all artifacts
        uses: actions/download-artifact@v4
        with:
          path: binaries
          merge-multiple: true

      - name: Set version
        run: echo "VERSION=$(date -u +"%Y%m%d%H%M%S")-beta" >> $GITEA_ENV

      - name: Create version.txt
        run: echo "${{ env.VERSION }}" > binaries/version.txt

      - name: Create Release
        uses: softprops/action-gh-release@v1
        with:
          tag_name: ${{ env.VERSION }}
          files: binaries/*
          prerelease: true
          generate_release_notes: true
```

## Daily Workflow

**File:** `.gitea/workflows/daily.yml`

```yaml
name: Daily Build

on:
  schedule:
    - cron: '0 3 * * *'  # 3am UTC daily
  push:
    branches:
      - main
      - master
  workflow_dispatch:

env:
  PROJECTNAME: casspeed

jobs:
  build:
    runs-on: ubuntu-latest
    strategy:
      matrix:
        include:
          - goos: linux
            goarch: amd64
          - goos: linux
            goarch: arm64

    steps:
      - uses: actions/checkout@v4

      - name: Set up Go
        uses: actions/setup-go@v5
        with:
          go-version: 'stable'

      - name: Set build info
        run: |
          echo "VERSION=$(date -u +"%Y%m%d%H%M%S")" >> $GITEA_ENV
          echo "COMMIT_ID=$(git rev-parse --short HEAD)" >> $GITEA_ENV
          echo "BUILD_DATE=$(date +"%a %b %d, %Y at %H:%M:%S %Z")" >> $GITEA_ENV

      - name: Build server
        env:
          GOOS: ${{ matrix.goos }}
          GOARCH: ${{ matrix.goarch }}
          CGO_ENABLED: 0
        run: |
          LDFLAGS="-s -w -X 'main.Version=${{ env.VERSION }}' -X 'main.CommitID=${{ env.COMMIT_ID }}' -X 'main.BuildDate=${{ env.BUILD_DATE }}'"
          go build -ldflags "${LDFLAGS}" -o ${{ env.PROJECTNAME }}-${{ matrix.goos }}-${{ matrix.goarch }} src

      # CLI build - only if src/client/ directory exists
      - name: Build CLI
        if: hashFiles('src/client/') != ''
        env:
          GOOS: ${{ matrix.goos }}
          GOARCH: ${{ matrix.goarch }}
          CGO_ENABLED: 0
        run: |
          LDFLAGS="-s -w -X 'main.Version=${{ env.VERSION }}' -X 'main.CommitID=${{ env.COMMIT_ID }}' -X 'main.BuildDate=${{ env.BUILD_DATE }}'"
          go build -ldflags "${LDFLAGS}" -o ${{ env.PROJECTNAME }}-${{ matrix.goos }}-${{ matrix.goarch }}-cli src/client

      - name: Upload server artifact
        uses: actions/upload-artifact@v4
        with:
          name: ${{ env.PROJECTNAME }}-${{ matrix.goos }}-${{ matrix.goarch }}
          path: ${{ env.PROJECTNAME }}-${{ matrix.goos }}-${{ matrix.goarch }}

      - name: Upload CLI artifact
        if: hashFiles('src/client/') != ''
        uses: actions/upload-artifact@v4
        with:
          name: ${{ env.PROJECTNAME }}-${{ matrix.goos }}-${{ matrix.goarch }}-cli
          path: ${{ env.PROJECTNAME }}-${{ matrix.goos }}-${{ matrix.goarch }}-cli

  release:
    needs: build
    runs-on: ubuntu-latest
    permissions:
      contents: write

    steps:
      - uses: actions/checkout@v4

      - name: Download all artifacts
        uses: actions/download-artifact@v4
        with:
          path: binaries
          merge-multiple: true

      - name: Set version
        run: echo "VERSION=$(date -u +"%Y%m%d%H%M%S")" >> $GITEA_ENV

      - name: Create version.txt
        run: echo "${{ env.VERSION }}" > binaries/version.txt

      - name: Delete previous daily release
        run: |
          # Use Gitea API to delete previous daily release
          curl -X DELETE \
            -H "Authorization: token ${{ secrets.GITEA_TOKEN }}" \
            "${{ gitea.server_url }}/api/v1/repos/${{ gitea.repository }}/releases/tags/daily" || true
          git push origin :refs/tags/daily 2>/dev/null || true

      - name: Create Release
        uses: softprops/action-gh-release@v1
        with:
          tag_name: daily
          name: "Daily Build ${{ env.VERSION }}"
          files: binaries/*
          prerelease: true
          body: "Daily build: ${{ env.VERSION }}"
```

## Docker Workflow

**File:** `.gitea/workflows/docker.yml`

```yaml
name: Docker Build

on:
  push:
    branches: ['**']  # ALL branches
    tags:
      - 'v*'
      - '*.*.*'
  workflow_dispatch:

env:
  PROJECTNAME: casspeed
  # Registry auto-detected from Gitea instance (works with self-hosted)
  # Format: {gitea-server}/owner/repo -> extracts server for registry
  IMAGE_NAME: ${{ gitea.repository }}

jobs:
  build:
    runs-on: ubuntu-latest
    permissions:
      contents: read
      packages: write

    steps:
      - uses: actions/checkout@v4

      - name: Set up QEMU
        uses: docker/setup-qemu-action@v3

      - name: Set up Docker Buildx
        uses: docker/setup-buildx-action@v3

      - name: Set registry from server URL
        run: |
          # Extract registry from Gitea server URL (works with self-hosted)
          # Example: https://git.example.com -> git.example.com
          SERVER_URL="${{ gitea.server_url }}"
          REGISTRY="${SERVER_URL#https://}"
          REGISTRY="${REGISTRY#http://}"
          echo "REGISTRY=${REGISTRY}" >> $GITEA_ENV

      - name: Log in to Container Registry
        uses: docker/login-action@v3
        with:
          registry: ${{ env.REGISTRY }}
          username: ${{ gitea.actor }}
          password: ${{ secrets.GITEA_TOKEN }}

      - name: Set build info
        run: |
          echo "COMMIT_ID=$(git rev-parse --short HEAD)" >> $GITEA_ENV
          echo "YYMM=$(date +"%y%m")" >> $GITEA_ENV
          if [[ "${{ gitea.ref }}" == refs/tags/* ]]; then
            VERSION="${GITEA_REF_NAME}"
            echo "VERSION=${VERSION#v}" >> $GITEA_ENV  # Strip 'v' prefix
            echo "IS_TAG=true" >> $GITEA_ENV
          else
            echo "VERSION=$(git rev-parse --short HEAD)" >> $GITEA_ENV
            echo "IS_TAG=false" >> $GITEA_ENV
          fi
          echo "BUILD_DATE=$(date +"%a %b %d, %Y at %H:%M:%S %Z")" >> $GITEA_ENV

      - name: Determine tags
        id: tags
        run: |
          # Use self-hosted registry URL
          TAGS="${{ env.REGISTRY }}/${{ env.IMAGE_NAME }}:${{ env.COMMIT_ID }}"

          if [[ "${{ env.IS_TAG }}" == "true" ]]; then
            # Release tag - version, latest, YYMM
            TAGS="$TAGS,${{ env.REGISTRY }}/${{ env.IMAGE_NAME }}:${{ env.VERSION }}"
            TAGS="$TAGS,${{ env.REGISTRY }}/${{ env.IMAGE_NAME }}:latest"
            TAGS="$TAGS,${{ env.REGISTRY }}/${{ env.IMAGE_NAME }}:${{ env.YYMM }}"
          else
            # All pushes get devel tag
            TAGS="$TAGS,${{ env.REGISTRY }}/${{ env.IMAGE_NAME }}:devel"

            # Beta branch also gets beta tag
            if [[ "${{ gitea.ref }}" == refs/heads/beta ]]; then
              TAGS="$TAGS,${{ env.REGISTRY }}/${{ env.IMAGE_NAME }}:beta"
            fi
          fi

          echo "tags=$TAGS" >> $GITEA_OUTPUT

      - name: Build and push
        uses: docker/build-push-action@v5
        with:
          context: .
          file: docker/Dockerfile
          platforms: linux/amd64,linux/arm64
          push: true
          tags: ${{ steps.tags.outputs.tags }}
          build-args: |
            VERSION="${{ env.VERSION }}"
            BUILD_DATE="${{ env.BUILD_DATE }}"
            COMMIT_ID="${{ env.COMMIT_ID }}"
          # OCI Image Labels (applied to image config)
          labels: |
            org.opencontainers.image.vendor="casapps"
            org.opencontainers.image.authors="casapps"
            org.opencontainers.image.title="${{ env.PROJECTNAME }}"
            org.opencontainers.image.base.name="${{ env.PROJECTNAME }}"
            org.opencontainers.image.description="Containerized version of ${{ env.PROJECTNAME }}"
            org.opencontainers.image.licenses=MIT
            org.opencontainers.image.version="${{ env.VERSION }}"
            org.opencontainers.image.created="${{ env.BUILD_DATE }}"
            org.opencontainers.image.revision="${{ env.COMMIT_ID }}"
            org.opencontainers.image.url="${{ gitea.server_url }}/${{ gitea.repository }}"
            org.opencontainers.image.source="${{ gitea.server_url }}/${{ gitea.repository }}"
            org.opencontainers.image.documentation="${{ gitea.server_url }}/${{ gitea.repository }}"
          # OCI Annotations for multi-arch manifest (required for registry display)
          annotations: |
            manifest:org.opencontainers.image.vendor=casapps
            manifest:org.opencontainers.image.authors=casapps
            manifest:org.opencontainers.image.title=${{ env.PROJECTNAME }}
            manifest:org.opencontainers.image.description=Containerized version of ${{ env.PROJECTNAME }}
            manifest:org.opencontainers.image.licenses=MIT
            manifest:org.opencontainers.image.version=${{ env.VERSION }}
            manifest:org.opencontainers.image.created=${{ env.BUILD_DATE }}
            manifest:org.opencontainers.image.revision=${{ env.COMMIT_ID }}
            manifest:org.opencontainers.image.url=${{ gitea.server_url }}/${{ gitea.repository }}
            manifest:org.opencontainers.image.source=${{ gitea.server_url }}/${{ gitea.repository }}
            manifest:org.opencontainers.image.documentation=${{ gitea.server_url }}/${{ gitea.repository }}
```

## Variable Mapping (GitHub → Gitea → Forgejo)

| GitHub | Gitea | Forgejo | Description |
|--------|-------|---------|-------------|
| `${{ github.* }}` | `${{ gitea.* }}` | `${{ forgejo.* }}` | Context variables |
| `GITHUB_ENV` | `GITEA_ENV` | `FORGEJO_ENV` | Environment file |
| `GITHUB_OUTPUT` | `GITEA_OUTPUT` | `FORGEJO_OUTPUT` | Output file |
| `GITHUB_REF_NAME` | `GITEA_REF_NAME` | `FORGEJO_REF_NAME` | Reference name |
| `github.token` | `secrets.GITEA_TOKEN` | `secrets.FORGEJO_TOKEN` | Auth token |
| `github.actor` | `gitea.actor` | `forgejo.actor` | Username |
| `github.repository` | `gitea.repository` | `forgejo.repository` | Repo path |
| `github.server_url` | `gitea.server_url` | `forgejo.server_url` | Server URL |

**Note:** Forgejo accepts both `FORGEJO_*` and `GITEA_*` variables for backwards compatibility.

**Notes:**
- Most GitHub Actions work on Gitea/Forgejo with minimal changes
- Use `secrets.GITEA_TOKEN` or `secrets.FORGEJO_TOKEN` for authentication
- Works with gitea.com, self-hosted Gitea, and self-hosted Forgejo
- Container registry auto-detected from server URL (e.g., `git.example.com/owner/repo`)
- Self-hosted runners: change `runs-on: ubuntu-latest` to your runner label
- Forgejo can use `.gitea/workflows/` directory for Gitea compatibility
- Some advanced GitHub features may not be available on older versions

---

# GITLAB CI

**For projects hosted on GitLab (gitlab.com or self-hosted), use this equivalent CI/CD configuration.**

GitLab CI uses a single `.gitlab-ci.yml` file in the repository root with stages instead of separate workflow files.

## Self-Hosted Configuration

| Setting | Value |
|---------|-------|
| GitLab version | 13.0+ (recommended 15.0+) |
| Runners | Register via `gitlab-runner register` |
| Container Registry | Enable in Admin Area → Settings → Container Registry |
| CI/CD Variables | Project → Settings → CI/CD → Variables |

All `$CI_*` variables are auto-populated by GitLab (works with self-hosted).

## Key Differences from GitHub/Gitea Actions

| Feature | GitHub/Gitea Actions | GitLab CI |
|---------|---------------------|-----------|
| Config location | `.github/workflows/*.yml` | `.gitlab-ci.yml` (single file) |
| Job grouping | Separate workflow files | Stages in single file |
| Triggers | `on:` block | `rules:` or `only/except` |
| Secrets | `${{ secrets.NAME }}` | `$NAME` (CI/CD variables) |
| Artifacts | `actions/upload-artifact` | `artifacts:` block |
| Matrix builds | `strategy.matrix` | `parallel:matrix` |
| Container registry | `ghcr.io` | `$CI_REGISTRY` |

## GitLab CI Configuration

**File:** `.gitlab-ci.yml`

```yaml
# GitLab CI/CD Pipeline for casspeed
# Equivalent to GitHub Actions: release.yml, beta.yml, daily.yml, docker.yml

variables:
  PROJECTNAME: "casspeed"
  PROJECTORG: "casapps"
  CGO_ENABLED: "0"
  GOOS: linux
  GOARCH: amd64

stages:
  - build
  - test
  - package
  - release
  - docker

# =============================================================================
# BUILD TEMPLATES
# =============================================================================

.go-build-template: &go-build
  image: golang:alpine
  before_script:
    - apk add --no-cache git bash
    - export VERSION="${CI_COMMIT_TAG#v}"
    - export COMMIT_ID="${CI_COMMIT_SHORT_SHA}"
    - export BUILD_DATE="$(date +"%a %b %d, %Y at %H:%M:%S %Z")"
    - export LDFLAGS="-s -w -X 'main.Version=${VERSION}' -X 'main.CommitID=${COMMIT_ID}' -X 'main.BuildDate=${BUILD_DATE}'"

# =============================================================================
# RELEASE BUILDS (Tag Push: v* or semver)
# =============================================================================

build:linux-amd64:
  <<: *go-build
  stage: build
  variables:
    GOOS: linux
    GOARCH: amd64
  script:
    - go build -ldflags "${LDFLAGS}" -o $CASSPEED-linux-amd64 src
    - if [ -d "src/client" ]; then go build -ldflags "${LDFLAGS}" -o $CASSPEED-linux-amd64-cli src/client; fi
  artifacts:
    paths:
      - $CASSPEED-linux-amd64*
    expire_in: 1 week
  rules:
    - if: $CI_COMMIT_TAG =~ /^v?\d+\.\d+\.\d+/

build:linux-arm64:
  <<: *go-build
  stage: build
  variables:
    GOOS: linux
    GOARCH: arm64
  script:
    - go build -ldflags "${LDFLAGS}" -o $CASSPEED-linux-arm64 src
    - if [ -d "src/client" ]; then go build -ldflags "${LDFLAGS}" -o $CASSPEED-linux-arm64-cli src/client; fi
  artifacts:
    paths:
      - $CASSPEED-linux-arm64*
    expire_in: 1 week
  rules:
    - if: $CI_COMMIT_TAG =~ /^v?\d+\.\d+\.\d+/

build:darwin-amd64:
  <<: *go-build
  stage: build
  variables:
    GOOS: darwin
    GOARCH: amd64
  script:
    - go build -ldflags "${LDFLAGS}" -o $CASSPEED-darwin-amd64 src
    - if [ -d "src/client" ]; then go build -ldflags "${LDFLAGS}" -o $CASSPEED-darwin-amd64-cli src/client; fi
  artifacts:
    paths:
      - $CASSPEED-darwin-amd64*
    expire_in: 1 week
  rules:
    - if: $CI_COMMIT_TAG =~ /^v?\d+\.\d+\.\d+/

build:darwin-arm64:
  <<: *go-build
  stage: build
  variables:
    GOOS: darwin
    GOARCH: arm64
  script:
    - go build -ldflags "${LDFLAGS}" -o $CASSPEED-darwin-arm64 src
    - if [ -d "src/client" ]; then go build -ldflags "${LDFLAGS}" -o $CASSPEED-darwin-arm64-cli src/client; fi
  artifacts:
    paths:
      - $CASSPEED-darwin-arm64*
    expire_in: 1 week
  rules:
    - if: $CI_COMMIT_TAG =~ /^v?\d+\.\d+\.\d+/

build:windows-amd64:
  <<: *go-build
  stage: build
  variables:
    GOOS: windows
    GOARCH: amd64
  script:
    - go build -ldflags "${LDFLAGS}" -o $CASSPEED-windows-amd64.exe src
    - if [ -d "src/client" ]; then go build -ldflags "${LDFLAGS}" -o $CASSPEED-windows-amd64-cli.exe src/client; fi
  artifacts:
    paths:
      - $CASSPEED-windows-amd64*.exe
    expire_in: 1 week
  rules:
    - if: $CI_COMMIT_TAG =~ /^v?\d+\.\d+\.\d+/

build:windows-arm64:
  <<: *go-build
  stage: build
  variables:
    GOOS: windows
    GOARCH: arm64
  script:
    - go build -ldflags "${LDFLAGS}" -o $CASSPEED-windows-arm64.exe src
    - if [ -d "src/client" ]; then go build -ldflags "${LDFLAGS}" -o $CASSPEED-windows-arm64-cli.exe src/client; fi
  artifacts:
    paths:
      - $CASSPEED-windows-arm64*.exe
    expire_in: 1 week
  rules:
    - if: $CI_COMMIT_TAG =~ /^v?\d+\.\d+\.\d+/

build:freebsd-amd64:
  <<: *go-build
  stage: build
  variables:
    GOOS: freebsd
    GOARCH: amd64
  script:
    - go build -ldflags "${LDFLAGS}" -o $CASSPEED-freebsd-amd64 src
    - if [ -d "src/client" ]; then go build -ldflags "${LDFLAGS}" -o $CASSPEED-freebsd-amd64-cli src/client; fi
  artifacts:
    paths:
      - $CASSPEED-freebsd-amd64*
    expire_in: 1 week
  rules:
    - if: $CI_COMMIT_TAG =~ /^v?\d+\.\d+\.\d+/

build:freebsd-arm64:
  <<: *go-build
  stage: build
  variables:
    GOOS: freebsd
    GOARCH: arm64
  script:
    - go build -ldflags "${LDFLAGS}" -o $CASSPEED-freebsd-arm64 src
    - if [ -d "src/client" ]; then go build -ldflags "${LDFLAGS}" -o $CASSPEED-freebsd-arm64-cli src/client; fi
  artifacts:
    paths:
      - $CASSPEED-freebsd-arm64*
    expire_in: 1 week
  rules:
    - if: $CI_COMMIT_TAG =~ /^v?\d+\.\d+\.\d+/

# =============================================================================
# TEST
# =============================================================================

test:
  <<: *go-build
  stage: test
  script:
    - go test -v -cover ./...
  rules:
    - if: $CI_COMMIT_TAG =~ /^v?\d+\.\d+\.\d+/
    - if: $CI_COMMIT_BRANCH == "main" || $CI_COMMIT_BRANCH == "master"
    - if: $CI_COMMIT_BRANCH == "beta"

# =============================================================================
# RELEASE (GitLab Release)
# =============================================================================

release:
  stage: release
  image: registry.gitlab.com/gitlab-org/release-cli:latest
  needs:
    - build:linux-amd64
    - build:linux-arm64
    - build:darwin-amd64
    - build:darwin-arm64
    - build:windows-amd64
    - build:windows-arm64
    - build:freebsd-amd64
    - build:freebsd-arm64
    - test
  script:
    - echo "Creating release ${CI_COMMIT_TAG}"
    - echo "${CI_COMMIT_TAG#v}" > version.txt
  artifacts:
    paths:
      - version.txt
      - $CASSPEED-*
  release:
    tag_name: $CI_COMMIT_TAG
    name: "Release $CI_COMMIT_TAG"
    description: "Release created by GitLab CI"
    assets:
      links:
        - name: "$CASSPEED-linux-amd64"
          url: "${CI_PROJECT_URL}/-/jobs/artifacts/${CI_COMMIT_TAG}/raw/$CASSPEED-linux-amd64?job=build:linux-amd64"
        - name: "$CASSPEED-linux-arm64"
          url: "${CI_PROJECT_URL}/-/jobs/artifacts/${CI_COMMIT_TAG}/raw/$CASSPEED-linux-arm64?job=build:linux-arm64"
        - name: "$CASSPEED-darwin-amd64"
          url: "${CI_PROJECT_URL}/-/jobs/artifacts/${CI_COMMIT_TAG}/raw/$CASSPEED-darwin-amd64?job=build:darwin-amd64"
        - name: "$CASSPEED-darwin-arm64"
          url: "${CI_PROJECT_URL}/-/jobs/artifacts/${CI_COMMIT_TAG}/raw/$CASSPEED-darwin-arm64?job=build:darwin-arm64"
        - name: "$CASSPEED-windows-amd64.exe"
          url: "${CI_PROJECT_URL}/-/jobs/artifacts/${CI_COMMIT_TAG}/raw/$CASSPEED-windows-amd64.exe?job=build:windows-amd64"
        - name: "$CASSPEED-windows-arm64.exe"
          url: "${CI_PROJECT_URL}/-/jobs/artifacts/${CI_COMMIT_TAG}/raw/$CASSPEED-windows-arm64.exe?job=build:windows-arm64"
        - name: "$CASSPEED-freebsd-amd64"
          url: "${CI_PROJECT_URL}/-/jobs/artifacts/${CI_COMMIT_TAG}/raw/$CASSPEED-freebsd-amd64?job=build:freebsd-amd64"
        - name: "$CASSPEED-freebsd-arm64"
          url: "${CI_PROJECT_URL}/-/jobs/artifacts/${CI_COMMIT_TAG}/raw/$CASSPEED-freebsd-arm64?job=build:freebsd-arm64"
  rules:
    - if: $CI_COMMIT_TAG =~ /^v?\d+\.\d+\.\d+/

# =============================================================================
# BETA BUILDS (Push to beta branch)
# =============================================================================

build:beta:linux:
  <<: *go-build
  stage: build
  variables:
    GOOS: linux
    GOARCH: amd64
  before_script:
    - apk add --no-cache git bash
    - export VERSION="$(date +%Y%m%d%H%M%S)-beta"
    - export COMMIT_ID="${CI_COMMIT_SHORT_SHA}"
    - export BUILD_DATE="$(date +"%a %b %d, %Y at %H:%M:%S %Z")"
    - export LDFLAGS="-s -w -X 'main.Version=${VERSION}' -X 'main.CommitID=${COMMIT_ID}' -X 'main.BuildDate=${BUILD_DATE}'"
  script:
    - go build -ldflags "${LDFLAGS}" -o $CASSPEED-linux-amd64 src
    - go build -ldflags "${LDFLAGS}" -o $CASSPEED-linux-arm64 src
  artifacts:
    paths:
      - $CASSPEED-linux-*
    expire_in: 1 week
  rules:
    - if: $CI_COMMIT_BRANCH == "beta"

# =============================================================================
# DAILY BUILDS (Scheduled + main/master push)
# =============================================================================

build:daily:linux:
  <<: *go-build
  stage: build
  variables:
    GOOS: linux
    GOARCH: amd64
  before_script:
    - apk add --no-cache git bash
    - export VERSION="$(date +%Y%m%d%H%M%S)"
    - export COMMIT_ID="${CI_COMMIT_SHORT_SHA}"
    - export BUILD_DATE="$(date +"%a %b %d, %Y at %H:%M:%S %Z")"
    - export LDFLAGS="-s -w -X 'main.Version=${VERSION}' -X 'main.CommitID=${COMMIT_ID}' -X 'main.BuildDate=${BUILD_DATE}'"
  script:
    - go build -ldflags "${LDFLAGS}" -o $CASSPEED-linux-amd64 src
    - go build -ldflags "${LDFLAGS}" -o $CASSPEED-linux-arm64 src
  artifacts:
    paths:
      - $CASSPEED-linux-*
    expire_in: 1 day
  rules:
    - if: $CI_PIPELINE_SOURCE == "schedule"
    - if: $CI_COMMIT_BRANCH == "main" || $CI_COMMIT_BRANCH == "master"
      when: manual
      allow_failure: true

# =============================================================================
# DOCKER BUILDS
# =============================================================================

docker:build:
  stage: docker
  image: docker:latest
  services:
    - docker:dind
  variables:
    DOCKER_TLS_CERTDIR: "/certs"
    DOCKER_BUILDKIT: "1"
  before_script:
    - docker login -u $CI_REGISTRY_USER -p $CI_REGISTRY_PASSWORD $CI_REGISTRY
    - docker buildx create --name multiarch-builder --use 2>/dev/null || docker buildx use multiarch-builder
  script:
    - |
      # Determine version and tags based on trigger
      if [ -n "$CI_COMMIT_TAG" ]; then
        VERSION="${CI_COMMIT_TAG#v}"
        YYMM=$(date +%y%m)
        TAGS="-t $CI_REGISTRY_IMAGE:$VERSION -t $CI_REGISTRY_IMAGE:latest -t $CI_REGISTRY_IMAGE:$YYMM -t $CI_REGISTRY_IMAGE:$CI_COMMIT_SHORT_SHA"
      elif [ "$CI_COMMIT_BRANCH" = "beta" ]; then
        VERSION="beta-$CI_COMMIT_SHORT_SHA"
        TAGS="-t $CI_REGISTRY_IMAGE:beta -t $CI_REGISTRY_IMAGE:devel -t $CI_REGISTRY_IMAGE:$CI_COMMIT_SHORT_SHA"
      else
        VERSION="devel-$CI_COMMIT_SHORT_SHA"
        TAGS="-t $CI_REGISTRY_IMAGE:devel -t $CI_REGISTRY_IMAGE:$CI_COMMIT_SHORT_SHA"
      fi
      BUILD_DATE="$(date -Iseconds)"
    - |
      # Build multi-arch with OCI labels and manifest annotations
      docker buildx build \
        -f docker/Dockerfile \
        --platform linux/amd64,linux/arm64 \
        --build-arg VERSION="${VERSION}" \
        --build-arg COMMIT_ID="${CI_COMMIT_SHORT_SHA}" \
        --build-arg BUILD_DATE="${BUILD_DATE}" \
        --label "org.opencontainers.image.vendor=${PROJECTORG}" \
        --label "org.opencontainers.image.authors=${PROJECTORG}" \
        --label "org.opencontainers.image.title=$CASSPEED" \
        --label "org.opencontainers.image.base.name=$CASSPEED" \
        --label "org.opencontainers.image.description=Containerized version of $CASSPEED" \
        --label "org.opencontainers.image.licenses=MIT" \
        --label "org.opencontainers.image.version=${VERSION}" \
        --label "org.opencontainers.image.created=${BUILD_DATE}" \
        --label "org.opencontainers.image.revision=${CI_COMMIT_SHORT_SHA}" \
        --label "org.opencontainers.image.url=${CI_PROJECT_URL}" \
        --label "org.opencontainers.image.source=${CI_PROJECT_URL}" \
        --label "org.opencontainers.image.documentation=${CI_PROJECT_URL}" \
        --annotation "manifest:org.opencontainers.image.vendor=${PROJECTORG}" \
        --annotation "manifest:org.opencontainers.image.authors=${PROJECTORG}" \
        --annotation "manifest:org.opencontainers.image.title=$CASSPEED" \
        --annotation "manifest:org.opencontainers.image.description=Containerized version of $CASSPEED" \
        --annotation "manifest:org.opencontainers.image.licenses=MIT" \
        --annotation "manifest:org.opencontainers.image.version=${VERSION}" \
        --annotation "manifest:org.opencontainers.image.created=${BUILD_DATE}" \
        --annotation "manifest:org.opencontainers.image.revision=${CI_COMMIT_SHORT_SHA}" \
        --annotation "manifest:org.opencontainers.image.url=${CI_PROJECT_URL}" \
        --annotation "manifest:org.opencontainers.image.source=${CI_PROJECT_URL}" \
        --annotation "manifest:org.opencontainers.image.documentation=${CI_PROJECT_URL}" \
        $TAGS \
        --push \
        .
  rules:
    - if: $CI_COMMIT_TAG =~ /^v?\d+\.\d+\.\d+/
    - if: $CI_COMMIT_BRANCH == "main" || $CI_COMMIT_BRANCH == "master"
    - if: $CI_COMMIT_BRANCH == "beta"
```

## GitLab CI Variables

Set these in GitLab Project → Settings → CI/CD → Variables:

| Variable | Description | Example |
|----------|-------------|---------|
| `CI_REGISTRY` | GitLab container registry (auto-set) | `registry.gitlab.com` |
| `CI_REGISTRY_USER` | Registry username (auto-set) | `gitlab-ci-token` |
| `CI_REGISTRY_PASSWORD` | Registry password (auto-set) | `$CI_JOB_TOKEN` |
| `CI_REGISTRY_IMAGE` | Full image path (auto-set) | `registry.gitlab.com/org/project` |

## GitLab Scheduled Pipelines (for Daily Builds)

Create in GitLab Project → Build → Pipeline schedules:

| Field | Value |
|-------|-------|
| Description | Daily Build |
| Interval Pattern | `0 3 * * *` (3am UTC daily) |
| Cron Timezone | UTC |
| Target Branch | `main` or `master` |
| Activated | Yes |

## Variable Mapping

| GitHub Actions | GitLab CI | Description |
|----------------|-----------|-------------|
| `${{ github.ref_name }}` | `$CI_COMMIT_REF_NAME` | Branch or tag name |
| `${{ github.sha }}` | `$CI_COMMIT_SHA` | Full commit SHA |
| `${{ github.repository }}` | `$CI_PROJECT_PATH` | Repo path (org/project) |
| `${{ github.server_url }}` | `$CI_SERVER_URL` | Server URL |
| `${{ secrets.NAME }}` | `$NAME` | CI/CD variables |
| `GITHUB_ENV` | `dotenv` artifact | Pass vars between jobs |

**Notes:**
- GitLab CI uses a single `.gitlab-ci.yml` file instead of multiple workflow files
- Use `rules:` (preferred) or `only/except` for conditional job execution
- GitLab has built-in container registry at `$CI_REGISTRY_IMAGE`
- Scheduled pipelines configured in GitLab UI, not in YAML
- Use `needs:` for job dependencies (DAG mode) instead of linear stages

---

# JENKINS

**For projects using Jenkins CI/CD (self-hosted).**

Jenkins provides equivalent functionality to GitHub Actions, Gitea Actions, and GitLab CI for self-hosted environments.

## Configuration

| Setting | Value |
|---------|-------|
| Agents | `arm64`, `amd64` (both required) |
| Build | All 8 platforms in parallel |
| Triggers | Tag push, beta branch, main/master, scheduled daily |

## Triggers (Matching GitHub Actions)

| Trigger | Jenkins Config | Equivalent To |
|---------|----------------|---------------|
| Tag push | `when { buildingTag() }` | `release.yml` |
| Beta branch | `when { branch 'beta' }` | `beta.yml` |
| Main/master | `when { anyOf { branch 'main'; branch 'master' } }` | `daily.yml` |
| Scheduled | `triggers { cron('0 3 * * *') }` | `daily.yml` schedule |
| All branches | Default (no `when`) | `docker.yml` |

## Jenkinsfile

All projects MUST have a `Jenkinsfile` in the repository root.

```groovy
pipeline {
    agent none

    triggers {
        // Daily build at 3am UTC (matches GitHub Actions daily.yml)
        cron('0 3 * * *')
    }

    environment {
        PROJECTNAME = 'casspeed'
        PROJECTORG = 'casapps'
        BINDIR = 'binaries'
        RELDIR = 'releases'
        GOCACHE = '/tmp/go-cache'
        GOMODCACHE = '/tmp/go-mod-cache'

        // =========================================================================
        // GIT PROVIDER CONFIGURATION
        // Uncomment ONE block below based on your git hosting platform
        // =========================================================================

        // ----- GITHUB (default) -----
        GIT_FQDN = 'github.com'
        GIT_TOKEN = credentials('github-token')  // Jenkins credentials ID
        REGISTRY = "ghcr.io/${PROJECTORG}/$CASSPEED"

        // ----- GITEA / FORGEJO (self-hosted) -----
        // GIT_FQDN = 'git.example.com'  // Your Gitea/Forgejo domain
        // GIT_TOKEN = credentials('gitea-token')  // Jenkins credentials ID
        // REGISTRY = "${GIT_FQDN}/${PROJECTORG}/$CASSPEED"

        // ----- GITLAB (gitlab.com or self-hosted) -----
        // GIT_FQDN = 'gitlab.com'  // or your self-hosted GitLab domain
        // GIT_TOKEN = credentials('gitlab-token')  // Jenkins credentials ID
        // REGISTRY = "registry.${GIT_FQDN}/${PROJECTORG}/$CASSPEED"

        // ----- DOCKER HUB -----
        // GIT_FQDN = 'github.com'  // Git host (separate from registry)
        // GIT_TOKEN = credentials('github-token')
        // REGISTRY = "docker.io/${PROJECTORG}/$CASSPEED"

        // =========================================================================
    }

    stages {
        stage('Setup') {
            agent { label 'amd64' }
            steps {
                script {
                    // Determine build type and version
                    if (env.TAG_NAME) {
                        // Release build (tag push) - matches release.yml
                        env.BUILD_TYPE = 'release'
                        env.VERSION = env.TAG_NAME.replaceFirst('^v', '')
                    } else if (env.BRANCH_NAME == 'beta') {
                        // Beta build - matches beta.yml
                        env.BUILD_TYPE = 'beta'
                        env.VERSION = sh(script: 'date -u +"%Y%m%d%H%M%S"', returnStdout: true).trim() + '-beta'
                    } else if (env.BRANCH_NAME == 'main' || env.BRANCH_NAME == 'master') {
                        // Daily build - matches daily.yml
                        env.BUILD_TYPE = 'daily'
                        env.VERSION = sh(script: 'date -u +"%Y%m%d%H%M%S"', returnStdout: true).trim()
                    } else {
                        // Other branches - dev build
                        env.BUILD_TYPE = 'dev'
                        env.VERSION = sh(script: 'date -u +"%Y%m%d%H%M%S"', returnStdout: true).trim() + '-dev'
                    }
                    env.COMMIT_ID = sh(script: 'git rev-parse --short HEAD', returnStdout: true).trim()
                    env.BUILD_DATE = sh(script: 'date +"%a %b %d, %Y at %H:%M:%S %Z"', returnStdout: true).trim()
                    env.LDFLAGS = "-s -w -X 'main.Version=${env.VERSION}' -X 'main.CommitID=${env.COMMIT_ID}' -X 'main.BuildDate=${env.BUILD_DATE}'"
                    env.HAS_CLI = sh(script: '[ -d src/client ] && echo true || echo false', returnStdout: true).trim()
                }
                sh 'mkdir -p ${BINDIR} ${RELDIR}'
                echo "Build type: ${BUILD_TYPE}, Version: ${VERSION}"
            }
        }

        stage('Build Server') {
            parallel {
                // Linux
                stage('Linux AMD64') {
                    agent { label 'amd64' }
                    steps {
                        sh '''
                            docker run --rm \
                                -v ${WORKSPACE}:/build \
                                -v ${GOCACHE}:/root/.cache/go-build \
                                -v ${GOMODCACHE}:/go/pkg/mod \
                                -w /build \
                                -e CGO_ENABLED=0 \
                                -e GOOS=linux \
                                -e GOARCH=amd64 \
                                golang:alpine \
                                go build -ldflags "${LDFLAGS}" -o ${BINDIR}/$CASSPEED-linux-amd64 src
                        '''
                    }
                }
                stage('Linux ARM64') {
                    agent { label 'arm64' }
                    steps {
                        sh '''
                            docker run --rm \
                                -v ${WORKSPACE}:/build \
                                -v ${GOCACHE}:/root/.cache/go-build \
                                -v ${GOMODCACHE}:/go/pkg/mod \
                                -w /build \
                                -e CGO_ENABLED=0 \
                                -e GOOS=linux \
                                -e GOARCH=arm64 \
                                golang:alpine \
                                go build -ldflags "${LDFLAGS}" -o ${BINDIR}/$CASSPEED-linux-arm64 src
                        '''
                    }
                }
                // Darwin (macOS)
                stage('Darwin AMD64') {
                    agent { label 'amd64' }
                    steps {
                        sh '''
                            docker run --rm \
                                -v ${WORKSPACE}:/build \
                                -v ${GOCACHE}:/root/.cache/go-build \
                                -v ${GOMODCACHE}:/go/pkg/mod \
                                -w /build \
                                -e CGO_ENABLED=0 \
                                -e GOOS=darwin \
                                -e GOARCH=amd64 \
                                golang:alpine \
                                go build -ldflags "${LDFLAGS}" -o ${BINDIR}/$CASSPEED-darwin-amd64 src
                        '''
                    }
                }
                stage('Darwin ARM64') {
                    agent { label 'amd64' }
                    steps {
                        sh '''
                            docker run --rm \
                                -v ${WORKSPACE}:/build \
                                -v ${GOCACHE}:/root/.cache/go-build \
                                -v ${GOMODCACHE}:/go/pkg/mod \
                                -w /build \
                                -e CGO_ENABLED=0 \
                                -e GOOS=darwin \
                                -e GOARCH=arm64 \
                                golang:alpine \
                                go build -ldflags "${LDFLAGS}" -o ${BINDIR}/$CASSPEED-darwin-arm64 src
                        '''
                    }
                }
                // Windows
                stage('Windows AMD64') {
                    agent { label 'amd64' }
                    steps {
                        sh '''
                            docker run --rm \
                                -v ${WORKSPACE}:/build \
                                -v ${GOCACHE}:/root/.cache/go-build \
                                -v ${GOMODCACHE}:/go/pkg/mod \
                                -w /build \
                                -e CGO_ENABLED=0 \
                                -e GOOS=windows \
                                -e GOARCH=amd64 \
                                golang:alpine \
                                go build -ldflags "${LDFLAGS}" -o ${BINDIR}/$CASSPEED-windows-amd64.exe src
                        '''
                    }
                }
                stage('Windows ARM64') {
                    agent { label 'amd64' }
                    steps {
                        sh '''
                            docker run --rm \
                                -v ${WORKSPACE}:/build \
                                -v ${GOCACHE}:/root/.cache/go-build \
                                -v ${GOMODCACHE}:/go/pkg/mod \
                                -w /build \
                                -e CGO_ENABLED=0 \
                                -e GOOS=windows \
                                -e GOARCH=arm64 \
                                golang:alpine \
                                go build -ldflags "${LDFLAGS}" -o ${BINDIR}/$CASSPEED-windows-arm64.exe src
                        '''
                    }
                }
                // FreeBSD
                stage('FreeBSD AMD64') {
                    agent { label 'amd64' }
                    steps {
                        sh '''
                            docker run --rm \
                                -v ${WORKSPACE}:/build \
                                -v ${GOCACHE}:/root/.cache/go-build \
                                -v ${GOMODCACHE}:/go/pkg/mod \
                                -w /build \
                                -e CGO_ENABLED=0 \
                                -e GOOS=freebsd \
                                -e GOARCH=amd64 \
                                golang:alpine \
                                go build -ldflags "${LDFLAGS}" -o ${BINDIR}/$CASSPEED-freebsd-amd64 src
                        '''
                    }
                }
                stage('FreeBSD ARM64') {
                    agent { label 'amd64' }
                    steps {
                        sh '''
                            docker run --rm \
                                -v ${WORKSPACE}:/build \
                                -v ${GOCACHE}:/root/.cache/go-build \
                                -v ${GOMODCACHE}:/go/pkg/mod \
                                -w /build \
                                -e CGO_ENABLED=0 \
                                -e GOOS=freebsd \
                                -e GOARCH=arm64 \
                                golang:alpine \
                                go build -ldflags "${LDFLAGS}" -o ${BINDIR}/$CASSPEED-freebsd-arm64 src
                        '''
                    }
                }
            }
        }

        // CLI builds - only if src/client/ exists (matches GitHub Actions)
        stage('Build CLI') {
            when {
                expression { env.HAS_CLI == 'true' }
            }
            parallel {
                stage('CLI Linux AMD64') {
                    agent { label 'amd64' }
                    steps {
                        sh '''
                            docker run --rm \
                                -v ${WORKSPACE}:/build \
                                -v ${GOCACHE}:/root/.cache/go-build \
                                -v ${GOMODCACHE}:/go/pkg/mod \
                                -w /build \
                                -e CGO_ENABLED=0 \
                                -e GOOS=linux \
                                -e GOARCH=amd64 \
                                golang:alpine \
                                go build -ldflags "${LDFLAGS}" -o ${BINDIR}/$CASSPEED-linux-amd64-cli src/client
                        '''
                    }
                }
                stage('CLI Linux ARM64') {
                    agent { label 'arm64' }
                    steps {
                        sh '''
                            docker run --rm \
                                -v ${WORKSPACE}:/build \
                                -v ${GOCACHE}:/root/.cache/go-build \
                                -v ${GOMODCACHE}:/go/pkg/mod \
                                -w /build \
                                -e CGO_ENABLED=0 \
                                -e GOOS=linux \
                                -e GOARCH=arm64 \
                                golang:alpine \
                                go build -ldflags "${LDFLAGS}" -o ${BINDIR}/$CASSPEED-linux-arm64-cli src/client
                        '''
                    }
                }
                stage('CLI Darwin AMD64') {
                    agent { label 'amd64' }
                    steps {
                        sh '''
                            docker run --rm \
                                -v ${WORKSPACE}:/build \
                                -v ${GOCACHE}:/root/.cache/go-build \
                                -v ${GOMODCACHE}:/go/pkg/mod \
                                -w /build \
                                -e CGO_ENABLED=0 \
                                -e GOOS=darwin \
                                -e GOARCH=amd64 \
                                golang:alpine \
                                go build -ldflags "${LDFLAGS}" -o ${BINDIR}/$CASSPEED-darwin-amd64-cli src/client
                        '''
                    }
                }
                stage('CLI Darwin ARM64') {
                    agent { label 'amd64' }
                    steps {
                        sh '''
                            docker run --rm \
                                -v ${WORKSPACE}:/build \
                                -v ${GOCACHE}:/root/.cache/go-build \
                                -v ${GOMODCACHE}:/go/pkg/mod \
                                -w /build \
                                -e CGO_ENABLED=0 \
                                -e GOOS=darwin \
                                -e GOARCH=arm64 \
                                golang:alpine \
                                go build -ldflags "${LDFLAGS}" -o ${BINDIR}/$CASSPEED-darwin-arm64-cli src/client
                        '''
                    }
                }
                stage('CLI Windows AMD64') {
                    agent { label 'amd64' }
                    steps {
                        sh '''
                            docker run --rm \
                                -v ${WORKSPACE}:/build \
                                -v ${GOCACHE}:/root/.cache/go-build \
                                -v ${GOMODCACHE}:/go/pkg/mod \
                                -w /build \
                                -e CGO_ENABLED=0 \
                                -e GOOS=windows \
                                -e GOARCH=amd64 \
                                golang:alpine \
                                go build -ldflags "${LDFLAGS}" -o ${BINDIR}/$CASSPEED-windows-amd64-cli.exe src/client
                        '''
                    }
                }
                stage('CLI Windows ARM64') {
                    agent { label 'amd64' }
                    steps {
                        sh '''
                            docker run --rm \
                                -v ${WORKSPACE}:/build \
                                -v ${GOCACHE}:/root/.cache/go-build \
                                -v ${GOMODCACHE}:/go/pkg/mod \
                                -w /build \
                                -e CGO_ENABLED=0 \
                                -e GOOS=windows \
                                -e GOARCH=arm64 \
                                golang:alpine \
                                go build -ldflags "${LDFLAGS}" -o ${BINDIR}/$CASSPEED-windows-arm64-cli.exe src/client
                        '''
                    }
                }
                stage('CLI FreeBSD AMD64') {
                    agent { label 'amd64' }
                    steps {
                        sh '''
                            docker run --rm \
                                -v ${WORKSPACE}:/build \
                                -v ${GOCACHE}:/root/.cache/go-build \
                                -v ${GOMODCACHE}:/go/pkg/mod \
                                -w /build \
                                -e CGO_ENABLED=0 \
                                -e GOOS=freebsd \
                                -e GOARCH=amd64 \
                                golang:alpine \
                                go build -ldflags "${LDFLAGS}" -o ${BINDIR}/$CASSPEED-freebsd-amd64-cli src/client
                        '''
                    }
                }
                stage('CLI FreeBSD ARM64') {
                    agent { label 'amd64' }
                    steps {
                        sh '''
                            docker run --rm \
                                -v ${WORKSPACE}:/build \
                                -v ${GOCACHE}:/root/.cache/go-build \
                                -v ${GOMODCACHE}:/go/pkg/mod \
                                -w /build \
                                -e CGO_ENABLED=0 \
                                -e GOOS=freebsd \
                                -e GOARCH=arm64 \
                                golang:alpine \
                                go build -ldflags "${LDFLAGS}" -o ${BINDIR}/$CASSPEED-freebsd-arm64-cli src/client
                        '''
                    }
                }
            }
        }

        stage('Test') {
            agent { label 'amd64' }
            steps {
                sh '''
                    docker run --rm \
                        -v ${WORKSPACE}:/build \
                        -v ${GOCACHE}:/root/.cache/go-build \
                        -v ${GOMODCACHE}:/go/pkg/mod \
                        -w /build \
                        golang:alpine \
                        go test -v -cover ./...
                '''
            }
        }

        // Stable Release - matches release.yml (tag push only)
        stage('Release: Stable') {
            agent { label 'amd64' }
            when {
                expression { env.BUILD_TYPE == 'release' }
            }
            steps {
                sh '''
                    echo "${VERSION}" > ${RELDIR}/version.txt

                    for f in ${BINDIR}/$CASSPEED-*; do
                        [ -f "$f" ] || continue
                        cp "$f" ${RELDIR}/
                    done

                    tar --exclude='.git' --exclude='.github' --exclude='.gitea' \
                        --exclude='.forgejo' --exclude='binaries' --exclude='releases' \
                        --exclude='*.tar.gz' \
                        -czf ${RELDIR}/$CASSPEED-${VERSION}-source.tar.gz .
                '''
                archiveArtifacts artifacts: 'releases/*', fingerprint: true
            }
        }

        // Beta Release - matches beta.yml (beta branch only)
        stage('Release: Beta') {
            agent { label 'amd64' }
            when {
                expression { env.BUILD_TYPE == 'beta' }
            }
            steps {
                sh '''
                    echo "${VERSION}" > ${RELDIR}/version.txt

                    for f in ${BINDIR}/$CASSPEED-*; do
                        [ -f "$f" ] || continue
                        cp "$f" ${RELDIR}/
                    done
                '''
                archiveArtifacts artifacts: 'releases/*', fingerprint: true
            }
        }

        // Daily Release - matches daily.yml (main/master + scheduled)
        stage('Release: Daily') {
            agent { label 'amd64' }
            when {
                expression { env.BUILD_TYPE == 'daily' }
            }
            steps {
                sh '''
                    echo "${VERSION}" > ${RELDIR}/version.txt

                    for f in ${BINDIR}/$CASSPEED-*; do
                        [ -f "$f" ] || continue
                        cp "$f" ${RELDIR}/
                    done
                '''
                archiveArtifacts artifacts: 'releases/*', fingerprint: true
            }
        }

        // Docker - matches docker.yml (ALL branches and tags)
        stage('Docker') {
            agent { label 'amd64' }
            steps {
                script {
                    def tags = "-t ${REGISTRY}:${COMMIT_ID}"

                    if (env.BUILD_TYPE == 'release') {
                        // Release tag - version, latest, YYMM
                        def yymm = new Date().format('yyMM')
                        tags += " -t ${REGISTRY}:${VERSION}"
                        tags += " -t ${REGISTRY}:latest"
                        tags += " -t ${REGISTRY}:${yymm}"
                    } else if (env.BUILD_TYPE == 'beta') {
                        // Beta branch - beta, devel
                        tags += " -t ${REGISTRY}:beta"
                        tags += " -t ${REGISTRY}:devel"
                    } else {
                        // All other branches - devel only
                        tags += " -t ${REGISTRY}:devel"
                    }

                    // Login to container registry
                    // Works with: ghcr.io, registry.gitlab.com, gitea/forgejo, docker.io
                    sh """
                        echo "\${GIT_TOKEN}" | docker login ${REGISTRY.split('/')[0]} -u ${PROJECTORG} --password-stdin
                    """

                    // Build multi-arch with OCI labels and manifest annotations
                    sh """
                        docker buildx create --name $CASSPEED-builder --use 2>/dev/null || docker buildx use $CASSPEED-builder
                        docker buildx build \
                            -f docker/Dockerfile \
                            --platform linux/amd64,linux/arm64 \
                            --build-arg VERSION="${VERSION}" \
                            --build-arg COMMIT_ID="${COMMIT_ID}" \
                            --build-arg BUILD_DATE="${BUILD_DATE}" \
                            --label "org.opencontainers.image.vendor=${PROJECTORG}" \
                            --label "org.opencontainers.image.authors=${PROJECTORG}" \
                            --label "org.opencontainers.image.title=$CASSPEED" \
                            --label "org.opencontainers.image.base.name=$CASSPEED" \
                            --label "org.opencontainers.image.description=Containerized version of $CASSPEED" \
                            --label "org.opencontainers.image.licenses=MIT" \
                            --label "org.opencontainers.image.version=${VERSION}" \
                            --label "org.opencontainers.image.created=${BUILD_DATE}" \
                            --label "org.opencontainers.image.revision=${COMMIT_ID}" \
                            --label "org.opencontainers.image.url=https://${GIT_FQDN}/${PROJECTORG}/$CASSPEED" \
                            --label "org.opencontainers.image.source=https://${GIT_FQDN}/${PROJECTORG}/$CASSPEED" \
                            --label "org.opencontainers.image.documentation=https://${GIT_FQDN}/${PROJECTORG}/$CASSPEED" \
                            --annotation "manifest:org.opencontainers.image.vendor=${PROJECTORG}" \
                            --annotation "manifest:org.opencontainers.image.authors=${PROJECTORG}" \
                            --annotation "manifest:org.opencontainers.image.title=$CASSPEED" \
                            --annotation "manifest:org.opencontainers.image.description=Containerized version of $CASSPEED" \
                            --annotation "manifest:org.opencontainers.image.licenses=MIT" \
                            --annotation "manifest:org.opencontainers.image.version=${VERSION}" \
                            --annotation "manifest:org.opencontainers.image.created=${BUILD_DATE}" \
                            --annotation "manifest:org.opencontainers.image.revision=${COMMIT_ID}" \
                            --annotation "manifest:org.opencontainers.image.url=https://${GIT_FQDN}/${PROJECTORG}/$CASSPEED" \
                            --annotation "manifest:org.opencontainers.image.source=https://${GIT_FQDN}/${PROJECTORG}/$CASSPEED" \
                            --annotation "manifest:org.opencontainers.image.documentation=https://${GIT_FQDN}/${PROJECTORG}/$CASSPEED" \
                            ${tags} \
                            --push \
                            .
                    """
                }
            }
        }
    }

    post {
        always {
            cleanWs()
        }
    }
}
```

## Jenkins Configuration

### Required Settings

| Setting | Value |
|---------|-------|
| Agent labels | `amd64` and `arm64` MUST be available |
| Docker | Required on all agents (builds use golang:alpine) |
| Docker buildx | Required on amd64 agent for multi-arch builds |
| Go caches | `/tmp/go-cache` and `/tmp/go-mod-cache` |

### Credentials Setup (Jenkins → Credentials → Add Credentials)

Create a **Secret text** credential for your git provider's API token:

| Git Provider | Credential ID | Token Source |
|--------------|---------------|--------------|
| GitHub | `github-token` | Settings → Developer settings → Personal access tokens |
| Gitea | `gitea-token` | User Settings → Applications → Access Tokens |
| Forgejo | `forgejo-token` | User Settings → Applications → Access Tokens |
| GitLab | `gitlab-token` | User Settings → Access Tokens |
| Docker Hub | `dockerhub-token` | Account Settings → Security → Access Tokens |

**Required Token Permissions:**

| Provider | Permissions |
|----------|-------------|
| GitHub | `write:packages`, `read:packages`, `delete:packages` |
| Gitea/Forgejo | `package:write` (or `write:package`) |
| GitLab | `write_registry`, `read_registry` |
| Docker Hub | Read/Write access |

### Provider Configuration

In the Jenkinsfile, uncomment the appropriate block:

```groovy
// ----- GITHUB (default) -----
GIT_FQDN = 'github.com'
GIT_TOKEN = credentials('github-token')
REGISTRY = "ghcr.io/${PROJECTORG}/$CASSPEED"

// ----- GITEA / FORGEJO (self-hosted) -----
// GIT_FQDN = 'git.example.com'
// GIT_TOKEN = credentials('gitea-token')
// REGISTRY = "${GIT_FQDN}/${PROJECTORG}/$CASSPEED"

// ----- GITLAB (gitlab.com or self-hosted) -----
// GIT_FQDN = 'gitlab.com'
// GIT_TOKEN = credentials('gitlab-token')
// REGISTRY = "registry.${GIT_FQDN}/${PROJECTORG}/$CASSPEED"
```

### Triggers Comparison

| Release Type | GitHub Actions | Jenkins |
|--------------|----------------|---------|
| Stable | `release.yml` (tag push) | `BUILD_TYPE == 'release'` (tag) |
| Beta | `beta.yml` (beta branch) | `BUILD_TYPE == 'beta'` (beta branch) |
| Daily | `daily.yml` (schedule + main) | `BUILD_TYPE == 'daily'` (cron + main/master) |
| Docker | `docker.yml` (all branches) | Docker stage (always runs) |

---

# CHECKPOINT 5: BUILD & DEPLOYMENT VERIFICATION

Before proceeding, confirm you understand:
- [ ] Docker uses tini as init, Alpine base
- [ ] Makefile has exactly 4 targets: build, release, docker, test
- [ ] Binary naming: NEVER include -musl suffix
- [ ] All 8 platform builds required (4 OS x 2 arch)
- [ ] CLI builds (if src/client/ exists): 8 additional binaries with `-cli` suffix

**CI/CD Equivalence:**

| Feature | GitHub Actions | Gitea/Forgejo | GitLab CI | Jenkins |
|---------|----------------|---------------|-----------|---------|
| Stable release | `release.yml` | `release.yml` | `rules: tag` | `BUILD_TYPE == 'release'` |
| Beta release | `beta.yml` | `beta.yml` | `rules: beta` | `BUILD_TYPE == 'beta'` |
| Daily release | `daily.yml` | `daily.yml` | `rules: schedule` | `BUILD_TYPE == 'daily'` |
| Docker images | `docker.yml` | `docker.yml` | `docker:build` | Docker stage |
| Self-hosted | No | Yes | Yes | Yes |

---

# PART 16: HEALTH & VERSIONING (NON-NEGOTIABLE)

## Health Checks

### /healthz (HTML)

- Status (healthy/unhealthy)
- Uptime
- Version
- Mode
- Node ID (cluster mode)
- Cluster status (if clustered)
- System resources (optional)

### /api/v1/healthz (JSON)

```json
{
  "status": "healthy",
  "version": "1.0.0",
  "mode": "production",
  "uptime": "2d 5h 30m",
  "timestamp": "2024-01-15T10:30:00Z",
  "node": {
    "id": "node-abc123",
    "hostname": "server-1.example.com"
  },
  "cluster": {
    "enabled": true,
    "status": "connected",
    "nodes": 3,
    "role": "member"
  },
  "checks": {
    "database": "ok",
    "cache": "ok",
    "disk": "ok",
    "cluster": "ok"
  }
}
```

### Single Instance Response

When not in cluster mode:

```json
{
  "status": "healthy",
  "version": "1.0.0",
  "mode": "production",
  "uptime": "2d 5h 30m",
  "timestamp": "2024-01-15T10:30:00Z",
  "node": {
    "id": "standalone",
    "hostname": "server.example.com"
  },
  "cluster": {
    "enabled": false
  },
  "checks": {
    "database": "ok",
    "cache": "ok",
    "disk": "ok"
  }
}
```

### Cluster Health Fields

| Field | Description |
|-------|-------------|
| `node.id` | Unique identifier for this node |
| `node.hostname` | Node hostname |
| `cluster.enabled` | Whether cluster mode is active |
| `cluster.status` | connected, degraded, disconnected |
| `cluster.nodes` | Number of nodes in cluster |
| `cluster.role` | member (all nodes are equal) |
| `checks.cluster` | ok, degraded, error |

## Versioning

### Semantic Versioning (SemVer) Rules

**ALL stable releases MUST follow semantic versioning:**

| Component | When to Increment | Example |
|-----------|-------------------|---------|
| **MAJOR** | Breaking API changes, incompatible config changes, database schema changes requiring migration | `1.0.0` → `2.0.0` |
| **MINOR** | New features (backward compatible), new config options, new API endpoints | `1.0.0` → `1.1.0` |
| **PATCH** | Bug fixes, security patches, documentation updates (no new features) | `1.0.0` → `1.0.1` |

**Version Rules:**
- Start at `1.0.0` for first stable release (NOT `0.x.x`)
- Never reuse version numbers
- Pre-release versions use suffix: `1.0.0-rc1`, `1.0.0-alpha`
- No leading zeros: `1.0.1` (NOT `1.0.01`)
- No `v` prefix in version string: `1.0.0` (NOT `v1.0.0`)
- Git tags add `v` prefix: `v1.0.0`

### Format

- Stable: Semantic versioning `MAJOR.MINOR.PATCH` (e.g., `1.0.0`)
- Beta: `YYYYMMDDHHMMSS-beta` (e.g., `20251205143022-beta`)
- Daily: `YYYYMMDDHHMMSS` (e.g., `20251218060432`)

### Sources (Priority Order)

1. `release.txt` in project root
2. Git tag (if available)
3. Fallback: `dev`

### --version Output

```
casspeed v1.0.0
Built: 2024-01-15T10:30:00Z
Go: 1.23
OS/Arch: linux/amd64
```

---


# PART 17: WEB FRONTEND (NON-NEGOTIABLE)

## Requirements

**ALL PROJECTS MUST HAVE A PROFESSIONAL, WELL-DESIGNED FRONTEND BUILT IN.**

| Requirement | Description |
|-------------|-------------|
| **Professional UI/UX** | Clean, modern, polished design |
| **Mobile Support** | Full responsive design with touch-friendly targets |
| **HTML5** | Full web standards compliance |
| **Accessibility** | WCAG 2.1 AA compliant, screen reader friendly |
| **UX** | Readable, navigable, intuitive, user-friendly, self-explanatory |
| **PWA Support** | Progressive Web App - installable, offline-capable |
| **CORS** | `Access-Control-Allow-Origin: *` for API endpoints |

## Smart Content Detection (NON-NEGOTIABLE)

**Frontend routes (`/**`) MUST automatically detect request type and respond appropriately.**

### Detection Logic (MUST Support Full CRUD)

**ALL frontend routes with CRUD operations MUST work in BOTH modes:**

```go
func detectClientType(r *http.Request) string {
    // 1. Check Accept header first (explicit preference)
    accept := r.Header.Get("Accept")

    if strings.Contains(accept, "text/html") {
        return "html"
    }
    if strings.Contains(accept, "text/plain") {
        return "text"
    }
    if strings.Contains(accept, "application/json") {
        return "json" // Rare for frontend, but support it
    }

    // 2. Check User-Agent for browser detection
    ua := r.Header.Get("User-Agent")

    // Browser User-Agents (common patterns)
    browsers := []string{
        "Mozilla/", "Chrome/", "Safari/", "Edge/", "Firefox/",
        "Opera/", "MSIE", "Trident/",
    }

    for _, browser := range browsers {
        if strings.Contains(ua, browser) {
            return "html"
        }
    }

    // 3. CLI tools (curl, wget, httpie, etc.)
    cliTools := []string{
        "curl/", "Wget/", "HTTPie/", "python-requests/",
        "Go-http-client/", "node-fetch/",
    }

    for _, tool := range cliTools {
        if strings.Contains(ua, tool) {
            return "text"
        }
    }

    // 4. Empty or unknown User-Agent
    if ua == "" {
        return "text" // Default to text for programmatic access
    }

    // 5. Default: HTML (safest fallback)
    return "html"
}
```

### Response by Client Type

**Frontend routes MUST respond differently based on client:**

| Route | Browser | curl/CLI | Accept: text/plain | Accept: text/html | Accept: application/json |
|-------|---------|----------|-------------------|-------------------|--------------------------|
| `/` | HTML page | Text | Text | HTML | JSON |
| `/users` | HTML list | Text list | Text list | HTML list | JSON array |
| `/users/123` | HTML profile | Text (username) | Text | HTML profile | JSON object |
| `/jokes/random` | HTML joke page | Just the joke | Just the joke | HTML page | JSON object |

### CRUD Operations MUST Work in All Modes

**ALL CRUD operations must be accessible via:**

1. **HTML Forms** (browser users):
   ```html
   <form action="/users" method="POST">...</form>
   <form action="/users/123" method="POST">
     <input type="hidden" name="_method" value="PUT">
   </form>
   ```

2. **API Endpoints** (programmatic):
   ```bash
   curl -X POST /api/v1/users -d '{"username":"test"}'
   curl -X PUT /api/v1/users/123 -d '{"email":"new@test.com"}'
   curl -X DELETE /api/v1/users/123
   ```

3. **Frontend Direct** (CLI/scripting):
   ```bash
   curl -X POST /users -d 'username=test'  # Form-encoded
   curl /users/123  # Returns text (auto-detected)
   ```

**Rule:** CRUD must work for browsers (HTML forms), APIs (JSON), and CLI (text/form-encoded).

### Frontend Testing Best Practice

**For automated testing, use text responses (much simpler than HTML parsing):**

```bash
# Easy: Test text output (no HTML parsing needed)
curl /users/123                           # Auto-detects CLI, returns text
curl -H "Accept: text/plain" /users/123  # Explicitly request text

# Hard: Testing HTML requires parsing
curl -H "Accept: text/html" /users/123 | grep "<title>"  # Fragile
```

**Recommended testing approach:**
- ✓ Use Accept: text/plain for frontend route testing
- ✓ Or rely on CLI auto-detection (curl returns text automatically)
- ✓ Verify text output contains expected data
- ✗ Avoid parsing HTML in test scripts (complex and fragile)

**Test scripts should:**
```bash
# Test frontend returns text for CLI
RESULT=$(curl -s http://localhost:80/users/123)
if echo "$RESULT" | grep -q "testuser"; then
    echo "✓ Frontend returns user data"
else
    echo "✗ FAILED: User data not returned"
fi

# Test frontend returns HTML for browser (optional, just check Content-Type)
CONTENT_TYPE=$(curl -s -H "Accept: text/html" -I http://localhost:80/users/123 | grep -i "content-type")
if echo "$CONTENT_TYPE" | grep -q "text/html"; then
    echo "✓ Frontend serves HTML to browsers"
fi
```

## Responsive Layout (NON-NEGOTIABLE)

**Content width adapts based on screen size:**

| Screen Width | Content Width | Margins | Device Category |
|--------------|---------------|---------|-----------------|
| ≥720px | 90% | 5% left, 5% right | Desktop/Tablet |
| <720px | 98% | 1% left, 1% right | Mobile |

```css
/* Responsive container */
.container {
  width: 98%;
  margin: 0 auto;
  max-width: 1400px;
}

@media (min-width: 720px) {
  .container {
    width: 90%;
  }
}
```

**Responsive Behavior by Element:**

| Element | <720px (Mobile) | ≥720px (Desktop) |
|---------|-----------------|------------------|
| **Admin Sidebar** | Hidden, hamburger menu toggle | Visible, collapsible |
| **Public Nav** | Hamburger menu | Horizontal links |
| **Tables** | Horizontal scroll or card layout | Full table |
| **Modals** | Full-width (98%) | Centered, max-width 600px |
| **Forms** | Single column, full-width inputs | Multi-column where appropriate |
| **Touch Targets** | Minimum 44x44px | Standard sizing |
| **Font Size** | Base 16px minimum | Base 16px |

**Footer Behavior:**
- Footer is ALWAYS at the bottom of the page content
- Footer scrolls with content (NOT fixed/sticky)
- Uses flexbox or grid to push footer down on short pages
- ALWAYS horizontally centered

```css
/* Footer always at bottom */
body {
  display: flex;
  flex-direction: column;
  min-height: 100vh;
}

main {
  flex: 1;
}

footer {
  text-align: center;
}
```

## Technology Stack (NON-NEGOTIABLE)

| Rule | Description | Details |
|------|-------------|---------|
| **Go Templates** | ALL HTML uses Go `html/template` | See Template Rules below |
| **Pure Vanilla JS** | NO frameworks | See JavaScript Rules below |
| **CSS-First** | Prefer CSS over JS | See CSS Rules below |
| **NO JS Alerts** | Use custom modals/toasts | See UI Components below |
| **NO Inline CSS/JS** | External files only | See CSS/JS Rules below |

## UI Components (NON-NEGOTIABLE)

### Buttons

| Type | Use For | Style |
|------|---------|-------|
| Primary | Main actions (Save, Submit, Create) | Filled, brand color |
| Secondary | Alternative actions (Cancel, Back) | Outlined or muted |
| Danger | Destructive actions (Delete, Remove) | Red, requires confirmation |
| Icon | Compact actions (Edit, Copy, Refresh) | Icon only with tooltip |

**Button States:** Normal, Hover, Active, Disabled, Loading

### Toggle Switches

**CSS-only toggle using hidden checkbox:**

```html
<label class="toggle">
  <input type="checkbox" name="setting">
  <span class="slider"></span>
  Enable Feature
</label>
```

### Modals

**Modal Behavior (NON-NEGOTIABLE):**

| Action | Modal Behavior |
|--------|----------------|
| Success (Save, Submit, Create) | Close automatically after success |
| Error | Stay open, display error message |
| Cancel button clicked | Close immediately |
| Escape key pressed | Close immediately |
| Backdrop clicked | Close immediately |
| Form with unsaved changes | Warn before closing |

**Modal Features:**
- Focus trap (Tab stays within modal)
- Escape key closes modal
- Backdrop click closes modal
- Body scroll locked while open
- Centered vertically and horizontally
- Responsive (full-width on mobile)

**Accessibility (NON-NEGOTIABLE):**

| Requirement | Implementation |
|-------------|----------------|
| **Focus trap** | Tab/Shift+Tab cycles through modal elements only |
| **Initial focus** | First focusable element OR primary action button |
| **Return focus** | Restore focus to trigger element on close |
| **ARIA attributes** | `role="dialog"`, `aria-modal="true"`, `aria-labelledby` |
| **Escape key** | Close modal (unless confirmation required) |
| **Screen reader** | Announce modal title on open |

```html
<!-- Modal structure using native <dialog> -->
<dialog id="confirm-modal" aria-labelledby="modal-title">
  <header>
    <h2 id="modal-title">Modal Title</h2>
    <button type="button" aria-label="Close" onclick="this.closest('dialog').close()">✕</button>
  </header>
  <main>Modal content here</main>
  <footer>
    <button type="button" onclick="this.closest('dialog').close()">Cancel</button>
    <button type="submit" autofocus>Confirm</button>
  </footer>
</dialog>
```

**Note:** Native `<dialog>` element handles focus trap and backdrop automatically. Use `showModal()` to open with backdrop, `close()` to close.

### Toast Notifications

**In-app notifications for immediate feedback:**

| Type | Use For | Auto-dismiss |
|------|---------|--------------|
| Success | Action completed | 3 seconds |
| Error | Action failed | Manual dismiss only |
| Warning | Caution needed | 5 seconds |
| Info | General information | 3 seconds |

**Position:** Top-right corner, stacked vertically

### Notification Bell

**Built-in notification center accessible via bell icon in header:**

- Bell icon with unread count badge
- Click opens notification dropdown/panel
- Mark as read on view
- "Mark all as read" action
- Links to full notification center
- See PART 25: EMAIL & NOTIFICATIONS for full specification

## Accessibility (NON-NEGOTIABLE)

**WCAG 2.1 AA Compliance Required:**

| Requirement | Implementation |
|-------------|----------------|
| **Keyboard Navigation** | All interactive elements focusable and operable via keyboard |
| **Focus Indicators** | Visible focus ring on all focusable elements |
| **ARIA Labels** | Proper `aria-label`, `aria-describedby`, `role` attributes |
| **Color Contrast** | Minimum 4.5:1 for normal text, 3:1 for large text |
| **Alt Text** | All images have descriptive `alt` attributes |
| **Form Labels** | All inputs have associated `<label>` elements |
| **Error Messages** | Announced to screen readers via `aria-live` |
| **Skip Links** | "Skip to content" link for keyboard users |
| **Semantic HTML** | Proper heading hierarchy (h1 → h2 → h3) |
| **Reduced Motion** | Respect `prefers-reduced-motion` preference |

```css
/* Respect reduced motion preference */
@media (prefers-reduced-motion: reduce) {
  *, *::before, *::after {
    animation-duration: 0.01ms !important;
    transition-duration: 0.01ms !important;
  }
}
```

## PWA Support (NON-NEGOTIABLE)

**Progressive Web App features:**

| Feature | Implementation |
|---------|----------------|
| **Manifest** | `/manifest.json` with app metadata |
| **Icons** | Multiple sizes (192x192, 512x512 minimum) |
| **Service Worker** | Cache static assets for offline use |
| **Installable** | Meets PWA install criteria |
| **HTTPS** | Required for service workers |

**Offline Behavior:**

| Resource Type | Cache Strategy | Offline Behavior |
|---------------|----------------|------------------|
| **Static assets** (CSS, JS, images) | Cache-first | Served from cache |
| **HTML pages** | Network-first, cache fallback | Show cached version if offline |
| **API calls** | Network-only | Show offline indicator, queue for retry |
| **Fonts** | Cache-first | Served from cache |

**Service Worker Caching:**
- Cache static assets on install
- Update cache on service worker activation
- Maximum cache size: 50MB
- Cache expiration: 7 days for static assets
- Never cache: API responses, user-specific data

**Offline Indicator:**
- Show banner/toast when offline: "You are offline. Some features may be unavailable."
- Hide automatically when connection restored
- Do not block UI - allow browsing cached pages

**manifest.json:**
```json
{
  "name": "{App Name}",
  "short_name": "{AppName}",
  "description": "{App description}",
  "start_url": "/",
  "display": "standalone",
  "background_color": "#ffffff",
  "theme_color": "#000000",
  "icons": [
    { "src": "/static/icons/icon-192.png", "sizes": "192x192", "type": "image/png" },
    { "src": "/static/icons/icon-512.png", "sizes": "512x512", "type": "image/png" }
  ]
}
```

**HTML head:**
```html
<link rel="manifest" href="/manifest.json">
<meta name="theme-color" content="#000000">
<link rel="apple-touch-icon" href="/static/icons/icon-192.png">
```

## HTTP Status Codes (NON-NEGOTIABLE)

**Use standard HTTP status codes consistently:**

| Code | Meaning | Use For |
|------|---------|---------|
| 200 | OK | Successful GET, PUT, PATCH |
| 201 | Created | Successful POST creating resource |
| 204 | No Content | Successful DELETE |
| 301 | Moved Permanently | Permanent redirects |
| 302 | Found | Temporary redirects |
| 400 | Bad Request | Invalid input, validation errors |
| 401 | Unauthorized | Not authenticated |
| 403 | Forbidden | Authenticated but not authorized |
| 404 | Not Found | Resource doesn't exist |
| 405 | Method Not Allowed | Wrong HTTP method |
| 409 | Conflict | Duplicate resource, version conflict |
| 422 | Unprocessable Entity | Semantic validation errors |
| 429 | Too Many Requests | Rate limit exceeded |
| 500 | Internal Server Error | Server-side errors |
| 503 | Service Unavailable | Maintenance mode |

## CORS Configuration (NON-NEGOTIABLE)

**API endpoints allow cross-origin requests:**

```go
// CORS headers for API endpoints
w.Header().Set("Access-Control-Allow-Origin", "*")
w.Header().Set("Access-Control-Allow-Methods", "GET, POST, PUT, PATCH, DELETE, OPTIONS")
w.Header().Set("Access-Control-Allow-Headers", "Content-Type, Authorization, X-API-Token")
w.Header().Set("Access-Control-Max-Age", "86400")
```

### HTML5 & CSS Over JavaScript (NON-NEGOTIABLE)

**Minimize JavaScript - prefer HTML5 and CSS solutions whenever possible.**

| Use Case | Use HTML5/CSS | Use JavaScript Only When |
|----------|---------------|--------------------------|
| Form validation | HTML5 `required`, `pattern`, `min`, `max`, `type="email"` | Complex cross-field validation |
| Collapsible sections | `<details>/<summary>` | Need animation or programmatic control |
| Tabs | CSS `:target` or radio button hack | Need deep linking or state management |
| Tooltips | CSS `::after` with `data-tooltip` | Need dynamic positioning |
| Modals | CSS `:target` selector | Need focus trap, escape key, backdrop click |
| Hover effects | CSS `:hover`, `:focus`, `:active` | Never - always CSS |
| Animations | CSS `@keyframes`, `transition` | Complex sequenced animations |
| Responsive design | CSS media queries | Never - always CSS |
| Toggle switches | CSS with hidden checkbox | Need state persistence |
| Dropdowns/menus | CSS `:focus-within` | Complex multi-level menus |
| Progress bars | HTML5 `<progress>` | Need dynamic updates |
| Sliders | HTML5 `<input type="range">` | Complex custom styling |
| Date pickers | HTML5 `<input type="date">` | Need custom calendar UI |
| Color pickers | HTML5 `<input type="color">` | Need swatches or advanced features |
| Accordions | `<details>/<summary>` | Need single-open behavior |

**JavaScript Guidelines:**
- **Last resort** - only when HTML5/CSS cannot achieve the functionality
- **Progressive enhancement** - features must work without JS where possible
- **No JS for styling** - unless it cannot be done in HTML5 and CSS
- **No JS for simple interactions** - hover, focus, basic toggles are CSS-only

**HTML5 Required (NON-NEGOTIABLE):**
- ALL HTML MUST be valid HTML5
- Use `<!DOCTYPE html>` declaration
- Use semantic HTML5 elements: `<header>`, `<nav>`, `<main>`, `<footer>`, `<article>`, `<section>`, `<aside>`
- Use HTML5 form elements: `<input type="email">`, `<input type="date">`, `<input type="number">`, etc.
- Use HTML5 attributes: `required`, `pattern`, `placeholder`, `autofocus`, `autocomplete`
- NO deprecated elements: `<center>`, `<font>`, `<marquee>`, `<blink>`, etc.
- NO deprecated attributes: `align`, `bgcolor`, `border`, `cellpadding`, etc.
- **Required for**: API calls, dynamic content loading, complex state, WebSockets
- **Size matters** - keep JS minimal, no large libraries for simple tasks

**Inline JavaScript - Allowed for simple operations:**
```html
<!-- Navigation -->
<button onclick="history.back()">Go Back</button>
<button onclick="history.forward()">Go Forward</button>
<button onclick="location.reload()">Refresh</button>

<!-- Print -->
<button onclick="window.print()">Print</button>

<!-- Scroll -->
<button onclick="window.scrollTo(0,0)">Back to Top</button>

<!-- Form helpers -->
<button onclick="document.getElementById('myform').reset()">Reset Form</button>
<button onclick="document.getElementById('field').select()">Select All</button>
```

**Rule:** Inline JS is fine for one-liner operations that cannot be done with CSS/HTML5.
Move to `static/js/app.js` if logic needs feedback, reuse, or exceeds one statement.
See **JavaScript Rules** section below for `app.js` structure.

**CSS-First Patterns (use these instead of JS):**

```html
<!-- Collapsible section - use <details>/<summary> NOT JS -->
<details>
  <summary>Click to expand</summary>
  <p>Hidden content revealed when clicked.</p>
</details>

<!-- Toggle menu - use checkbox hack NOT JS -->
<label for="menu-toggle" class="menu-btn">☰ Menu</label>
<input type="checkbox" id="menu-toggle" hidden>
<nav class="menu">
  <a href="/">Home</a>
  <a href="/about">About</a>
</nav>

<style>
.menu { display: none; }
#menu-toggle:checked ~ .menu { display: block; }
</style>

<!-- Dropdown - use :focus-within NOT JS -->
<div class="dropdown">
  <button>Options</button>
  <div class="dropdown-content">
    <a href="#">Option 1</a>
    <a href="#">Option 2</a>
  </div>
</div>

<style>
.dropdown-content { display: none; }
.dropdown:focus-within .dropdown-content { display: block; }
</style>
```

### Go Templates (NON-NEGOTIABLE)

**ALL frontend HTML MUST use Go's `html/template` package.**

| Location | Purpose |
|----------|---------|
| `src/server/templates/` | All `.tmpl` AI.mds |
| `src/server/templates/partials/` | Reusable template partials |
| `src/server/templates/layouts/` | Base layouts |
| `src/server/templates/pages/` | Page-specific templates |
| `src/server/static/` | Static assets (CSS, JS, images) |

**Template Structure (all files use `.tmpl` extension):**
```
src/server/templates/
├── layouts/
│   ├── public.tmpl         # Public-facing layout (/, /auth/*, /server/*)
│   └── admin.tmpl          # Admin panel layout (/admin/*)
├── partials/
│   ├── public/
│   │   ├── header.tmpl     # Public header (logo, nav, login)
│   │   ├── nav.tmpl        # Public navigation
│   │   └── footer.tmpl     # Public footer (about, privacy, etc.)
│   ├── admin/
│   │   ├── header.tmpl     # Admin header (logo, search, notifications, logout)
│   │   ├── sidebar.tmpl    # Admin sidebar navigation
│   │   └── footer.tmpl     # Admin footer (version, docs)
│   ├── head.tmpl           # <head> contents (meta, CSS)
│   └── scripts.tmpl        # JavaScript includes
├── pages/
│   ├── index.tmpl          # Home page
│   ├── healthz.tmpl        # Health check page
│   └── error.tmpl          # Error pages (404, 500, etc.)
├── auth/
│   ├── login.tmpl          # Login page
│   ├── register.tmpl       # Registration page
│   └── forgot.tmpl         # Password reset
├── admin/
│   ├── dashboard.tmpl      # Admin dashboard
│   ├── settings.tmpl       # Settings page
│   └── ...
└── components/
    ├── modal.tmpl          # Reusable modal component
    ├── toast.tmpl          # Toast notifications
    └── ...
```

## Layout Separation (NON-NEGOTIABLE)

**Public and Admin routes use DIFFERENT layouts:**

| Layout | Routes | Design Philosophy |
|--------|--------|-------------------|
| `public.tmpl` | `/`, `/auth/*`, `/server/*`, `/user/*` | Clean, marketing-friendly, top navigation |
| `admin.tmpl` | `/admin/*` | Dashboard-style, sidebar navigation, data-dense |

### Public Layout (`public.tmpl`)

**For end-users and public-facing pages:**

```
┌─────────────────────────────────────────────────────────────────┐
│  [Logo]              Home  API  Docs                [Login]     │  ← Header + Top Nav
├─────────────────────────────────────────────────────────────────┤
│                                                                 │
│                                                                 │
│                         <main>                                  │  ← Page content
│                     (centered, clean)                           │
│                                                                 │
│                                                                 │
├─────────────────────────────────────────────────────────────────┤
│        About · Privacy · Contact · GitHub · v1.0.0              │  ← Footer (centered)
└─────────────────────────────────────────────────────────────────┘
```

**Public Layout Characteristics:**
- Top horizontal navigation bar
- Clean, minimal design with whitespace
- Centered content area
- Marketing/product-focused styling
- Simple footer with links

**Public Navigation Rules (NON-NEGOTIABLE):**

| Rule | Description |
|------|-------------|
| **App-focused** | Navigation reflects the application's features and purpose |
| **NO admin links** | NEVER link to `/admin` from public pages |
| **NO admin hints** | Do not advertise that an admin panel exists |
| **Direct access only** | Admin panel accessed by navigating directly to `{fqdn}/admin` |

**Public nav contains (project-specific):**
- Home (`/`)
- App-specific feature pages (e.g., API docs, features, pricing)
- Login/Register (if multi-user) or just Login link
- User menu (if logged in): Profile, Settings, Logout

**Public nav NEVER contains:**
- ❌ Admin link
- ❌ Dashboard link (unless user dashboard)
- ❌ Settings link to admin settings
- ❌ Any hint of `/admin/*` routes

### Admin Layout (`admin.tmpl`)

**For server administrators:**

```
┌─────────────────────────────────────────────────────────────────┐
│  [Logo]        [Search...]              [🔔] [Admin ▼] [Logout] │  ← Header
├──────────────┬──────────────────────────────────────────────────┤
│              │                                                  │
│  Dashboard   │                                                  │
│              │                                                  │
│  📦 Server   │              <main>                              │
│  🔒 Security │          (content area)                          │
│  🌐 Network  │                                                  │
│  👥 Users    │                                                  │
│  🔗 Cluster  │                                                  │
│              │                                                  │
│  Sidebar     │                                                  │
├──────────────┴──────────────────────────────────────────────────┤
│                    v1.0.0 · Docs · Status                       │  ← Footer
└─────────────────────────────────────────────────────────────────┘
```

**Admin Layout Characteristics:**
- Collapsible sidebar navigation (left)
- Header with search, notifications bell, admin menu
- Data-dense, dashboard-style design
- Compact footer with version and links
- Breadcrumbs for navigation context

### Layout Partials

| Partial | Public | Admin | Purpose |
|---------|:------:|:-----:|---------|
| `partials/public/header.tmpl` | ✓ | | Logo + top nav + login/user menu |
| `partials/public/nav.tmpl` | ✓ | | Horizontal navigation links |
| `partials/public/footer.tmpl` | ✓ | | About, Privacy, Contact links |
| `partials/admin/header.tmpl` | | ✓ | Logo + search + bell + admin menu |
| `partials/admin/sidebar.tmpl` | | ✓ | Collapsible sidebar navigation |
| `partials/admin/footer.tmpl` | | ✓ | Version, docs, status |
| `partials/head.tmpl` | ✓ | ✓ | Shared `<head>` contents |
| `partials/scripts.tmpl` | ✓ | ✓ | Shared JavaScript includes |

### Static Assets Organization (NON-NEGOTIABLE)

```
src/server/static/
├── css/
│   ├── common.css      # Reset, variables, utilities (loaded first)
│   ├── public.css      # Public layout styles
│   ├── admin.css       # Admin layout styles
│   └── components.css  # Shared components (modals, buttons, toasts)
├── js/
│   └── app.js          # ALL JavaScript in ONE file (minimal)
├── images/
│   ├── logo.svg        # App logo (SVG preferred)
│   ├── favicon.ico     # Favicon
│   └── icons/          # UI icons (SVG preferred)
└── fonts/              # Self-hosted fonts (if any)
```

### CSS Rules (NON-NEGOTIABLE)

| Rule | Description |
|------|-------------|
| **One file per context** | `common.css`, `public.css`, `admin.css`, `components.css` |
| **Load order matters** | common → components → public/admin |
| **CSS variables** | Define in `common.css` `:root {}` for theming |
| **NO inline styles** | All styles in CSS files, never in HTML |
| **NO `!important`** | Exception: print styles only |
| **BEM-like naming** | `.component`, `.component-element`, `.component--modifier` |
| **Mobile-first** | Base styles for mobile, `@media (min-width)` for larger |

**CSS Variables (common.css):**
```css
:root {
  /* Colors */
  --primary-color: #007bff;
  --success-color: #28a745;
  --warning-color: #ffc107;
  --danger-color: #dc3545;
  --bg-color: #ffffff;
  --text-color: #212529;

  /* Typography */
  --font-family: system-ui, -apple-system, sans-serif;
  --font-size-base: 1rem;

  /* Spacing */
  --spacing-xs: 0.25rem;
  --spacing-sm: 0.5rem;
  --spacing-md: 1rem;
  --spacing-lg: 2rem;

  /* Borders */
  --border-radius: 0.25rem;
  --border-color: #dee2e6;
}
```

### JavaScript Rules (NON-NEGOTIABLE)

| Rule | Description |
|------|-------------|
| **ONE file only** | All JS in `static/js/app.js` - no multiple files |
| **Minimal JS** | CSS-first, JS only when absolutely necessary |
| **No frameworks** | No React, Vue, Alpine, jQuery, etc. |
| **No bundlers** | No webpack, vite, rollup - plain JS only |
| **No transpilers** | No TypeScript, Babel - browser-native JS only |
| **No npm/node** | No package.json for frontend |

**app.js Structure:**
```js
// static/js/app.js - Keep this file SMALL

// ============================================================================
// Clipboard (with feedback)
// ============================================================================
function copyToClipboard(text, btn) {
  navigator.clipboard.writeText(text).then(() => {
    const original = btn.textContent;
    btn.textContent = 'Copied!';
    btn.classList.add('copied');
    setTimeout(() => {
      btn.textContent = original;
      btn.classList.remove('copied');
    }, 2000);
  });
}

// ============================================================================
// Toast notifications
// ============================================================================
function showToast(message, type = 'info', duration = 3000) {
  const toast = document.createElement('div');
  toast.className = `toast toast-${type}`;
  toast.textContent = message;
  document.body.appendChild(toast);

  setTimeout(() => toast.remove(), duration);
}

// ============================================================================
// Modal helpers (for native <dialog>)
// ============================================================================
function openModal(id) {
  document.getElementById(id).showModal();
}

function closeModal(id) {
  document.getElementById(id).close();
}

// ============================================================================
// Form helpers
// ============================================================================
function confirmDelete(form, message = 'Are you sure?') {
  if (confirm(message)) {
    form.submit();
  }
}
```

**What goes in app.js:**
- Clipboard with feedback
- Toast notifications
- Modal helpers
- Form validation (complex only)
- Dynamic content loading (AJAX)
- WebSocket connections

**What stays inline (simple one-liners):**
- `onclick="history.back()"`
- `onclick="window.print()"`
- `onclick="this.closest('dialog').close()"`

### Template Rules (NON-NEGOTIABLE)

| Rule | Description |
|------|-------------|
| **Go templates only** | `html/template` package, `.tmpl` extension |
| **Layouts for structure** | `layouts/public.tmpl`, `layouts/admin.tmpl` |
| **Partials for reuse** | Header, nav, footer, components |
| **Pages for content** | One `.tmpl` per page/route |
| **No logic in templates** | Minimal `{{if}}`, `{{range}}` - logic in handlers |

**Template Inheritance:**
```
layouts/public.tmpl
  └── includes partials/head.tmpl
  └── includes partials/public/header.tmpl
  └── includes partials/public/nav.tmpl
  └── yields to page content
  └── includes partials/public/footer.tmpl
  └── includes partials/scripts.tmpl
```

### Partials Rules (NON-NEGOTIABLE)

| Rule | Description |
|------|-------------|
| **Shared partials** | `partials/head.tmpl`, `partials/scripts.tmpl` |
| **Context partials** | `partials/public/*`, `partials/admin/*` |
| **Component partials** | Reusable UI: `partials/toast.tmpl`, `partials/modal.tmpl` |
| **No page-specific partials** | If used once, it's not a partial |
| **Self-contained** | Partials include their own styles/scripts if needed |

**Mandatory Partials:**
```
partials/
├── head.tmpl           # <head> - meta, CSS links (REQUIRED)
├── scripts.tmpl        # JS includes before </body> (REQUIRED)
├── public/
│   ├── header.tmpl     # Public header (REQUIRED)
│   ├── nav.tmpl        # Public nav (REQUIRED)
│   └── footer.tmpl     # Public footer (REQUIRED)
└── admin/
    ├── header.tmpl     # Admin header (REQUIRED)
    ├── sidebar.tmpl    # Admin sidebar (REQUIRED)
    └── footer.tmpl     # Admin footer (REQUIRED)
```

**Optional Component Partials:**
```
partials/
├── toast.tmpl          # Toast notification container
├── modal.tmpl          # Reusable modal structure
├── pagination.tmpl     # Pagination controls
├── search.tmpl         # Search form
└── {project}/          # Project-specific partials
    └── *.tmpl
```

**Page Structure - Public:**

```
┌─────────────────────────────────────────┐
│              <header>                   │  ← public/header.tmpl
├─────────────────────────────────────────┤
│               <nav>                     │  ← public/nav.tmpl (TOP)
├─────────────────────────────────────────┤
│                                         │
│              <main>                     │  ← Page content
│                                         │
├─────────────────────────────────────────┤
│              <footer>                   │  ← public/footer.tmpl (BOTTOM)
└─────────────────────────────────────────┘
```

**Page Structure - Admin:**

```
┌─────────────────────────────────────────┐
│              <header>                   │  ← admin/header.tmpl
├──────────┬──────────────────────────────┤
│          │                              │
│  <aside> │         <main>               │  ← admin/sidebar.tmpl + content
│          │                              │
├──────────┴──────────────────────────────┤
│              <footer>                   │  ← admin/footer.tmpl
└─────────────────────────────────────────┘
```

**Nav vs Footer (NON-NEGOTIABLE):**

| Element | Position | Purpose | Contents |
|---------|----------|---------|----------|
| `<nav>` | TOP | Navigation | Links to app sections, user menu |
| `<footer>` | BOTTOM | Information | About, Privacy, Contact, Help, GitHub, version |

**Nav contains (app navigation):**
- Home link
- App-specific sections (project-defined)
- User menu (right side):
  - If logged in: Username dropdown → Profile, Settings, Logout
  - If logged out: Login link

**Nav does NOT contain:**
- API link (users access via /openapi if needed)
- Admin link (don't advertise - admins know where it is)
- Help link (belongs in footer)

**Default Navigation (nav.tmpl):**

```
Desktop:
┌─────────────────────────────────────────────────────────────────┐
│  casspeed                                      [User Icon] │  ← Header
├─────────────────────────────────────────────────────────────────┤
│  Home  |  [App Section 1]  |  [App Section 2]  |  ...           │  ← Nav
└─────────────────────────────────────────────────────────────────┘

Mobile:
┌─────────────────────────────────────────────────────────────────┐
│  casspeed                                      [User Icon] │  ← Header
├─────────────────────────────────────────────────────────────────┤
│                                                      [☰ Menu]   │  ← Nav row
└─────────────────────────────────────────────────────────────────┘
                                              ┌───────────────────┐
                                              │  Home             │
                                              │  App Section 1    │  ← Slide-in
                                              │  App Section 2    │     from right
                                              │  ...              │
                                              └───────────────────┘
```

```html
<!-- Header bar: site name + user icon -->
<header class="header">
  <a href="/" class="site-brand">casspeed</a>

  <!-- User icon (always visible, far right) -->
  <div class="user-menu">
    {{ if .User }}
      <!-- Logged in: user icon dropdown -->
      <div class="dropdown">
        <button class="dropdown-toggle user-icon" aria-label="User menu">
          <svg>...</svg>
        </button>
        <div class="dropdown-menu">
          <span class="dropdown-header">{{ .User.Username }}</span>
          <a href="/user/profile">Profile</a>
          <a href="/user/settings">Settings</a>
          <hr />
          <a href="/auth/logout">Logout</a>
        </div>
      </div>
    {{ else }}
      <!-- Logged out: login icon -->
      <a href="/auth/login" class="user-icon" aria-label="Login">
        <svg>...</svg>
      </a>
    {{ end }}
  </div>
</header>

<!-- Nav bar: separate row below header (CSS-only mobile menu) -->
<nav class="nav">
  <!-- Hidden checkbox controls menu state - NO JavaScript -->
  <input type="checkbox" id="nav-toggle" class="nav-checkbox" hidden>

  <!-- Desktop: inline links | Mobile: hamburger only -->
  <div class="nav-links">
    <a href="/">Home</a>
    <!-- App-specific sections (project-defined) -->
  </div>

  <!-- Mobile: hamburger toggle (checkbox label) -->
  <label for="nav-toggle" class="nav-toggle" aria-label="Toggle navigation">☰</label>

  <!-- Slide-in panel for mobile -->
  <div class="nav-panel">
    <label for="nav-toggle" class="nav-close" aria-label="Close menu">✕</label>
    <a href="/">Home</a>
    <!-- App-specific sections (project-defined) -->
  </div>

  <!-- Overlay - clicking label unchecks checkbox, closing menu -->
  <label for="nav-toggle" class="nav-overlay"></label>
</nav>
```

**Mobile Menu Behavior:**
- Menu slides in from RIGHT edge
- Slides LEFT to open (right-to-left)
- Slides RIGHT to close (left-to-right)
- Overlay dims background, click to close
- User icon stays in header (NOT in menu) - keeps menu clean

**Smart Menu (NON-NEGOTIABLE):**
- If all nav links fit on screen → show inline links, NO hamburger
- If nav links overflow → show hamburger menu
- Detect dynamically on load and resize
- Don't show hamburger if not needed

**CSS-Only Mobile Menu (NO JavaScript):**
```css
/* Mobile slide-in menu using checkbox hack */
@media (max-width: 768px) {
  /* Hide hamburger on desktop, show on mobile */
  .nav-toggle { display: block; cursor: pointer; }
  .nav-links { display: none; }

  /* Slide-in panel */
  .nav-panel {
    position: fixed;
    top: 0;
    right: -280px;           /* Hidden off-screen right */
    width: 280px;
    height: 100vh;
    background: var(--bg-color);
    transition: right 0.3s ease;
    z-index: 1001;
  }

  /* Overlay (hidden by default) */
  .nav-overlay {
    display: none;
    position: fixed;
    inset: 0;
    background: rgba(0, 0, 0, 0.5);
    z-index: 1000;
    cursor: pointer;
  }

  /* When checkbox is checked: show menu and overlay */
  .nav-checkbox:checked ~ .nav-panel {
    right: 0;                /* Slide in from right */
  }

  .nav-checkbox:checked ~ .nav-overlay {
    display: block;
  }
}

@media (min-width: 769px) {
  /* Desktop: show inline links, hide hamburger */
  .nav-toggle, .nav-panel, .nav-overlay { display: none; }
  .nav-links { display: flex; }
}
```

**Mobile Responsive Rules:**
- Nav row below header: inline links or hamburger
- User icon ALWAYS in header (never in menu)
- Menu slides from right edge
- Touch-friendly: minimum 44x44px tap targets
- Overlay closes menu on tap (CSS label toggles checkbox - no JS)

**No Fixed/Pinned Elements (NON-NEGOTIABLE):**
- Header, nav, footer all scroll with page
- NOTHING pinned/fixed to viewport
- User scrolls down → header/nav scroll away
- User scrolls to bottom → footer appears

**Footer Position (NON-NEGOTIABLE):**
- Footer ALWAYS at bottom of page (not floating in middle)
- If content is short → footer still at bottom of viewport
- If content is long → footer below content (scroll to see)
- Use min-height layout to push footer down

```css
/* Footer at bottom, no fixed elements */
body {
  display: flex;
  flex-direction: column;
  min-height: 100vh;
}

main {
  flex: 1;  /* Grows to push footer to bottom */
}

/* NO position: fixed or position: sticky on header/nav/footer */
```

**Print Styles (NON-NEGOTIABLE):**

```css
@media print {
  /* Hide non-essential elements */
  header,
  nav,
  footer,
  .nav-toggle,
  .nav-panel,
  .nav-overlay,
  .no-print,
  button:not(.print-include),
  .toast,
  .modal {
    display: none !important;
  }

  /* Reset backgrounds for ink saving */
  body {
    background: white !important;
    color: black !important;
  }

  /* Ensure content is full width */
  main, .container {
    width: 100% !important;
    max-width: none !important;
    margin: 0 !important;
    padding: 0 !important;
  }

  /* Show URLs after links */
  a[href^="http"]:after {
    content: " (" attr(href) ")";
    font-size: 0.8em;
    color: #666;
  }

  /* Avoid page breaks inside elements */
  pre, blockquote, table, img {
    page-break-inside: avoid;
  }

  /* Start new sections on new page */
  h1, h2 {
    page-break-after: avoid;
  }
}
```

**Print utility classes:**
- `.no-print` - Hide element when printing
- `.print-only` - Show element only when printing (use `display: none` normally)
- `.print-include` - Exception for buttons that should print

**Footer contains (informational links):**
- Standard pages: About, Privacy, Contact, Help
- External links: GitHub
- Branding: project name, version, copyright

**Rule:** Every page template MUST include header, nav, and footer partials. No page may define its own header/nav/footer - use the shared partials only. This ensures:
- Consistent branding across all pages
- Single point of change for navigation updates
- Uniform user experience

**App-Specific Partials (Optional):**

Projects can create additional partials for functionality unique to that application. Place these in `partials/` alongside the mandatory ones.

| Example Partial | Project | Purpose |
|-----------------|---------|---------|
| `search-box.tmpl` | airports, jokes | Reusable search form component |
| `airport-card.tmpl` | airports | Airport info display card |
| `joke-card.tmpl` | jokes | Joke display with copy button |
| `map.tmpl` | airports | Embedded map component |
| `passphrase-generator.tmpl` | wordList | Generator form and output |
| `geoip-result.tmpl` | airports | GeoIP lookup result display |
| `code-block.tmpl` | gitignore | Syntax-highlighted code display |
| `pagination.tmpl` | any | Reusable pagination controls |
| `filters.tmpl` | any | Search/filter form for lists |
| `stats-card.tmpl` | any | Statistics display card |

**App-Specific Partials (add to existing structure):**

See **Template Structure** above for mandatory partials (`partials/public/*`, `partials/admin/*`, `partials/head.tmpl`, `partials/scripts.tmpl`).

Projects add app-specific partials alongside the mandatory ones:
```
src/server/templates/partials/
├── public/                  # MANDATORY (see Template Structure)
├── admin/                   # MANDATORY (see Template Structure)
├── head.tmpl                # MANDATORY
├── scripts.tmpl             # MANDATORY
├── search-box.tmpl          # APP-SPECIFIC - search component
├── result-card.tmpl         # APP-SPECIFIC - result display
└── pagination.tmpl          # APP-SPECIFIC - pagination controls
```

**Usage in page templates:**
```go
{{ define "content" }}
<div class="search-section">
  {{ template "search-box" . }}
</div>

<div class="results">
  {{ range .Results }}
    {{ template "result-card" . }}
  {{ end }}
</div>

{{ template "pagination" .Pagination }}
{{ end }}
```

**Guidelines for app-specific partials:**
- Create a partial when the same HTML is used in 2+ places
- Keep partials focused on one component/purpose
- Pass only the data the partial needs
- Name clearly: `{thing}-{purpose}.tmpl` (e.g., `airport-card.tmpl`, `joke-list.tmpl`)

**Embedding Templates (NON-NEGOTIABLE):**

All templates and static assets MUST be embedded in the binary:

```go
package server

import "embed"

//go:embed templates/*.tmpl templates/**/*.tmpl
var templatesFS embed.FS

//go:embed static/*
var staticFS embed.FS
```

**Template Usage:**
```go
{{ define "base" }}
<!DOCTYPE html>
<html lang="en">
<head>{{ template "head" . }}</head>
<body>
  {{ template "header" . }}
  {{ template "nav" . }}
  <main>{{ template "content" . }}</main>
  {{ template "footer" . }}
  {{ template "scripts" . }}
</body>
</html>
{{ end }}
```

### Embedded vs External Assets

| Type | Embedded in Binary | External (Downloaded) |
|------|-------------------|----------------------|
| Templates (`.tmpl`) | YES | NO |
| CSS files | YES | NO |
| JavaScript files | YES | NO |
| Images/Icons | YES | NO |
| Fonts | YES | NO |
| Application data (JSON) | YES | NO |
| GeoIP databases | NO | YES - downloaded on first run, updated weekly |
| IP/Domain Blocklists | NO | YES - downloaded on first run, updated daily |
| CVE databases | NO | YES - downloaded on first run, updated daily |
| SSL certificates | NO | YES - only when using ports 80,443 |

**External Data Rules:**
- Security-related data that needs frequent updates is NEVER embedded
- Downloaded automatically on first run if not present
- Updated automatically via built-in scheduler (see PART 26: SCHEDULER)
- All scheduler tasks configurable via admin panel
- Graceful degradation if download fails (continues without data)
- SSL certificates only generated/managed when running on ports `80,443`

**Benefits:**
- Single static binary deployment
- No external file dependencies at runtime
- Consistent layout across all pages
- Reusable components (DRY principle)
- Auto-escaping for security (XSS prevention)

### CSS Rules

| Bad | Good |
|-----|------|
| `<div style="color: red;">` | `<div class="error-text">` |
| `style="margin: 10px;"` | `class="spacing-sm"` |

**All styles MUST be in CSS files, not HTML elements.**

### Frontend UI Elements (NON-NEGOTIABLE)

**NEVER use default JavaScript UI elements. ALWAYS use custom styled components.**

| NEVER Use | ALWAYS Use Instead |
|-----------|---------------------|
| `alert()` | Custom modal with CSS classes |
| `confirm()` | Custom confirmation modal |
| `prompt()` | Custom input modal or inline form |
| Plain text inputs for options | Dropdowns (`<select>`) |
| Plain text for yes/no | Checkboxes or toggle switches |
| Plain text for multiple options | Radio buttons or dropdown |
| Inline text entry | Only when truly needed (search, names, etc.) |

**UI Element Guidelines:**

| Element | When to Use |
|---------|-------------|
| **Dropdown (`<select>`)** | Selecting from predefined options |
| **Checkbox** | Boolean on/off, enable/disable |
| **Toggle Switch** | Boolean with visual feedback |
| **Radio Buttons** | Mutually exclusive options (2-5 choices) |
| **Dropdown** | Mutually exclusive options (>5 choices) |
| **Multi-select** | Multiple selections from list |
| **Text Input** | Free-form text (names, URLs, search) |
| **Textarea** | Multi-line free-form text |
| **Number Input** | Numeric values with spin buttons |
| **Date/Time Picker** | Date and time selection |
| **Color Picker** | Color selection |
| **File Upload** | File selection with drag-drop |

**Modal Requirements:**
- Custom CSS-styled modals (no browser defaults)
- Backdrop overlay
- Close button (X) in corner
- Click outside to close (optional, configurable)
- Escape key to close
- Focus trap (tab stays within modal)
- Animated entrance/exit
- **Auto-close on action** - clicking any action button (OK, Yes, No, Cancel, Save, Delete, Submit, etc.) automatically closes the modal after performing the action. User should never need to click an action then manually close.

**Toast/Notification Requirements:**
- Non-blocking notifications
- Auto-dismiss with configurable timeout
- Manual dismiss option
- Stacking for multiple notifications
- Types: success, error, warning, info
- Icon + message format

## Layout

| Screen Size | Width |
|-------------|-------|
| ≥ 720px | 90% (5% margins) |
| < 720px | 98% (1% margins) |
| Footer | Always centered, always at bottom |

## Themes (NON-NEGOTIABLE - PROJECT-WIDE)

**Theme system applies to THE ENTIRE PROJECT:**
- Web interface (HTML pages)
- Admin panel
- Swagger UI
- GraphiQL interface
- ReadTheDocs documentation (if possible)
- All interactive elements

**Three Required Themes:**

| Theme | When Active | Default | Color Scheme |
|-------|-------------|---------|--------------|
| **Dark** | User selects dark OR system dark + auto mode | **YES** | Dark theme colors (see `dark.css`) |
| **Light** | User selects light OR system light + auto mode | No | Light theme colors (see `light.css`) |
| **Auto** | Follows system preference (light/dark) | No | System `prefers-color-scheme` |

**Critical Theme Rules (APPLY TO ENTIRE PROJECT):**
- **BOTH light AND dark themes MUST be easy to read**
- **NO color conflicts** - nothing should be invisible or unreadable in either theme
- **Sufficient contrast ratio** - minimum WCAG AA compliance (4.5:1) in both themes
- **Theme applies everywhere** - web UI, admin panel, Swagger, GraphQL, etc.
- **Theme switching MUST work seamlessly** without page reload
- **All interactive elements MUST be clearly visible** in both themes
- **Syntax highlighting MUST adapt** to theme (use appropriate colors for each theme)
- **User preference persisted** in localStorage or cookie
- **Default to dark** if no preference set

**Theme Implementation Location:**

| Component | File Location | Purpose |
|-----------|---------------|---------|
| Theme core logic | `src/server/theme.go` | Theme detection, switching, persistence |
| Swagger theming | `src/swagger/theme.go` | Swagger UI theme application |
| GraphQL theming | `src/graphql/theme.go` | GraphiQL theme application |
| Web UI theming | `src/server/template/` | HTML template theme classes |
| CSS variables | Embedded in templates | Theme-specific CSS custom properties |

**Theme Detection Flow:**
```
1. Check user preference in localStorage/cookie
2. If no preference OR preference is "auto":
   - Check system preference via prefers-color-scheme media query
   - Apply matching theme (light or dark)
3. If preference is "light" or "dark":
   - Apply selected theme directly
4. Default to dark if all detection fails
```

**Theme Switching:**
- Provide theme toggle in UI (☀️ Light / 🌙 Dark / 🔄 Auto)
- Store preference in `localStorage.theme` or cookie
- Apply theme class to `<html>` element: `theme-light`, `theme-dark`
- NO page reload required - instant switching via CSS classes
- All components (Swagger, GraphQL, admin) switch simultaneously

**Accessibility Requirements:**
- Both themes MUST pass WCAG AA contrast requirements (4.5:1 minimum)
- Focus indicators MUST be visible in both themes
- Keyboard navigation MUST work identically in both themes
- Screen readers MUST work correctly in both themes
- No information conveyed by color alone

## Branding & SEO (NON-NEGOTIABLE)

**White labeling is cosmetic only - it changes what users see, not how the server works.**

### What Branding Changes

| Changes (User-Visible) | Does NOT Change (System) |
|------------------------|--------------------------|
| Page titles | Directory names (`casspeed/`) |
| Browser tab | System username (`casspeed`) |
| Header/logo text | Log filenames |
| Footer branding | Config paths |
| Email "From" name | Binary name |
| SEO meta tags | API routes |
| OpenGraph data | Service names |
| Swagger UI title | Container names |

### Configuration

```yaml
server:
  branding:
    # Display name (e.g., "Jokes API")
    title: "casspeed"
    # Short slogan (e.g., "The best jokes API")
    tagline: ""
    # Longer description for SEO/about
    description: ""

  seo:
    # Project-specific - define per app
    # e.g., ["jokes", "api", "humor", "free api"]
    keywords: []
    # Author/organization name
    author: ""
    # OpenGraph image URL for social sharing
    og_image: ""
    # Twitter @handle for cards
    twitter_handle: ""
```

### Where Branding Is Used

| Field | Used In |
|-------|---------|
| `title` | `<title>` tag, header, emails, footer, Swagger UI |
| `tagline` | Homepage hero section, meta description fallback |
| `description` | Meta description, OpenGraph description, about page |
| `keywords` | Meta keywords tag |
| `author` | Meta author tag |
| `og_image` | OpenGraph/Twitter card image |
| `twitter_handle` | Twitter card attribution |

### SEO Meta Tags (Generated)

```html
<head>
  <title>{title} - {tagline}</title>
  <meta name="description" content="{description}">
  <meta name="keywords" content="{keywords}">
  <meta name="author" content="{author}">

  <!-- OpenGraph -->
  <meta property="og:title" content="{title}">
  <meta property="og:description" content="{description}">
  <meta property="og:image" content="{og_image}">
  <meta property="og:type" content="website">
  <meta property="og:url" content="{current_url}">

  <!-- Twitter Card -->
  <meta name="twitter:card" content="summary_large_image">
  <meta name="twitter:title" content="{title}">
  <meta name="twitter:description" content="{description}">
  <meta name="twitter:image" content="{og_image}">
  <meta name="twitter:site" content="{twitter_handle}">
</head>
```

### Static Files

| File | Purpose | Generated |
|------|---------|-----------|
| `/sitemap.xml` | Site map for search engines | Yes - auto-generated |
| `/favicon.ico` | Browser favicon | Embedded default, customizable |

### Admin Panel (/admin/server/branding)

| Element | Type | Description |
|---------|------|-------------|
| Title | Text input | Application display name |
| Tagline | Text input | Short slogan |
| Description | Textarea | Longer description for SEO |
| Keywords | Tag input | SEO keywords (comma-separated) |
| Author | Text input | Author/organization |
| OG Image | File upload / URL | Social sharing image |
| Twitter Handle | Text input | @handle |
| Favicon | File upload / URL | Custom favicon |
| Logo | File upload / URL | Custom logo (header) |

### Image Sources

**Logo, favicon, and OG image can be from local file or remote URL.**

| Source | Format | Example |
|--------|--------|---------|
| Local file | File upload | Upload via admin panel |
| Remote URL | URL input | `https://example.com/logo.png` |
| Embedded default | - | Built-in fallback |

### Image Scaling

**Images are automatically scaled/resized as needed:**

| Image | Sizes Generated |
|-------|-----------------|
| Logo | Original, 200px width (header), 50px width (mobile) |
| Favicon | 16x16, 32x32, 48x48, 180x180 (apple-touch-icon), 192x192, 512x512 |
| OG Image | Original, 1200x630 (OpenGraph standard) |

**Scaling Rules:**
- Preserve aspect ratio
- Generate multiple sizes on upload/fetch
- Cache scaled versions locally
- Re-fetch remote URLs periodically (configurable, default: daily)
- Fallback to embedded default if remote URL fails

### Defaults

| Field | Default Value |
|-------|---------------|
| `title` | `casspeed` |
| `tagline` | Empty |
| `description` | Empty |
| `keywords` | Empty |
| All others | Empty |

**Rule:** If `title` is empty, fall back to `casspeed`. Other fields are optional.

## Announcements (NON-NEGOTIABLE)

**Admin messages shown in UI for downtime notices, updates, etc.**

### Configuration

```yaml
web:
  announcements:
    enabled: true
    # List of announcement messages
    messages: []
```

### Announcement Structure

```yaml
messages:
  - id: "maintenance-2025-01"
    type: warning
    # warning, info, error, success
    title: "Scheduled Maintenance"
    message: "The server will be down for maintenance on Jan 15, 2025 from 2-4 AM UTC."
    start: "2025-01-14T00:00:00Z"
    # When to start showing
    end: "2025-01-15T04:00:00Z"
    # When to stop showing
    dismissible: true
    # User can dismiss
```

### Admin Panel (/admin/server/announcements)

| Element | Type | Description |
|---------|------|-------------|
| Enable announcements | Toggle | Turn announcements on/off |
| Announcement list | Table | All announcements |
| Add announcement | Button | Create new announcement |
| Type | Dropdown | warning, info, error, success |
| Title | Text input | Short title |
| Message | Textarea | Full message content |
| Start date | Datetime picker | When to start showing |
| End date | Datetime picker | When to stop showing |
| Dismissible | Toggle | Allow users to dismiss |
| Delete | Button | Remove announcement |

## CORS (NON-NEGOTIABLE)

**Default CORS policy allows all origins (`*`).**

### Configuration

```yaml
web:
  # CORS origin configuration
  # - "*": Allow all origins (default)
  # - "https://example.com": Single origin
  # - "https://example.com,https://app.example.com": Multiple origins (comma-separated)
  # - "": Disable CORS headers entirely
  cors: "*"
```

### CORS Headers

| Header | Value |
|--------|-------|
| `Access-Control-Allow-Origin` | Configured origin(s) or `*` |
| `Access-Control-Allow-Methods` | `GET, POST, PUT, PATCH, DELETE, OPTIONS` |
| `Access-Control-Allow-Headers` | `*` |
| `Access-Control-Allow-Credentials` | `true` (only when specific origin, not `*`) |
| `Access-Control-Max-Age` | `86400` (24 hours) |

### Behavior

| Scenario | Behavior |
|----------|----------|
| `cors: "*"` | Allow all origins, credentials NOT allowed |
| `cors: "https://example.com"` | Allow single origin, credentials allowed |
| `cors: "https://a.com,https://b.com"` | Allow listed origins, credentials allowed |
| `cors: ""` | No CORS headers (same-origin only) |
| Preflight (OPTIONS) | Return CORS headers, 204 No Content |

### Mode-Specific Behavior

| Mode | Default | Behavior |
|------|---------|----------|
| Production | `*` | Allow all origins by default (configure if needed) |
| Development | `*` | Allow all origins |

### Admin Panel (/admin/server/web)

| Element | Type | Description |
|---------|------|-------------|
| CORS Origins | Text input | Comma-separated list of allowed origins |
| Allow All | Toggle | Quick toggle for `*` (all origins) |
| Preview | Read-only | Shows resulting CORS headers |

## CSRF Protection (NON-NEGOTIABLE)

**ALL forms MUST have CSRF protection.**

### Configuration

```yaml
web:
  csrf:
    enabled: true
    # Token length in bytes
    token_length: 32
    cookie_name: csrf_token
    header_name: X-CSRF-Token
    # Secure cookie: auto, true, false
    secure: auto
```

### Implementation

- All forms include hidden CSRF token field
- All non-GET requests validate CSRF token
- Token stored in cookie and must match form/header value
- Tokens regenerated on login

## Footer Customization (NON-NEGOTIABLE)

### Configuration

```yaml
web:
  footer:
    # Google Analytics tracking ID (empty = disabled)
    # Example: UA-936146-1 or G-XXXXXXXXXX
    tracking_id: ""

    # Cookie consent popup (EU GDPR compliance)
    cookie_consent:
      enabled: true
      message: "This site uses cookies for functionality and analytics."
      policy_url: ""
      # URL to privacy policy

    # Custom branding HTML above the Application Footer
    # - Not set or "": Use default branding (built-in)
    # - " " (space): Disable branding, show only Application Footer
    # - Custom HTML: Use your own branding
    custom_html: ""
```

### Available Footer Variables

| Variable | Description |
|----------|-------------|
| `{currentyear}` | Current year (e.g., 2025) |
| `casspeed` | Project name |
| `casapps` | Organization name |
| `{projectversion}` | Application version |
| `{builddatetime}` | Build date/time |

### Default Application Footer (Always Shown)

```html
<footer class="footer">
  <!-- Standard page links (always first) -->
  <p>
    <a href="/server/about">About</a>
    <span>•</span>
    <a href="/server/privacy">Privacy</a>
    <span>•</span>
    <a href="/server/contact">Contact</a>
    <span>•</span>
    <a href="/server/help">Help</a>
  </p>

  <br />

  <!-- Application branding -->
  <p>
    <a href="https://github.com/casapps/casspeed" target="_blank">casspeed</a>
    <span>•</span>
    <span>Made with ❤️</span>
    <span>•</span>
    <span>{projectversion}</span>
  </p>

  <br />

  <a href="/healthz">Last update: {builddatetime}</a>
</footer>
```

### Admin Panel (/admin/server/footer)

| Element | Type | Description |
|---------|------|-------------|
| Google Analytics ID | Text input | Tracking ID (empty = disabled) |
| Cookie consent enabled | Toggle | Show cookie consent popup |
| Cookie consent message | Textarea | Consent message |
| Privacy policy URL | Text input | Link to privacy policy |
| Custom branding HTML | Textarea | HTML above application footer |
| Preview | Preview pane | Shows rendered footer |

## Standard Pages (NON-NEGOTIABLE)

**ALL applications MUST have these standard pages. Content is defined per-application.**

### /server/about

**About the application - what it does, version info, and optionally Tor access.**

| Section | Description |
|---------|-------------|
| Application name | From branding config |
| Version | Current version |
| Description | From branding config or project-specific |
| Features | Key features list (project-specific) |
| Tor access | If Tor installed, show .onion address with copy button |
| Links | GitHub, documentation, etc. |

**Tor Section (shown only if `tor` binary is installed - auto-detected):**

```html
<!-- Example Tor section -->
<div class="tor-access">
  <h3>Tor Hidden Service</h3>
  <p>This application is also available via Tor for enhanced privacy.</p>
  <div class="onion-address">
    <code>{onion_address}</code>
    <button onclick="copyToClipboard()">[Copy]</button>
  </div>
  <p class="note">Requires Tor Browser or Tor-enabled browser.</p>
</div>
```

### /server/privacy

**Privacy policy - what data is collected, how it's used, retention, etc.**

| Section | Description |
|---------|-------------|
| Data collection | What data is collected |
| Data usage | How data is used |
| Data retention | How long data is kept |
| Third parties | What data is shared with third parties |
| Cookies | What cookies are used |
| User rights | How users can access/delete their data |
| Contact | How to contact for privacy concerns |

**Default template provided, customizable via admin panel.**

### /server/contact

**Contact form - sends message to admin or dedicated contact address.**

| Field | Type | Required | Description |
|-------|------|----------|-------------|
| Name | Text | Yes | Sender's name |
| Email | Email | Yes | Sender's email (for reply) |
| Subject | Text | Yes | Message subject |
| Message | Textarea | Yes | Message body |
| Captcha | Captcha | Yes | Spam prevention |

**Submission sends email to `server.contact` address (or admin email if not set).**

### /server/help

**Help page - documentation and usage instructions for the application.**

| Section | Description |
|---------|-------------|
| Getting started | Quick start guide |
| Features | How to use key features |
| API Documentation | Links to Swagger (/openapi) and GraphQL (/graphql) - both in sync |
| FAQ | Frequently asked questions |
| Troubleshooting | Common issues and solutions |

**API Documentation section (always shown):**
```html
<div class="api-docs">
  <h3>API Documentation</h3>
  <p>This application provides a full REST API with interactive documentation.</p>
  <ul>
    <li><a href="/openapi">Swagger UI</a> - Interactive REST API explorer</li>
    <li><a href="/graphql">GraphiQL</a> - Interactive GraphQL explorer</li>
  </ul>
</div>
```

**Content is project-specific. Markdown supported.**

### Configuration

```yaml
server:
  # Contact form recipient
  # If not set, uses admin email
  contact: ""

  pages:
    about:
      # Additional content for about page (markdown supported)
      content: ""
      # Show Tor section (auto-detected from tor.enabled, but can override)
      show_tor: auto

    privacy:
      # Privacy policy content (markdown supported)
      # If empty, uses default template
      content: ""

    contact:
      # Enable contact form
      enabled: true
      # Recipient email (if empty, uses server.contact or admin email)
      recipient: ""
      # Captcha type: recaptcha, hcaptcha, simple (built-in)
      captcha: simple
      # Success message after form submission
      success_message: "Thank you for your message. We'll respond soon."

    help:
      # Help page content (markdown supported)
      # Project-specific - must be defined per application
      content: ""
```

### Admin Panel (/admin/server/pages)

| Element | Type | Description |
|---------|------|-------------|
| **About Page** | | |
| Content | Markdown editor | Additional about page content |
| Show Tor section | Toggle | Show .onion address (auto/yes/no) |
| Preview | Button | Preview about page |
| **Privacy Policy** | | |
| Content | Markdown editor | Privacy policy content |
| Reset to default | Button | Restore default template |
| Preview | Button | Preview privacy page |
| **Contact Page** | | |
| Enable contact form | Toggle | Enable/disable contact form |
| Recipient email | Text input | Email to receive messages |
| Captcha type | Dropdown | recaptcha, hcaptcha, simple |
| Success message | Textarea | Message shown after submission |
| Test form | Button | Send test message |
| **Help Page** | | |
| Content | Markdown editor | Help/documentation content |
| Preview | Button | Preview help page |

---


# PART 18: SERVER CONFIGURATION (NON-NEGOTIABLE)

## Request Limits

```yaml
server:
  limits:
    max_body_size: 10MB
    read_timeout: 30s
    write_timeout: 30s
    idle_timeout: 120s
```

| Setting | Description | Default |
|---------|-------------|---------|
| `max_body_size` | Maximum request body size | 10MB |
| `read_timeout` | Read timeout | 30s |
| `write_timeout` | Write timeout | 30s |
| `idle_timeout` | Idle connection timeout | 120s |

## Response Compression

```yaml
server:
  compression:
    enabled: true
    # Compression level 1-9
    level: 5
    # MIME types to compress
    types:
      - text/html
      - text/css
      - text/javascript
      - application/json
      - application/xml
```

## Trusted Proxies

```yaml
server:
  trusted_proxies:
    # Additional IPs/CIDRs to trust (private ranges always trusted)
    additional: []
```

## Session Configuration

```yaml
server:
  session:
    # Admin sessions (server.db admin_sessions table)
    admin:
      cookie_name: admin_session
      # Cookie max age: 30 days (absolute session lifetime)
      max_age: 2592000
      # Idle timeout: 24 hours (session expires after inactivity)
      idle_timeout: 86400
    # User sessions (users.db user_sessions table) - only if app has users
    user:
      cookie_name: user_session
      # Cookie max age: 7 days
      max_age: 604800
      # Idle timeout: 24 hours
      idle_timeout: 86400
    # Common settings (apply to both)
    extend_on_activity: true     # Reset idle timeout on each request
    # auto, true, false
    secure: auto
    http_only: true
    # strict, lax, none
    same_site: lax
```

**Session Lifetime vs Idle Timeout:**

| Setting | Admin Default | User Default | Description |
|---------|---------------|--------------|-------------|
| `max_age` | 30 days | 7 days | Absolute session lifetime (cookie expiry) |
| `idle_timeout` | 24 hours | 24 hours | Expires after inactivity (reset on each request if `extend_on_activity` is true) |

## Rate Limiting

```yaml
server:
  rate_limit:
    enabled: true
    # Requests allowed per window
    requests: 120
    # Window size in seconds
    window: 60
```

## Internationalization (i18n)

```yaml
server:
  i18n:
    default_language: en
    supported: [en]
```

## Cache Configuration (NON-NEGOTIABLE)

**EVERY application MUST support Valkey/Redis.** This is REQUIRED for:
- Clustering (session sharing, state sync)
- Mixed Mode (cross-database synchronization)
- Horizontal scaling
- Rate limiting in distributed deployments

| Mode | Cache Requirement |
|------|-------------------|
| **Single Instance** | `memory` (default) - works standalone |
| **Cluster** | `valkey` or `redis` - REQUIRED for state sync |
| **Mixed Mode** | `valkey` or `redis` - REQUIRED for cross-DB sync |

```yaml
server:
  cache:
    # Type: none (disabled), memory (default), valkey, redis
    # IMPORTANT: Use valkey/redis for cluster or mixed mode deployments
    type: memory

    # Connection: Use EITHER url OR host/port/password (not both)
    # url takes precedence if both are specified
    # Format: redis://user:password@host:port/db or valkey://...
    url: ""

    # Individual connection settings (alternative to url)
    host: localhost
    port: 6379
    # ACL username (Redis 6+)
    username: ""
    password: ""
    db: 0

    # TLS settings (for secure connections)
    tls: false
    tls_skip_verify: false

    # Connection pool
    pool_size: 10
    min_idle: 2
    timeout: 5s

    # Key prefix to avoid collisions (use unique prefix per app)
    prefix: "casspeed:"

    # Default TTL in seconds
    ttl: 3600

    # Cluster settings (when using Valkey/Redis Cluster)
    cluster: false
    # e.g., ["node1:6379", "node2:6379", "node3:6379"]
    cluster_nodes: []
```

### Connection Methods

**Two ways to configure connection (pick one):**

| Method | When to Use |
|--------|-------------|
| `url` | Simple, single connection string, environment-friendly |
| `host`/`port`/etc | More explicit, when fields come from different sources |

**URL Format:**
```
redis://[[username:]password@]host[:port][/database]
valkey://[[username:]password@]host[:port][/database]
rediss://...  # Redis with TLS
```

### Valkey/Redis Configuration Examples

**Using connection URL:**
```yaml
server:
  cache:
    type: valkey
    url: ${CACHE_URL}  # valkey://user:pass@valkey.example.com:6379/0
    prefix: "casspeed:"
```

**Using individual fields:**
```yaml
server:
  cache:
    type: valkey
    host: valkey.example.com
    port: 6379
    password: ${VALKEY_PASSWORD}
    db: 0
    prefix: "casspeed:"
```

**Valkey/Redis Cluster:**
```yaml
server:
  cache:
    type: valkey
    cluster: true
    cluster_nodes:
      - valkey1.example.com:6379
      - valkey2.example.com:6379
      - valkey3.example.com:6379
    password: ${VALKEY_PASSWORD}
    prefix: "casspeed:"
```

### Cache Usage in Application

| Feature | Uses Cache | Purpose |
|---------|------------|---------|
| Sessions | Yes | Session data storage |
| Rate limiting | Yes | Request counters per IP/user |
| API responses | Optional | Response caching |
| Cluster heartbeat | Yes | Node liveness detection |
| Pub/Sub events | Yes | Real-time state sync |
| Distributed locks | Yes | Prevent duplicate task execution |

## Admin Panel (/admin/server/settings)

All settings above MUST be configurable via admin panel:

| Section | Settings |
|---------|----------|
| Request Limits | Body size, timeouts |
| Compression | Enable, level, MIME types |
| Trusted Proxies | Additional IPs/CIDRs |
| Session | Cookie name, max age, secure, http_only, same_site |
| Rate Limiting | Enable, requests, window |
| i18n | Default language, supported languages |
| Cache | Type, connection settings, prefix, TTL |

---



# PART 19: ADMIN PANEL (NON-NEGOTIABLE)

**ALL projects MUST have a full admin panel.**

## Admin Panel Isolation (NON-NEGOTIABLE)

**The admin panel is completely isolated from the public site.**

| Rule | Description |
|------|-------------|
| **NEVER link to /admin** | No links to /admin on ANY public routes (`/**`) |
| **Intentional access only** | Users must manually type `/admin` in browser |
| **Separate authentication** | Admin account is ONLY valid for `/admin/**` routes |
| **No admin mentions** | Don't advertise admin panel existence anywhere |
| **Separate session** | Admin session is separate from user sessions |

### User Types

| User Type | Valid Routes | Authentication |
|-----------|--------------|----------------|
| **Admin** | `/admin/**` ONLY | Admin credentials (username/password) |
| **Guest/Anon** | `/**` (except /admin) | None |
| **Normal User** | `/**` (except /admin) | User account (if multi-user enabled) |

**Admin credentials are stored in `users.db` (admins table), NOT in config file.**

### Testing Admin Routes

**Admin authentication MUST be tested, not bypassed:**

| Testing Approach | Use For | Method |
|------------------|---------|--------|
| **Proper testing** | Automated tests, beta testing, CI/CD | Use setup token → create admin → test login |
| **Manual dev only** | Quick UI exploration while coding | Use `--debug` flag (bypasses auth) |

**Automated tests MUST:**
1. Verify unauthenticated requests are blocked
2. Use setup token to create admin account
3. Test login with valid credentials
4. Verify admin routes work with session
5. Verify invalid credentials are rejected

**See PART 13: Testing & Development for complete admin authentication testing examples.**

### Why Isolated?

- Security: Admin panel not discoverable
- Separation: Admin functions separate from user functions
- Simplicity: No confusion between admin and user roles
- Protection: Reduces attack surface

## Design Principles

| Principle | Description |
|-----------|-------------|
| Server Admin Focus | Designed for server administration, not end-users |
| Pretty | Clean, modern, professional design |
| Intuitive | Self-explanatory, no manual needed |
| Easy Navigation | Logical grouping, breadcrumbs, search |
| Frontend Rules | Dark theme (default), light/dark/auto themes, responsive, accessible |
| No JS Alerts | Custom modals, toasts, confirmations |
| Real-time Feedback | Show save status, validation errors inline |
| Mobile-Friendly | Works on all screen sizes |
| Keyboard Shortcuts | Power users can navigate quickly |

## Admin Panel Layout (NON-NEGOTIABLE)

### Overall Structure

```
┌─────────────────────────────────────────────────────────────────────────┐
│ HEADER                                                                   │
│ ┌─────────────────────────────────────────────────────────────────────┐ │
│ │ Logo/Title          Search...              [Status] [User] [Logout] │ │
│ └─────────────────────────────────────────────────────────────────────┘ │
├──────────────┬──────────────────────────────────────────────────────────┤
│   SIDEBAR    │                    MAIN CONTENT                          │
│              │                                                          │
│  Dashboard   │  ┌─────────────────────────────────────────────────────┐ │
│              │  │ Breadcrumb: Dashboard > Server > Settings           │ │
│  Server ▼    │  └─────────────────────────────────────────────────────┘ │
│   Settings   │                                                          │
│   SSL/TLS    │  ┌─────────────────────────────────────────────────────┐ │
│   Scheduler  │  │                                                     │ │
│   Logs       │  │              PAGE CONTENT                           │ │
│              │  │                                                     │ │
│  Security ▼  │  │                                                     │ │
│   Auth       │  │                                                     │ │
│   Tokens     │  │                                                     │ │
│   Firewall   │  │                                                     │ │
│              │  │                                                     │ │
│  Network ▼   │  │                                                     │ │
│   Tor        │  │                                                     │ │
│   GeoIP      │  │                                                     │ │
│              │  └─────────────────────────────────────────────────────┘ │
│  Users ▼     │                                                          │
│  (if multi)  │  ┌─────────────────────────────────────────────────────┐ │
│              │  │ FOOTER: Version | Docs | Status                     │ │
│  Cluster ▼   │  └─────────────────────────────────────────────────────┘ │
│  (if enabled)│                                                          │
│              │                                                          │
└──────────────┴──────────────────────────────────────────────────────────┘
```

### Header

| Element | Position | Description |
|---------|----------|-------------|
| Logo/Title | Left | Project name, clickable → dashboard |
| Search | Center | Global search (settings, logs, etc.) |
| Status Indicator | Right | ● Green (OK), ● Yellow (Warning), ● Red (Error) |
| Admin Name | Right | Current admin username |
| Logout | Right | Always visible, one-click logout |

### Sidebar Navigation

**Collapsible sidebar with grouped sections.**

```
📊 Dashboard

📦 Server
   ├── Settings
   ├── Branding
   ├── SSL/TLS
   ├── Scheduler
   ├── Email
   ├── Logs
   ├── Backup
   ├── Maintenance
   ├── Updates
   └── Info

🔒 Security
   ├── Authentication
   ├── API Tokens
   ├── Rate Limiting
   └── Firewall

🌐 Network
   ├── Tor
   ├── GeoIP
   └── Blocklists

👥 Users (if multi-user)
   ├── User List
   ├── Invites
   └── Roles

🔗 Cluster (if enabled)
   ├── Nodes
   ├── Add Node
   └── Settings

❓ Help
   └── Documentation
```

### Sidebar Behavior

| Feature | Description |
|---------|-------------|
| Collapsible | Click section header to expand/collapse |
| Active indicator | Highlight current page |
| Collapse all | Double-click header to collapse sidebar |
| Remember state | Persist expanded/collapsed state |
| Icons | Each section has icon for quick recognition |
| Mobile | Hamburger menu, slide-out drawer |

## /admin (Web Interface)

### Authentication

| Feature | Description |
|---------|-------------|
| Login page | `/admin` (when not logged in) |
| Login form | Username/password, centered card |
| Session | Cookie-based (30 days default, configurable) |
| CSRF | Protection on all forms |
| Remember Me | Option available (extends to 90 days) |
| Logout | Always visible in header |
| MFA | TOTP support (optional, configurable) |

### Login Page (`/admin`)

```
┌─────────────────────────────────────────┐
│                                         │
│         ┌───────────────────┐           │
│         │   {Project Name}  │           │
│         │   Admin Panel     │           │
│         ├───────────────────┤           │
│         │                   │           │
│         │  Username: [____] │           │
│         │  Password: [____] │           │
│         │                   │           │
│         │  [ ] Remember me  │           │
│         │                   │           │
│         │    [  Login  ]    │           │
│         │                   │           │
│         └───────────────────┘           │
│                                         │
│              v1.2.3                     │
└─────────────────────────────────────────┘
```

**Login page rules:**
- Centered card on dark background
- Project name/logo at top
- No links to public site
- Version number at bottom (small)
- No "Forgot password" (admin resets via CLI if needed)

### Dashboard (`/admin/dashboard`)

**Overview of server status and system resources at a glance.**

```
┌─────────────────────────────────────────────────────────────────────────┐
│ Dashboard                                                                │
├─────────────────────────────────────────────────────────────────────────┤
│                                                                         │
│  ┌──────────────┐  ┌──────────────┐  ┌──────────────┐  ┌──────────────┐ │
│  │   STATUS     │  │   UPTIME     │  │   REQUESTS   │  │   ERRORS     │ │
│  │   ● Online   │  │   5d 12h 3m  │  │   12,345     │  │   23         │ │
│  │              │  │              │  │   (24h)      │  │   (24h)      │ │
│  └──────────────┘  └──────────────┘  └──────────────┘  └──────────────┘ │
│                                                                         │
│  ┌─────────────────────────────────┐  ┌─────────────────────────────┐   │
│  │ SYSTEM RESOURCES                │  │ QUICK ACTIONS               │   │
│  │                                 │  │                             │   │
│  │ CPU:    [████████░░] 78%        │  │ [Restart Server]            │   │
│  │ Memory: [██████░░░░] 62%        │  │ [Clear Cache]               │   │
│  │ Disk:   [████░░░░░░] 45%        │  │ [Create Backup]             │   │
│  │                                 │  │ [View Logs]                 │   │
│  └─────────────────────────────────┘  └─────────────────────────────┘   │
│                                                                         │
│  ┌─────────────────────────────────┐  ┌─────────────────────────────┐   │
│  │ RECENT ACTIVITY                 │  │ SCHEDULED TASKS             │   │
│  │                                 │  │                             │   │
│  │ 10:30 Config updated            │  │ SSL Renewal    in 23 days   │   │
│  │ 10:15 Admin login               │  │ GeoIP Update   in 2 days    │   │
│  │ 09:45 Backup completed          │  │ Auto Backup    in 5 hours   │   │
│  │ 09:00 SSL renewed               │  │ Session Clean  in 45 min    │   │
│  └─────────────────────────────────┘  └─────────────────────────────┘   │
│                                                                         │
│  ┌─────────────────────────────────────────────────────────────────┐    │
│  │ ALERTS / WARNINGS                                                │    │
│  │                                                                  │    │
│  │ ⚠️  SSL certificate expires in 23 days                          │    │
│  │ ⚠️  Disk usage above 80% threshold                              │    │
│  │ ℹ️  Update available: v1.2.4                                    │    │
│  └─────────────────────────────────────────────────────────────────┘    │
│                                                                         │
└─────────────────────────────────────────────────────────────────────────┘
```

### Dashboard Widgets

| Widget | Content |
|--------|---------|
| Status | Online/Maintenance/Error indicator |
| Uptime | Time since last restart |
| Requests | Request count (24h) |
| Errors | Error count (24h) |
| System Resources | CPU, Memory, Disk usage bars |
| Quick Actions | Common admin tasks |
| Recent Activity | Last 5-10 audit log entries |
| Scheduled Tasks | Next scheduled tasks |
| Alerts | Warnings and notifications |

### Required Admin Pages

| Route | Page | Description |
|-------|------|-------------|
| `/admin` | Login | Login form (if not authenticated) |
| `/admin/dashboard` | Dashboard | Overview, stats, quick actions |
| `/admin/server/settings` | Server Settings | Port, mode, FQDN, etc. |
| `/admin/server/branding` | Branding | Title, logo, favicon, colors |
| `/admin/server/ssl` | SSL/TLS | Certificates, Let's Encrypt |
| `/admin/server/scheduler` | Scheduler | View/edit scheduled tasks |
| `/admin/server/email` | Email | SMTP settings, templates |
| `/admin/server/logs` | Logs | View access, error, audit logs |
| `/admin/server/security/auth` | Authentication | Password, MFA, sessions |
| `/admin/server/security/tokens` | API Tokens | Generate, revoke tokens |
| `/admin/server/security/ratelimit` | Rate Limiting | Configure rate limits |
| `/admin/server/security/firewall` | Firewall | IP allow/block lists |
| `/admin/server/network/tor` | Tor | View .onion address, status (auto-enabled if installed) |
| `/admin/server/network/geoip` | GeoIP | Country blocking, database updates |
| `/admin/server/network/blocklists` | Blocklists | IP/domain blocklists |
| `/admin/server/moderation/users` | Users | User moderation (if multi-user) |
| `/admin/server/users/invites` | Invites | Invite codes (if multi-user) |
| `/admin/server/backup` | Backup | Create/restore backups |
| `/admin/server/maintenance` | Maintenance | Maintenance mode |
| `/admin/server/updates` | Updates | Check/apply updates |
| `/admin/server/info` | Server Info | Version, environment, deps |
| `/admin/server/cluster/nodes` | Nodes | Cluster node management |
| `/admin/server/cluster/add` | Add Node | Generate join token |
| `/admin/help` | Help | Documentation links |

### Settings Page Layout

**Standard layout for all settings pages.**

```
┌─────────────────────────────────────────────────────────────────────────┐
│ Server Settings                                              [Save All] │
├─────────────────────────────────────────────────────────────────────────┤
│                                                                         │
│  General                                                                │
│  ─────────────────────────────────────────────────────────────────────  │
│                                                                         │
│  Port                                                                   │
│  [64580        ]  ⓘ The port the server listens on                     │
│                   ⚠️ Requires restart                                   │
│                                                                         │
│  Mode                                                                   │
│  [Production ▼]   ⓘ Production enforces strict host validation         │
│                                                                         │
│  FQDN                                                                   │
│  [api.example.com]  ⓘ Fully qualified domain name (auto-detected)      │
│                                                                         │
│  ─────────────────────────────────────────────────────────────────────  │
│                                                                         │
│  Process                                                                │
│  ─────────────────────────────────────────────────────────────────────  │
│                                                                         │
│  Daemonize                                                              │
│  [○ Off]            ⓘ Detach from terminal on start (for manual start) │
│                     ⚠️ Requires restart. Don't use with systemd/docker. │
│                                                                         │
│  ─────────────────────────────────────────────────────────────────────  │
│                                                                         │
│  Advanced                                                    [Expand ▼] │
│  ─────────────────────────────────────────────────────────────────────  │
│                                                                         │
│                                                                         │
│  ┌─────────────────────────────────────────────────────────────────┐    │
│  │                                            [Cancel] [Save]      │    │
│  └─────────────────────────────────────────────────────────────────┘    │
│                                                                         │
└─────────────────────────────────────────────────────────────────────────┘
```

### Form Elements (NON-NEGOTIABLE)

| Element | Visual | Usage |
|---------|--------|-------|
| **Toggle** | `[● On]` / `[○ Off]` | Boolean on/off (preferred for enable/disable) |
| **Checkbox** | `[✓]` / `[ ]` | Boolean, multiple selections, opt-in features |
| **Dropdown** | `[Value ▼]` | Selection from predefined list |
| **Text** | `[value_____]` | Single-line string |
| **Number** | `[123_______]` | Numeric values (port, limit, count) |
| **Password** | `[••••••] 👁` | Secrets with show/hide toggle |
| **Textarea** | Multi-line box | JSON, lists, long text |
| **Tags** | `[tag1][tag2][+]` | Multiple values (IPs, keywords) |
| **File** | `[Choose File]` | Upload (logos, certs) |
| **Color** | `[#FF5733] 🎨` | Color picker |
| **Duration** | `[5] [minutes ▼]` | Time with unit dropdown |
| **Readonly** | `value (locked)` | Display only, not editable |

### Form Behavior

| Feature | Description |
|---------|-------------|
| Tooltips | ⓘ icon shows help on hover |
| Validation | Real-time, inline error messages |
| Unsaved indicator | Show when form has unsaved changes |
| Save feedback | Toast notification on save |
| Confirm dangerous | Modal for destructive actions |
| Restart warning | ⚠️ icon if setting requires restart |
| Default values | Show default in placeholder |
| Live reload | No ⚠️ = changes apply immediately |

### Server Settings Field Definitions

**`/admin/server/settings` - All fields with control types:**

#### General Section

| Setting | Control | Default | Restart | Description |
|---------|---------|---------|---------|-------------|
| `port` | Number | `64580` | ⚠️ Yes | Server listen port |
| `mode` | Dropdown | `production` | ⚠️ Yes | `production` / `development` |
| `fqdn` | Text | (auto) | No | Fully qualified domain name |
| `address` | Text | `[::]` | ⚠️ Yes | Listen address |

#### Process Section

| Setting | Control | Default | Restart | Description |
|---------|---------|---------|---------|-------------|
| `daemonize` | Toggle | Off | ⚠️ Yes | Detach from terminal on start |
| `pidfile` | Toggle | On | ⚠️ Yes | Create PID file |

#### Branding Section

| Setting | Control | Default | Restart | Description |
|---------|---------|---------|---------|-------------|
| `title` | Text | `casspeed` | No | App display name |
| `tagline` | Text | (empty) | No | Short slogan |
| `description` | Textarea | (empty) | No | SEO/about description |
| `logo` | File | (none) | No | Logo image upload |
| `favicon` | File | (none) | No | Favicon upload |
| `theme` | Dropdown | `auto` | No | `auto` / `light` / `dark` |
| `accent_color` | Color | `#007bff` | No | Primary accent color |

#### SEO Section

| Setting | Control | Default | Restart | Description |
|---------|---------|---------|---------|-------------|
| `keywords` | Tags | (empty) | No | Meta keywords |
| `author` | Text | (empty) | No | Author/org name |
| `og_image` | File | (none) | No | OpenGraph image |
| `twitter_handle` | Text | (empty) | No | Twitter @handle |

#### Security Section (`/admin/server/security`)

| Setting | Control | Default | Restart | Description |
|---------|---------|---------|---------|-------------|
| `rate_limit.enabled` | Toggle | On | No | Enable rate limiting |
| `rate_limit.requests` | Number | `120` | No | Requests per window |
| `rate_limit.window` | Duration | `1 minute` | No | Rate limit window |
| `cors.enabled` | Toggle | On | No | Enable CORS |
| `cors.origins` | Tags | `*` | No | Allowed origins |
| `cors.methods` | Checkbox group | GET,POST,etc | No | Allowed methods |
| `csp.enabled` | Toggle | On | No | Content Security Policy |
| `hsts.enabled` | Toggle | On | No | HTTP Strict Transport Security |
| `hsts.max_age` | Duration | `1 year` | No | HSTS max age |

#### Account Lockout Section

| Setting | Control | Default | Restart | Description |
|---------|---------|---------|---------|-------------|
| `soft_lock_attempts` | Number | `5` | No | Attempts before soft lock |
| `soft_lock_duration` | Duration | `15 min` | No | Soft lock duration |
| `hard_lock_attempts` | Number | `10` | No | Attempts before hard lock |
| `hard_lock_duration` | Duration | `1 hour` | No | Hard lock duration |
| `permanent_lock_attempts` | Number | `15` | No | Attempts before permanent lock |

#### IP Blocking Section

| Setting | Control | Default | Restart | Description |
|---------|---------|---------|---------|-------------|
| `ip_block.enabled` | Toggle | On | No | Enable IP blocking |
| `ip_block.escalation` | Toggle | On | No | Escalating block durations |
| `ip_block.first_duration` | Duration | `1 hour` | No | First block duration |
| `ip_block.max_duration` | Duration | `7 days` | No | Maximum block duration |
| `allowlist` | Tags | (empty) | No | IPs never blocked |
| `blocklist` | Tags | (empty) | No | IPs always blocked |

#### SSL/TLS Section (`/admin/server/security/ssl`)

| Setting | Control | Default | Restart | Description |
|---------|---------|---------|---------|-------------|
| `ssl.enabled` | Toggle | Off | ⚠️ Yes | Enable HTTPS |
| `ssl.cert` | File/Text | (auto) | ⚠️ Yes | Certificate path or upload |
| `ssl.key` | File/Text | (auto) | ⚠️ Yes | Private key path or upload |
| `ssl.min_version` | Dropdown | `TLS 1.2` | ⚠️ Yes | Minimum TLS version |
| `ssl.letsencrypt.enabled` | Toggle | Off | No | Use Let's Encrypt |
| `ssl.letsencrypt.email` | Text | (required) | No | Contact email |
| `ssl.letsencrypt.staging` | Toggle | Off | No | Use LE staging server |
| `ssl.letsencrypt.challenge` | Dropdown | `http-01` | No | Challenge type |

#### Authentication Section (`/admin/server/security/auth`)

| Setting | Control | Default | Restart | Description |
|---------|---------|---------|---------|-------------|
| `session.timeout` | Duration | `24 hours` | No | Session expiry |
| `session.extend_on_activity` | Toggle | On | No | Extend on activity |
| `mfa.enabled` | Toggle | Off | No | Require MFA for admins |
| `mfa.methods` | Checkbox group | TOTP | No | Allowed MFA methods |
| `password.min_length` | Number | `8` | No | Minimum password length |
| `password.require_uppercase` | Toggle | On | No | Require uppercase |
| `password.require_number` | Toggle | On | No | Require number |
| `password.require_special` | Toggle | Off | No | Require special char |

#### Backup Section (`/admin/server/backup`)

| Setting | Control | Default | Restart | Description |
|---------|---------|---------|---------|-------------|
| `backup.enabled` | Toggle | On | No | Enable scheduled backups |
| `backup.schedule` | Text | `0 2 * * *` | No | Cron schedule |
| `backup.retention.max_backups` | Number | `4` | No | Max backups to keep |
| `backup.retention.policy` | Dropdown | `count` | No | `count`/`days`/`weeks` |
| `backup.encryption.enabled` | Toggle | Off | No | Encrypt backups |
| `backup.encryption.password` | Password | (none) | No | Encryption password |

#### Email/SMTP Section (`/admin/server/email`)

| Setting | Control | Default | Restart | Description |
|---------|---------|---------|---------|-------------|
| `smtp.host` | Text | (autodetect) | No | SMTP server |
| `smtp.port` | Number | `587` | No | SMTP port |
| `smtp.username` | Text | (none) | No | SMTP username |
| `smtp.password` | Password | (none) | No | SMTP password |
| `smtp.tls` | Dropdown | `auto` | No | `auto`/`starttls`/`tls`/`none` |
| `from.name` | Text | (app title) | No | Sender name |
| `from.email` | Text | `no-reply@{fqdn}` | No | Sender email |
| `[Test Connection]` | Button | - | - | Send test email |

#### Notifications Section (`/admin/server/notifications`)

| Setting | Control | Default | Restart | Description |
|---------|---------|---------|---------|-------------|
| `notifications.backup_success` | Toggle | Off | No | Notify on backup success |
| `notifications.backup_failure` | Toggle | On | No | Notify on backup failure |
| `notifications.ssl_expiring` | Toggle | On | No | Notify SSL expiring |
| `notifications.ssl_expiring_days` | Number | `14` | No | Days before expiry |
| `notifications.security_alerts` | Toggle | On | No | Security event alerts |
| `notifications.update_available` | Toggle | On | No | New version available |

#### Scheduler Section (`/admin/server/scheduler`)

| Setting | Control | Default | Restart | Description |
|---------|---------|---------|---------|-------------|
| `scheduler.enabled` | Toggle | On | No | Enable scheduler |
| Task rows with: | | | | |
| - Task name | Readonly | - | - | Task identifier |
| - Enabled | Toggle | varies | No | Enable/disable task |
| - Schedule | Text | cron expr | No | Cron expression |
| - Last run | Readonly | timestamp | - | Last execution |
| - Next run | Readonly | timestamp | - | Next execution |
| - `[Run Now]` | Button | - | - | Trigger immediately |

#### URL Detection Section (`/admin/server/url`)

| Setting | Control | Default | Restart | Description |
|---------|---------|---------|---------|-------------|
| `url_detection.learning` | Toggle | On | No | Learn domain patterns |
| `url_detection.min_samples` | Number | `3` | No | Min samples for wildcard |
| `url_detection.sample_window` | Duration | `5 min` | No | Sample time window |
| `url_detection.log_changes` | Toggle | On | No | Log domain changes |
| `url_detection.live_reload` | Toggle | On | No | Live reload on detection |
| Detected domains | Readonly | - | - | Currently detected FQDNs |
| Inferred wildcard | Readonly | - | - | `*.example.com` if detected |

#### Tor Section (`/admin/server/tor`) - *if tor installed*

| Setting | Control | Default | Restart | Description |
|---------|---------|---------|---------|-------------|
| `tor.enabled` | Toggle | (auto) | No | Enable hidden service |
| `tor.onion_address` | Readonly | - | - | `.onion` address |
| `tor.status` | Readonly | - | - | Running/Stopped |
| `[Copy Address]` | Button | - | - | Copy onion to clipboard |

#### GeoIP Section (`/admin/server/geoip`)

| Setting | Control | Default | Restart | Description |
|---------|---------|---------|---------|-------------|
| `geoip.enabled` | Toggle | On | No | Enable GeoIP lookups |
| `geoip.auto_update` | Toggle | On | No | Auto-update databases |
| `geoip.update_schedule` | Text | `0 3 * * *` | No | Update cron schedule |
| `geoip.country_block` | Tags | (empty) | No | Blocked country codes |
| `geoip.country_allow` | Tags | (empty) | No | Allowed country codes |
| Database status | Readonly | - | - | Last update, size |

### Control Type Guidelines

| When to use | Control |
|-------------|---------|
| Enable/disable feature | **Toggle** |
| Yes/no with label | **Checkbox** |
| Multiple options (2-5) | **Dropdown** |
| Multiple options (5+) | **Searchable dropdown** |
| Select multiple | **Checkbox group** or **Tags** |
| Free text, short | **Text** |
| Free text, long | **Textarea** |
| Number with constraints | **Number** (with min/max) |
| Secret value | **Password** |
| Time period | **Duration** (number + unit dropdown) |
| List of values | **Tags** |
| File upload | **File** |
| Read-only info | **Readonly** |
| Trigger action | **Button** |

### Log Viewer (`/admin/server/logs`)

```
┌─────────────────────────────────────────────────────────────────────────┐
│ Logs                                                                     │
├─────────────────────────────────────────────────────────────────────────┤
│                                                                         │
│  [Access ▼]  [Last 100 ▼]  [Search...        ]  [Auto-refresh: ON]     │
│                                                                         │
│  ┌─────────────────────────────────────────────────────────────────┐    │
│  │ 2025-01-15 10:30:45  GET  /api/v1/health  200  12ms  192.168.1.1│    │
│  │ 2025-01-15 10:30:44  POST /api/v1/data    201  45ms  192.168.1.2│    │
│  │ 2025-01-15 10:30:43  GET  /healthz        200  2ms   192.168.1.1│    │
│  │ 2025-01-15 10:30:42  GET  /api/v1/users   401  5ms   10.0.0.50  │    │
│  │ ...                                                              │    │
│  └─────────────────────────────────────────────────────────────────┘    │
│                                                                         │
│  [< Prev]  Page 1 of 50  [Next >]           [Download] [Clear Logs]    │
│                                                                         │
└─────────────────────────────────────────────────────────────────────────┘
```

### Log Types

| Log | Description |
|-----|-------------|
| Access | HTTP request logs |
| Error | Application errors |
| Audit | Security/admin events |
| Security | Auth failures, blocked IPs |
| Debug | Debug output (dev mode) |

### Keyboard Shortcuts

| Shortcut | Action |
|----------|--------|
| `g d` | Go to Dashboard |
| `g s` | Go to Settings |
| `g l` | Go to Logs |
| `/` | Focus search |
| `Esc` | Close modal/menu |
| `Ctrl+S` | Save current form |
| `?` | Show shortcuts help |

## /admin Authentication Flow

```
User visits /admin
       │
       ▼
Check for valid admin session
       │
       ├─► No session/expired
       │   │
       │   ▼
       │   Show login form
       │   │
       │   ▼
       │   User submits credentials
       │   │
       │   ▼
       │   Validate against admins table
       │   │
       │   ├─► Invalid: Show error, log attempt
       │   │
       │   └─► Valid credentials
       │       │
       │       ▼
       │       Check if 2FA enabled (TOTP or Passkey)
       │       │
       │       ├─► No 2FA: Create session, redirect to dashboard
       │       │
       │       └─► 2FA enabled
       │           │
       │           ▼
       │           Show 2FA prompt (TOTP code or Passkey)
       │           │
       │           ├─► Invalid: Show error, allow retry
       │           │
       │           └─► Valid: Create session, redirect to dashboard
       │
       └─► Valid session
           │
           ▼
           Show requested admin page
```

## Admin Session vs User Session

| Aspect | Admin Session | User Session |
|--------|---------------|--------------|
| Cookie name | `admin_session` | `user_session` |
| Valid routes | `/admin/**` only | `/**` except `/admin/**` |
| Stored in | `server.db` (admin_sessions) | `users.db` (user_sessions) |
| Credentials | `admins` table | `users` table |
| Default duration | 30 days | 7 days |
| MFA | Optional (TOTP) | Optional (TOTP) |

### Scheduler Management (Admin Panel)

The admin panel MUST include a scheduler section with:

| Feature | Description |
|---------|-------------|
| **Task List** | View all scheduled tasks with status |
| **Next Run** | Show next scheduled run time for each task |
| **Last Run** | Show last run time and result (success/failure) |
| **Run History** | View history of past runs with timestamps |
| **Manual Trigger** | Button to manually run any task |
| **Enable/Disable** | Toggle tasks on/off |
| **Edit Schedule** | Modify task frequency (cron-style or preset) |
| **Task Details** | View task configuration and logs |

**Preset Schedules:**
- `hourly` - Every hour
- `daily` - Once per day (configurable time)
- `weekly` - Once per week (configurable day/time)
- `monthly` - Once per month (configurable day/time)
- `custom` - Cron expression

## /api/v1/admin (REST API)

### Authentication

`Authorization: Bearer {token}`

### Required Endpoints

| Endpoint | Method | Description |
|----------|--------|-------------|
| `/api/v1/admin/server/settings` | GET | Get server settings |
| `/api/v1/admin/server/settings` | PATCH | Update server settings |
| `/api/v1/admin/server/status` | GET | Server status |
| `/api/v1/admin/server/health` | GET | Detailed health |
| `/api/v1/admin/server/stats` | GET | Statistics |
| `/api/v1/admin/server/logs/access` | GET | Access logs |
| `/api/v1/admin/server/logs/error` | GET | Error logs |
| `/api/v1/admin/server/backup` | POST | Create backup |
| `/api/v1/admin/server/backup/restore` | POST | Restore backup |
| `/api/v1/admin/server/email/test` | POST | Send test email |
| `/api/v1/admin/profile/password` | POST | Change admin password |
| `/api/v1/admin/profile/token` | POST | Regenerate API token |

---


# PART 20: API STRUCTURE (NON-NEGOTIABLE)

**Note:** This section covers API structure and requirements. For specific route listings, see:
- Admin Web Routes: PART 18 (Admin Panel)
- Admin API Routes: PART 18 (Admin Panel → API Routes)
- Project-specific Routes: PART 36 (Project-Specific Sections)

## API Versioning

**Use versioned API: `/api/v1`**

## URL Parameters (NON-NEGOTIABLE)

**Prefer path parameters over query parameters.**

| Parameter Type | Use When | Example |
|----------------|----------|---------|
| **Path params** | Identifying a resource | `/api/v1/users/{id}`, `/api/v1/jokes/{category}` |
| **Query params** | Filtering, sorting, pagination | `?page=2&limit=10&sort=date` |

**Path Parameters (Preferred):**
```
GET /api/v1/users/123              ✓ Good - resource ID in path
GET /api/v1/jokes/programming      ✓ Good - category in path
GET /api/v1/search/golang          ✓ Good - search term in path

GET /api/v1/users?id=123           ✗ Bad - should be path param
GET /api/v1/jokes?category=prog    ✗ Bad - should be path param
```

**Query Parameters (When Needed):**
```
GET /api/v1/users?page=2&limit=10          ✓ Pagination
GET /api/v1/jokes?sort=rating&order=desc   ✓ Sorting
GET /api/v1/search/golang?safe=true        ✓ Filtering/options
GET /api/v1/users?status=active&role=admin ✓ Multiple filters
```

**Rules:**
| Rule | Description |
|------|-------------|
| **Resource identity → path** | IDs, slugs, categories in URL path |
| **Modifiers → query** | Pagination, sorting, filtering as query params |
| **No redundancy** | Don't duplicate path params as query params |
| **Clean URLs** | Prefer `/jokes/random` over `/jokes?type=random` |

## Response Formatting (NON-NEGOTIABLE)

**ALL responses and ALL code MUST be properly formatted.**

### Universal Formatting Rules

**These rules apply to EVERYTHING: responses, code files, templates, configs.**

| Rule | Applies To | Requirement |
|------|-----------|-------------|
| **Single trailing newline** | JSON, TXT, HTML, XML, YAML, Go, all files | End with exactly one `\n` |
| **2-space indentation** | HTML, JSON, YAML, JavaScript, CSS | Use 2 spaces per level |
| **Tab indentation** | Go code, Makefiles | Use tabs where required by language |
| **Proper nesting** | All structured formats | Each level indented correctly |
| **No trailing whitespace** | All files | No spaces/tabs at end of lines |

### JSON Formatting (API Responses)

```go
// ALL JSON responses MUST be indented and end with newline
data, _ := json.MarshalIndent(response, "", "  ")  // 2-space indent
w.Header().Set("Content-Type", "application/json")
w.Write(data)
w.Write([]byte("\n"))  // Single trailing newline
```

**Output:**
```json
{
  "id": "123",
  "name": "Test User",
  "items": [
    {
      "id": "1"
    }
  ]
}
⏎
```

### Text Formatting (TXT Responses)

```go
// ALL text responses MUST end with single newline
w.Header().Set("Content-Type", "text/plain; charset=utf-8")
fmt.Fprintf(w, "%s\n", text)  // Single trailing newline
```

**Output:**
```
This is the response text.
⏎
```

### HTML Formatting (Frontend Responses)

```go
// ALL HTML MUST be indented with 2 spaces and end with newline
```

**Output:**
```html
<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Page Title</title>
  </head>
  <body>
    <div class="container">
      <h1>Heading</h1>
      <p>Paragraph text here.</p>
      <ul>
        <li>Item 1</li>
        <li>Item 2</li>
      </ul>
    </div>
  </body>
</html>
⏎
```

### YAML Formatting (Config Files)

```yaml
# 2-space indentation, single trailing newline
server:
  address: 0.0.0.0
  port: 80

  users:
    enabled: false
    registration:
      mode: disabled
⏎
```

### Go Code Formatting

```go
// Use tabs for indentation (gofmt standard)
func Handler(w http.ResponseWriter, r *http.Request) {
	// Tab indent
	if err := validate(r); err != nil {
		// Tab indent
		http.Error(w, "Invalid", 400)
		return
	}

	// Response
	fmt.Fprintf(w, "OK\n")
}
⏎
```

### CSS Formatting

```css
/* 2-space indentation */
.container {
  width: 90%;
  max-width: 1400px;
  margin: 0 auto;
}

@media (min-width: 720px) {
  .container {
    width: 98%;
  }
}
⏎
```

### JavaScript Formatting

```javascript
// 2-space indentation
function handleClick(event) {
  event.preventDefault();

  const data = {
    id: 123,
    name: "test"
  };

  fetch('/api/v1/users', {
    method: 'POST',
    body: JSON.stringify(data)
  });
}
⏎
```

### Formatting Rules Summary

**Indentation:**
- **2 spaces**: HTML, JSON, YAML, CSS, JavaScript
- **Tabs**: Go code, Makefiles
- **NEVER mix**: Use consistent indentation throughout file

**Newlines:**
- **Every file**: Ends with exactly one newline
- **Every response**: Ends with exactly one newline
- **No extra blank lines**: At end of files/responses

**Validation:**
```bash
# Check file ends with single newline
tail -c 2 file.txt | od -An -tx1
# Should show: '0a' (one newline) or 'XX 0a' (char + newline)
# Should NOT show: '0a 0a' (two newlines) or no '0a' (no newline)
```

## Content Negotiation (NON-NEGOTIABLE)

**All endpoints respond based on how they are accessed.**

### Accept Header Detection

| Accept Header | Response Format |
|---------------|-----------------|
| `text/html` | HTML (full page or fragment) |
| `application/json` | JSON |
| `text/plain` | Plain text |
| `*/*` or missing | Default for endpoint type |

### Response by Endpoint Type

| Endpoint | Default | Browser | curl/CLI | API Client |
|----------|---------|---------|----------|------------|
| `/` (public pages) | HTML | HTML | HTML | HTML |
| `/admin/*` | HTML | HTML | HTML | HTML |
| `/api/v1/*` | JSON | JSON | JSON | JSON |
| `/healthz` | HTML | HTML | Text | JSON (if Accept: application/json) |
| `*.txt` extension | Text | Text | Text | Text |

### Smart Content Negotiation (NON-NEGOTIABLE)

**Frontend routes (`/**`) have BUILT-IN smart detection:**
- Browser request → HTML
- CLI/curl → text (via User-Agent or lack of browser headers)
- Accept: text/plain → text
- Accept: text/html → HTML

**Frontend routes do NOT need `.txt` extension - smart detection handles it.**

### The `.txt` Extension for API Routes (NON-NEGOTIABLE)

**ALL API endpoints MUST support `.txt` extension for simplicity.**

**`.txt` extension is ONLY for API routes:**
- ✓ ALL `/api/v1/*` endpoints
- ✓ Health API endpoints (`/api/v1/healthz`)
- ✓ Project-specific API endpoints
- ✓ Admin API endpoints (`/api/v1/admin/*`)

**Frontend routes (`/**`) do NOT use `.txt` extension - they use smart detection instead.**

**API Routes (support .txt extension):**

| Endpoint | Default | With `.txt` | Smart Detection |
|----------|---------|-------------|-----------------|
| `/api/v1/jokes/random` | JSON | Plain text | Accept: text/plain → text |
| `/api/v1/healthz` | JSON | Plain text | Accept: text/plain → text |
| `/api/v1/status` | JSON | Plain text | Accept: text/plain → text |
| `/api/v1/users/123` | JSON | Plain text | Accept: text/plain → text |

**Frontend Routes (smart detection only, no .txt extension):**

| Endpoint | Browser | CLI/curl | Accept: text/plain | Accept: text/html |
|----------|---------|----------|-------------------|-------------------|
| `/jokes/random` | HTML | Text | Text | HTML |
| `/users/123` | HTML | Text | Text | HTML |
| `/healthz` | HTML | Text | Text | HTML |
| `/` | HTML | Text | Text | HTML |

**Use cases:**

**API with `.txt` extension:**
- `curl https://api.example.com/api/v1/joke/random.txt` → Just the joke text
- `curl https://api.example.com/api/v1/healthz.txt` → "OK" or "ERROR: ..."
- Scripts that need plain output without JSON parsing

**Frontend with smart detection:**
- `curl https://example.com/joke/random` → Auto-detects CLI, returns text (no .txt needed)
- `curl -H "Accept: text/plain" https://example.com/users/123` → Plain text
- Browser visit to `/joke/random` → HTML page
- Command-line tools get text automatically

**Testing:** Test scripts MUST verify:
- API `.txt` extension works
- Frontend smart detection works (browser → HTML, CLI → text)
- Accept headers work on both API and frontend (see PART 13: Testing)

### Content Negotiation Priority (NON-NEGOTIABLE)

**For API routes (`/api/v1/*`), response format is determined in this order:**

| Priority | Method | Example | Returns |
|----------|--------|---------|---------|
| **1** | `.txt` extension | `/api/v1/joke.txt` | Plain text (ALWAYS) |
| **2** | `Accept: application/json` header | `Accept: application/json` | JSON |
| **3** | `Accept: text/plain` header | `Accept: text/plain` | Plain text |
| **4** | Default | `/api/v1/joke` | JSON |

**For frontend routes (`/**`), response format is determined in this order:**

| Priority | Method | Example | Returns |
|----------|--------|---------|---------|
| **1** | `Accept: text/html` header | `Accept: text/html` | HTML |
| **2** | `Accept: text/plain` header | `Accept: text/plain` | Plain text |
| **3** | User-Agent (browser detection) | Browser visit | HTML |
| **4** | CLI/curl (no browser UA) | `curl /joke` | Plain text |
| **5** | Default | Any request | HTML |

**Summary:**
- API routes: Support .txt extension + Accept headers + smart defaults
- Frontend routes: Smart detection only (User-Agent + Accept headers)
- No .txt extension needed on frontend - smart detection handles it

### Content Negotiation Implementation

```go
func detectResponseFormat(r *http.Request) string {
    // 1. Check for .txt extension
    if strings.HasSuffix(r.URL.Path, ".txt") {
        return "text/plain"
    }

    // 2. Check Accept header
    accept := r.Header.Get("Accept")

    switch {
    case strings.Contains(accept, "application/json"):
        return "application/json"
    case strings.Contains(accept, "text/plain"):
        return "text/plain"
    case strings.Contains(accept, "text/html"):
        return "text/html"
    default:
        // 3. Default based on endpoint
        if strings.HasPrefix(r.URL.Path, "/api/") {
            return "application/json"
        }
        return "text/html"
    }
}
```

### Response Examples

**JSON (default for `/api/*`):**
```json
{
  "joke": "Why do programmers prefer dark mode? Because light attracts bugs.",
  "category": "programming",
  "id": "joke_123"
}
```

**Text (`.txt` extension or `Accept: text/plain`):**
```
Why do programmers prefer dark mode? Because light attracts bugs.
```

**HTML (browser request):**
```html
<!DOCTYPE html>
<html>
<head><title>Random Joke</title></head>
<body>
  <p>Why do programmers prefer dark mode? Because light attracts bugs.</p>
</body>
</html>
```

## API Types

**ALL PROJECTS GET ALL THREE:**

| Type | Required |
|------|----------|
| REST API | YES (primary) |
| Swagger/OpenAPI | YES |
| GraphQL | YES |

### Swagger & GraphQL Sync (NON-NEGOTIABLE)

**Swagger and GraphQL MUST always be in sync with each other AND with the project's API.**

| Rule | Description |
|------|-------------|
| **Sync with project** | Both MUST reflect current project API at all times |
| **Sync with each other** | Both Swagger and GraphQL expose identical functionality |
| **Auto-generated** | Both specs generated from code (annotations, comments, or schema) |
| **Never manual** | NEVER manually edit OpenAPI JSON or GraphQL schema |
| **Build-time generation** | Specs regenerated on every build |
| **JSON only** | OpenAPI spec uses JSON format only (NO YAML) |
| **Single source of truth** | Code is the source, specs are generated output |
| **Match site theme** | Both UIs styled to match site theme (light/dark/auto) |
| **Standardized locations** | ALWAYS `src/swagger/` and `src/graphql/` (NEVER in root `.`) |

**Standardized File Locations (NON-NEGOTIABLE):**

| Component | Location | Never Use |
|-----------|----------|-----------|
| Swagger handler | `src/swagger/swagger.go` | `./swagger.go`, `swagger/swagger.go` |
| Swagger theming | `src/swagger/theme.go` | `./theme.go`, `public/swagger-theme.css` |
| Swagger annotations | `src/swagger/annotations.go` | `./docs/`, anywhere else |
| GraphQL handler | `src/graphql/graphql.go` | `./graphql.go`, `graphql/graphql.go` |
| GraphQL schema | `src/graphql/schema.go` | `./schema.graphql`, `graph/schema.graphqls` |
| GraphQL resolvers | `src/graphql/resolvers.go` | `./resolvers.go`, anywhere else |
| GraphQL theming | `src/graphql/theme.go` | `./theme.go`, `public/graphql-theme.css` |

**All paths MUST be relative to `src/` directory. Files in project root (`.`) are FORBIDDEN.**

**Sync Flow:**
```
Code Changes (handlers, routes, types)
         │
         ▼
Build Process
         │
         ├──► src/swagger/swagger.go → Generate OpenAPI JSON from code annotations
         │
         └──► src/graphql/schema.go → Generate GraphQL schema from code annotations
         │
         ▼
Both specs automatically in sync with project
```

**Implementation:**
- Use Go struct tags and comments for documentation
- Generate OpenAPI spec at build time (e.g., swaggo/swag)
- Generate GraphQL schema from same structs
- Embed generated specs in binary
- Serve at runtime from embedded files
- All implementation files in `src/swagger/` and `src/graphql/`

**Why both?**
- Swagger: Industry standard, tooling support, code generation
- GraphQL: Flexible queries, reduced over-fetching, modern clients

**NEVER:**
- Manually edit `openapi.json`
- Manually edit GraphQL schema files
- Let specs drift from actual API
- Have endpoints not documented in both
- Put swagger/graphql files in project root (`.`)
- Use relative paths from project root

### Swagger & GraphQL Theming (NON-NEGOTIABLE)

**Both Swagger UI and GraphiQL MUST match the PROJECT-WIDE theme system.**

See the **"Themes (NON-NEGOTIABLE - PROJECT-WIDE)"** section for the complete theme system that applies to the entire project, including Swagger and GraphQL.

**Key Points:**
- Swagger/GraphQL UIs automatically use the same theme as the rest of the application
- Theme switching is synchronized across all components (no page reload)
- BOTH light AND dark themes MUST be easy to read with no color conflicts
- File locations: `src/swagger/theme.go` and `src/graphql/theme.go`

---

**Dark Theme - DEFAULT:**

**Color Palette:**
```css
/* Dark Theme Colors */
--dark-bg: #282a36;           /* Background */
--dark-bg-alt: #1e1f29;       /* Alternate background (topbar, etc.) */
--dark-bg-elevated: #44475a;  /* Elevated elements (inputs, buttons) */
--dark-text: #f8f8f2;         /* Primary text */
--dark-text-muted: #6272a4;   /* Muted text, borders */
--dark-accent-cyan: #8be9fd;  /* Links, GET methods */
--dark-accent-green: #50fa7b; /* Success, POST methods */
--dark-accent-orange: #ffb86c; /* Warning, PUT methods */
--dark-accent-red: #ff5555;   /* Error, DELETE methods */
--dark-accent-purple: #bd93f9; /* Primary accent */
--dark-accent-pink: #ff79c6;  /* Secondary accent */
--dark-accent-yellow: #f1fa8c; /* Highlights */
```

| Element | Style |
|---------|-------|
| Background | `#282a36` (--dark-bg) |
| Text | `#f8f8f2` (--dark-text) |
| Links/Accents | Cyan `#8be9fd`, Green `#50fa7b`, Purple `#bd93f9` |
| Code blocks | Syntax highlighted with dark theme colors |
| Inputs | Dark background `#44475a`, light text `#f8f8f2`, visible borders `#6272a4` |
| Buttons | Accent colors from dark palette |

**Swagger UI - Dark Theme:**

```css
/* Swagger UI - Dark Theme */
.swagger-ui.theme-dark {
  background: #282a36;
  color: #f8f8f2;
}

.swagger-ui.theme-dark .topbar {
  background: #1e1f29;
}

.swagger-ui.theme-dark .info .title,
.swagger-ui.theme-dark .opblock-tag {
  color: #f8f8f2;
}

.swagger-ui.theme-dark .opblock.opblock-get {
  background: rgba(139, 233, 253, 0.1);
  border-color: #8be9fd;
}

.swagger-ui.theme-dark .opblock.opblock-post {
  background: rgba(80, 250, 123, 0.1);
  border-color: #50fa7b;
}

.swagger-ui.theme-dark .opblock.opblock-put {
  background: rgba(255, 184, 108, 0.1);
  border-color: #ffb86c;
}

.swagger-ui.theme-dark .opblock.opblock-delete {
  background: rgba(255, 85, 85, 0.1);
  border-color: #ff5555;
}

.swagger-ui.theme-dark input,
.swagger-ui.theme-dark textarea,
.swagger-ui.theme-dark select {
  background: #44475a;
  color: #f8f8f2;
  border: 1px solid #6272a4;
}

.swagger-ui.theme-dark .btn {
  background: #6272a4;
  color: #f8f8f2;
}
```

**GraphiQL - Dark Theme:**

```css
/* GraphiQL - Dark Theme */
.graphiql-container.theme-dark {
  background: #282a36;
  color: #f8f8f2;
}

.graphiql-container.theme-dark .CodeMirror {
  background: #282a36;
  color: #f8f8f2;
}

.graphiql-container.theme-dark .CodeMirror-gutters {
  background: #1e1f29;
  border-right: 1px solid #44475a;
}

.graphiql-container.theme-dark .result-window {
  background: #282a36;
}

.graphiql-container.theme-dark .execute-button {
  background: #50fa7b;
  color: #282a36;
}

.graphiql-container.theme-dark .toolbar-button {
  background: #44475a;
  color: #f8f8f2;
}
```

---

**Light Theme:**

**Color Palette:**
```css
/* Light Theme Colors */
--light-bg: #ffffff;           /* Background */
--light-bg-alt: #f5f5f5;       /* Alternate background (topbar, etc.) */
--light-bg-elevated: #e0e0e0;  /* Elevated elements, borders */
--light-text: #1a1a1a;         /* Primary text */
--light-text-muted: #666666;   /* Muted text */
--light-accent-blue: #0066cc;  /* Links, GET methods */
--light-accent-green: #008000; /* Success, POST methods */
--light-accent-orange: #ff8c00; /* Warning, PUT methods */
--light-accent-red: #cc0000;   /* Error, DELETE methods */
--light-accent-purple: #6600cc; /* Primary accent */
--light-accent-teal: #008080;  /* Secondary accent */
```

| Element | Style |
|---------|-------|
| Background | `#ffffff` (--light-bg) |
| Text | `#1a1a1a` (--light-text) |
| Links/Accents | Blue `#0066cc`, Green `#008000`, Purple `#6600cc` |
| Code blocks | Syntax highlighted with light theme colors |
| Inputs | White background, dark text, visible borders `#cccccc` |
| Buttons | Accent colors with sufficient contrast (4.5:1 minimum) |

**Swagger UI - Light Theme:**

```css
/* Swagger UI - Light Theme */
.swagger-ui.theme-light {
  background: #ffffff;
  color: #1a1a1a;
}

.swagger-ui.theme-light .topbar {
  background: #f5f5f5;
  border-bottom: 1px solid #e0e0e0;
}

.swagger-ui.theme-light .info .title,
.swagger-ui.theme-light .opblock-tag {
  color: #1a1a1a;
}

.swagger-ui.theme-light .opblock.opblock-get {
  background: rgba(0, 102, 204, 0.05);
  border-color: #0066cc;
}

.swagger-ui.theme-light .opblock.opblock-post {
  background: rgba(0, 128, 0, 0.05);
  border-color: #008000;
}

.swagger-ui.theme-light .opblock.opblock-put {
  background: rgba(255, 140, 0, 0.05);
  border-color: #ff8c00;
}

.swagger-ui.theme-light .opblock.opblock-delete {
  background: rgba(204, 0, 0, 0.05);
  border-color: #cc0000;
}

.swagger-ui.theme-light input,
.swagger-ui.theme-light textarea,
.swagger-ui.theme-light select {
  background: #ffffff;
  color: #1a1a1a;
  border: 1px solid #cccccc;
}

.swagger-ui.theme-light .btn {
  background: #0066cc;
  color: #ffffff;
}
```

**GraphiQL - Light Theme:**

```css
/* GraphiQL - Light Theme */
.graphiql-container.theme-light {
  background: #ffffff;
  color: #1a1a1a;
}

.graphiql-container.theme-light .CodeMirror {
  background: #ffffff;
  color: #1a1a1a;
}

.graphiql-container.theme-light .CodeMirror-gutters {
  background: #f5f5f5;
  border-right: 1px solid #e0e0e0;
}

.graphiql-container.theme-light .result-window {
  background: #ffffff;
}

.graphiql-container.theme-light .execute-button {
  background: #008000;
  color: #ffffff;
}

.graphiql-container.theme-light .toolbar-button {
  background: #f5f5f5;
  color: #1a1a1a;
  border: 1px solid #cccccc;
}
```

---

**Theme Implementation Requirements:**

1. **Theme Detection:**
   - Check `localStorage` or cookie for user preference
   - Fall back to `prefers-color-scheme` media query if auto mode
   - Default to dark if no preference set

2. **Theme Switching:**
   - Provide theme toggle in UI (light/dark/auto)
   - Store preference in `localStorage` or cookie
   - Apply theme class to root element (`theme-light`, `theme-dark`)
   - NO page reload required

3. **Accessibility:**
   - Both themes MUST pass WCAG AA contrast requirements
   - Focus indicators MUST be visible in both themes
   - Keyboard navigation MUST work identically in both themes

## External API Compatibility (NON-NEGOTIABLE)

**Focus on create/init endpoint compatibility and response format matching - NOT replicating entire APIs.**

When the user requests compatibility with external services (e.g., "compatible with pastebin.com", "support microbin clients", "work with opengist"), you MUST focus on **creation endpoints and response formats** - not hundreds of redundant routes.

### Why Limited Compatibility?

**Problem:** Replicating entire external APIs creates hundreds of routes that do mostly the same thing, adding massive complexity for minimal benefit.

**Solution:** Implement ONLY the create/init endpoints and match response formats. This allows existing clients to work while keeping our codebase clean.

### Compatibility Implementation (NON-NEGOTIABLE)

**1. Research the target service:**
   - Look up official API documentation
   - Identify the **create/init endpoint** (how resources are created)
   - Document the **response format** (fields, structure, content-type: JSON/XML/text)
   - Note required request parameters and authentication (if any)

**2. Implement create/init compatibility:**
   - Match the exact URL path for creating resources
   - Support same request method (POST, PUT, etc.)
   - Accept same parameters (query params, form fields, JSON body)
   - Return response in same format with matching field names
   - Preserve response content-type (JSON, XML, plain text, etc.)

**3. Use our standard routes for everything else:**
   - View: Use our standard `/api/v1/{resource}/{id}` pattern
   - List: Use our standard `/api/v1/{resource}` pattern
   - Search: Use our standard `/api/v1/{resource}/search` pattern
   - DO NOT replicate their entire API surface

**Example - Pastebin Compatibility:**

```
User: "Make it compatible with pastebin.com"

AI Research:
- Create endpoint: POST /api/api_post.php
- Parameters: api_paste_code, api_paste_format, api_paste_expire_date
- Response: Plain text paste ID or URL

AI Implementation:
✓ POST /api/api_post.php → Create paste (compatible)
✓ Response format matches (plain text ID)
✗ Skip their /api/list, /api/trends, /api/raw/{id} (use our routes instead)

Result:
- pastebin.com clients can CREATE pastes using familiar endpoint
- Viewing/listing uses OUR standard API routes
- Clean codebase without route duplication
```

**Rules:**
| Rule | Description |
|------|-------------|
| **Research first** | NEVER guess - look up actual API documentation |
| **Create/init only** | Implement creation endpoints, skip view/list/search/delete duplicates |
| **Match response format** | Field names, structure, content-type must match target exactly |
| **Standard routes for rest** | Use our `/api/v1/*` patterns for all other operations |
| **Avoid complexity** | Do NOT add hundreds of redundant routes |
| **Document compatibility** | List what IS and ISN'T compatible in AI.md |

**What to implement:**
- ✓ Create/init endpoints
- ✓ Response format matching
- ✓ Required authentication if applicable

**What NOT to implement:**
- ✗ View/retrieve endpoints (use our routes)
- ✗ List/search endpoints (use our routes)
- ✗ Delete endpoints (use our routes)
- ✗ Pagination variants (use our standard pagination)
- ✗ Any route that duplicates our functionality

### RFC-Based Applications (CRITICAL - NON-NEGOTIABLE)

**IF THE APPLICATION ITSELF IMPLEMENTS AN RFC-DEFINED PROTOCOL, YOU MUST FOLLOW ALL RELEVANT RFCs COMPLETELY.**

This is NOT optional. This is NOT about "adding compatibility." If you're building a protocol implementation, you MUST be RFC-compliant or the application is fundamentally broken.

| Application Type | Required RFCs | Compliance Level |
|------------------|---------------|------------------|
| **DNS Server** | RFC 1034, 1035, 2181, 6891 (EDNS), etc. | FULL - ALL DNS RFCs |
| **DHCP Server** | RFC 2131, 2132, 3046, etc. | FULL - ALL DHCP RFCs |
| **SMTP Server** | RFC 5321, 5322, 6531, etc. | FULL - ALL SMTP RFCs |
| **HTTP Server** | RFC 7230-7235, 9110-9114, etc. | FULL - ALL HTTP RFCs |
| **FTP Server** | RFC 959, 2428, 4217, etc. | FULL - ALL FTP RFCs |
| **NTP Server** | RFC 5905, 5906, etc. | FULL - ALL NTP RFCs |
| **LDAP Server** | RFC 4510-4519, etc. | FULL - ALL LDAP RFCs |
| **WebDAV Server** | RFC 4918, etc. | FULL - ALL WebDAV RFCs |

**Why this is critical:**
- DNS server that violates DNS RFCs = broken DNS, network failures
- SMTP server that violates SMTP RFCs = rejected by mail servers
- DHCP server that violates DHCP RFCs = clients can't get IP addresses
- HTTP server that violates HTTP RFCs = browsers/clients break

**Implementation requirements:**
1. **Research ALL relevant RFCs** for the protocol being implemented
2. **Implement ALL required behavior** per specifications
3. **Follow exact message formats, response codes, headers, etc.**
4. **Handle edge cases and error conditions** as specified
5. **Document which RFCs are implemented** in AI.md

**Example:**
```
User: "Build a DNS server"

AI Response:
"A DNS server MUST comply with DNS RFCs. I'll implement:
- RFC 1034: Domain Names - Concepts and Facilities
- RFC 1035: Domain Names - Implementation and Specification
- RFC 2181: Clarifications to the DNS Specification
- RFC 6891: Extension Mechanisms for DNS (EDNS)
- Additional RFCs for DNSSEC, dynamic updates, etc.

This is mandatory - DNS clients expect RFC-compliant behavior."
```

**This is different from optional compatibility** (see next section).

### Exceptions: Full Compatibility Required

**Some cases require complete API/protocol implementation:**

| Case | Action | Example |
|------|--------|---------|
| **Protocol compliance** | Implement ALL required endpoints | Matrix, ActivityPub, XMPP |
| **Adding RFC feature to existing app** | Follow RFC specification exactly | Adding WebDAV to file server |
| **Explicit user request** | User specifies which endpoints needed | "Also need delete and list endpoints" |

**How to determine:**

**1. Full protocol/standard (Matrix, ActivityPub, WebDAV, etc.):**
```
User: "Build a Matrix homeserver"

AI Response:
"Matrix is a complete protocol requiring full specification compliance.
I'll implement ALL Matrix Client-Server API endpoints per the spec:
- Account registration and login
- Room creation and management
- Event sending and syncing
- Media uploads
- Presence and typing indicators
This is NOT optional - Matrix clients expect the full protocol."
```

**2. RFC compliance:**
```
User: "Add WebDAV support"

AI Response:
"WebDAV is defined by RFC 4918 which requires specific HTTP methods
and behavior. I'll implement:
- PROPFIND, PROPPATCH (property management)
- MKCOL (collection creation)
- COPY, MOVE (resource operations)
- LOCK, UNLOCK (locking mechanism)
All endpoints required for RFC compliance."
```

**3. Simple service compatibility (pastebin, URL shortener, etc.):**
```
User: "Compatible with pastebin.com"

AI Response:
"Pastebin.com is a simple service, not a protocol.
I'll implement:
✓ POST /api/api_post.php (create endpoint)
✗ Skip view/list/delete (use our /api/v1/* routes)

Need additional compatible endpoints?"
```

**Smart determination rules:**

| If compatibility target is... | Then... |
|-------------------------------|---------|
| Full protocol (Matrix, XMPP, ActivityPub) | Implement complete spec |
| RFC-defined standard (WebDAV, CalDAV, CardDAV) | Follow RFC exactly |
| Simple web service (pastebin, URL shortener) | Create/init endpoint only |
| Unclear/ambiguous | Ask user: "Do you need full protocol compliance or just create endpoint compatibility?" |

**When in doubt, ASK the user:**
- "This appears to be a full protocol. Do you need complete specification compliance?"
- "I found 25 endpoints in their API. Do you need all of them, or just create/init compatibility?"
- "RFC 4918 defines 9 required methods. Should I implement the full RFC?"

## Root-Level Endpoints (NON-NEGOTIABLE)

| Endpoint | Method | Auth | Description |
|----------|--------|------|-------------|
| `/` | GET | None | Web interface (HTML) |
| `/healthz` | GET | None | Health check (HTML) |
| `/openapi` | GET | None | Swagger UI |
| `/openapi.json` | GET | None | OpenAPI spec (JSON only) |
| `/graphql` | GET | None | GraphiQL interface |
| `/graphql` | POST | None | GraphQL queries |
| `/metrics` | GET | Optional | Prometheus metrics |
| `/admin` | GET | Session | Admin panel login |
| `/admin/*` | ALL | Session | Admin panel pages |
| `/api/v1/healthz` | GET | None | Health check (JSON) |
| `/api/v1/admin/*` | ALL | Bearer | Admin API |

**NOTE: No `/openapi.yaml` endpoint. JSON only.**

## Response Standards

| Route Type | Response Format |
|------------|-----------------|
| `/` routes | HTML |
| `/api` routes | JSON (default) or text |
| `/api/**/*.txt` | Text |

### Standard Response Formats

**All API responses MUST follow these formats for consistency:**

#### Single Item Response

```json
{
  "id": "item_123",
  "name": "Example",
  "created_at": "2024-01-15T10:30:00Z"
}
```

*Returns the item directly without wrapper.*

#### Action Response (Create, Update, Delete)

```json
{
  "success": true,
  "message": "Item created successfully",
  "id": "item_123"
}
```

| Field | Required | Description |
|-------|----------|-------------|
| `success` | Yes | Always `true` for successful actions |
| `message` | No | Human-readable status message |
| `id` | If created | ID of created/affected resource |
| `{data}` | If applicable | Additional response data as needed |

#### Error Response

```json
{
  "error": "Human readable message",
  "code": "ERROR_CODE",
  "status": 400,
  "details": {}
}
```

| Field | Required | Description |
|-------|----------|-------------|
| `error` | Yes | Human-readable error message |
| `code` | Yes | Machine-readable error code (e.g., `INVALID_INPUT`, `NOT_FOUND`) |
| `status` | Yes | HTTP status code |
| `details` | No | Additional error context (validation errors, field names) |

#### Pagination (default: 250 items)

```json
{
  "data": [],
  "pagination": {
    "page": 1,
    "limit": 250,
    "total": 1000,
    "pages": 4
  }
}
```

---

# CHECKPOINT 6: FRONTEND & API VERIFICATION

Before proceeding, confirm you understand:
- [ ] Frontend is required for ALL projects
- [ ] NO inline CSS, NO JS alerts
- [ ] Project-wide theme system: light/dark/auto (dark is default)
- [ ] Themes apply to entire project: web UI, admin, Swagger, GraphQL
- [ ] All 3 API types required: REST, Swagger, GraphQL (Swagger & GraphQL in sync)
- [ ] Standard endpoints must exist (/healthz, /openapi, /openapi.json, /graphql, /admin)
- [ ] OpenAPI uses JSON only (no YAML)

---

# PART 21: SSL/TLS & LET'S ENCRYPT (NON-NEGOTIABLE)

## Built-in Let's Encrypt Support

**ALL projects MUST have built-in Let's Encrypt support.**

### Supported Challenge Types

| Type | Description |
|------|-------------|
| HTTP-01 | HTTP-based challenge (default, requires port 80) |
| TLS-ALPN-01 | TLS-based challenge (requires port 443) |
| DNS-01 | DNS TXT record challenge (wildcard certs, no port requirements) |

### DNS-01 Provider Configuration

**ALL DNS providers are supported.** The admin WebUI provides a dropdown that dynamically shows the appropriate credential fields based on the selected provider.

**Admin WebUI Flow (`/admin/server/ssl`):**

1. Select DNS provider from dropdown (all lego-supported providers available)
2. Form dynamically shows required credential fields for that provider
3. Submit credentials → app validates by attempting DNS API connection
4. On success, credentials are **encrypted** and stored for reuse
5. Certificate requests use stored encrypted credentials

**Provider Credential Storage:**

| Field | Description |
|-------|-------------|
| `provider` | Provider identifier (e.g., `cloudflare`, `route53`) |
| `credentials_encrypted` | AES-256-GCM encrypted JSON of provider credentials |
| `validated_at` | Timestamp of last successful validation |

**Common Providers (examples):**

| Provider | Required Fields |
|----------|-----------------|
| `cloudflare` | `api_token` OR (`api_key` + `email`) |
| `route53` | `access_key_id`, `secret_access_key`, `region` |
| `digitalocean` | `auth_token` |
| `godaddy` | `api_key`, `api_secret` |
| `namecheap` | `api_user`, `api_key`, `client_ip` |
| `rfc2136` | `nameserver`, `tsig_key`, `tsig_secret`, `tsig_algorithm` |

**Note:** Full provider list from [lego DNS providers](https://go-acme.github.io/lego/dns/). Fields are determined dynamically at runtime.

**See PART 35: CUSTOM DOMAINS for user/org custom domain support (optional per-project feature).**

### FQDN Resolution (NON-NEGOTIABLE)

**See PART 7: URL Variables for complete `{proto}`, `{fqdn}`, `{port}` resolution.**

**Summary - `{fqdn}` resolution order:**

| Priority | Source |
|----------|--------|
| 1 | Reverse Proxy Headers (`X-Forwarded-Host`, etc.) |
| 2 | `DOMAIN` env var |
| 3 | `os.Hostname()` |
| 4 | `$HOSTNAME` env var |
| 5 | Public IPv6 (excludes private/link-local) |
| 6 | Public IPv4 (excludes 10/8, 172.16/12, 192.168/16) |
| 7 | `localhost` |

**We prefer to run behind a reverse proxy. Reverse proxy headers take priority.**

**DOMAIN Usage:**

| Environment | DOMAIN Value | Example |
|-------------|--------------|---------|
| **Development** | `casspeed` | `DOMAIN=jokes` |
| **Production** | Valid FQDN | `DOMAIN=api.example.com` |

**Valid Production DOMAIN formats (comma-separated list supported):**
```
# Single domain
DOMAIN=example.com
DOMAIN=api.example.com

# Multiple domains (first is primary, auto-infers wildcard)
DOMAIN=myapp.com,www.myapp.com,api.myapp.com
# Result: fqdn=myapp.com, wildcard=*.myapp.com, CORS includes all

# Complex TLDs work too
DOMAIN=google.co.uk,www.google.co.uk
```

**Do NOT set DOMAIN to overlay network addresses:**
- `.onion`, `.i2p`, `.exit` - these are app-generated and managed
- App handles overlay network registration/generation automatically
- Overlay addresses shown separately in console (see below)

**Go Implementation:**
```go
// GetHostFromRequest - use this for request-time host resolution (preferred)
func GetHostFromRequest(r *http.Request, projectName string) string {
    // 1. Reverse proxy headers (highest priority - we prefer to be behind a proxy)
    for _, header := range []string{"X-Forwarded-Host", "X-Real-Host", "X-Original-Host"} {
        if host := r.Header.Get(header); host != "" {
            // Strip port if present (we handle port separately)
            if h, _, err := net.SplitHostPort(host); err == nil {
                return h
            }
            return host
        }
    }

    // 2. Fall back to static resolution
    return GetFQDN(projectName)
}

// GetFQDN - use this when no request context available (startup, background tasks)
// Returns first domain from DOMAIN env var (comma-separated list supported)
func GetFQDN(projectName string) string {
    // 1. DOMAIN env var (explicit user override, comma-separated)
    if domain := os.Getenv("DOMAIN"); domain != "" {
        // Return first domain as primary
        if idx := strings.Index(domain, ","); idx > 0 {
            return strings.TrimSpace(domain[:idx])
        }
        return domain
    }

    // 2. os.Hostname() - cross-platform (Linux, macOS, Windows, BSD)
    if hostname, err := os.Hostname(); err == nil && hostname != "" {
        if !isLoopback(hostname) {
            return hostname
        }
    }

    // 3. $HOSTNAME env var (skip loopback)
    if hostname := os.Getenv("HOSTNAME"); hostname != "" {
        if !isLoopback(hostname) {
            return hostname
        }
    }

    // 4. Global IPv6 (preferred for modern networks)
    if ipv6 := getGlobalIPv6(); ipv6 != "" {
        return ipv6
    }

    // 5. Global IPv4
    if ipv4 := getGlobalIPv4(); ipv4 != "" {
        return ipv4
    }

    // Last resort (not recommended)
    return "localhost"
}

func isLoopback(host string) bool {
    lower := strings.ToLower(host)
    if lower == "localhost" {
        return true
    }
    if ip := net.ParseIP(host); ip != nil {
        return ip.IsLoopback()
    }
    return false
}

// getGlobalIPv6 returns first public IPv6 address
// Excludes: loopback (::1), link-local (fe80::/10), unique local (fc00::/7)
func getGlobalIPv6() string {
    addrs, err := net.InterfaceAddrs()
    if err != nil {
        return ""
    }
    for _, addr := range addrs {
        if ipnet, ok := addr.(*net.IPNet); ok {
            ip := ipnet.IP
            // Must be IPv6 (not IPv4), globally routable, and not private
            if ip.To4() == nil && ip.IsGlobalUnicast() && !ip.IsPrivate() {
                return ip.String()
            }
        }
    }
    return ""
}

// getGlobalIPv4 returns first public IPv4 address
// Excludes: loopback (127.0.0.0/8), private (10/8, 172.16/12, 192.168/16), link-local (169.254/16)
func getGlobalIPv4() string {
    addrs, err := net.InterfaceAddrs()
    if err != nil {
        return ""
    }
    for _, addr := range addrs {
        if ipnet, ok := addr.(*net.IPNet); ok {
            ip := ipnet.IP
            // Must be IPv4, globally routable, and not private
            // Note: IsGlobalUnicast() alone is NOT enough for IPv4 (returns true for private)
            if ip4 := ip.To4(); ip4 != nil && ip.IsGlobalUnicast() && !ip.IsPrivate() {
                return ip4.String()
            }
        }
    }
    return ""
}

// isPublicIP checks if an IP is publicly routable (not private, loopback, or link-local)
func isPublicIP(ip net.IP) bool {
    return ip.IsGlobalUnicast() && !ip.IsPrivate() && !ip.IsLoopback() && !ip.IsLinkLocalUnicast()
}

// GetAllDomains returns all domains from DOMAIN env var
// Used for CORS configuration and SSL certificates
func GetAllDomains() []string {
    domain := os.Getenv("DOMAIN")
    if domain == "" {
        return nil
    }
    parts := strings.Split(domain, ",")
    domains := make([]string, 0, len(parts))
    for _, p := range parts {
        if d := strings.TrimSpace(p); d != "" {
            domains = append(domains, d)
        }
    }
    return domains
}

// GetWildcardDomain infers wildcard from DOMAIN list or learned patterns
// Returns "*.example.com" if multiple subdomains share same base, else ""
func GetWildcardDomain() string {
    domains := GetAllDomains()
    if len(domains) < 2 {
        return "" // Need multiple to infer wildcard
    }

    // Extract base domain from first (primary)
    base := extractBaseDomain(domains[0])

    // Check if all share same base
    for _, d := range domains[1:] {
        if extractBaseDomain(d) != base {
            return "" // Different base domains, no wildcard
        }
    }

    return "*." + base
}

// extractBaseDomain gets eTLD+1 using publicsuffix
func extractBaseDomain(domain string) string {
    // Uses golang.org/x/net/publicsuffix
    base, err := publicsuffix.EffectiveTLDPlusOne(domain)
    if err != nil {
        return domain
    }
    return base
}
```

**Note:** For production SSL/Let's Encrypt, always set `DOMAIN` explicitly:
```bash
# Single domain
export DOMAIN=api.example.com

# Multiple domains (first is primary, all get SSL certs)
export DOMAIN=myapp.com,www.myapp.com,api.myapp.com
```

**The resolved FQDN is used for:**
- SSL certificate lookup and generation
- Let's Encrypt certificate requests
- `server.host` default value (if not configured)

### Dev TLD Handling (NON-NEGOTIABLE)

**Dev TLDs are allowed in development mode but require global IP fallback for remote access.**

**Dynamic Dev TLDs (project name as TLD):**
- `casspeed` - e.g., `app.jokes`, `my.quotes`, `dev.api`
- `casspeed.local` - e.g., `app.jokes.local`
- `casspeed.test` - e.g., `app.jokes.test`

**Static Dev TLDs:**
- `.local`, `.test`, `.example`, `.invalid` (RFC 6761)
- `.localhost`, `.lan`, `.internal`, `.home`, `.localdomain`
- `.home.arpa`, `.intranet`, `.corp`, `.private`

**Get display URL (returns ONE URL):**

```go
// GetDisplayURL returns the best URL for display/access
// Prefers valid FQDN, falls back to global IP if dev TLD
// isHTTPS: true if this is the HTTPS port (second port in dual mode)
func GetDisplayURL(projectName string, port int, isHTTPS bool) string {
    fqdn := GetFQDN(projectName)

    // If valid production FQDN, use it
    if !isDevTLD(fqdn, projectName) && fqdn != "localhost" {
        return formatURL(fqdn, port, isHTTPS)
    }

    // Dev TLD or localhost - use global IP instead
    if ipv6 := getGlobalIPv6(); ipv6 != "" {
        return formatURL("["+ipv6+"]", port, isHTTPS)
    }
    if ipv4 := getGlobalIPv4(); ipv4 != "" {
        return formatURL(ipv4, port, isHTTPS)
    }

    // Last resort
    return formatURL(fqdn, port, isHTTPS)
}

func isDevTLD(host, projectName string) bool {
    lower := strings.ToLower(host)

    // Check dynamic project-specific TLD (e.g., app.jokes, dev.quotes, quotes, jokes, casspeed)
    if projectName != "" && strings.HasSuffix(lower, "."+strings.ToLower(projectName)) {
        return true
    }

    // Check static dev TLDs
    for tld := range devOnlyTLDs {
        if strings.HasSuffix(lower, "."+tld) || lower == tld {
            return true
        }
    }

    return false
}
```

**Startup Banner - Pretty Console with Icons:**

**IMPORTANT: Logs are ALWAYS raw text. No icons, ASCII art, or special characters in log output.**

| Element | Icon | Usage |
|---------|------|-------|
| App name | 🚀 | Header |
| Version | 📦 | Version info |
| Production mode | 🔒 | Mode indicator |
| Development mode | 🔧 | Mode indicator |
| Debugging | 🐛 | Debug flag active |
| Tor/Onion | 🧅 | Overlay network |
| I2P | 🔗 | Overlay network |
| SSL/HTTPS | 🔐 | Secure connection |
| HTTP | 🌐 | Non-secure connection |
| IPv6 | 🌍 | Network address |
| IPv4 | 🌐 | Network address |
| Success | ✅ | Status |
| Warning | ⚠️ | Status |
| Error | ❌ | Status |
| Info | ℹ️ | Status |

**Mode Line (NON-NEGOTIABLE):**

Displayed immediately after the header line, before URLs. Shows current mode and debug status.

| Mode | Debug | Output |
|------|-------|--------|
| production | false | `🔒 Running in mode: production` |
| production | true | `🔒 Running in mode: production [debugging]` |
| development | false | `🔧 Running in mode: development` |
| development | true | `🔧 Running in mode: development [debugging]` |

**Note:** Development mode always has debug features enabled internally, but `[debugging]` only shows when `--debug` flag or `DEBUG=true` is explicitly set.

**Port Configuration (Project-Wide, NON-NEGOTIABLE):**

| Mode | Config | HTTP Port | HTTPS Port |
|------|--------|-----------|------------|
| Single HTTP | `--port 8080` | 8080 | None |
| Single HTTPS | `--port 443` | None | 443 |
| Dual | `--port 80,443` | 80 | 443 |
| Dual | `--port 8080,8443` | 8080 | 8443 |

**Rules:**
- Single port: HTTP by default
- **Exception: If single port is 443 → HTTPS-only mode**
- Dual ports: First = HTTP, Second = HTTPS
- **Override: `CONFIG(ssl.enabled)` can override HTTP → HTTPS on any port**

**URL Format Rule:**

**ALWAYS strip :80 and :443.**

| Port | Protocol | URL |
|------|----------|-----|
| 80 | HTTP | `http://host` |
| 443 | HTTPS | `https://host` |
| Other | Depends on config | `{proto}://host:{port}` |

```go
func formatURL(host string, port int, isHTTPS bool) string {
    proto := "http"
    if isHTTPS || port == 443 {
        proto = "https"
    }

    // Always strip :80 and :443
    if port == 80 || port == 443 {
        return proto + "://" + host
    }

    return fmt.Sprintf("%s://%s:%d", proto, host, port)
}
```

**Usage:**
```go
// Single HTTP port
formatURL(host, 8080, false)  // http://host:8080

// Single HTTPS port (443 = HTTPS-only mode)
formatURL(host, 443, false)   // https://host  (443 forces HTTPS)

// Dual port mode
formatURL(host, 80, false)    // http://host
formatURL(host, 443, true)    // https://host
formatURL(host, 8080, false)  // http://host:8080
formatURL(host, 8443, true)   // https://host:8443
```

**Overlay Network Protocol Rules (Tor, I2P, etc.):**

| Network | Default | HTTPS-Only Mode | Certificate |
|---------|---------|-----------------|-------------|
| Clearnet | HTTP/HTTPS | Port 443 | Let's Encrypt or local |
| Tor (.onion) | HTTP | When clearnet is HTTPS-only | Self-signed (LE doesn't support .onion) |
| I2P (.i2p) | HTTP | When clearnet is HTTPS-only | Self-signed (LE doesn't support .i2p) |

**Rules:**
- Overlay networks inherit HTTPS-only mode from clearnet configuration
- If clearnet port is 443 (HTTPS-only) → overlay also uses HTTPS
- If clearnet is dual port (80,443) → overlay uses HTTP (encryption provided by overlay)
- Overlay HTTPS requires self-signed certificates (Let's Encrypt doesn't support .onion/.i2p)

**Banner Examples:**

| Clearnet Config | Tor URL | I2P URL |
|-----------------|---------|---------|
| `--port 8080` | `http://{onion}.onion` | `http://{i2p}.b32.i2p` |
| `--port 443` | `https://{onion}.onion` | `https://{i2p}.b32.i2p` |
| `--port 80,443` | `http://{onion}.onion` | `http://{i2p}.b32.i2p` |
| `--port 8080,8443` | `http://{onion}.onion` | `http://{i2p}.b32.i2p` |

**Why HTTP for overlays in dual mode?**
- Tor/I2P provide end-to-end encryption at the network layer
- HTTPS adds overhead without additional security benefit
- Only use HTTPS on overlays when HTTPS-only mode is required (port 443)

**Footer timestamp format:** `%a %b %d, %Y at %H:%M:%S %Z` → `Wed Jan 15, 2025 at 09:00:00 EST`

**Example (Production with SSL + Tor on 443):**
```
╭─────────────────────────────────────────────────────────────╮
│  🚀 CASSPEED · 📦 v1.0.0                                │
├─────────────────────────────────────────────────────────────┤
│  🔒 Running in mode: production                             │
├─────────────────────────────────────────────────────────────┤
│  🧅 Tor    http://abc123def456ghi789jklmnop.onion           │
│  🔐 HTTPS  https://api.example.com                          │
├─────────────────────────────────────────────────────────────┤
│  📡 Listening on https://203.0.113.50                       │
│  ✅ Server started on Wed Jan 15, 2025 at 09:00:00 EST      │
╰─────────────────────────────────────────────────────────────╯
```

**Example (Production with Tor + I2P on 443):**
```
╭─────────────────────────────────────────────────────────────╮
│  🚀 CASSPEED · 📦 v1.0.0                                │
├─────────────────────────────────────────────────────────────┤
│  🔒 Running in mode: production                             │
├─────────────────────────────────────────────────────────────┤
│  🧅 Tor    http://abc123def456ghi789jklmnop.onion           │
│  🔗 I2P    http://xyz789abc123def456uvwxyz.b32.i2p          │
│  🔐 HTTPS  https://api.example.com                          │
├─────────────────────────────────────────────────────────────┤
│  📡 Listening on https://203.0.113.50                       │
│  ✅ Server started on Wed Jan 15, 2025 at 09:00:00 EST      │
╰─────────────────────────────────────────────────────────────╯
```

**Example (Production on port 8080):**
```
╭─────────────────────────────────────────────────────────────╮
│  🚀 CASSPEED · 📦 v1.0.0                                │
├─────────────────────────────────────────────────────────────┤
│  🔒 Running in mode: production                             │
├─────────────────────────────────────────────────────────────┤
│  🌐 HTTP   http://api.example.com:8080                      │
├─────────────────────────────────────────────────────────────┤
│  📡 Listening on http://203.0.113.50:8080                   │
│  ✅ Server started on Wed Jan 15, 2025 at 09:00:00 EST      │
╰─────────────────────────────────────────────────────────────╯
```

**Example (Development on port 8080):**
```
╭─────────────────────────────────────────────────────────────╮
│  🚀 CASSPEED · 📦 v1.0.0                                │
├─────────────────────────────────────────────────────────────┤
│  🔧 Running in mode: development                            │
├─────────────────────────────────────────────────────────────┤
│  🌐 HTTP   http://192.168.1.100:8080                        │
├─────────────────────────────────────────────────────────────┤
│  📡 Listening on http://192.168.1.100:8080                  │
│  ✅ Server started on Wed Jan 15, 2025 at 09:00:00 EST      │
╰─────────────────────────────────────────────────────────────╯
```

**Example (Development IPv6 on port 8080):**
```
╭─────────────────────────────────────────────────────────────╮
│  🚀 CASSPEED · 📦 v1.0.0                                │
├─────────────────────────────────────────────────────────────┤
│  🔧 Running in mode: development                            │
├─────────────────────────────────────────────────────────────┤
│  🌍 IPv6   http://[2001:db8::1]:8080                        │
├─────────────────────────────────────────────────────────────┤
│  📡 Listening on http://[2001:db8::1]:8080                  │
│  ✅ Server started on Wed Jan 15, 2025 at 09:00:00 EST      │
╰─────────────────────────────────────────────────────────────╯
```

**Example (Production on port 80):**
```
╭─────────────────────────────────────────────────────────────╮
│  🚀 CASSPEED · 📦 v1.0.0                                │
├─────────────────────────────────────────────────────────────┤
│  🔒 Running in mode: production                             │
├─────────────────────────────────────────────────────────────┤
│  🌐 HTTP   http://api.example.com                           │
├─────────────────────────────────────────────────────────────┤
│  📡 Listening on http://203.0.113.50                        │
│  ✅ Server started on Wed Jan 15, 2025 at 09:00:00 EST      │
╰─────────────────────────────────────────────────────────────╯
```

**Example (Production with debugging enabled):**
```
╭─────────────────────────────────────────────────────────────╮
│  🚀 CASSPEED · 📦 v1.0.0                                │
├─────────────────────────────────────────────────────────────┤
│  🔒 Running in mode: production [debugging]                 │
├─────────────────────────────────────────────────────────────┤
│  🌐 HTTP   http://api.example.com                           │
├─────────────────────────────────────────────────────────────┤
│  📡 Listening on http://203.0.113.50                        │
│  ✅ Server started on Wed Jan 15, 2025 at 09:00:00 EST      │
╰─────────────────────────────────────────────────────────────╯
```

**Example (First Run - Setup Required):**
```
╭─────────────────────────────────────────────────────────────╮
│  🚀 CASSPEED · 📦 v1.0.0                                │
├─────────────────────────────────────────────────────────────┤
│  🔧 Running in mode: development                            │
├─────────────────────────────────────────────────────────────┤
│  🌐 HTTP   http://192.168.1.100:8080                        │
├─────────────────────────────────────────────────────────────┤
│  📡 Listening on http://192.168.1.100:8080                  │
│  ✅ Server started on Wed Jan 15, 2025 at 09:00:00 EST      │
╰─────────────────────────────────────────────────────────────╯

┌─────────────────────────────────────────────────────────────┐
│  🔑 SETUP REQUIRED                                          │
├─────────────────────────────────────────────────────────────┤
│  Setup Token: a1b2c3d4e5f67890abcdef1234567890              │
│                                                             │
│  Go to /admin and enter this token to complete setup.       │
│  This token will only be shown ONCE.                        │
└─────────────────────────────────────────────────────────────┘
```

**Note:** Setup token is displayed ONCE on first run. After setup wizard is completed, this section never appears again.

### Console vs Logs (NON-NEGOTIABLE)

| Output | Icons | ASCII Art | Colors | Format |
|--------|-------|-----------|--------|--------|
| **Startup banner** | ✅ Yes | ✅ Yes | ✅ Yes | Pretty |
| **Interactive console** | ✅ Yes | ✅ Yes | ✅ Yes | Pretty |
| **Log files** | ❌ Never | ❌ Never | ❌ Never | Raw text |
| **Log output (stdout)** | ❌ Never | ❌ Never | ❌ Never | Raw text |

**Log format is ALWAYS plain text:**
```
2025-01-15 09:00:00 INFO  Server started on :8080
2025-01-15 09:00:01 INFO  Database connected
2025-01-15 09:00:05 WARN  High memory usage: 85%
2025-01-15 09:00:10 ERROR Connection timeout to upstream
```

**Never this in logs:**
```
✅ Server started    <- NO icons in logs
🔧 Development mode  <- NO icons in logs
```

### Certificate Lookup Order (NON-NEGOTIABLE)

**On startup, check for existing certificates in this order:**

| Priority | Path | Description |
|----------|------|-------------|
| 1 | `/etc/letsencrypt/live/domain/` | Literal "domain" directory (common shared setup) |
| 2 | `/etc/letsencrypt/live/{fqdn}/` | FQDN-named directory (e.g., `/etc/letsencrypt/live/api.example.com/`) |
| 3 | `{config_dir}/ssl/letsencrypt/{fqdn}/` | App-managed Let's Encrypt certificates |
| 4 | `{config_dir}/ssl/local/{fqdn}/` | Self-signed or user-provided certificates |

**Certificate Validation:**
- Certificate CN or SAN must match configured FQDN (`server.host`)
- Certificate must not be expired
- Both cert and key files must be readable

### Certificate Directory Structure

```
{config_dir}/ssl/
├── letsencrypt/
│   └── {fqdn}/                # e.g., api.example.com/
│       ├── fullchain.pem
│       └── privkey.pem
└── local/
    └── {fqdn}/                # e.g., api.example.com/
        ├── cert.pem
        └── key.pem
```

**Mirrors certbot structure** (`/etc/letsencrypt/live/{fqdn}/`) for consistency.

### Certificate Management Ownership

| Location | Manager | Renewal |
|----------|---------|---------|
| `/etc/letsencrypt/live/**` | **System** (certbot) | App does NOT renew |
| `{config_dir}/ssl/letsencrypt/{fqdn}/` | **App** | Auto-renew 7 days before expiry |
| `{config_dir}/ssl/local/{fqdn}/` | **User** | No auto-renewal (manual) |

**Rule: If cert is in `{config_dir}/ssl/**`, app manages. Subdirectory determines HOW.**

### Renewal Rules

| Directory | Check Frequency | Renewal Trigger |
|-----------|-----------------|-----------------|
| `{config_dir}/ssl/letsencrypt/{fqdn}/` | Daily (03:00) | 7 days before expiry |
| `{config_dir}/ssl/local/{fqdn}/` | Never | Manual only |
| `/etc/letsencrypt/live/**` | Never | System (certbot) manages |

**Logic Flow:**
```
Startup (for configured FQDN)
   │
   ├─► Check /etc/letsencrypt/live/domain/
   │   └─► Found + cert matches FQDN? → Use it (system manages)
   │
   ├─► Check /etc/letsencrypt/live/{fqdn}/
   │   └─► Found? → Use it (system manages)
   │
   ├─► Check {config_dir}/ssl/letsencrypt/{fqdn}/
   │   └─► Found? → Use it (app auto-renews)
   │
   ├─► Check {config_dir}/ssl/local/{fqdn}/
   │   └─► Found? → Use it (no auto-renewal)
   │
   └─► Not found anywhere
       └─► Request new cert via Let's Encrypt
           └─► Save to {config_dir}/ssl/letsencrypt/{fqdn}/ (app auto-renews)
```

**Important:**
- `/etc/letsencrypt/` → app uses but does NOT manage renewal
- `{config_dir}/ssl/letsencrypt/{fqdn}/` → app manages, auto-renews 7 days before expiry
- `{config_dir}/ssl/local/{fqdn}/` → app uses but does NOT auto-renew (user manages)

---


# PART 22: SECURITY & LOGGING (NON-NEGOTIABLE)

## Security Headers

**All responses MUST include:**

```
X-Content-Type-Options: nosniff
X-Frame-Options: SAMEORIGIN
X-XSS-Protection: 1; mode=block
Referrer-Policy: strict-origin-when-cross-origin
Content-Security-Policy: default-src 'self'; script-src 'self' 'unsafe-inline'; style-src 'self' 'unsafe-inline'
Permissions-Policy: geolocation=(), microphone=(), camera=()
```

**When SSL is enabled, also include:**

```
Strict-Transport-Security: max-age=31536000; includeSubDomains
```

**Notes:**
- `X-XSS-Protection` is deprecated in modern browsers but kept for older browser compatibility
- `'unsafe-inline'` in CSP is required for many frameworks; tighten if your app allows
- HSTS `max-age` is configurable (default 1 year = 31536000 seconds)

**In development mode, these may be relaxed.**

## Well-Known Files (NON-NEGOTIABLE)

**Standard files served at well-known paths. Generated automatically if no file exists.**

### Required Files

| File | Path | Purpose |
|------|------|---------|
| `robots.txt` | `/robots.txt` | Search engine crawling rules |
| `security.txt` | `/.well-known/security.txt` | Security vulnerability reporting (RFC 9116) |

### Additional Well-Known Paths

| Path | Purpose |
|------|---------|
| `/.well-known/acme-challenge/` | Let's Encrypt HTTP-01 challenge |
| `/.well-known/change-password` | Password change URL (redirects to `/user/security/password` if logged in, `/auth/password/forgot` if not) |

### Well-Known Directory Support

Files can be served from:
1. Files in `{data_dir}/web/.well-known/` (checked first)
2. Embedded files in binary
3. Dynamically generated (e.g., ACME challenges, config-based security.txt)

### robots.txt

```
# Served at /robots.txt - generated if no file exists

User-agent: *
Allow: /
Allow: /api
Disallow: /admin
Sitemap: {app_url}/sitemap.xml
```

**Configuration:**
```yaml
web:
  robots:
    allow:
      - /
      - /api
    deny:
      - /admin
```

### security.txt (RFC 9116)

**ALL projects MUST serve a valid security.txt file.**

```
# Served at /.well-known/security.txt

Contact: mailto:{security_contact}
Expires: {expiry_date}
```

**Configuration:**
```yaml
web:
  security:
    contact: "security@{fqdn}"    # Security contact email
    expires: "{1year}"            # Auto-calculated 1 year from generation
```

**Fields:**
| Field | Required | Description |
|-------|----------|-------------|
| `Contact` | YES | Email for reporting vulnerabilities (mailto: prefix added automatically) |
| `Expires` | YES | Expiration date (auto-renewed yearly by default) |

### Admin Panel (/admin/web)

**robots.txt Settings:**

| Element | Type | Description |
|---------|------|-------------|
| Allow paths | Tag input / List | Paths to allow crawling (e.g., `/`, `/api`) |
| Deny paths | Tag input / List | Paths to deny crawling (e.g., `/admin`) |
| Preview | Read-only textarea | Shows generated robots.txt content |

**security.txt Settings:**

| Element | Type | Description |
|---------|------|-------------|
| Security contact | Text input | Email for vulnerability reports |
| Expires | Date picker | Expiration date (default: 1 year from now, auto-renews) |
| Preview | Read-only textarea | Shows generated security.txt content |

## Logging

### Log Files

| Log | Purpose | Default Format | Available Formats |
|-----|---------|----------------|-------------------|
| `access.log` | HTTP requests | `apache` | `apache`, `nginx`, `json` |
| `server.log` | Application events | `text` | `text`, `json` |
| `error.log` | Error messages | `text` | `text`, `json` |
| `audit.log` | Security events | `json` | `json` only (must be machine-parseable) |
| `security.log` | Security/auth events | `fail2ban` | `fail2ban`, `syslog`, `cef`, `json`, `text` |
| `debug.log` | Debug (dev mode) | `text` | `text`, `json` |

### Log Format Details

**Access Log Formats:**
| Format | Description | Example |
|--------|-------------|---------|
| `apache` | Apache Combined Log Format (default) | `127.0.0.1 - - [10/Oct/2024:13:55:36 -0700] "GET /api/v1/health HTTP/1.1" 200 2326 "-" "curl/7.64.1"` |
| `nginx` | Nginx Common Log Format | `127.0.0.1 - - [10/Oct/2024:13:55:36 -0700] "GET /api/v1/health HTTP/1.1" 200 2326` |
| `json` | Structured JSON | `{"ip":"127.0.0.1","time":"2024-10-10T13:55:36Z","method":"GET","path":"/api/v1/health","status":200,"size":2326,"ua":"curl/7.64.1"}` |

**Security Log Formats:**
| Format | Description | Use Case |
|--------|-------------|----------|
| `fail2ban` | Fail2ban compatible (default) | Intrusion prevention integration |
| `syslog` | RFC 5424 syslog format | SIEM integration, centralized logging |
| `cef` | Common Event Format | SIEM/security tools (ArcSight, Splunk) |
| `json` | Structured JSON | Custom parsing, ELK stack |
| `text` | Plain text | Human readable |

**Text Log Format:**
```
2024-10-10 13:55:36 [INFO] Server started on :8080
2024-10-10 13:55:40 [ERROR] Database connection failed: timeout
```

**JSON Log Format:**
```json
{"time":"2024-10-10T13:55:36Z","level":"INFO","msg":"Server started on :8080"}
{"time":"2024-10-10T13:55:40Z","level":"ERROR","msg":"Database connection failed","error":"timeout"}
```

**Fail2ban Format:**
```
2024-10-10 13:55:36 [security] Failed login attempt from 192.168.1.100 for user admin
2024-10-10 13:55:40 [security] Rate limit exceeded from 192.168.1.100
```

### Custom Format Variables

When using `format: custom`, these variables are available:

| Variable | Description |
|----------|-------------|
| `{time}` | Time only |
| `{date}` | Date only |
| `{datetime}` | Date and time |
| `{remote_ip}` | Client IP address |
| `{method}` | HTTP method |
| `{path}` | Request path |
| `{query}` | Query string |
| `{status}` | HTTP status code |
| `{bytes}` | Response size |
| `{latency}` | Request latency (human readable) |
| `{latency_ms}` | Request latency (milliseconds) |
| `{user_agent}` | User agent string |
| `{referer}` | Referer header |
| `{request_id}` | Request ID |
| `{fqdn}` | Request host |
| `{protocol}` | HTTP protocol version |
| `{tls_version}` | TLS version (if HTTPS) |
| `{country}` | GeoIP country code |
| `{asn}` | GeoIP ASN |

### Rotation Options

| Option | Description |
|--------|-------------|
| `never` | Never rotate |
| `daily` | Rotate daily |
| `weekly` | Rotate weekly |
| `monthly` | Rotate monthly |
| `yearly` | Rotate yearly |
| `NMB` | Rotate at N megabytes (e.g., `50MB`) |
| `NGB` | Rotate at N gigabytes (e.g., `1GB`) |
| Combined | Time + size, whichever first (e.g., `weekly,50MB`) |

### Retention Options

| Option | Description |
|--------|-------------|
| `none` | Do not keep old logs (delete after rotation) |
| `N` | Keep N old log files |
| `Nd` | Keep logs for N days |
| `Nw` | Keep logs for N weeks |
| `Nm` | Keep logs for N months |
| `forever` | Keep forever (no automatic deletion) |

### Configuration

```yaml
server:
  logs:
    # Global log level: debug, info, warn, error
    level: warn

    # All log types share these options:
    #   filename: name of log file
    #   format: output format (varies by log type)
    #   custom: custom format string (when format=custom)
    #   rotate: rotation policy
    #   keep: retention policy

    access:
      filename: access.log
      # Format: apache, nginx, json, custom
      format: apache
      custom: ""
      rotate: monthly
      keep: none

    server:
      filename: server.log
      # Format: text, json
      format: text
      custom: ""
      rotate: weekly,50MB
      keep: none

    error:
      filename: error.log
      # Format: text, json
      format: text
      custom: ""
      rotate: weekly,50MB
      keep: none

    audit:
      enabled: true
      filename: audit.log
      # Format: json only (text not supported for audit - must be machine-parseable)
      format: json
      rotate: daily
      keep: none
      # Compress rotated logs (only useful if keep > 0)
      compress: false

    security:
      filename: security.log
      # Format: fail2ban, syslog, cef, json, text
      format: fail2ban
      custom: ""
      rotate: weekly,50MB
      keep: none

    debug:
      # Debug log has an enabled flag since it's for troubleshooting only
      enabled: false
      filename: debug.log
      # Format: text, json
      format: text
      custom: ""
      rotate: weekly,50MB
      keep: none
```

### Log Output Rules (NON-NEGOTIABLE)

**All log FILES MUST use raw text only:**
- NO emojis
- NO ANSI color codes
- NO special characters or formatting
- Plain ASCII text only
- Machine-parseable format

**Console output (stdout/stderr) CAN be pretty:**
- Emojis allowed (e.g., `✅ Server started`, `❌ Error`, `⚠️ Warning`)
- ANSI colors allowed
- Pretty formatting allowed
- Used for start/stop/restart/status messages
- User-facing CLI output can be visually appealing

**Rule:** Log files = raw/plain text. Console = pretty is OK.

### Log Rotation

**Defaults:**
| Log Type | Rotation | Keep |
|----------|----------|------|
| access.log | monthly | none |
| audit.log | daily | none |
| All others | weekly,50MB | none |

**Rules:**
- `weekly,50MB` = rotate on weekly OR 50MB, whichever comes first
- `keep: none` = do not retain old logs (default)
- Built-in rotation support (no external logrotate needed)
- Old logs deleted immediately after rotation (default)
- Optional: compress before delete, retain with `keep: weekly:N` or `monthly:N`

### Audit Log (NON-NEGOTIABLE)

**The audit log records ALL security-relevant events and administrative actions. It is the authoritative record of who did what and when.**

## Audit Log Purpose

| Purpose | Description |
|---------|-------------|
| **Accountability** | Track all admin and user actions |
| **Security** | Detect unauthorized access attempts |
| **Compliance** | Meet regulatory requirements (GDPR, SOC2, etc.) |
| **Debugging** | Investigate issues and incidents |
| **Forensics** | Post-incident analysis |

## Audit Log Events

### Server Admin Events

| Event | Description | Logged Data |
|-------|-------------|-------------|
| `admin.login` | Admin logged in | IP, user agent, MFA used, admin username |
| `admin.logout` | Admin logged out | Admin username, session duration |
| `admin.login_failed` | Failed login attempt | IP, user agent, reason, attempted username |
| `admin.created` | New admin account created | New admin username, created by (admin username) |
| `admin.deleted` | Admin account removed | Deleted admin username, deleted by (admin username) |
| `admin.password_changed` | Admin changed password | Admin username, IP (NEVER log password) |
| `admin.mfa_enabled` | Admin enabled 2FA | Admin username, method (TOTP, WebAuthn) |
| `admin.mfa_disabled` | Admin disabled 2FA | Admin username, method |
| `admin.token_regenerated` | Admin API token regenerated | Admin username, IP |
| `admin.session_expired` | Admin session timed out | Admin username, session ID |
| `admin.session_revoked` | Admin session manually ended | Admin username, revoked by |

### User Events (Multi-User Mode)

| Event | Description | Logged Data |
|-------|-------------|-------------|
| `user.registered` | New user registered | User ID, IP, registration method (form, OIDC, invite) |
| `user.login` | User logged in | User ID, IP, user agent, auth method |
| `user.logout` | User logged out | User ID, session duration |
| `user.login_failed` | Failed login attempt | IP, user agent, reason (NOT username/email) |
| `user.created` | Admin created user | User ID, created by (admin username) |
| `user.deleted` | User account deleted | User ID, deleted by (admin/self), reason |
| `user.suspended` | User account suspended | User ID, suspended by, reason |
| `user.unsuspended` | User account reactivated | User ID, unsuspended by |
| `user.role_changed` | User role modified | User ID, old role, new role, changed by |
| `user.password_changed` | User changed password | User ID, IP, method (direct, reset link) |
| `user.password_reset_requested` | Password reset requested | IP (NOT email/username) |
| `user.password_reset_completed` | Password reset completed | User ID, IP |
| `user.email_verified` | Email address verified | User ID, email (masked) |
| `user.mfa_enabled` | User enabled 2FA | User ID, method |
| `user.mfa_disabled` | User disabled 2FA | User ID, method, disabled by (self/admin) |
| `user.recovery_key_used` | Recovery key consumed | User ID, keys remaining |

### Organization Events (Multi-User Mode)

| Event | Description | Logged Data |
|-------|-------------|-------------|
| `org.created` | Organization created | Org ID, org slug, created by (user ID) |
| `org.deleted` | Organization deleted | Org ID, org slug, deleted by, member count at deletion |
| `org.settings_updated` | Org settings changed | Org ID, changed keys, changed by |
| `org.member_invited` | Member invitation sent | Org ID, invited email (masked), role, invited by |
| `org.member_joined` | Member joined org | Org ID, user ID, role, join method (invite, direct) |
| `org.member_removed` | Member removed from org | Org ID, user ID, removed by, reason |
| `org.member_left` | Member left org voluntarily | Org ID, user ID |
| `org.role_changed` | Member role changed | Org ID, user ID, old role, new role, changed by |
| `org.role_created` | Custom role created | Org ID, role name, permissions, created by |
| `org.role_updated` | Custom role modified | Org ID, role name, changed permissions, updated by |
| `org.role_deleted` | Custom role deleted | Org ID, role name, deleted by |
| `org.token_created` | Org API token created | Org ID, token ID (partial), permissions, created by |
| `org.token_revoked` | Org API token revoked | Org ID, token ID (partial), revoked by |
| `org.ownership_transferred` | Org ownership transferred | Org ID, old owner, new owner |
| `org.billing_updated` | Billing settings changed | Org ID, changed by (NOT payment details) |

### Organization Audit Compliance

**Org audit logs are stored separately per organization for compliance isolation.**

| Requirement | Implementation |
|-------------|----------------|
| **Isolation** | Each org's audit log stored in separate table/partition |
| **Retention** | Configurable per-org (default: 2 years, min: 90 days) |
| **Immutability** | Append-only, no modification or deletion by org admins |
| **Export** | JSON, CSV, or PDF export for auditors (`/org/{slug}/security/audit/export`) |
| **Filtering** | Filter by date range, event type, actor, target |
| **Search** | Full-text search on audit entries |
| **Access control** | Only org admins with `audit:read` permission |
| **Server admin access** | Server admins can view for moderation (logged as `admin.org_audit_viewed`) |

**Compliance Export Format:**
```json
{
  "export_info": {
    "org_id": "org_abc123",
    "org_slug": "acme-corp",
    "exported_at": "2025-01-15T10:00:00Z",
    "exported_by": "user_xyz",
    "date_range": { "from": "2024-01-01", "to": "2024-12-31" },
    "total_events": 15420,
    "hash": "sha256:abc123..."
  },
  "events": [...]
}
```

**Org Audit API Endpoints:**

| Endpoint | Method | Description |
|----------|--------|-------------|
| `/api/v1/org/{slug}/security/audit` | GET | List audit events (paginated) |
| `/api/v1/org/{slug}/security/audit/export` | POST | Request audit export |
| `/api/v1/org/{slug}/security/audit/export/{id}` | GET | Download audit export |
| `/api/v1/org/{slug}/security/audit/retention` | GET | Get retention settings |
| `/api/v1/org/{slug}/security/audit/retention` | PATCH | Update retention (org owner only) |

### OIDC/LDAP Events

| Event | Description | Logged Data |
|-------|-------------|-------------|
| `oidc.login` | User logged in via OIDC | User ID, provider name, IP |
| `oidc.login_failed` | OIDC login failed | Provider name, IP, reason |
| `oidc.user_created` | Auto-provisioned user via OIDC | User ID, provider name |
| `oidc.admin_granted` | Admin access via group mapping | User ID, provider name, group name |
| `oidc.admin_revoked` | Admin access removed (group change) | User ID, provider name |
| `ldap.login` | User logged in via LDAP | User ID, IP |
| `ldap.login_failed` | LDAP login failed | IP, reason |
| `ldap.admin_granted` | Admin access via group mapping | User ID, group DN |
| `ldap.admin_revoked` | Admin access removed (group change) | User ID |

### Configuration Events

| Event | Description | Logged Data |
|-------|-------------|-------------|
| `config.updated` | Configuration changed | Changed keys (NOT sensitive values), changed by |
| `config.smtp_updated` | SMTP settings changed | Changed by (NOT credentials) |
| `config.ssl_updated` | SSL certificate changed | Subject, expiry, changed by |
| `config.ssl_expired` | SSL certificate expired | Domain |
| `config.tor_address_regenerated` | Onion address regenerated | Changed by |
| `config.branding_updated` | Branding settings changed | Changed by |
| `config.oidc_provider_added` | OIDC provider configured | Provider name, added by |
| `config.oidc_provider_removed` | OIDC provider removed | Provider name, removed by |
| `config.ldap_updated` | LDAP settings changed | Changed by |
| `config.admin_groups_updated` | Admin group mapping changed | Old groups, new groups, changed by |

### Security Events

| Event | Description | Logged Data |
|-------|-------------|-------------|
| `security.rate_limit_exceeded` | Rate limit hit | IP, endpoint, limit |
| `security.ip_blocked` | IP address blocked | IP, reason, duration |
| `security.ip_unblocked` | IP address unblocked | IP, unblocked by |
| `security.country_blocked` | Request blocked by GeoIP | IP, country code |
| `security.csrf_failure` | CSRF token validation failed | IP, endpoint |
| `security.invalid_token` | Invalid API token used | Token type, IP |
| `security.brute_force_detected` | Brute force attempt detected | IP, target (masked), attempt count |
| `security.suspicious_activity` | Unusual activity detected | IP, activity type, details |

### Token Events

| Event | Description | Logged Data |
|-------|-------------|-------------|
| `token.created` | API token created | Token ID (partial), permissions, expiry, created by |
| `token.revoked` | API token revoked | Token ID (partial), revoked by |
| `token.expired` | API token expired | Token ID (partial) |
| `token.used` | API token used (optional, high volume) | Token ID (partial), endpoint, IP |

### Backup & System Events

| Event | Description | Logged Data |
|-------|-------------|-------------|
| `backup.created` | Backup created | Filename, size, created by |
| `backup.restored` | Backup restored | Filename, restored by |
| `backup.deleted` | Backup deleted | Filename, deleted by |
| `backup.failed` | Backup failed | Error message |
| `server.started` | Application started | Version, mode, node ID |
| `server.stopped` | Application stopped | Reason, uptime |
| `server.maintenance_entered` | Maintenance mode enabled | Reason, enabled by |
| `server.maintenance_exited` | Maintenance mode disabled | Duration, disabled by |
| `server.updated` | Application updated | Old version, new version |
| `scheduler.task_failed` | Scheduled task failed | Task name, error |
| `scheduler.task_manual_run` | Task manually triggered | Task name, triggered by |

### Cluster Events

| Event | Description | Logged Data |
|-------|-------------|-------------|
| `cluster.node_joined` | Node joined cluster | Node ID, IP |
| `cluster.node_removed` | Node removed from cluster | Node ID, removed by |
| `cluster.node_failed` | Node became unreachable | Node ID, last seen |
| `cluster.token_generated` | Join token generated | Token ID (partial), generated by |
| `cluster.mode_changed` | Cluster mode changed | Old mode, new mode, changed by |

## Audit Log Format

**All audit logs are JSON format, one entry per line (JSON Lines).**

```json
{
  "id": "audit_01HQXYZ123ABC",
  "time": "2025-01-15T10:30:00.123Z",
  "event": "admin.login",
  "category": "authentication",
  "severity": "info",
  "actor": {
    "type": "admin",
    "id": "administrator",
    "ip": "192.168.1.100",
    "user_agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64)..."
  },
  "target": {
    "type": "session",
    "id": "sess_abc123"
  },
  "details": {
    "mfa_used": true,
    "mfa_method": "totp"
  },
  "result": "success",
  "node_id": "node-1"
}
```

**Required Fields:**

| Field | Type | Description |
|-------|------|-------------|
| `id` | String | Unique audit entry ID (ULID format) |
| `time` | String | ISO 8601 timestamp with milliseconds, UTC |
| `event` | String | Event type (e.g., `admin.login`) |
| `category` | String | Event category (e.g., `authentication`) |
| `severity` | String | `info`, `warn`, `error`, `critical` |
| `actor` | Object | Who performed the action |
| `result` | String | `success` or `failure` |

**Optional Fields:**

| Field | Type | Description |
|-------|------|-------------|
| `target` | Object | What was acted upon |
| `details` | Object | Event-specific details |
| `node_id` | String | Node ID (cluster mode) |
| `reason` | String | Reason for action (if provided) |

## Severity Levels

| Severity | Use For | Examples |
|----------|---------|----------|
| `info` | Successful normal operations | Login, config save, backup complete |
| `warn` | Failed attempts, recoverable issues | Failed login, rate limit hit |
| `error` | Failures requiring attention | Backup failed, scheduler error |
| `critical` | Security incidents, server failures | Brute force detected, maintenance mode |

## Audit Log Configuration

**Extended audit options (in addition to basic log options):**

```yaml
server:
  logs:
    audit:
      # Basic options (same as other logs)
      enabled: true
      filename: audit.log
      format: json           # json only - must be machine-parseable
      rotate: daily          # daily, weekly, monthly, NMB, or combined
      keep: none             # none, N, Nd, Nw, Nm
      compress: false

      # What to log (event categories)
      events:
        authentication: true  # Login/logout events
        configuration: true   # Config changes
        security: true        # Security events
        tokens: true          # Token create/revoke
        users: true           # User management
        backup: true          # Backup/restore
        server: true          # Server events (start, stop, maintenance)
        cluster: true         # Cluster events
        token_usage: false    # Individual token uses (high volume - disabled by default)

      # Sensitive data handling
      mask_emails: true       # Show j***n@e***.com instead of full
      mask_usernames: false   # Show full usernames in logs
      include_user_agent: true
```

## Sane Defaults

| Setting | Default | Description |
|---------|---------|-------------|
| `enabled` | `true` | Audit logging enabled |
| `format` | `json` | JSON format (required) |
| `rotate` | `daily` | Rotate daily |
| `keep` | `none` | Delete on rotation (no old logs kept) |
| `compress` | `false` | No compression (deleted immediately) |
| `mask_emails` | `true` | Mask email addresses |
| All event categories | `true` | Log all events |
| `token_usage` | `false` | Don't log every token use |

**Why `keep: none` by default?**
- Reduces disk usage
- Minimizes data retention liability
- Users who need log history can configure retention
- Current log always available until rotation

## Audit Log Rules (NON-NEGOTIABLE)

**NEVER Log:**
- ❌ Passwords (plain, hashed, or encrypted)
- ❌ API tokens or secrets (full value)
- ❌ Session tokens (full value)
- ❌ Recovery keys
- ❌ TOTP secrets
- ❌ Private keys
- ❌ Credit card numbers
- ❌ Full email addresses (mask them)

**ALWAYS Log:**
- ✓ Timestamp in UTC with milliseconds
- ✓ IP address for all events
- ✓ Actor identity (who did it)
- ✓ Event result (success/failure)
- ✓ Unique event ID

**Token/ID Masking:**
- Show only first 8 characters: `token_abc12345...`
- Or use separate ID field that doesn't expose token value

## Admin Panel (`/admin/server/logs/audit`)

| Element | Type | Description |
|---------|------|-------------|
| Log viewer | Table | Paginated audit log entries |
| Filters | Dropdowns | Filter by category, severity, date range |
| Search | Text input | Search by actor, IP, event type |
| Export | Button | Download filtered results as JSON/CSV |
| Retention | Display | Show current retention policy |
| Stats | Cards | Event counts by category/severity |

**Log Viewer Columns:**
| Column | Description |
|--------|-------------|
| Time | Timestamp (local timezone) |
| Event | Event type with icon |
| Actor | Who performed action |
| Target | What was affected |
| IP | Source IP address |
| Result | Success/failure badge |
| Details | Expandable row |

**Filters:**
- Category: All, Authentication, Configuration, Security, etc.
- Severity: All, Info, Warn, Error, Critical
- Result: All, Success, Failure
- Date range: Today, Last 7 days, Last 30 days, Custom
- Actor: Text search
- IP: Text search

**Export Options:**
- Format: JSON (default), CSV
- Range: Current view, All matching filters, Full log
- Note: Export respects same masking rules as display

## Audit Log Integrity

**The audit log is append-only and tamper-evident.**

| Protection | Description |
|------------|-------------|
| Append-only | Application can only append, never modify or delete entries |
| No truncate | Application cannot truncate the log file |
| Rotation only | Only log rotation can remove old entries |
| Checksum | Optional: Include running checksum for tamper detection |

**File Permissions:**
```
audit.log: 0640 (rw-r-----)
Owner: application user
Group: audit group (if configured)
```

## Audit Log Retention

| Retention | Description |
|-----------|-------------|
| `keep: none` | Delete on rotation (default) - no old logs kept |
| `keep: 30d` | Keep 30 days |
| `keep: 90d` | Keep 90 days |
| `keep: 12m` | Keep 1 year (365d also works) |
| `keep: forever` | Keep forever (no automatic deletion) |

**Rotation Schedule:**
- Daily rotation at midnight UTC
- If `keep: none`: Old log deleted immediately after rotation
- If `keep: Nd`: Rotated files named `audit.log.2025-01-15.gz`, deleted after N days
- Current day's log always available until next rotation

## Compliance Standards

**All compliance standards are DISABLED by default. Enable individually as needed.**

### Available Standards

| Standard | Description | Region/Industry |
|----------|-------------|-----------------|
| `gdpr` | General Data Protection Regulation | EU/EEA |
| `ccpa` | California Consumer Privacy Act | California, USA |
| `hipaa` | Health Insurance Portability and Accountability Act | USA Healthcare |
| `soc2` | Service Organization Control 2 | USA (Trust Services) |
| `pci_dss` | Payment Card Industry Data Security Standard | Global (Payments) |
| `iso27001` | Information Security Management | Global |
| `fedramp` | Federal Risk and Authorization Management | USA Government |
| `lgpd` | Lei Geral de Proteção de Dados | Brazil |
| `pipeda` | Personal Information Protection and Electronic Documents Act | Canada |
| `appi` | Act on Protection of Personal Information | Japan |
| `pdpa` | Personal Data Protection Act | Singapore |

### Configuration

```yaml
server:
  compliance:
    # All disabled by default - enable individually
    gdpr: false
    ccpa: false
    hipaa: false
    soc2: false
    pci_dss: false
    iso27001: false
    fedramp: false
    lgpd: false
    pipeda: false
    appi: false
    pdpa: false
```

### Compliance Requirements Matrix

| Requirement | GDPR | CCPA | HIPAA | SOC2 | PCI-DSS | ISO27001 |
|-------------|------|------|-------|------|---------|----------|
| Data encryption at rest | ✓ | - | ✓ | ✓ | ✓ | ✓ |
| Data encryption in transit | ✓ | - | ✓ | ✓ | ✓ | ✓ |
| Audit log retention (min) | 1yr | 1yr | 6yr | 1yr | 1yr | 3yr |
| Right to erasure | ✓ | ✓ | - | - | - | - |
| Data portability | ✓ | ✓ | - | - | - | - |
| Consent tracking | ✓ | ✓ | ✓ | - | - | - |
| Access logging | ✓ | - | ✓ | ✓ | ✓ | ✓ |
| Breach notification | 72hr | - | 60days | ✓ | ✓ | ✓ |
| Data residency | ✓ | - | - | - | - | - |
| MFA requirement | - | - | ✓ | ✓ | ✓ | - |
| Password policy | ✓ | - | ✓ | ✓ | ✓ | ✓ |
| Session timeout | - | - | ✓ | ✓ | ✓ | - |
| Vulnerability scanning | - | - | - | ✓ | ✓ | ✓ |

### Overlap Resolution (NON-NEGOTIABLE)

**When multiple compliance standards are enabled and conflict, the STRICTEST requirement wins.**

| Conflict Type | Resolution | Example |
|---------------|------------|---------|
| **Retention period** | Use longest | HIPAA (6yr) beats GDPR (1yr) |
| **Encryption strength** | Use strongest | AES-256 over AES-128 |
| **Breach notification** | Use shortest | GDPR (72hr) beats HIPAA (60days) |
| **Password requirements** | Use strictest | Longest min length, most complexity |
| **Session timeout** | Use shortest | 15min beats 30min |
| **MFA requirement** | Required if ANY standard requires it | |
| **Right to erasure vs retention** | See below | |

**Special Case: Right to Erasure vs Retention Requirements**

When GDPR/CCPA (right to erasure) conflicts with HIPAA/SOC2 (retention requirements):
1. User data is **anonymized** (not deleted) to preserve audit trail
2. All PII is removed, replaced with `[REDACTED]` or anonymized IDs
3. Audit log entries reference anonymized user ID
4. Original user ID mapping is deleted
5. This satisfies both erasure (PII gone) and retention (audit preserved)

### Compliance-Specific Behaviors

#### GDPR (gdpr: true)

| Feature | Behavior |
|---------|----------|
| Cookie consent | Required popup before any tracking |
| Data export | `/user/data/export` endpoint enabled |
| Data deletion | `/user/data/delete` endpoint enabled |
| Consent tracking | All consents logged with timestamp |
| Data residency | Configurable allowed regions |
| Privacy policy | Required, must specify data processing |
| DPO contact | Displayed in privacy policy |
| Breach notification | 72-hour automated alert system |

#### HIPAA (hipaa: true)

| Feature | Behavior |
|---------|----------|
| PHI encryption | All health data encrypted with per-record keys |
| Audit trail | 6-year minimum retention, tamper-evident |
| Access controls | Role-based with minimum necessary access |
| Session timeout | 15 minutes maximum idle |
| MFA | Required for all users |
| BAA tracking | Business Associate Agreements logged |
| Breach notification | 60-day notification system |

#### SOC2 (soc2: true)

| Feature | Behavior |
|---------|----------|
| Change management | All config changes require approval workflow |
| Access reviews | Quarterly access review reminders |
| Vulnerability management | Integration with security scanners |
| Incident response | Defined escalation paths |
| Vendor management | Third-party risk tracking |
| Availability monitoring | Uptime SLA tracking |

#### PCI-DSS (pci_dss: true)

| Feature | Behavior |
|---------|----------|
| Cardholder data | Never stored (use tokenization) |
| Network segmentation | Cardholder environment isolated |
| Password policy | 12+ chars, complexity, 90-day rotation |
| Session timeout | 15 minutes maximum |
| Audit logging | All access to cardholder data logged |
| Vulnerability scanning | Quarterly scans required |
| Penetration testing | Annual requirement tracking |

#### CCPA (ccpa: true)

| Feature | Behavior |
|---------|----------|
| Data disclosure | `/user/data/export` - what data is collected and sold |
| Opt-out of sale | `/user/privacy/do-not-sell` toggle |
| Right to delete | `/user/data/delete` endpoint enabled |
| Non-discrimination | Cannot deny service for exercising rights |
| Privacy notice | "Do Not Sell My Personal Information" link required |
| Verification | Identity verification before data requests |
| Response time | 45 days to fulfill requests (90 with extension) |

#### ISO27001 (iso27001: true)

| Feature | Behavior |
|---------|----------|
| Risk assessment | Documented risk register required |
| Asset inventory | All data assets tracked |
| Access control | Role-based, principle of least privilege |
| Cryptography | Encryption policy enforced |
| Physical security | N/A (cloud-native, document controls) |
| Operations security | Change management, capacity planning |
| Incident management | Defined response procedures |
| Business continuity | Backup and recovery procedures |
| Audit logging | 3-year minimum retention |

#### FedRAMP (fedramp: true)

| Feature | Behavior |
|---------|----------|
| Authorization level | Low/Moderate/High impact configurable |
| Continuous monitoring | Automated security scanning |
| FIPS 140-2 | Cryptographic module compliance |
| Data residency | US-only data centers required |
| Personnel security | Background check tracking |
| Incident response | US-CERT notification procedures |
| Vulnerability scanning | Monthly automated scans |
| Penetration testing | Annual third-party testing |
| POA&M tracking | Plan of Action & Milestones dashboard |

#### LGPD (lgpd: true)

| Feature | Behavior |
|---------|----------|
| Legal basis | Consent or legitimate interest tracking |
| Data subject rights | Access, correction, deletion, portability |
| DPO requirement | Data Protection Officer contact displayed |
| International transfer | Adequacy or safeguards required |
| Breach notification | ANPD notification within reasonable time |
| Privacy notice | Clear, accessible privacy policy in Portuguese |
| Consent | Granular, specific, freely given |
| Children's data | Parental consent for under 18 |

#### PIPEDA (pipeda: true)

| Feature | Behavior |
|---------|----------|
| Consent | Meaningful consent for collection/use/disclosure |
| Purpose limitation | Data used only for stated purposes |
| Access rights | Users can access their personal information |
| Accuracy | Users can challenge and correct data |
| Retention limits | Data kept only as long as necessary |
| Safeguards | Appropriate security for sensitivity level |
| Openness | Privacy policies publicly available |
| Accountability | Designated privacy officer |
| Breach notification | OPC notification for significant breaches |

#### APPI (appi: true)

| Feature | Behavior |
|---------|----------|
| Purpose specification | Clear purpose before collection |
| Use limitation | No use beyond specified purpose |
| Proper acquisition | No deceptive collection practices |
| Accuracy | Keep data accurate and up-to-date |
| Security control | Appropriate safeguards required |
| Third-party oversight | Supervise data handling by processors |
| Disclosure restrictions | User consent for third-party sharing |
| Cross-border transfer | Consent or equivalent protection required |
| Breach notification | PPC and affected individuals notified |

#### PDPA (pdpa: true)

| Feature | Behavior |
|---------|----------|
| Consent | Consent required before collection |
| Purpose limitation | Data used only for notified purposes |
| Notification | Inform users of purposes at collection |
| Access and correction | Users can access and correct data |
| Accuracy | Reasonable efforts to ensure accuracy |
| Protection | Reasonable security arrangements |
| Retention limitation | Delete when no longer needed |
| Transfer limitation | Adequate protection for overseas transfers |
| DPO requirement | Data Protection Officer for certain orgs |
| Breach notification | PDPC notification within 3 days |

### Compliance Routes

| Route | Method | Description |
|-------|--------|-------------|
| `/user/data/export` | GET | Request personal data export (GDPR/CCPA) |
| `/user/data/export/{id}` | GET | Download data export |
| `/user/data/delete` | POST | Request account deletion (GDPR/CCPA) |
| `/user/consents` | GET | View consent history |
| `/user/consents` | PATCH | Update consent preferences |
| `/server/privacy` | GET | Privacy policy |
| `/server/dpo` | GET | Data Protection Officer contact (GDPR) |
| `/admin/server/compliance` | GET | Compliance dashboard |
| `/admin/server/compliance/report` | POST | Generate compliance report |
| `/admin/server/compliance/breach` | POST | Report data breach |

### Compliance API Endpoints

| Endpoint | Method | Description |
|----------|--------|-------------|
| `/api/v1/user/data/export` | POST | Request data export |
| `/api/v1/user/data/export/{id}` | GET | Download export |
| `/api/v1/user/data/delete` | POST | Request deletion |
| `/api/v1/user/consents` | GET | Get consents |
| `/api/v1/user/consents` | PATCH | Update consents |
| `/api/v1/admin/server/compliance` | GET | Compliance status |
| `/api/v1/admin/server/compliance/standards` | GET | Enabled standards |
| `/api/v1/admin/server/compliance/report` | POST | Generate report |
| `/api/v1/admin/server/compliance/breach` | POST | Report breach |
| `/api/v1/admin/server/compliance/audit` | GET | Compliance audit log |

### Admin UI: Compliance Dashboard

**Location:** `/admin/server/compliance`

| Section | Description |
|---------|-------------|
| Enabled Standards | Toggle switches for each standard |
| Compliance Score | Per-standard compliance percentage |
| Issues | Outstanding compliance issues |
| Data Requests | Pending export/deletion requests |
| Breach Log | Data breach history |
| Reports | Generate/download compliance reports |
| Upcoming | Scheduled audits, certificate renewals |

### Compliance Audit Events

| Event | Description | Logged Data |
|-------|-------------|-------------|
| `compliance.standard_enabled` | Standard enabled | Standard name, enabled by |
| `compliance.standard_disabled` | Standard disabled | Standard name, disabled by |
| `compliance.data_export_requested` | User requested data export | User ID, request ID |
| `compliance.data_export_completed` | Data export ready | User ID, request ID, file size |
| `compliance.data_deletion_requested` | User requested deletion | User ID, request ID |
| `compliance.data_deletion_completed` | Deletion completed | User ID (anonymized after) |
| `compliance.consent_updated` | User updated consents | User ID, consent type, new value |
| `compliance.breach_reported` | Data breach reported | Breach ID, severity, reporter |
| `compliance.breach_notified` | Breach notification sent | Breach ID, notification type |
| `compliance.breach_investigation_started` | Investigation began | Breach ID, investigator |
| `compliance.breach_investigation_completed` | Investigation closed | Breach ID, outcome |
| `compliance.breach_escalated` | Breach escalated to authorities | Breach ID, authority |
| `compliance.report_generated` | Compliance report generated | Report type, generated by |

### Data Protection

**Encryption Strategy:**

| Data Type | Protection | Method |
|-----------|------------|--------|
| Passwords | Always hashed | Argon2id |
| API tokens | Always hashed | SHA-256 |
| 2FA secrets | Always encrypted | AES-256-GCM (server key) |
| Recovery keys | Always hashed | SHA-256 |
| Backups | Encrypted if password set | AES-256-GCM (user password) |
| Database at rest | OS responsibility | Use encrypted filesystem |
| Data in transit | Always TLS | TLS 1.2+ required |

**Database Encryption:**

The application does **not** implement database-level encryption. This is intentional:

| Reason | Explanation |
|--------|-------------|
| Complexity | Key management adds significant complexity |
| Performance | Encryption/decryption overhead on every query |
| OS-level better | LUKS, FileVault, BitLocker handle this transparently |
| SQLite limitation | SQLite doesn't support transparent encryption natively |

**Recommendation:** Use OS-level disk encryption (LUKS on Linux, FileVault on macOS, BitLocker on Windows) for encryption at rest. This protects all data including databases, logs, and config files.

**What IS Protected by the Application:**

| Protected | How |
|-----------|-----|
| Passwords | Argon2id hash (never stored in plain text) |
| API tokens | SHA-256 hash (never stored in plain text) |
| 2FA secrets | AES-256-GCM encrypted with server-generated key |
| Backup files | AES-256-GCM encrypted with admin password (if configured) |
| Session tokens | Cryptographically random, short-lived |

**Server Encryption Key:**

For 2FA secrets and other server-encrypted data:

```yaml
# Auto-generated on first run, stored in server.yml
server:
  security:
    encryption_key: "base64-encoded-32-byte-random-key"
```

- Generated automatically on first run (32 bytes from crypto/rand)
- Stored in config file (protected by file permissions)
- Used to encrypt 2FA secrets and similar sensitive data
- If lost, users must re-enroll 2FA

### Breach Detection

**Automated Detection Mechanisms:**

| Detection Type | Trigger | Severity | Auto-Action |
|----------------|---------|----------|-------------|
| **Brute Force** | 10+ failed logins in 5min from same IP | Medium | Block IP, alert admin |
| **Credential Stuffing** | 50+ failed logins in 10min across accounts | High | Rate limit, alert admin |
| **Unusual Access Pattern** | Access from new country + sensitive action | Medium | Require 2FA, alert user |
| **Mass Data Export** | Export requests > threshold in timeframe | High | Queue for review, alert admin |
| **Privilege Escalation** | Unauthorized admin action attempt | Critical | Block session, alert admin |
| **API Abuse** | API rate exceeded 10x normal | Medium | Throttle, alert admin |
| **Session Anomaly** | Same session from multiple IPs/locations | High | Invalidate session, alert user |
| **Database Anomaly** | Unusual query patterns (injection attempts) | Critical | Block request, alert admin |
| **File Access Anomaly** | Access to backup/export files without request | Critical | Block, alert admin |
| **Config Tampering** | Unauthorized config file modification | Critical | Rollback, alert admin |

**Detection Configuration:**

Breach detection is **always enabled** with sane defaults. Thresholds are configurable but detection cannot be disabled.

```yaml
server:
  security:
    breach_detection:
      # Brute force: too many failed logins from same IP
      brute_force:
        attempts: 10
        window: 5m
        block_duration: 1h

      # Credential stuffing: failed logins across many accounts
      credential_stuffing:
        attempts: 50
        window: 10m

      # Unusual access patterns
      unusual_access:
        new_country_alert: true
        new_device_alert: true

      # Mass data export detection
      mass_export:
        threshold: 10
        window: 1h

      # API abuse (multiplier of normal rate)
      api_abuse:
        multiplier: 10

      # Auto-actions (all enabled by default)
      auto_block_ip: true
      auto_invalidate_sessions: true
      auto_alert_admin: true
      auto_alert_user: true
```

**Sane Defaults (NON-NEGOTIABLE):**

| Setting | Default | Rationale |
|---------|---------|-----------|
| Brute force threshold | 10 attempts / 5min | Catches attacks, allows typos |
| Credential stuffing | 50 attempts / 10min | Cross-account pattern detection |
| Block duration | 1 hour | Sufficient deterrent, not permanent |
| New country alert | Enabled | High-value security signal |
| New device alert | Enabled | Helps users spot compromises |
| Mass export threshold | 10 / hour | Prevents data scraping |
| API abuse multiplier | 10x | Catches abuse, allows bursts |
| Auto-block IP | Enabled | Immediate threat response |
| Auto-invalidate sessions | Enabled | Limits breach scope |
| Auto-alert admin | Enabled | Ensures visibility |
| Auto-alert user | Enabled | User can take action |

**Detection Events (Audit Log):**

| Event | Description | Logged Data |
|-------|-------------|-------------|
| `security.breach_detected` | Automated breach detection triggered | Detection type, severity, details |
| `security.breach_auto_action` | Auto-action taken | Action type, target, reason |
| `security.threat_blocked` | Threat automatically blocked | Threat type, source IP, target |
| `security.anomaly_detected` | Anomalous pattern detected | Anomaly type, score, details |

### IP Block Management

**Block Types:**

| Type | Duration | Release | Description |
|------|----------|---------|-------------|
| **Temporary** | Configurable (default 1h) | Auto-release after expiry | Brute force, rate limiting |
| **Extended** | 24 hours | Auto-release after expiry | Credential stuffing, repeated offenses |
| **Permanent** | Indefinite | Manual only | Admin-added, severe threats |

**Auto-Release:**

Temporary blocks are automatically released when:
1. Block duration expires (checked every minute by scheduler)
2. Admin manually unblocks
3. IP is added to allowlist

**Escalation (Repeat Offenders):**

| Offense | Block Duration |
|---------|----------------|
| 1st | 1 hour (configurable) |
| 2nd within 24h | 4 hours |
| 3rd within 24h | 24 hours |
| 4th+ within 7 days | 7 days + admin alert |

### Account Lockout (User-Level)

**Separate from IP blocking.** When a specific user account has too many failed login attempts:

| Failed Attempts | Action | Duration |
|-----------------|--------|----------|
| 5 in 15 minutes | Soft lock | 15 minutes |
| 10 in 1 hour | Hard lock | 1 hour |
| 15 in 24 hours | Account lock | Until admin unlock OR password reset |

**Sane Defaults:**
```yaml
server:
  security:
    account_lockout:
      # Soft lock: brief lockout after few failures
      soft_lock_attempts: 5
      soft_lock_window: 15m
      soft_lock_duration: 15m
      # Hard lock: longer lockout after more failures
      hard_lock_attempts: 10
      hard_lock_window: 1h
      hard_lock_duration: 1h
      # Permanent lock: requires admin unlock or password reset
      permanent_lock_attempts: 15
      permanent_lock_window: 24h
```

**Lockout Behavior:**
- **Soft lock**: User sees "Too many attempts, try again in X minutes"
- **Hard lock**: Same message, longer wait
- **Permanent lock**: User must reset password via email OR admin unlocks

**Unlock Methods:**
| Method | Who Can Do | When |
|--------|------------|------|
| Wait | System | Soft/hard lock expiry |
| Password reset | User | Any lockout |
| Admin unlock | Server admin | Any lockout |
| Allowlisted IP | System | Never locked from trusted IPs |

**Why Both IP Block AND Account Lockout?**
- IP block stops distributed attacks from one source
- Account lockout stops attacks targeting one account from multiple IPs
- Together they cover credential stuffing (many accounts, one IP) AND targeted attacks (one account, many IPs)

**IP Block Data Model:**

```go
type IPBlock struct {
    IP          string    `json:"ip"`
    CIDR        string    `json:"cidr,omitempty"`     // Optional range block
    Type        BlockType `json:"type"`               // temporary, extended, permanent
    Reason      string    `json:"reason"`
    BlockedAt   time.Time `json:"blocked_at"`
    ExpiresAt   *time.Time `json:"expires_at,omitempty"` // nil = permanent
    OffenseCount int      `json:"offense_count"`
    AutoBlocked bool      `json:"auto_blocked"`        // true = system, false = admin
    BlockedBy   string    `json:"blocked_by,omitempty"` // admin ID if manual
}
```

**IP Management API:**

| Endpoint | Method | Description |
|----------|--------|-------------|
| `/api/v1/admin/server/security/blocked-ips` | GET | List blocked IPs |
| `/api/v1/admin/server/security/blocked-ips` | POST | Manually block IP/CIDR |
| `/api/v1/admin/server/security/blocked-ips/{ip}` | GET | Get block details |
| `/api/v1/admin/server/security/blocked-ips/{ip}` | DELETE | Unblock IP |
| `/api/v1/admin/server/security/blocked-ips/expired` | DELETE | Purge expired blocks from log |
| `/api/v1/admin/server/security/allowlist` | GET | List allowed IPs |
| `/api/v1/admin/server/security/allowlist` | POST | Add IP/CIDR to allowlist |
| `/api/v1/admin/server/security/allowlist/{ip}` | DELETE | Remove from allowlist |

**Account Lockout API:**

| Endpoint | Method | Description |
|----------|--------|-------------|
| `/api/v1/admin/server/security/locked-accounts` | GET | List locked accounts |
| `/api/v1/admin/server/security/locked-accounts/{id}` | DELETE | Unlock account |

**Security Settings API:**

| Endpoint | Method | Description |
|----------|--------|-------------|
| `/api/v1/admin/server/security/settings` | GET | Get all security settings |
| `/api/v1/admin/server/security/settings` | PATCH | Update security settings |
| `/api/v1/admin/server/security/auth` | GET | Get auth settings (password policy, etc.) |
| `/api/v1/admin/server/security/auth` | PATCH | Update auth settings |
| `/api/v1/admin/server/security/ratelimit` | GET | Get rate limit settings |
| `/api/v1/admin/server/security/ratelimit` | PATCH | Update rate limit settings |

**Password Policy (Sane Defaults):**

```yaml
server:
  security:
    password:
      # Minimum 8 chars (auto-upgrades to 12 if HIPAA/SOC2 enabled)
      min_length: 8
      # Complexity requirements (auto-enabled if compliance standards active)
      require_uppercase: false
      require_lowercase: false
      require_number: false
      require_special: false
      # Password expiry (0 = never, auto-sets to 90 if compliance)
      max_age_days: 0
      # Password history (0 = none, auto-sets to 12 if compliance)
      history_count: 0
```

**Password Policy Auto-Upgrade (Compliance):**

When compliance standards are enabled, password policy automatically upgrades:

| Setting | Default | HIPAA/SOC2/PCI-DSS |
|---------|---------|---------------------|
| min_length | 8 | 12 |
| require_uppercase | false | true |
| require_number | false | true |
| require_special | false | true |
| max_age_days | 0 | 90 |
| history_count | 0 | 12 |

**Note:** These are minimums. Admin can set stricter policies but not weaker when compliance is enabled.

**API Token Management:**

| Endpoint | Method | Description |
|----------|--------|-------------|
| `/api/v1/admin/server/security/tokens` | GET | List all API tokens (admin view) |
| `/api/v1/admin/server/security/tokens/{id}` | DELETE | Revoke token |
| `/api/v1/admin/server/security/tokens/{id}/rotate` | POST | Force token rotation |

**Token Expiry (Sane Defaults):**

```yaml
server:
  security:
    tokens:
      # 0 = tokens never expire
      default_expiry: 0
      # Maximum allowed expiry (365 days)
      max_expiry: 365d
      # Remind admin to rotate after 90 days
      rotation_reminder: 90d
```

**Allowlist:**

IPs on the allowlist are **never auto-blocked**. Use for:
- Office IPs
- CI/CD servers
- Monitoring services
- Load balancers / reverse proxies

```yaml
server:
  security:
    allowlist:
      - 10.0.0.0/8        # Internal network
      - 192.168.1.0/24    # Office
      # Add trusted IPs/CIDRs
```

**Admin UI: IP Blocks**

**Location:** `/admin/server/security/blocked-ips`

| Section | Description |
|---------|-------------|
| Active Blocks | Currently blocked IPs with expiry countdown |
| Block History | Past blocks (configurable retention) |
| Allowlist | Trusted IPs that bypass blocking |
| Add Block | Manually block IP/CIDR |
| Bulk Actions | Unblock selected, export list |

**Block Details View:**

| Field | Description |
|-------|-------------|
| IP/CIDR | Blocked address or range |
| Type | Temporary / Extended / Permanent |
| Reason | Why blocked (brute_force, credential_stuffing, manual, etc.) |
| Blocked At | Timestamp |
| Expires At | Countdown or "Never" |
| Offense Count | Number of times this IP triggered blocks |
| Related Events | Link to audit log entries |
| Actions | Unblock, Extend, Make Permanent |

**Audit Events:**

| Event | Description | Logged Data |
|-------|-------------|-------------|
| `security.ip_blocked` | IP was blocked | IP, reason, duration, auto/manual |
| `security.ip_unblocked` | IP was unblocked | IP, unblocked_by (system/admin), reason |
| `security.ip_block_extended` | Block duration extended | IP, new_expiry, reason |
| `security.ip_allowlisted` | IP added to allowlist | IP/CIDR, added_by |
| `security.ip_allowlist_removed` | IP removed from allowlist | IP/CIDR, removed_by |
| `security.account_soft_locked` | Account soft locked | User ID (masked), attempts, duration |
| `security.account_hard_locked` | Account hard locked | User ID (masked), attempts, duration |
| `security.account_locked` | Account permanently locked | User ID (masked), attempts |
| `security.account_unlocked` | Account unlocked | User ID, unlocked_by (system/admin/password_reset) |
| `security.password_policy_changed` | Password policy updated | Changed fields, changed_by |
| `security.token_revoked` | API token revoked | Token ID (masked), revoked_by |
| `security.token_rotated` | API token rotated | Token ID (masked), rotated_by |

### Breach Management

**Breach Lifecycle:**

```
┌─────────────┐     ┌──────────────┐     ┌───────────────┐     ┌─────────────┐
│  Detected   │────▶│ Investigating│────▶│   Contained   │────▶│  Notifying  │
└─────────────┘     └──────────────┘     └───────────────┘     └─────────────┘
                                                                      │
                    ┌──────────────┐     ┌───────────────┐           │
                    │   Resolved   │◀────│  Remediated   │◀──────────┘
                    └──────────────┘     └───────────────┘
```

**Breach Severity Levels:**

| Level | Description | Notification Timeline | Auto-Escalate |
|-------|-------------|----------------------|---------------|
| **Critical** | Active data exfiltration, full system compromise | Immediate | Yes |
| **High** | Unauthorized access to sensitive data | 24 hours | Yes (72hr) |
| **Medium** | Potential data exposure, failed attacks | 72 hours | No |
| **Low** | Minor security events, policy violations | 7 days | No |

**Breach Management API:**

| Endpoint | Method | Description |
|----------|--------|-------------|
| `/api/v1/admin/server/breaches` | GET | List all breaches |
| `/api/v1/admin/server/breaches` | POST | Report new breach |
| `/api/v1/admin/server/breaches/{id}` | GET | Get breach details |
| `/api/v1/admin/server/breaches/{id}` | PATCH | Update breach status |
| `/api/v1/admin/server/breaches/{id}/investigate` | POST | Start investigation |
| `/api/v1/admin/server/breaches/{id}/contain` | POST | Mark as contained |
| `/api/v1/admin/server/breaches/{id}/notify` | POST | Send notifications |
| `/api/v1/admin/server/breaches/{id}/resolve` | POST | Mark as resolved |
| `/api/v1/admin/server/breaches/{id}/affected` | GET | List affected users |
| `/api/v1/admin/server/breaches/{id}/timeline` | GET | Breach timeline/events |
| `/api/v1/admin/server/breaches/{id}/report` | GET | Generate breach report |

**Breach Data Model:**

```go
type Breach struct {
    ID              string        `json:"id"`
    Status          BreachStatus  `json:"status"`
    Severity        Severity      `json:"severity"`
    Type            string        `json:"type"`
    Summary         string        `json:"summary"`
    Description     string        `json:"description"`
    DetectedAt      time.Time     `json:"detected_at"`
    DetectedBy      string        `json:"detected_by"`      // "system" or admin ID
    DetectionMethod string        `json:"detection_method"` // automated/manual/external
    AffectedData    []string      `json:"affected_data"`    // data categories
    AffectedUsers   int           `json:"affected_users"`
    ContainedAt     *time.Time    `json:"contained_at,omitempty"`
    NotifiedAt      *time.Time    `json:"notified_at,omitempty"`
    ResolvedAt      *time.Time    `json:"resolved_at,omitempty"`
    RootCause       string        `json:"root_cause,omitempty"`
    Remediation     string        `json:"remediation,omitempty"`
    Timeline        []BreachEvent `json:"timeline"`
    Compliance      []string      `json:"compliance"`       // applicable standards
    NotifyDeadline  time.Time     `json:"notify_deadline"`  // based on strictest standard
}

type BreachStatus string
const (
    BreachDetected     BreachStatus = "detected"
    BreachInvestigating BreachStatus = "investigating"
    BreachContained    BreachStatus = "contained"
    BreachNotifying    BreachStatus = "notifying"
    BreachRemediated   BreachStatus = "remediated"
    BreachResolved     BreachStatus = "resolved"
)
```

**Admin UI: Breach Management**

**Location:** `/admin/server/compliance/breaches`

| Section | Description |
|---------|-------------|
| Active Breaches | Current breaches requiring attention |
| Breach Timeline | Visual timeline of all breach events |
| Affected Users | List users impacted, notification status |
| Notification Queue | Pending notifications, send/preview |
| Authority Reporting | Generate reports for regulatory authorities |
| Breach History | All past breaches with outcomes |

**Report New Breach Form:**

| Field | Type | Required | Description |
|-------|------|----------|-------------|
| Severity | Select | Yes | Critical/High/Medium/Low |
| Type | Select | Yes | Unauthorized access, Data exposure, etc. |
| Summary | Text | Yes | Brief description (shown in notifications) |
| Description | Textarea | Yes | Full details for internal use |
| Affected Data | Multi-select | Yes | Categories: credentials, email, profile, etc. |
| Detection Method | Select | Yes | Automated/Manual/External report |
| Estimated Affected Users | Number | No | Initial estimate |

---


# PART 23: USER MANAGEMENT (NON-NEGOTIABLE)

## Overview

**Projects can operate in two modes: admin-only or multi-user.**

| Mode | Use Case | Default |
|------|----------|---------|
| **Admin-only** | Simple APIs (jokes, quotes, etc.) - just admin account | YES |
| **Multi-user** | Apps needing user accounts, registration, profiles, API tokens | NO |

## Server Admin vs Regular Users (NON-NEGOTIABLE)

**Server admins are ADMINISTRATIVE ACCOUNTS responsible for managing the application itself. Regular users are end-users of the application.**

### Key Distinction

| Aspect | Server Admin | Regular User |
|--------|--------------|--------------|
| **Purpose** | Manage server, configuration, other users | Use the application features |
| **Scope** | Server-wide administration | Own account and data only |
| **Storage** | `admins` table | `users` table |
| **Login** | `/auth/login` → `/admin/*` | `/auth/login` → `/user/*` |
| **Access** | Admin panel (`/admin/*`) | User routes (`/user/*`) |
| **Created by** | Setup wizard, existing admin, or OIDC/LDAP group mapping | Registration or admin invitation |

### Account Types Summary

| Account Type | Storage | Login | Access |
|--------------|---------|-------|--------|
| **Server Admin** | Database (`admins` table) | `/auth/login` | `/admin/*` only |
| **Regular Users** | Database (`users` table) | `/auth/login` | `/user/*` routes |

**Important:** Server admins and regular users are completely separate account types. A server admin is NOT a "privileged user" - they are a different kind of account entirely.

### Server Admin Behavior

| Route | Server Admin Access |
|-------|---------------------|
| `/admin/*` | Full access |
| `/user/*` | NO - treated as guest (redirect to `/admin`) |
| `/auth/login` | Login page |
| `/auth/logout` | Logout |
| Public routes (`/`, `/server/*`, etc.) | Guest view (no user-specific content) |

## Registration Modes (Multi-User Apps Only)

**Multi-user apps use a SINGLE setting to control registration behavior.**

**Config setting:**
```yaml
users:
  # Enable multi-user mode
  enabled: true

  registration:
    # Registration mode: disabled, public, private, approval
    mode: disabled
```

### Registration Mode Definitions

| Mode | Who Can Register | Use Case | Admin Action Required |
|------|------------------|----------|----------------------|
| **disabled** | No one | Admin-created accounts only | Admin creates all users |
| **public** | Anyone | Open community, public service | None (auto-active after email verify) |
| **private** | Invite code holders only | Controlled growth, beta testing | Users generate invite codes |
| **approval** | Anyone (pending approval) | Moderated community | Admin approves each registration |

### Mode: disabled

**No registration allowed. Admin creates all user accounts.**

- `/auth/register` → 404 or redirect to `/auth/login`
- Registration form not shown anywhere
- Only admins can create users via `/admin/server/users/create`
- Use for: Internal tools, admin-only services

### Mode: public

**Anyone can register with valid email. Immediate access after email verification.**

- `/auth/register` → Registration form
- User submits username, email, password
- Email verification sent (if `require_email_verification: true`)
- After verification → account immediately active
- No admin approval needed
- Use for: Public services, open communities

### Mode: private

**Invite-only registration. Users need an invite code.**

- Existing users generate invite codes at `/user/invites/create`
- Invite code has expiration (`invite_expiration_days` config)
- New user visits `/auth/register?invite={code}`
- Invite code validated, user submits registration form
- Email verification sent (if `require_email_verification: true`)
- After verification → account active
- Invite code consumed (one-time use)
- Use for: Controlled growth, beta testing, exclusive communities

**Invite code management:**
- Users can create up to `max_invites_per_user` codes
- Invite codes expire after `invite_expiration_days`
- Track who invited whom (referral tracking)
- Admin can see all invites at `/admin/server/users/invites`

### Mode: approval

**Anyone can register, but admin must approve before account is active.**

- `/auth/register` → Registration form
- User submits registration form
- Email verification sent (if `require_email_verification: true`)
- After verification → account created as **pending**
- Admin notified of pending user
- Admin reviews at `/admin/server/users/pending`
- Admin approves/rejects
- If approved → account active, user notified
- If rejected → account deleted, user notified
- Use for: Moderated communities, quality control

**Server Admin Setup (Setup Wizard Flow):**

**IMPORTANT: App works perfectly with sane defaults before setup.** Setup wizard is optional and allows customization. Server is fully functional immediately on first run.

### First Run Experience (NON-NEGOTIABLE)

**On first run, the application:**

1. Creates default `server.yml` with sane defaults
2. Creates empty `server.db` database
3. Auto-detects and configures SMTP (if available)
4. Selects random available port (64xxx range)
5. Generates one-time setup token
6. Displays startup information in console
7. **Starts serving immediately** - fully functional

**Console Output (First Run):**

```
╔══════════════════════════════════════════════════════════════════════╗
║                                                                      ║
║   CASSPEED v1.0.0                                               ║
║                                                                      ║
║   Status: Running (first run - setup available)                      ║
║                                                                      ║
╠══════════════════════════════════════════════════════════════════════╣
║                                                                      ║
║   🌐 Web Interface:                                                   ║
║      http://localhost:64521                                          ║
║      http://192.168.1.100:64521                                      ║
║                                                                      ║
║   🔧 Admin Panel:                                                     ║
║      http://localhost:64521/admin                                    ║
║                                                                      ║
║   🔑 Setup Token (use at /admin):                                     ║
║      a1b2c3d4e5f67890abcdef1234567890                                ║
║                                                                      ║
║   📧 SMTP: Auto-detected (localhost:25)                               ║
║                                                                      ║
║   ⚠️  Save the setup token! It will not be shown again.               ║
║                                                                      ║
╚══════════════════════════════════════════════════════════════════════╝

[INFO] Server started successfully
[INFO] Listening on 0.0.0.0:64521
[INFO] SMTP auto-detected: localhost:25 (enabled)
```

**If SMTP Not Detected:**

```
║   📧 SMTP: Not detected (email features disabled)                     ║
║      Configure manually at /admin/server/email                       ║
```

### SMTP Auto-Detection & Test (NON-NEGOTIABLE)

**SMTP detection/testing is always enabled - no toggle.**

| SMTP Host | Behavior |
|-----------|----------|
| Not configured | Auto-detect local SMTP servers |
| Configured | Test connection on startup |

**Auto-Detection (when host not set):**

| Check | Hosts | Ports |
|-------|-------|-------|
| 1 | `localhost` | 25, 587, 465 |
| 2 | `127.0.0.1` | 25, 587, 465 |
| 3 | `172.17.0.1` (Docker host) | 25, 587, 465 |
| 4 | Gateway IP | 25, 587, 465 |

**Auto-Detection Process:**
1. Try each host/port combination
2. Attempt SMTP handshake (EHLO)
3. First successful connection is used
4. Save to `server.yml` and enable email features
5. If all fail → email features disabled (not an error)

**Connection Test (when host is set):**
1. On every startup, test configured SMTP connection
2. Attempt SMTP handshake (EHLO)
3. If success → email enabled
4. If fail → email disabled, log warning, continue running
5. Retry on next startup

**SMTP Config:**
```yaml
server:
  notifications:
    email:
      smtp:
        # If empty: autodetect. If set: test connection.
        host: ""
        port: 587
        username: ""
        password: ""
        # TLS mode: auto, starttls, tls, none
        tls: auto
      from:
        # Default: app title
        name: ""
        # Default: no-reply@{fqdn}
        email: ""
```

**Environment Variable Priority:**

`SMTP_*` env vars override config file settings. Useful for containers.

| Env Var | Config Path | Default |
|---------|-------------|---------|
| `SMTP_HOST` | `smtp.host` | (autodetect) |
| `SMTP_PORT` | `smtp.port` | 587 |
| `SMTP_USERNAME` | `smtp.username` | (none) |
| `SMTP_PASSWORD` | `smtp.password` | (none) |
| `SMTP_TLS` | `smtp.tls` | auto |
| `SMTP_FROM_NAME` | `from.name` | (app title) |
| `SMTP_FROM_EMAIL` | `from.email` | no-reply@{fqdn} |

**Behavior Summary:**
- **No host configured**: Autodetect on every startup until found
- **Host configured**: Test on every startup
- **Test fails**: Email disabled, app continues, warning logged
- **Test succeeds**: Email enabled
- No manual "enable/disable" toggle - determined by SMTP availability
- Logged to console and audit log

### App Usability Before Setup

**The app is FULLY FUNCTIONAL before completing the setup wizard.**

| Feature | Available Before Setup? |
|---------|------------------------|
| Public API endpoints | ✓ Yes |
| Public web pages | ✓ Yes |
| Health checks (`/healthz`) | ✓ Yes |
| OpenAPI docs (`/openapi`) | ✓ Yes |
| GraphQL (if applicable) | ✓ Yes |
| Admin panel (`/admin`) | ✓ Yes (requires setup token) |
| Email features | ✓ Yes (if SMTP auto-detected) |
| Scheduled tasks | ✓ Yes (with defaults) |

**What Setup Wizard Provides:**
- Custom admin username/password (instead of generated)
- Customize app name/branding
- Configure optional features (Tor, SSL, multi-user)
- Receive API token for programmatic access

**Why This Matters:**
- Zero-config deployment works immediately
- Docker containers start serving instantly
- Setup can be done later at convenience
- CI/CD pipelines don't need interactive setup

### Setup Flow

On first run, a one-time setup token is generated and displayed in console. Admin setup follows this flow:

| Step | Action |
|------|--------|
| 1 | Server generates one-time setup token (displayed in console ONCE) |
| 2 | User navigates to `/admin` |
| 3 | User enters setup token |
| 4 | Redirect to `/admin/server/setup` (setup wizard) |

**Setup Wizard Steps (`/admin/server/setup`):**

**Step 1: Create Admin Account**
| Field | Default | Notes |
|-------|---------|-------|
| Username | `administrator` | Changeable to anything (username blacklist does NOT apply to admin) |
| Password | Random (generated) | User MUST copy, OR can enter custom + confirm |

**Step 2: API Token**
| Action | Notes |
|--------|-------|
| Auto-generate API token | User MUST copy (shown once) |
| Token is tied to admin account | Used for API access |

**Step 3: Server Configuration**
| Setting | Description |
|---------|-------------|
| App name | Display name for the application |
| Domain/FQDN | Primary domain (if known) |
| Mode | Production / Development |
| Timezone | Server timezone |

**Step 4: Security Settings**
| Setting | Default | Recommended | Description |
|---------|---------|-------------|-------------|
| Backup encryption password | (none) | **SET ONE** | Encrypts all backups (AES-256-GCM) |
| Enable 2FA for this admin | No | Yes | Adds TOTP to admin account |

**Backup Encryption Password:**
- If set, ALL backups are encrypted with AES-256-GCM
- Password is **never stored** - admin must remember it
- Cannot recover backups without this password
- Can be changed later (new backups use new password, old backups need old password)
- **Highly recommended** - shown with warning if skipped

```
┌─────────────────────────────────────────────────────────────────────┐
│  STEP 4: SECURITY SETTINGS                                          │
├─────────────────────────────────────────────────────────────────────┤
│                                                                      │
│  Backup Encryption Password                                          │
│  ┌─────────────────────────────────────────────────────────────────┐│
│  │ ••••••••••••••                                            [👁] ││
│  └─────────────────────────────────────────────────────────────────┘│
│  ┌─────────────────────────────────────────────────────────────────┐│
│  │ ••••••••••••••  (confirm)                                 [👁] ││
│  └─────────────────────────────────────────────────────────────────┘│
│                                                                      │
│  ⚠️  IMPORTANT: This password encrypts all backups. If you lose     │
│  it, you CANNOT recover your backups. Store it securely!            │
│                                                                      │
│  [ ] Skip (not recommended)                                          │
│                                                                      │
│  ────────────────────────────────────────────────────────────────── │
│                                                                      │
│  [ ] Enable 2FA for my admin account                                │
│      (You can enable this later in /admin/profile)                  │
│                                                                      │
└─────────────────────────────────────────────────────────────────────┘
```

**Step 5: Optional Services**
| Setting | Description |
|---------|-------------|
| Enable SSL | Configure HTTPS |
| Enable Users | Enable multi-user mode |

**Note:** Tor is auto-enabled if installed (no setup option needed).

**Step 6: Complete**
| Action | Notes |
|--------|-------|
| Save configuration | Write to `server.yml` |
| Mark setup complete | Setup token invalidated |
| Redirect to `/admin` | Logged in as admin |

**Setup Token Rules:**
- Generated on first run ONLY
- Displayed in console ONCE (never stored in plain text)
- Single use - invalidated after setup complete
- If lost, must reset database to regenerate

**Setup Token Format:**
```
Format: {random-32-hex-chars}
Example: a1b2c3d4e5f67890abcdef1234567890

Display in console:
  Setup Token: a1b2c3d4e5f67890abcdef1234567890
```
- 32 hexadecimal characters (128-bit random)
- No prefix, no dashes (simple format for easy copy/paste)
- Case-insensitive for input validation

**Server Admin Credentials Storage:**
- Stored in database (`admins` table) - NEVER in config file
- Managed via `/admin/server/settings` (NOT `/user/profile`)
- NOT in the users table (separate table for isolation)
- Multiple server admin accounts supported (primary admin created during setup)

### Multiple Server Admins (NON-NEGOTIABLE)

**Server admins CAN add additional server admins.**

| Method | Description |
|--------|-------------|
| **Manual creation** | Primary admin invites additional admin accounts via `/admin/server/admins` |
| **OIDC/LDAP group mapping** | Map external identity provider groups to server admin role |

**Admin Hierarchy:**
| Admin Type | Created By | Can Create Admins? | Can Delete Admins? |
|------------|------------|--------------------|--------------------|
| **Primary Admin** | Setup wizard | Yes | Yes (except self) |
| **Additional Admins** | Primary or other admin | Yes | Yes (except self and primary) |
| **OIDC/LDAP Admins** | Group mapping | Yes | Yes (except primary) |

**Rules:**
- Primary admin cannot be deleted (only via `--maintenance setup`)
- All admins have equal permissions (except deletion hierarchy)
- OIDC/LDAP admin access is automatic based on group membership
- Removing user from external group removes admin access on next login
- All admin actions are audited with admin username

### Server Admin Security (NON-NEGOTIABLE)

**ALL security settings that apply to the primary server admin ALSO apply to additional server admins.**

| Security Feature | Applies To | Required/Recommended |
|------------------|------------|---------------------|
| Password complexity requirements | All server admins | REQUIRED |
| TOTP 2FA support | All server admins | REQUIRED (usage recommended) |
| Passkey/WebAuthn support | All server admins | REQUIRED (usage recommended) |
| Recovery keys (when MFA enabled) | All server admins | REQUIRED |
| Session timeout | All server admins | REQUIRED |
| API token security | All server admins | REQUIRED |
| Audit logging | All server admins | REQUIRED |
| Rate limiting | All server admins | REQUIRED |
| IP restrictions (if configured) | All server admins | OPTIONAL |

**MFA for Server Admins:**
- Every project MUST support TOTP and Passkeys for server admins
- MFA is optional but STRONGLY recommended - admin chooses to enable
- This applies even to simple apps without regular users (e.g., `jokes`, `airports`)
- Admin panel shows clear prompts encouraging MFA setup

**No exceptions.** Additional admins do not get weaker security than the primary admin.

### Server Admin Privacy (NON-NEGOTIABLE)

**Server admins CANNOT see other server admin accounts, similar to user privacy.**

| What Admin CAN See | What Admin CANNOT See |
|--------------------|----------------------|
| Own account details | Other admin usernames |
| Own API token (regenerate) | Other admin emails |
| Own 2FA status | Other admin passwords |
| Own session history | Other admin API tokens |
| Total admin count (number only) | Other admin 2FA secrets |
| | Other admin session data |

**Admin Panel (`/admin/server/admins`):**
```
┌─────────────────────────────────────────────────────────────┐
│  Server Administrators                                      │
├─────────────────────────────────────────────────────────────┤
│  Your Account: administrator                                │
│  Total Admins: 3                                            │
│                                                             │
│  ┌─────────────────────────────────────────────────────┐    │
│  │  [Invite New Admin]                                 │    │
│  └─────────────────────────────────────────────────────┘    │
│                                                             │
│  Note: For security, you cannot view other admin accounts.  │
│  Each admin manages their own credentials independently.    │
└─────────────────────────────────────────────────────────────┘
```

**Why This Restriction?**
- **Separation of trust**: Compromised admin cannot enumerate other admins
- **Privacy**: Admin credentials are personal, not shared
- **Security**: Prevents admin-to-admin attacks
- **Audit integrity**: Each admin accountable for own actions only

**What Admins CAN Do With Other Admins:**
| Action | Allowed? | Notes |
|--------|----------|-------|
| Know total count | ✓ | Number only, no details |
| See who is logged in | ✓ | Username only (e.g., "administrator logged in") |
| Add new admin (invite) | ✓ | Creates invite, credentials shown once to new admin |
| Remove admin (non-primary) | ✓ | By username only (must know it) |
| View other admin details | ✗ | Privacy by design |
| Reset other admin password | ✗ | Each admin manages own credentials |
| Disable other admin 2FA | ✗ | Use `--maintenance setup` for recovery |

### Adding Additional Server Admins

**Three methods to add server admins:**

| Method | Description | Use Case |
|--------|-------------|----------|
| **Invite** | Generate invite link/code | Manual admin creation |
| **OIDC Group Mapping** | Automatic via group membership | SSO environments |
| **LDAP Group Mapping** | Automatic via group membership | Enterprise environments |

#### Admin Invite Flow

```
Admin Panel (/admin/server/admins)
┌─────────────────────────────────────────────────────────────┐
│  Server Administrators                                      │
├─────────────────────────────────────────────────────────────┤
│  Your Account: administrator                                │
│  Total Admins: 2                                            │
│  Currently Online: administrator, backup-admin              │
│                                                             │
│  [+ Invite New Admin]                                       │
└─────────────────────────────────────────────────────────────┘

Admin clicks "Invite New Admin"
         ↓
┌─────────────────────────────────────────────────────────────┐
│  Invite New Server Admin                                    │
├─────────────────────────────────────────────────────────────┤
│  Username: [                    ]                           │
│                                                             │
│  Invite expires in: [24 hours ▼]                            │
│                                                             │
│  [Cancel]  [Generate Invite]                                │
└─────────────────────────────────────────────────────────────┘

         ↓ (Invite generated)

┌─────────────────────────────────────────────────────────────┐
│  ✅ Admin Invite Created                                     │
├─────────────────────────────────────────────────────────────┤
│  Username: backup-admin                                     │
│                                                             │
│  Invite URL (share with new admin):                         │
│  ┌─────────────────────────────────────────────────────┐    │
│  │ https://app.example.com/auth/invite/server/abc123...│    │
│  └─────────────────────────────────────────────────────┘    │
│  [Copy URL]                                                 │
│                                                             │
│  ⚠️  This link will only work ONCE and expires in 24 hours. │
│  The new admin will set their own password on first use.    │
│                                                             │
│  [Done]                                                     │
└─────────────────────────────────────────────────────────────┘
```

**New Admin Setup (via invite link):**

```
New admin visits invite URL
         ↓
┌─────────────────────────────────────────────────────────────┐
│  Complete Admin Setup                                       │
├─────────────────────────────────────────────────────────────┤
│  Username: [backup-admin              ]                     │
│            (you can change this)                            │
│                                                             │
│  Create Password: [                    ]                    │
│  Confirm Password: [                    ]                   │
│                                                             │
│  ☐ Enable Two-Factor Authentication (recommended)           │
│                                                             │
│  [Complete Setup]                                           │
└─────────────────────────────────────────────────────────────┘

         ↓ (Setup complete)

┌─────────────────────────────────────────────────────────────┐
│  ✅ Admin Account Created                                    │
├─────────────────────────────────────────────────────────────┤
│  Your API Token (copy now - shown once):                    │
│  ┌─────────────────────────────────────────────────────┐    │
│  │ adm_xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx                │    │
│  └─────────────────────────────────────────────────────┘    │
│  [Copy Token]                                               │
│                                                             │
│  ⚠️  Save this token securely. It cannot be retrieved.      │
│                                                             │
│  [Continue to Admin Panel]                                  │
└─────────────────────────────────────────────────────────────┘
```

**Invite Rules:**
- Invite link is single-use (invalidated after first use or expiry)
- Default expiry: 24 hours (configurable: 1h, 6h, 24h, 48h, 7d)
- New admin can set their own username (username blacklist ignored for admins)
- New admin sets their own password and optional 2FA
- API token generated and shown once
- Invite creation logged to audit log

#### OIDC/LDAP Admin Sync

**When a user authenticates via OIDC/LDAP and belongs to a mapped admin group:**

1. User authenticates with OIDC/LDAP provider
2. Server retrieves user's group memberships
3. If user is in `admin_groups` → create/update local admin record
4. Admin credentials synced to local database
5. On next login, even if OIDC/LDAP is down, local credentials work

**Local Sync Fields (`admins` table):**
| Field | Description |
|-------|-------------|
| `username` | From OIDC/LDAP claim |
| `password` | Argon2id hash (synced or set locally) |
| `source` | `local`, `oidc:{provider}`, `ldap` |
| `external_id` | Provider's user ID |
| `groups` | JSON array of cached group memberships |
| `last_sync` | Last successful sync timestamp |

**Fallback Behavior:**
| Scenario | Behavior |
|----------|----------|
| OIDC/LDAP available | Authenticate with provider, sync to local |
| OIDC/LDAP unavailable | Use cached local credentials |
| User removed from admin group | Next successful OIDC/LDAP login revokes admin |
| Provider permanently down | Local credentials continue to work |

**Sync Frequency:**
- On every login (real-time)
- Background sync every 1 hour (if configured)
- Manual sync via admin panel

### Admin Session Visibility

**Admins can see which other admins are currently logged in (username only).**

```
Admin Panel Header:
┌─────────────────────────────────────────────────────────────┐
│  {app_name} Admin    │  🟢 2 admins online  │  🔔  │  [You] │
└─────────────────────────────────────────────────────────────┘
                              │
                              ▼ (click to expand)
                       ┌──────────────────┐
                       │  Admins Online   │
                       ├──────────────────┤
                       │  🟢 administrator │
                       │  🟢 backup-admin  │
                       └──────────────────┘
```

**What IS Shown:**
- Username of logged-in admins
- Online status (green dot)
- Total count

**What is NOT Shown:**
- IP address
- Session duration
- Last activity
- Device/browser info

**Why This Is Allowed:**
- Helps admins know if others are working
- Useful for coordination
- Does not expose sensitive details
- Username is not considered private (admins know each other)

### Additional Admin Recovery

**Additional admins (non-primary) who lose access:**

| Scenario | Recovery Method |
|----------|-----------------|
| Forgot password | Use own recovery keys OR contact primary admin |
| Lost 2FA + recovery keys | Contact primary admin to delete account, re-invite |
| OIDC/LDAP admin locked out | Fix in identity provider, or primary admin removes mapping |

**Primary admin CANNOT:**
- Reset other admin's password directly
- View other admin's credentials
- Disable other admin's 2FA directly

**Primary admin CAN:**
- Delete the additional admin account entirely
- Re-invite them (they set up fresh credentials)

### Regular User Behavior

| Route | Regular User Access |
|-------|---------------------|
| `/admin/*` | NO - 403 Forbidden (unless user has admin role) |
| `/user/*` | Full access to own profile, settings, tokens |
| `/auth/login` | Login page |
| `/auth/logout` | Logout |
| Public routes | Authenticated view (may show user-specific content) |

**Regular User Accounts:**
- Stored in database (users table)
- Managed via `/user/profile`, `/user/settings`
- Can have roles (admin, user, custom)
- Multiple accounts supported

### Username Validation (NON-NEGOTIABLE)

**Username Rules:**
| Rule | Value |
|------|-------|
| Min length | 3 characters |
| Max length | 32 characters |
| Allowed chars | `a-z`, `0-9`, `_`, `-` (lowercase only) |
| Must start with | Letter (`a-z`) |
| Cannot end with | `_` or `-` |
| No consecutive | `__`, `--`, `_-`, `-_` |

**Username Blocklist (case-insensitive):**

```go
var UsernameBlocklist = []string{
    // System & Administrative
    "admin", "administrator", "root", "system", "sysadmin", "superuser",
    "master", "owner", "operator", "manager", "moderator", "mod",
    "staff", "support", "helpdesk", "help", "service", "daemon",

    // Server & Technical
    "server", "host", "node", "cluster", "api", "www", "web", "mail",
    "email", "smtp", "ftp", "ssh", "dns", "proxy", "gateway", "router",
    "firewall", "localhost", "local", "internal", "external", "public",
    "private", "network", "database", "db", "cache", "redis", "mysql",
    "postgres", "mongodb", "elastic", "nginx", "apache", "docker",

    // Application & Service Names
    "app", "application", "bot", "robot", "crawler", "spider", "scraper",
    "webhook", "callback", "cron", "scheduler", "worker", "queue", "job",
    "task", "process", "service", "microservice", "lambda", "function",

    // Authentication & Security
    "auth", "authentication", "login", "logout", "signin", "signout",
    "signup", "register", "password", "passwd", "token", "oauth", "sso",
    "saml", "ldap", "kerberos", "security", "secure", "ssl", "tls",
    "certificate", "cert", "key", "secret", "credential", "session",

    // Roles & Permissions
    "guest", "anonymous", "anon", "user", "users", "member", "members",
    "subscriber", "editor", "author", "contributor", "reviewer", "auditor",
    "analyst", "developer", "dev", "devops", "engineer", "architect",
    "designer", "tester", "qa", "billing", "finance", "legal", "hr",
    "sales", "marketing", "ceo", "cto", "cfo", "coo", "founder", "cofounder",

    // Common Reserved
    "account", "accounts", "profile", "profiles", "settings", "config",
    "configuration", "dashboard", "panel", "console", "portal", "home",
    "index", "main", "default", "null", "nil", "undefined", "void",
    "true", "false", "test", "testing", "debug", "demo", "example",
    "sample", "temp", "temporary", "tmp", "backup", "archive", "log",
    "logs", "audit", "report", "reports", "analytics", "stats", "status",

    // API & Endpoints
    "api", "rest", "graphql", "grpc", "websocket", "ws", "wss", "http",
    "https", "endpoint", "endpoints", "route", "routes", "path", "url",
    "uri", "callback", "hook", "hooks", "event", "events", "stream",

    // Content & Media
    "blog", "news", "article", "articles", "post", "posts", "page", "pages",
    "feed", "rss", "atom", "sitemap", "robots", "favicon", "static",
    "assets", "images", "image", "img", "media", "upload", "uploads",
    "download", "downloads", "file", "files", "document", "documents",

    // Communication
    "contact", "message", "messages", "chat", "notification", "notifications",
    "alert", "alerts", "inbox", "outbox", "sent", "draft", "drafts",
    "spam", "abuse", "report", "flag", "block", "mute", "ban",

    // Commerce & Billing
    "shop", "store", "cart", "checkout", "order", "orders", "invoice",
    "invoices", "payment", "payments", "subscription", "subscriptions",
    "plan", "plans", "pricing", "billing", "refund", "coupon", "discount",

    // Social Features
    "follow", "follower", "followers", "following", "friend", "friends",
    "like", "likes", "share", "shares", "comment", "comments", "reply",
    "mention", "mentions", "tag", "tags", "group", "groups", "team", "teams",
    "community", "communities", "forum", "forums", "channel", "channels",

    // Brand & Legal
    "official", "verified", "trusted", "partner", "affiliate", "sponsor",
    "brand", "trademark", "copyright", "legal", "terms", "privacy",
    "policy", "policies", "tos", "eula", "gdpr", "dmca", "abuse",

    // Offensive / Impersonation Prevention
    "fuck", "shit", "ass", "bitch", "bastard", "damn", "cunt", "dick",
    "penis", "vagina", "sex", "porn", "xxx", "nude", "naked", "nsfw",
    "kill", "murder", "death", "die", "suicide", "hate", "nazi", "hitler",
    "racist", "racism", "terrorist", "terrorism", "isis", "alqaeda",

    // Numbers & Special
    "0", "1", "123", "1234", "12345", "000", "111", "666", "911", "420", "69",

    // Common Spam Patterns
    "info", "noreply", "no-reply", "donotreply", "mailer", "postmaster",
    "webmaster", "hostmaster", "abuse", "spam", "junk", "trash",

    // Project-specific (dynamic)
    "casspeed", "casapps",
}
```

**Blocklist Notes:**
- Server admin account is exempt from this blocklist
- Blocklist is checked case-insensitively
- Also blocks usernames that contain blocklisted words as substrings for critical terms (admin, root, system, mod, official, verified)
- Custom blocklist entries can be added via config

### Username & Email Rules (NON-NEGOTIABLE)

**Case Insensitivity:**
- Usernames are case-insensitive: `admin` = `Admin` = `aDmIn`
- Emails are case-insensitive: `me@example.com` = `Me@Example.COM`
- Stored in lowercase, compared in lowercase

**Login Identifier:**
- Users can log in with **either** username OR email
- Both must be unique across all users

**Email Addresses:**
| SMTP Configured | Max Emails | Verification |
|-----------------|------------|--------------|
| No | 1 (primary only) | Not possible |
| Yes | Unlimited | Additional emails must be verified |

**Email Types:**
| Type | Purpose | Used For |
|------|---------|----------|
| **Account Email** | Security & account recovery | Password reset, 2FA recovery, security alerts, login notifications |
| **Notification Email** | Non-security communications | Newsletters, updates, marketing, general notifications |

**Email Rules:**
- Primary email set at registration (becomes account email by default)
- User can designate a different verified email as account email
- Additional emails require verification (SMTP required)
- All emails must be unique across all users
- Unverified emails cannot be used for login
- Account email receives security-sensitive communications ONLY
- Notification email receives everything else (if set, otherwise account email)

### Server Admin Limitations (NON-NEGOTIABLE)

**What Server Admin CAN do:**
| Action | Description |
|--------|-------------|
| Send password reset link | Triggers email to user's account email |
| Disable user's 2FA | After manual identity verification (out-of-band) |
| Disable/suspend account | Block user from logging in |
| Enable/unsuspend account | Restore access |
| View masked email | `j***n@e***.com` (for support identification) |
| View username | For support identification |
| View account status | Active, suspended, 2FA enabled, etc. |
| View last login | Timestamp only |

**What Server Admin CANNOT do:**
| Action | Reason |
|--------|--------|
| View full email addresses | Privacy - only masked version visible |
| View passwords | Passwords are hashed, not stored |
| Set/change user passwords | Only user can set via reset link |
| View recovery keys | Keys are hashed, not stored |
| View 2FA secrets | Secrets are encrypted with user's password |
| Read user's private data | Privacy by design |
| Impersonate without logging | All admin actions are audited |

**Admin Password Reset Flow:**
```
Admin Panel (/admin/server/moderation/users/{id})
┌─────────────────────────────────────────────────────────────┐
│  User: johndoe                                              │
│  Email: j***n@e***.com (masked)                             │
│  Status: Active                                             │
│  2FA: Enabled                                               │
│  Last Login: 2025-01-15 09:00:00                            │
├─────────────────────────────────────────────────────────────┤
│  Actions:                                                   │
│  [Send Password Reset]  [Disable 2FA]  [Suspend Account]    │
└─────────────────────────────────────────────────────────────┘

Admin clicks "Send Password Reset"
         ↓
┌─────────────────────────────────────────────────────────────┐
│  Confirm Action                                             │
├─────────────────────────────────────────────────────────────┤
│  This will send a password reset link to the user's         │
│  account email (j***n@e***.com).                            │
│                                                             │
│  You will NOT see the reset link or new password.           │
│                                                             │
│  Reason (required for audit log):                           │
│  [User requested via support ticket #1234    ]              │
│                                                             │
│  [Cancel]  [Send Reset Link]                                │
└─────────────────────────────────────────────────────────────┘

         ↓ (email sent to user)

User receives: "Password reset requested by administrator.
               Click here to set a new password."
```

**Why These Limitations?**
- **Zero-knowledge design**: Admin cannot access what they don't need
- **Privacy by default**: User data is user's data
- **Audit trail**: All admin actions logged with reason
- **Trust minimization**: Even compromised admin account has limited damage potential

### Error Messages (NON-NEGOTIABLE)

**Specific Errors (OK to reveal - validation only):**
| Scenario | Error Message |
|----------|---------------|
| Blocklisted username | `Username contains blocked word: {word}` |
| Username too short | `Username must be at least 3 characters` |
| Username too long | `Username cannot exceed 32 characters` |
| Invalid characters | `Username can only contain lowercase letters, numbers, underscore, and hyphen` |
| Invalid email format | `Please enter a valid email address` |
| Password too weak | `Password must be at least 8 characters` |

**Generic Errors (NEVER reveal existence):**
| Scenario | Error Message |
|----------|---------------|
| Username/email taken | `Unable to complete registration. [Forgot credentials?](/auth/password/forgot)` |
| Login failed (any reason) | `Invalid credentials. [Forgot password?](/auth/password/forgot)` |
| Reset request | `If an account exists, instructions have been sent.` |

**Why Generic Errors?**
- Prevents username/email enumeration attacks
- Attacker cannot determine if account exists
- Same response time for both cases (prevent timing attacks)
- Links to recovery flow instead of revealing information

### 2FA, Passkeys & OIDC (NON-NEGOTIABLE)

**Supported Authentication Methods:**
| Method | Description |
|--------|-------------|
| Password | Standard username/email + password |
| TOTP (2FA) | Time-based one-time passwords (Google Authenticator, Authy, etc.) |
| Passkeys | WebAuthn/FIDO2 passwordless authentication |
| OIDC | External identity providers |

**OIDC Providers (Examples):**
- Self-hosted: Authentik, Authelia, Keycloak, Dex, Zitadel
- Cloud: Auth0, Okta, Azure AD, Google, GitHub, GitLab

**Recovery Keys (CRITICAL):**
| Rule | Description |
|------|-------------|
| **Format** | `{8-hex-chars}-{4-hex-chars}` (e.g., `a1b2c3d4-e5f6`) |
| **Count** | 10 recovery keys generated |
| **Generated once** | Recovery keys generated when 2FA/passkey enabled |
| **User must copy** | Displayed ONCE, user MUST save them |
| **Hashed storage** | Keys are hashed (Argon2id), NOT stored in plain text |
| **NOT recoverable** | If lost, cannot be retrieved - account recovery required |
| **Single use** | Each recovery key can only be used once |
| **Case insensitive** | Keys are validated case-insensitively |

**Recovery Key Flow:**
```
┌─────────────────────────────────────────────────────────────┐
│  🔑 SAVE YOUR RECOVERY KEYS                                 │
├─────────────────────────────────────────────────────────────┤
│  These keys can be used to access your account if you       │
│  lose access to your 2FA device. Each key can only be       │
│  used once.                                                 │
│                                                             │
│  ⚠️  SAVE THESE NOW - THEY WILL NOT BE SHOWN AGAIN          │
│                                                             │
│  1. a1b2c3d4-e5f6    6. k5l6m7n8-o9p0                       │
│  2. g7h8i9j0-k1l2    7. q1r2s3t4-u5v6                       │
│  3. m3n4o5p6-q7r8    8. w7x8y9z0-a1b2                       │
│  4. s9t0u1v2-w3x4    9. c3d4e5f6-g7h8                       │
│  5. y5z6a7b8-c9d0   10. i9j0k1l2-m3n4                       │
│                                                             │
│  [Download as TXT]  [Copy All]                              │
│                                                             │
│  ☑️ I have saved my recovery keys                            │
│                                                             │
│  [Continue]                                                 │
└─────────────────────────────────────────────────────────────┘
```

**Admin Panel MFA Setup (`/admin/account/security`):**

```
┌─────────────────────────────────────────────────────────────┐
│  🔐 Account Security                                        │
├─────────────────────────────────────────────────────────────┤
│                                                             │
│  Two-Factor Authentication                                  │
│  ─────────────────────────────────────────────────────────  │
│  Add an extra layer of security to your admin account.      │
│                                                             │
│  TOTP (Authenticator App)              [Not Enabled]        │
│  Use Google Authenticator, Authy,      [Set Up →]           │
│  or any TOTP-compatible app                                 │
│                                                             │
│  Passkey (Biometric/Security Key)      [Not Enabled]        │
│  Use fingerprint, Face ID, or a        [Set Up →]           │
│  hardware security key                                      │
│                                                             │
│  Recovery Keys                         [Not Generated]      │
│  Generated when you enable MFA         [──────────]         │
│                                                             │
└─────────────────────────────────────────────────────────────┘
```

**TOTP Setup Flow (`/admin/account/security/totp/setup`):**

```
┌─────────────────────────────────────────────────────────────┐
│  📱 Set Up Authenticator App                                │
├─────────────────────────────────────────────────────────────┤
│                                                             │
│  Step 1: Confirm your password                              │
│  Password: [••••••••••••            ]  [Continue]           │
│                                                             │
├─────────────────────────────────────────────────────────────┤
│                                                             │
│  Step 2: Scan QR code with your authenticator app           │
│                                                             │
│         ┌─────────────────┐                                 │
│         │  █▀▀▀▀▀▀▀▀▀█   │                                 │
│         │  █ QR CODE █   │   Can't scan?                   │
│         │  █▄▄▄▄▄▄▄▄▄█   │   Manual key: JBSWY3DPEHPK3PXP  │
│         └─────────────────┘   [Copy Key]                    │
│                                                             │
│  Step 3: Enter the 6-digit code from your app               │
│  Verification Code: [      ]  [Verify]                      │
│                                                             │
└─────────────────────────────────────────────────────────────┘
```

**Passkey Setup Flow (`/admin/account/security/passkey/setup`):**

```
┌─────────────────────────────────────────────────────────────┐
│  🔑 Set Up Passkey                                          │
├─────────────────────────────────────────────────────────────┤
│                                                             │
│  Step 1: Confirm your password                              │
│  Password: [••••••••••••            ]  [Continue]           │
│                                                             │
├─────────────────────────────────────────────────────────────┤
│                                                             │
│  Step 2: Register your passkey                              │
│                                                             │
│  Your browser will prompt you to use:                       │
│  • Fingerprint (Touch ID)                                   │
│  • Face recognition (Face ID)                               │
│  • Hardware security key (YubiKey, etc.)                    │
│  • Device PIN                                               │
│                                                             │
│  Passkey Name: [MacBook Pro Touch ID    ]                   │
│                                                             │
│  [Register Passkey]                                         │
│                                                             │
│  ℹ️  You can register multiple passkeys for backup          │
│                                                             │
└─────────────────────────────────────────────────────────────┘
```

**After MFA Enabled - Recovery Keys Shown:**
(See Recovery Key Flow above)

**2FA/Passkey Setup Requirements:**
1. User/admin must be logged in
2. User/admin must re-enter password to confirm identity
3. For TOTP: scan QR code and verify with 6-digit code
4. For Passkey: complete WebAuthn registration flow
5. Recovery keys generated and displayed (MUST save)
6. User/admin must confirm they saved recovery keys (checkbox)
7. Only then is 2FA/passkey activated

### Account Recovery Matrix (NON-NEGOTIABLE)

**What CAN be recovered:**
| User Knows | User Forgot | Recovery Method |
|------------|-------------|-----------------|
| Email | Password | `/auth/password/forgot` → email link → set new password |
| Username | Password | `/auth/password/forgot` → email link → set new password |
| Email + Password | 2FA code | `/auth/login` → `/auth/recovery/use` → disable/reset 2FA |
| Username + Password | 2FA code | `/auth/login` → `/auth/recovery/use` → disable/reset 2FA |

**What CANNOT be recovered:**
| Scenario | Result |
|----------|--------|
| Forgot username AND email | ❌ No recovery - account lost |
| Forgot password + no email access | ❌ No recovery - account lost |
| Lost 2FA + no recovery keys | ❌ Contact admin (manual identity verification) |
| Lost everything | ❌ No recovery - account lost |

**Why no recovery without username/email?**
- We cannot store data that identifies users without credentials
- This is a security feature, not a limitation
- Users MUST remember at least one identifier (username or email)

### Server Admin Recovery (NON-NEGOTIABLE)

The server admin (administrator with access to the server/binary) has ONE recovery method:

| Scenario | Recovery Method |
|----------|-----------------|
| Admin forgot password | `casspeed --maintenance setup` |
| Admin lost API token | `casspeed --maintenance setup` |
| Admin lost recovery keys | `casspeed --maintenance setup` |
| Admin lost 2FA + no recovery keys | `casspeed --maintenance setup` |
| Admin lost everything | `casspeed --maintenance setup` |

**This requires:**
- Console/SSH access to the server to run the binary
- Console access to see the new setup token
- The service should be stopped first

**This does NOT require:**
- Previous password
- Previous API token
- Previous recovery keys
- Email access

See **PART 24: BACKUP & RESTORE → Admin Recovery Command** for full details.

### Recovery Key Usage Flow

**When Recovery Keys Are Used:**
- User has 2FA/passkey enabled
- User lost access to 2FA device (phone lost, authenticator wiped, etc.)
- User still knows username/email AND password

**Flow:**
```
┌─────────────────────────────────────────────────────────────┐
│  /auth/login                                                │
├─────────────────────────────────────────────────────────────┤
│  Username/Email: [john@example.com        ]                 │
│  Password:       [••••••••••••            ]                 │
│                                                             │
│  [Login]                                                    │
└─────────────────────────────────────────────────────────────┘
                            ↓
                    (2FA is enabled)
                            ↓
┌─────────────────────────────────────────────────────────────┐
│  Two-Factor Authentication                                  │
├─────────────────────────────────────────────────────────────┤
│  Enter the 6-digit code from your authenticator app:        │
│                                                             │
│  [      ]                                                   │
│                                                             │
│  [Verify]                                                   │
│                                                             │
│  ─────────────────────────────────────────────────────────  │
│  Lost access to your authenticator?                         │
│  [Use Recovery Key]                                         │
└─────────────────────────────────────────────────────────────┘
                            ↓
                (User clicks "Use Recovery Key")
                            ↓
┌─────────────────────────────────────────────────────────────┐
│  Use Recovery Key                                           │
├─────────────────────────────────────────────────────────────┤
│  Enter one of your recovery keys:                           │
│                                                             │
│  [a1b2c3d4-e5f6                          ]                  │
│                                                             │
│  ⚠️  This key will be invalidated after use.                 │
│                                                             │
│  [Submit]                                                   │
└─────────────────────────────────────────────────────────────┘
                            ↓
                (Valid recovery key entered)
                            ↓
┌─────────────────────────────────────────────────────────────┐
│  Recovery Key Accepted                                      │
├─────────────────────────────────────────────────────────────┤
│  ✅ Recovery key accepted and invalidated.                   │
│  You have X recovery keys remaining.                        │
│                                                             │
│  What would you like to do?                                 │
│                                                             │
│  ○ Disable 2FA temporarily (login with password only)       │
│  ○ Set up new 2FA device now                                │
│                                                             │
│  [Continue]                                                 │
└─────────────────────────────────────────────────────────────┘
                            ↓
        (If "Set up new 2FA" → new recovery keys generated)
                            ↓
┌─────────────────────────────────────────────────────────────┐
│  🔑 NEW RECOVERY KEYS                                        │
├─────────────────────────────────────────────────────────────┤
│  Your old recovery keys have been invalidated.              │
│  Save these new recovery keys:                              │
│                                                             │
│  1. x1y2z3a4-b5c6    6. p5q6r7s8-t9u0                       │
│  2. d7e8f9g0-h1i2    7. v1w2x3y4-z5a6                       │
│  3. j3k4l5m6-n7o8    8. b7c8d9e0-f1g2                       │
│  4. q9r0s1t2-u3v4    9. h3i4j5k6-l7m8                       │
│  5. w5x6y7z8-a9b0   10. n9o0p1q2-r3s4                       │
│                                                             │
│  [Download as TXT]  [Copy All]                              │
│                                                             │
│  ☑️ I have saved my recovery keys                            │
│                                                             │
│  [Complete Setup]                                           │
└─────────────────────────────────────────────────────────────┘
```

**Recovery Key API Flow:**
```
POST /api/v1/auth/login
  → { "identifier": "john@example.com", "password": "..." }
  ← { "requires_2fa": true, "session_token": "temp_xxx" }

POST /api/v1/auth/recovery/use
  → { "session_token": "temp_xxx", "recovery_key": "a1b2c3d4-e5f6" }
  ← { "success": true, "token": "auth_xxx", "remaining_keys": 9 }

# Now authenticated - can manage 2FA via /user/security/
POST /api/v1/user/security/2fa/disable
  ← { "success": true }
     OR (setup new device)
POST /api/v1/user/security/2fa/enable
  ← { "qr_code": "...", "secret": "...", "recovery_keys": [...] }
```

**Recovery Key Rules:**
| Rule | Description |
|------|-------------|
| Single use | Each key invalidated after one use |
| Hashed storage | Keys stored as hashes, cannot be retrieved |
| Regeneration | New 2FA setup = new recovery keys |
| Old keys invalidated | All old keys invalidated when new keys generated |
| Remaining count | Show user how many keys remain |
| Last key warning | ⚠️ Warning when only 1-2 keys remaining |
| Zero keys + lost 2FA | Must contact admin for manual verification |

**OIDC/LDAP Configuration:**
```yaml
server:
  auth:
    oidc:
      enabled: false
      providers:
        - name: authentik
          display_name: "Login with Authentik"
          issuer: "https://auth.example.com/application/o/myapp/"
          client_id: "{client_id}"
          client_secret: "{client_secret}"
          scopes: ["openid", "profile", "email", "groups"]
          # Auto-create user on first login
          auto_register: true
          # Map OIDC claims to user fields
          claims_mapping:
            username: "preferred_username"
            email: "email"
            name: "name"
            # Claim containing group memberships
            groups: "groups"
          # Map external groups to server admin role
          # Users in these groups become server admins
          admin_groups:
            - "admins"
            - "server-admins"
            - "app-administrators"
          # Map external groups to user roles (if multi-user enabled)
          role_mapping:
            admin: ["admins", "app-administrators"]
            moderator: ["moderators", "support-staff"]
            user: ["users", "members"]

    ldap:
      enabled: false
      server: "ldap://ldap.example.com:389"
      bind_dn: "cn=readonly,dc=example,dc=com"
      bind_password: "{ldap_password}"
      base_dn: "dc=example,dc=com"
      user_filter: "(uid={username})"
      # Map LDAP attributes to user fields
      attributes:
        username: "uid"
        email: "mail"
        name: "cn"
        groups: "memberOf"
      # Map LDAP groups to server admin role
      admin_groups:
        - "cn=admins,ou=groups,dc=example,dc=com"
        - "cn=server-admins,ou=groups,dc=example,dc=com"
      # Map LDAP groups to user roles (if multi-user enabled)
      role_mapping:
        admin: ["cn=admins,ou=groups,dc=example,dc=com"]
        moderator: ["cn=moderators,ou=groups,dc=example,dc=com"]
        user: ["cn=users,ou=groups,dc=example,dc=com"]
```

### Server Admin Group Mapping (NON-NEGOTIABLE)

**Server admins can map external identity provider groups to the server admin role.**

| Provider | Configuration | Description |
|----------|---------------|-------------|
| **OIDC** | `admin_groups` list | Group names from the `groups` claim |
| **LDAP** | `admin_groups` list | Full DN of groups (e.g., `cn=admins,ou=groups,dc=example,dc=com`) |

**How Group Mapping Works:**

1. User authenticates via OIDC/LDAP
2. Server retrieves user's group memberships from identity provider
3. If user belongs to ANY group in `admin_groups` → grant server admin access
4. Admin access persists for session duration
5. On next login, group membership is re-evaluated
6. If user is removed from all `admin_groups` → admin access revoked

**Admin Panel (`/admin/server/security/auth`):**

| Element | Type | Description |
|---------|------|-------------|
| OIDC Providers | Section | List of configured OIDC providers |
| LDAP Configuration | Section | LDAP server settings |
| Admin Groups | Tag input | Groups that grant server admin access |
| Role Mapping | Table | Map external groups to application roles |
| Test Connection | Button | Test OIDC/LDAP connectivity |
| Test Group Mapping | Button | Test user's groups and resulting role |

**Sane Defaults:**
- `admin_groups`: Empty (no external groups granted admin by default)
- `role_mapping`: Empty (users get default role unless mapped)
- `auto_register`: `false` (users must be pre-created unless enabled)
- Group membership checked on every login (not cached)

### Why This Separation?

| Reason | Description |
|--------|-------------|
| **Security** | Server admin has server-level access, not app-level |
| **Simplicity** | Admin-only mode doesn't need user management |
| **Isolation** | Server admin credentials separate from user data |
| **Recovery** | Can access admin even if database is corrupted |

## Configuration

```yaml
server:
  users:
    # Enable multi-user mode (default: disabled = admin-only)
    enabled: false

    registration:
      # Registration mode: disabled, public, private, approval
      # - disabled: No registration allowed (admin creates users only)
      # - public: Anyone can register (open registration)
      # - private: Invite-only (requires invite code)
      # - approval: Anyone can register, admin must approve
      mode: disabled

      # Email verification (applies to all modes except disabled)
      require_email_verification: true

      # Email domain restrictions (applies to public/approval modes)
      allowed_domains: []      # Empty = all domains allowed
      blocked_domains: []      # Block specific domains

      # Invite settings (for private mode)
      invite_expiration_days: 7     # How long invite codes are valid
      max_invites_per_user: 10      # How many invites each user can create

    roles:
      # Available roles
      available:
        - admin
        - user
      # Default role for new users
      default: user

    tokens:
      # Allow users to generate API tokens
      enabled: true
      # Maximum tokens per user
      max_per_user: 5
      # Token expiration (0 = never)
      expiration_days: 0

    profile:
      # Allow users to upload avatars
      allow_avatar: true
      # Allow users to set display name
      allow_display_name: true
      # Allow users to set bio
      allow_bio: true

    auth:
      # Session duration
      session_duration: 30d
      # Require 2FA for all users
      require_2fa: false
      # Allow 2FA (user choice)
      allow_2fa: true
      # Password requirements
      password_min_length: 8
      password_require_uppercase: false
      password_require_number: false
      password_require_special: false

    limits:
      # Rate limits per user (0 = use global)
      requests_per_minute: 0
      requests_per_day: 0
```

## User Roles & Permissions

| Role | Description | Default Permissions |
|------|-------------|---------------------|
| `admin` | Full access | All permissions |
| `user` | Standard user | Read, own profile, own API tokens |

### Custom Roles

Projects can define custom roles with specific permissions:

```yaml
server:
  users:
    roles:
      available:
        - admin
        - moderator
        - user
        - readonly
      default: user
      permissions:
        moderator:
          - read
          - write
          - moderate
        readonly:
          - read
```

## User Features

### Registration Modes (NON-NEGOTIABLE)

**Single setting controls all registration behavior:**

| Mode | Description | Who Can Register | Workflow |
|------|-------------|------------------|----------|
| **disabled** | No registration | No one (admin creates users only) | Registration form hidden |
| **public** | Open registration | Anyone with valid email | Submit form → verify email → active |
| **private** | Invite-only | Users with invite code only | Enter code → submit form → verify email → active |
| **approval** | Admin approval required | Anyone, but admin must approve | Submit form → verify email → admin approves → active |

### Registration Flow by Mode

**Mode: disabled**
```
/auth/register → 404 or redirect to login
No registration allowed, admin creates users manually
```

**Mode: public**
```
1. User visits /auth/register
2. Submits registration form (username, email, password)
3. Email verification sent (if require_email_verification: true)
4. User clicks verification link
5. Account active → user can log in
```

**Mode: private**
```
1. Existing user generates invite code (/user/invites/create)
2. New user visits /auth/register?invite={code}
3. Submits registration form
4. Email verification sent (if require_email_verification: true)
5. User clicks verification link
6. Account active → user can log in
```

**Mode: approval**
```
1. User visits /auth/register
2. Submits registration form
3. Email verification sent (if require_email_verification: true)
4. User clicks verification link
5. Admin notified of pending user
6. Admin approves user at /admin/server/users/pending
7. Account active → user can log in
```

### Authentication Methods

| Method | Use For |
|--------|---------|
| Session (cookie) | Web interface |
| API token | API access (passed as Bearer token in Authorization header) |

### Password Reset Flow

```
1. User requests password reset
2. Email sent with reset link (expires in 1 hour)
3. User clicks link, sets new password
4. All existing sessions invalidated
5. User must log in with new password
```

### Two-Factor Authentication (2FA)

| Feature | Description |
|---------|-------------|
| TOTP | Time-based one-time passwords (Google Authenticator, etc.) |
| Passkeys/WebAuthn | FIDO2 passwordless authentication (biometric, security keys) |
| Recovery keys | 10 one-time use keys (format: `a1b2c3d4-e5f6`) |
| Remember device | Optional "trust this device" for 30 days |

## User Profile

| Field | Type | Configurable |
|-------|------|--------------|
| Email | Required | No (always required) |
| Display name | Optional | `profile.allow_display_name` |
| Avatar | Optional | `profile.allow_avatar` |
| Bio | Optional | `profile.allow_bio` |
| Timezone | Optional | Always available |
| Language | Optional | Always available |

## API Tokens

| Feature | Description |
|---------|-------------|
| Generate | User can create API tokens from profile |
| Name/Label | User can name tokens for identification |
| Permissions | Optional: limit token to specific scopes |
| Expiration | Optional: set expiry date |
| Last used | Track when token was last used |
| Revoke | User can delete tokens anytime |

### API Token Format

```
casspeed_{random_32_chars}

Example: jokes_a1b2c3d4e5f6g7h8i9j0k1l2m3n4o5p6
```

## Admin Panel

### /admin/server/moderation/users (User Moderation)

| Element | Type | Description |
|---------|------|-------------|
| User list | Table | All users with search/filter |
| Delete user | Button | Remove user (confirmation required) |
| Impersonate | Button | Log in as user (admin only) |
| Disable/Enable | Toggle | Temporarily disable account |
| Revoke sessions | Button | Log user out everywhere |

### /admin/server/moderation/users/{id} (User Detail)

| Section | Contents |
|---------|----------|
| Profile | Email, name, avatar, bio, role (read-only) |
| Security | 2FA status, sessions |
| Activity | Login history, API usage |
| Actions | Disable, delete, impersonate |

### /admin/server/roles (Role Management)

| Element | Type | Description |
|---------|------|-------------|
| Role list | Table | All roles |
| Create role | Button | Define new role |
| Edit permissions | Checkboxes | Set role permissions |
| Delete role | Button | Remove role (reassign users first) |

### /admin/server/users/invites (User Invitation Codes)

| Element | Type | Description |
|---------|------|-------------|
| Generate invite | Button | Create invitation code/link |
| Invite list | Table | All invites with status |
| Expiration | Date picker | When invite expires |
| Max uses | Number | How many times invite can be used |
| Role | Dropdown | What role invited users get |
| Revoke | Button | Disable invite |

## Route Standards (NON-NEGOTIABLE)

**All routes MUST follow these standards:**

| Rule | Description |
|------|-------------|
| **Scoped** | Routes grouped by scope: `/auth`, `/user`, `/org`, `/admin` |
| **Mirrored** | Web (`/`) and API (`/api/v1/`) use same structure |
| **Intuitive** | Simple, predictable paths |
| **Params over queries** | Use path params, limit query params to defined cases |
| **Duplicated when needed** | Same resource may exist in multiple scopes |
| **Auth under /auth/** | NEVER `/login`, `/register`, `/password/*` at root - ALWAYS `/auth/login`, `/auth/register`, `/auth/password/*`, etc. |
| **Admin scoped** | `/admin/**` requires authenticated admin - unauthenticated flows (invites) go through `/auth/` |

### Response Formats

| Route | Default | Options |
|-------|---------|---------|
| `/` (web) | HTML | - |
| `/api/v1/` | JSON (`application/json`) | JSON, Text |
| `/api/v1/**/*.txt` | Text (`text/plain`) | - |

### Scopes

| Scope | Web | API | Description |
|-------|-----|-----|-------------|
| Public | `/` | `/api/v1/` | Public resources, unauthenticated |
| Auth | `/auth/` | `/api/v1/auth/` | Authentication flows |
| User | `/user/` | `/api/v1/user/` | Current user's resources |
| Org | `/org/` | `/api/v1/org/` | Organization resources (if applicable) |
| Admin | `/admin/` | `/api/v1/admin/` | Admin/server management |

### Authentication Requirements

| Scope | Web Auth | API Auth | Notes |
|-------|----------|----------|-------|
| Public | None | None | Unauthenticated access |
| Server (`/server/`) | None | None | Static info pages |
| Auth | None | None | Used to obtain authentication |
| User | Session cookie | `Authorization: Bearer {token}` | User must be logged in |
| Org | Session cookie | `Authorization: Bearer {token}` | User + org membership |
| Admin | Session cookie | `Authorization: Bearer {admin_token}` | Admin-only access |

**API Token Types:**

| Token Type | Prefix | Use For | Stored In |
|------------|--------|---------|-----------|
| Admin primary token | `adm_` | Admin operations, CLI | `admins.api_token_hash` |
| Additional API keys | `key_` | Custom scoped access | `api_keys.key_hash` |

**API Keys Table (`api_keys`):**
- Supports both admin and user tokens via `owner_type` (admin/user)
- Each key has scopes: `["read", "write", "admin"]`
- `key_prefix` stores first 8 chars for display: `"key_abc1..."`

**Web Session Cookies:**

| Cookie | Scope | Max Age | Notes |
|--------|-------|---------|-------|
| `admin_session` | `/admin/` | 30 days | Admin web sessions |
| `user_session` | `/user/`, `/org/` | 7 days | User web sessions |

## Web Routes

### Public (`/`)

| Path | Description |
|------|-------------|
| `/` | Home page |
| `/healthz` | Health check |
| `/openapi` | Swagger UI |
| `/graphql` | GraphiQL interface |

### Server (`/server/`)

| Path | Description |
|------|-------------|
| `/server/about` | About the application |
| `/server/privacy` | Privacy policy |
| `/server/contact` | Contact form |
| `/server/help` | Help / documentation |

### Auth (`/auth/`)

| Path | Description |
|------|-------------|
| `/auth/login` | Login form (username/email + password) |
| `/auth/logout` | Logout |
| `/auth/register` | Registration form |
| `/auth/2fa` | 2FA verification step (after password, before session) |
| `/auth/passkey` | Passkey authentication (WebAuthn) |
| `/auth/password/forgot` | Request password reset (sends email) |
| `/auth/password/reset/{token}` | Set new password (from email link) |
| `/auth/username/forgot` | Request username reminder (sends email) |
| `/auth/recovery/use` | Use recovery key (2FA bypass) |
| `/auth/verify/{token}` | Email verification |
| `/auth/invite/user/{token}` | User invite acceptance (set username, password) |
| `/auth/invite/server/{token}` | Server admin invite acceptance (set username, password) |
| `/auth/oidc/{provider}` | OIDC login initiation (redirect to provider) |
| `/auth/oidc/{provider}/callback` | OIDC callback (provider redirects back) |
| `/auth/ldap` | LDAP login form (if separate from main login) |

### User (`/user/`)

| Path | Description |
|------|-------------|
| `/user/profile` | View/edit profile |
| `/user/settings` | Account settings |
| `/user/tokens` | Manage API tokens |
| `/user/security` | Password, 2FA, sessions, recovery |
| `/user/security/password` | Change password |
| `/user/security/sessions` | Active sessions |
| `/user/security/2fa` | Two-factor settings |
| `/user/security/recovery` | View/regenerate recovery keys |
| `/user/security/passkeys` | Manage passkeys (WebAuthn) |

### Org (`/org/`)

Organizations - only for projects with multi-user collaboration. Routes always use `/org/` but UI display name can be customized to "Team" if project requires (rarely needed).

| Path | Description |
|------|-------------|
| `/org` | List user's organizations |
| `/org/new` | Create new organization |
| `/org/{slug}` | Organization dashboard |
| `/org/{slug}/settings` | Organization settings |
| `/org/{slug}/tokens` | Organization API tokens |
| `/org/{slug}/members` | Member management |
| `/org/{slug}/members/invite` | Invite new members |
| `/org/{slug}/roles` | Organization roles |
| `/org/{slug}/security` | Security settings |
| `/org/{slug}/security/audit` | Audit log |
| `/org/{slug}/security/audit/export` | Export audit log (compliance) |
| `/org/{slug}/security/sessions` | Active sessions (org-wide) |
| `/org/{slug}/billing` | Billing & subscription (if applicable) |

### Admin (`/admin/`)

| Path | Description |
|------|-------------|
| `/admin` | Dashboard |
| `/admin/profile` | Your admin account (password, API token, 2FA) |

### Admin - Server (`/admin/server/`)

| Path | Description |
|------|-------------|
| `/admin/server/setup` | Initial setup wizard |
| `/admin/server/settings` | Server settings |
| `/admin/server/branding` | Branding & SEO |
| `/admin/server/ssl` | SSL/TLS settings |
| `/admin/server/tor` | Tor hidden service |
| `/admin/server/web` | Web settings (robots.txt, security.txt) |
| `/admin/server/pages` | Standard pages (about, privacy, contact) |
| `/admin/server/email` | Email/SMTP settings |
| `/admin/server/email/templates` | Email templates |
| `/admin/server/notifications` | Notification settings |
| `/admin/server/scheduler` | Scheduled tasks |
| `/admin/server/backup` | Backup & restore |
| `/admin/server/logs` | Log viewer |
| `/admin/server/roles` | Role definitions |
| `/admin/server/users/invites` | User registration invite codes (multi-user apps) |

### Admin - Server Admins (`/admin/server/admins/`)

| Path | Description |
|------|-------------|
| `/admin/server/admins` | Server admin accounts |
| `/admin/server/admins/invite` | Invite new server admin (generates link) |
| `/admin/server/admins/{id}` | Admin detail |

### Admin - Moderation (`/admin/server/moderation/`)

| Path | Description |
|------|-------------|
| `/admin/server/moderation/users` | User moderation |
| `/admin/server/moderation/users/{id}` | User detail |
| `/admin/server/moderation/orgs` | Org moderation |
| `/admin/server/moderation/orgs/{slug}` | Org detail |

## API Routes

### Public (`/api/v1/`)

| Endpoint | Method | Description |
|----------|--------|-------------|
| `/api/v1/healthz` | GET | Health check |
| `/api/v1/openapi.json` | GET | OpenAPI spec (JSON only) |

### Server (`/api/v1/server/`)

| Endpoint | Method | Description |
|----------|--------|-------------|
| `/api/v1/server/about` | GET | About information |
| `/api/v1/server/privacy` | GET | Privacy policy |
| `/api/v1/server/contact` | POST | Submit contact form |
| `/api/v1/server/help` | GET | Help content |

### Auth (`/api/v1/auth/`)

| Endpoint | Method | Description |
|----------|--------|-------------|
| `/api/v1/auth/register` | POST | Register new user |
| `/api/v1/auth/login` | POST | User login (returns session or 2FA challenge) |
| `/api/v1/auth/logout` | POST | User logout |
| `/api/v1/auth/2fa` | POST | Complete 2FA verification |
| `/api/v1/auth/passkey/challenge` | POST | Get WebAuthn challenge |
| `/api/v1/auth/passkey/verify` | POST | Verify WebAuthn response |
| `/api/v1/auth/password/forgot` | POST | Request password reset (sends email) |
| `/api/v1/auth/password/reset` | POST | Set new password (with token from email) |
| `/api/v1/auth/username/forgot` | POST | Request username reminder (sends email) |
| `/api/v1/auth/recovery/use` | POST | Use recovery key (2FA bypass) |
| `/api/v1/auth/verify` | POST | Verify email address |
| `/api/v1/auth/refresh` | POST | Refresh session/token |
| `/api/v1/auth/invite/user/{token}` | GET | Validate user invite token |
| `/api/v1/auth/invite/user/{token}` | POST | Complete user invite (set username, password) |
| `/api/v1/auth/invite/server/{token}` | GET | Validate server admin invite token |
| `/api/v1/auth/invite/server/{token}` | POST | Complete admin invite (set username, password) |
| `/api/v1/auth/oidc/{provider}` | GET | Get OIDC authorization URL |
| `/api/v1/auth/oidc/{provider}/callback` | POST | Exchange OIDC code for session |
| `/api/v1/auth/ldap` | POST | LDAP authentication |

### User (`/api/v1/user/`)

| Endpoint | Method | Description |
|----------|--------|-------------|
| `/api/v1/user/profile` | GET | Get own profile |
| `/api/v1/user/profile` | PATCH | Update own profile |
| `/api/v1/user/tokens` | GET | List own API tokens |
| `/api/v1/user/tokens` | POST | Create API token |
| `/api/v1/user/tokens/{id}` | GET | Get token details |
| `/api/v1/user/tokens/{id}` | DELETE | Revoke API token |
| `/api/v1/user/security/password` | POST | Change password |
| `/api/v1/user/security/sessions` | GET | List active sessions |
| `/api/v1/user/security/sessions/{id}` | DELETE | Revoke session |
| `/api/v1/user/security/2fa` | GET | Get 2FA status |
| `/api/v1/user/security/2fa/enable` | POST | Enable 2FA |
| `/api/v1/user/security/2fa/disable` | POST | Disable 2FA |
| `/api/v1/user/security/recovery` | GET | Get recovery keys status |
| `/api/v1/user/security/recovery/regenerate` | POST | Regenerate recovery keys |
| `/api/v1/user/security/passkeys` | GET | List passkeys |
| `/api/v1/user/security/passkeys` | POST | Register new passkey |
| `/api/v1/user/security/passkeys/{id}` | DELETE | Remove passkey |

### Org (`/api/v1/org/`)

Organizations - only for projects with multi-user collaboration.

| Endpoint | Method | Description |
|----------|--------|-------------|
| `/api/v1/org` | GET | List user's organizations |
| `/api/v1/org` | POST | Create organization |
| `/api/v1/org/{slug}` | GET | Get organization details |
| `/api/v1/org/{slug}` | PATCH | Update organization |
| `/api/v1/org/{slug}` | DELETE | Delete organization |
| `/api/v1/org/{slug}/settings` | GET | Get org settings |
| `/api/v1/org/{slug}/settings` | PATCH | Update org settings |
| `/api/v1/org/{slug}/tokens` | GET | List org API tokens |
| `/api/v1/org/{slug}/tokens` | POST | Create org API token |
| `/api/v1/org/{slug}/tokens/{id}` | GET | Get token details |
| `/api/v1/org/{slug}/tokens/{id}` | DELETE | Revoke token |
| `/api/v1/org/{slug}/members` | GET | List members |
| `/api/v1/org/{slug}/members` | POST | Add member |
| `/api/v1/org/{slug}/members/{id}` | GET | Get member details |
| `/api/v1/org/{slug}/members/{id}` | PATCH | Update member role |
| `/api/v1/org/{slug}/members/{id}` | DELETE | Remove member |
| `/api/v1/org/{slug}/invites` | GET | List pending invites |
| `/api/v1/org/{slug}/invites` | POST | Create invite |
| `/api/v1/org/{slug}/invites/{id}` | DELETE | Revoke invite |
| `/api/v1/org/{slug}/roles` | GET | List organization roles |
| `/api/v1/org/{slug}/roles` | POST | Create custom role |
| `/api/v1/org/{slug}/roles/{id}` | PATCH | Update role |
| `/api/v1/org/{slug}/roles/{id}` | DELETE | Delete role |
| `/api/v1/org/{slug}/security/audit` | GET | List audit events (paginated) |
| `/api/v1/org/{slug}/security/audit/export` | POST | Request audit export |
| `/api/v1/org/{slug}/security/audit/export/{id}` | GET | Download audit export |
| `/api/v1/org/{slug}/security/audit/retention` | GET | Get retention settings |
| `/api/v1/org/{slug}/security/audit/retention` | PATCH | Update retention (org owner only) |
| `/api/v1/org/{slug}/security/sessions` | GET | List org-wide sessions |

### Admin - Server (`/api/v1/admin/server/`)

| Endpoint | Method | Description |
|----------|--------|-------------|
| `/api/v1/admin/server/setup` | GET | Get setup status (is_complete, current_step) |
| `/api/v1/admin/server/setup/verify` | POST | Verify setup token |
| `/api/v1/admin/server/setup/account` | POST | Create admin account (Step 1) |
| `/api/v1/admin/server/setup/token` | POST | Generate API token (Step 2) |
| `/api/v1/admin/server/setup/config` | POST | Save server config (Step 3) |
| `/api/v1/admin/server/setup/security` | POST | Security settings - backup password, 2FA (Step 4) |
| `/api/v1/admin/server/setup/services` | POST | Configure services (Step 5) |
| `/api/v1/admin/server/setup/complete` | POST | Complete setup wizard (Step 6) |
| `/api/v1/admin/server/settings` | GET | Get server settings |
| `/api/v1/admin/server/settings` | PATCH | Update server settings |
| `/api/v1/admin/server/status` | GET | Server status |
| `/api/v1/admin/server/health` | GET | Detailed health |
| `/api/v1/admin/server/stats` | GET | Statistics |
| `/api/v1/admin/server/restart` | POST | Restart server |

### Admin - Server Roles (`/api/v1/admin/server/roles/`)

| Endpoint | Method | Description |
|----------|--------|-------------|
| `/api/v1/admin/server/roles` | GET | List roles |
| `/api/v1/admin/server/roles` | POST | Create role |
| `/api/v1/admin/server/roles/{id}` | GET | Get role details |
| `/api/v1/admin/server/roles/{id}` | PATCH | Update role |
| `/api/v1/admin/server/roles/{id}` | DELETE | Delete role |

### Admin - User Invites (`/api/v1/admin/server/users/invites/`)

User registration invite codes (multi-user apps only).

| Endpoint | Method | Description |
|----------|--------|-------------|
| `/api/v1/admin/server/users/invites` | GET | List user invite codes |
| `/api/v1/admin/server/users/invites` | POST | Create user invite code |
| `/api/v1/admin/server/users/invites/{id}` | GET | Get invite details |
| `/api/v1/admin/server/users/invites/{id}` | DELETE | Revoke invite |

### Admin - Server Admins (`/api/v1/admin/server/admins/`)

| Endpoint | Method | Description |
|----------|--------|-------------|
| `/api/v1/admin/server/admins` | GET | List server admins |
| `/api/v1/admin/server/admins/{id}` | GET | Get admin details |
| `/api/v1/admin/server/admins/{id}` | DELETE | Delete admin |
| `/api/v1/admin/server/admins/{id}/disable` | POST | Disable admin |
| `/api/v1/admin/server/admins/{id}/enable` | POST | Enable admin |
| `/api/v1/admin/server/admins/invite` | POST | Generate admin invite link |

### Admin - Moderation Users (`/api/v1/admin/server/moderation/users/`)

| Endpoint | Method | Description |
|----------|--------|-------------|
| `/api/v1/admin/server/moderation/users` | GET | List all users |
| `/api/v1/admin/server/moderation/users/{id}` | GET | Get user details |
| `/api/v1/admin/server/moderation/users/{id}` | DELETE | Delete user |
| `/api/v1/admin/server/moderation/users/{id}/disable` | POST | Disable user |
| `/api/v1/admin/server/moderation/users/{id}/enable` | POST | Enable user |
| `/api/v1/admin/server/moderation/users/{id}/impersonate` | POST | Get impersonation token |

### Admin - Moderation Orgs (`/api/v1/admin/server/moderation/orgs/`)

Moderation only - server admin does not manage org members/roles.

| Endpoint | Method | Description |
|----------|--------|-------------|
| `/api/v1/admin/server/moderation/orgs` | GET | List all organizations |
| `/api/v1/admin/server/moderation/orgs/{slug}` | GET | Get organization details |
| `/api/v1/admin/server/moderation/orgs/{slug}` | DELETE | Delete organization |
| `/api/v1/admin/server/moderation/orgs/{slug}/disable` | POST | Disable organization |
| `/api/v1/admin/server/moderation/orgs/{slug}/enable` | POST | Enable organization |

### Admin - Profile (`/api/v1/admin/profile/`)

| Endpoint | Method | Description |
|----------|--------|-------------|
| `/api/v1/admin/profile` | GET | Get admin profile |
| `/api/v1/admin/profile` | PATCH | Update admin profile (username, icon) |
| `/api/v1/admin/profile/password` | POST | Change admin password |
| `/api/v1/admin/profile/token` | GET | Get current API token (masked) |
| `/api/v1/admin/profile/token` | POST | Regenerate API token (returns new token ONCE) |

### Admin - Branding (`/api/v1/admin/server/branding/`)

| Endpoint | Method | Description |
|----------|--------|-------------|
| `/api/v1/admin/server/branding` | GET | Get branding settings |
| `/api/v1/admin/server/branding` | PATCH | Update branding |

### Admin - SSL (`/api/v1/admin/server/ssl/`)

| Endpoint | Method | Description |
|----------|--------|-------------|
| `/api/v1/admin/server/ssl` | GET | Get SSL settings |
| `/api/v1/admin/server/ssl` | PATCH | Update SSL settings |
| `/api/v1/admin/server/ssl/renew` | POST | Force certificate renewal |

### Admin - Tor (`/api/v1/admin/server/tor/`)

| Endpoint | Method | Description |
|----------|--------|-------------|
| `/api/v1/admin/server/tor` | GET | Get Tor status |
| `/api/v1/admin/server/tor` | PATCH | Update Tor settings |
| `/api/v1/admin/server/tor/regenerate` | POST | Regenerate .onion address |
| `/api/v1/admin/server/tor/vanity` | GET | Get vanity generation status |
| `/api/v1/admin/server/tor/vanity` | POST | Start vanity generation |
| `/api/v1/admin/server/tor/vanity` | DELETE | Cancel vanity generation |
| `/api/v1/admin/server/tor/vanity/apply` | POST | Apply vanity address |
| `/api/v1/admin/server/tor/import` | POST | Import external keys |

### Admin - Web (robots.txt, security.txt) (`/api/v1/admin/server/web/`)

| Endpoint | Method | Description |
|----------|--------|-------------|
| `/api/v1/admin/server/web` | GET | Get web settings |
| `/api/v1/admin/server/web` | PATCH | Update web settings |
| `/api/v1/admin/server/web/robots` | GET | Get robots.txt config |
| `/api/v1/admin/server/web/robots` | PATCH | Update robots.txt |
| `/api/v1/admin/server/web/robots/preview` | GET | Preview robots.txt |
| `/api/v1/admin/server/web/security` | GET | Get security.txt config |
| `/api/v1/admin/server/web/security` | PATCH | Update security.txt |
| `/api/v1/admin/server/web/security/preview` | GET | Preview security.txt |

### Admin - Pages (`/api/v1/admin/server/pages/`)

| Endpoint | Method | Description |
|----------|--------|-------------|
| `/api/v1/admin/server/pages` | GET | Get all page settings |
| `/api/v1/admin/server/pages/about` | GET | Get about page content |
| `/api/v1/admin/server/pages/about` | PATCH | Update about page content |
| `/api/v1/admin/server/pages/privacy` | GET | Get privacy policy content |
| `/api/v1/admin/server/pages/privacy` | PATCH | Update privacy policy content |
| `/api/v1/admin/server/pages/contact` | GET | Get contact page settings |
| `/api/v1/admin/server/pages/contact` | PATCH | Update contact page settings |
| `/api/v1/admin/server/pages/help` | GET | Get help page content |
| `/api/v1/admin/server/pages/help` | PATCH | Update help page content |

### Admin - Email (`/api/v1/admin/server/email/`)

| Endpoint | Method | Description |
|----------|--------|-------------|
| `/api/v1/admin/server/email` | GET | Get email settings |
| `/api/v1/admin/server/email` | PATCH | Update email settings |
| `/api/v1/admin/server/email/test` | POST | Send test email |
| `/api/v1/admin/server/email/templates` | GET | List email templates |
| `/api/v1/admin/server/email/templates/{name}` | GET | Get template |
| `/api/v1/admin/server/email/templates/{name}` | PUT | Update template |
| `/api/v1/admin/server/email/templates/{name}/reset` | POST | Reset to default |
| `/api/v1/admin/server/email/templates/{name}/preview` | POST | Preview template |

### Admin - Scheduler (`/api/v1/admin/server/scheduler/`)

| Endpoint | Method | Description |
|----------|--------|-------------|
| `/api/v1/admin/server/scheduler` | GET | List scheduled tasks |
| `/api/v1/admin/server/scheduler/{id}` | GET | Get task details |
| `/api/v1/admin/server/scheduler/{id}` | PATCH | Update task |
| `/api/v1/admin/server/scheduler/{id}/run` | POST | Run task now |
| `/api/v1/admin/server/scheduler/{id}/enable` | POST | Enable task |
| `/api/v1/admin/server/scheduler/{id}/disable` | POST | Disable task |

### Admin - Backup (`/api/v1/admin/server/backup/`)

| Endpoint | Method | Description |
|----------|--------|-------------|
| `/api/v1/admin/server/backup` | GET | List backups |
| `/api/v1/admin/server/backup` | POST | Create backup |
| `/api/v1/admin/server/backup/{id}` | GET | Get backup details |
| `/api/v1/admin/server/backup/{id}` | DELETE | Delete backup |
| `/api/v1/admin/server/backup/{id}/download` | GET | Download backup file |
| `/api/v1/admin/server/backup/restore` | POST | Restore from backup |

### Admin - Logs (`/api/v1/admin/server/logs/`)

| Endpoint | Method | Description |
|----------|--------|-------------|
| `/api/v1/admin/server/logs` | GET | List log files |
| `/api/v1/admin/server/logs/{type}` | GET | Get log entries |
| `/api/v1/admin/server/logs/{type}/download` | GET | Download log file |

## Email Templates (User-Related)

| Template | Purpose |
|----------|---------|
| `user_welcome` | Welcome email after registration |
| `user_verify_email` | Email verification link |
| `user_password_reset` | Password reset link |
| `user_password_changed` | Confirmation of password change |
| `user_2fa_enabled` | Confirmation of 2FA enabled |
| `user_new_login` | Alert for login from new device/location |
| `user_invite` | Invitation email |
| `user_account_disabled` | Account has been disabled |

## Database Architecture (NON-NEGOTIABLE)

**Applications use TWO separate SQLite databases by default.**

### Database Files

| Database | File | Purpose |
|----------|------|---------|
| **Server DB** | `{data_dir}/db/server.db` | Admin credentials, server state, scheduler |
| **Users DB** | `{data_dir}/db/users.db` | User accounts, tokens, sessions (multi-user mode) |

### Why Two Databases?

| Reason | Description |
|--------|-------------|
| **Isolation** | Admin credentials separate from user data |
| **Security** | Compromised user DB doesn't expose admin |
| **Backup** | Can backup/restore independently |
| **Logical separation** | Server config vs user data |

### Database Modes

| Mode | Server DB | Users DB | Use Case |
|------|-----------|----------|----------|
| **Single Instance** | Local SQLite | Local SQLite | Default, simple deployment |
| **Cluster** | Remote (shared) | Remote (shared) | Multi-node, load distribution |
| **Mixed Mode** | Any supported | Any supported | Heterogeneous backend infrastructure |

#### Clustering vs High Availability (IMPORTANT TERMINOLOGY)

**These are NOT interchangeable terms.**

| Term | Meaning |
|------|---------|
| **Clustering** | Multiple application nodes sharing state via a common database and Valkey/Redis. Enables horizontal scaling and load distribution. All nodes are equal peers. |
| **High Availability (HA)** | Fault tolerance for the database backend itself (e.g., PostgreSQL replication, Galera for MariaDB). This is OUTSIDE the application's scope. |

**The application provides clustering (multi-node). Database HA is your infrastructure's responsibility.**

```
┌─────────────────────────────────────────────────────────────────┐
│                      APPLICATION LAYER                          │
│                                                                 │
│   ┌─────────┐     ┌─────────┐     ┌─────────┐                 │
│   │ Node 1  │     │ Node 2  │     │ Node 3  │  ← Clustering   │
│   └────┬────┘     └────┬────┘     └────┬────┘                 │
│        │               │               │                       │
│        └───────────────┼───────────────┘                       │
│                        │                                        │
│              ┌─────────▼─────────┐                             │
│              │  Valkey/Redis     │  ← Cluster coordination     │
│              └─────────┬─────────┘                             │
│                        │                                        │
└────────────────────────┼────────────────────────────────────────┘
                         │
┌────────────────────────┼────────────────────────────────────────┐
│                        ▼              INFRASTRUCTURE LAYER      │
│              ┌───────────────────┐                              │
│              │ Database Backend  │  ← HA is YOUR responsibility│
│              │ (PostgreSQL/MySQL)│                              │
│              └───────────────────┘                              │
│                                                                 │
│   Examples of HA (not our concern):                            │
│   - PostgreSQL: Patroni, pgpool, streaming replication          │
│   - MySQL/MariaDB: Galera Cluster, Group Replication           │
│   - Managed: AWS RDS Multi-AZ, CloudSQL HA                     │
└─────────────────────────────────────────────────────────────────┘
```

### Single Instance (Default)

Both databases are local SQLite files:

```yaml
server:
  database:
    driver: sqlite
    # Both databases stored locally
    # {data_dir}/db/server.db
    # {data_dir}/db/users.db
```

### Cluster Mode (Remote Database)

**When clustering, BOTH databases MUST use the same remote database.**

All nodes need shared access to:
- Admin credentials (same login works on any node)
- Server settings (consistent configuration)
- User accounts (users can access any node)
- Sessions (no re-login when switching nodes)
- API tokens (tokens work on any node)

**Two ways to configure connection (pick one):**

| Method | When to Use |
|--------|-------------|
| `url` | Simple, single connection string, environment-friendly |
| `host`/`port`/etc | More explicit, when fields come from different sources |

**Using connection URL:**
```yaml
server:
  database:
    driver: postgres
    url: ${DATABASE_URL}  # postgres://user:pass@host:5432/dbname?sslmode=require
```

**Using individual fields:**
```yaml
server:
  database:
    driver: postgres
    host: db.example.com
    port: 5432
    name: myapp
    username: myapp
    password: ${DB_PASSWORD}
    sslmode: require

    # Connection pool
    max_open: 25
    max_idle: 5
    max_lifetime: 5m
```

**URL Format:**
```
postgres://[username[:password]@]host[:port]/database[?sslmode=mode]
mysql://[username[:password]@]host[:port]/database[?params]
```

**Note:** `url` takes precedence if both url and individual fields are specified.

```yaml
# All tables go in same database with prefixes:
# - srv_* tables (config, admin_sessions, rate_limits, audit_log, scheduler_*, backups)
# - usr_* tables (admins, users, api_keys, password_resets, email_verifications, totp_secrets, passkeys, trusted_devices, user_sessions)
```

### Table Prefixes in Shared Database

| Prefix | Tables |
|--------|--------|
| `srv_` | `srv_config`, `srv_config_meta`, `srv_admin_sessions`, `srv_rate_limits`, `srv_audit_log`, `srv_scheduler_tasks`, `srv_scheduler_history`, `srv_backups` |
| `usr_` | `usr_admins`, `usr_users`, `usr_api_keys`, `usr_password_resets`, `usr_email_verifications`, `usr_totp_secrets`, `usr_passkeys`, `usr_trusted_devices`, `usr_user_sessions` |

### Cluster Requirements

| Requirement | Description |
|-------------|-------------|
| **Shared database** | All nodes connect to same PostgreSQL/MySQL |
| **Same credentials** | Admin can log into any node |
| **Session sharing** | User sessions valid across all nodes |
| **Token validation** | API tokens work on any node |
| **Config sync** | Settings changes propagate to all nodes |

### Cluster Initialization (NON-NEGOTIABLE)

**The FIRST node is the source of truth. Subsequent nodes inherit from the remote database.**

#### First Node (Primary Setup)

```
1. Deploy first node
         │
         ▼
2. First run creates local SQLite databases
   - Admin credentials auto-generated
   - Server settings initialized
         │
         ▼
3. Configure application via admin panel
   - Set branding, SSL, etc.
   - Create users (if multi-user mode)
         │
         ▼
4. Ready to migrate to cluster?
         │
         ▼
5. Setup remote database (PostgreSQL/MySQL)
         │
         ▼
6. Update config: driver: postgres (or use Web UI)
         │
         ▼
7. Restart - app auto-migrates local data to remote
         │
         ▼
8. Now using remote DB
   (First node is source of truth)
```

#### Additional Nodes (Inherit from Remote)

```
1. Deploy new node
         │
         ▼
2. Configure with SAME remote database connection
   driver: postgres
   host: db.example.com (same as first node)
         │
         ▼
3. First run detects existing data in remote DB
         │
         ▼
4. SKIP initialization - inherit everything:
   - Admin credentials (same login)
   - Server settings (same config)
   - Users (same accounts)
   - Sessions (shared)
         │
         ▼
5. Node joins cluster automatically
```

#### Node Behavior

| Scenario | Behavior |
|----------|----------|
| **First node + SQLite** | Create admin, init settings |
| **First node + empty remote DB** | Create admin, init settings (becomes source of truth) |
| **New node + remote DB with data** | Skip init, inherit everything from DB |
| **Any node + settings change** | Write to DB, all nodes see change |

#### Migration Methods

**Migration to remote database is done via config file OR admin web UI - NO CLI commands.**

**Method 1: Config File**

```yaml
# server.yml - change driver and add connection details
server:
  database:
    driver: postgres
    host: db.example.com
    port: 5432
    name: myapp
    username: myapp
    password: ${DB_PASSWORD}
    sslmode: require
```

On restart, the application:
1. Detects driver change from `sqlite` to `postgres`
2. Connects to remote database
3. If empty: migrates local SQLite data automatically
4. If has data: uses existing data (node joins cluster)

**Method 2: Admin Web UI**

`/admin/server/database`

| Element | Type | Description |
|---------|------|-------------|
| Current Driver | Read-only | Shows current database driver |
| Driver | Dropdown | sqlite, postgres, mysql |
| Host | Text input | Database host (shown when not sqlite) |
| Port | Number input | Database port |
| Database Name | Text input | Database name |
| Username | Text input | Database username |
| Password | Password input | Database password |
| SSL Mode | Dropdown | disable, require, verify-full |
| Test Connection | Button | Verify connection before saving |
| Migrate & Switch | Button | Migrate data and switch to remote |

**Migration Process (automatic on driver change):**

```
1. Test connection to remote database
         │
         ▼
2. If remote DB empty:
   - Create tables
   - Export local SQLite data
   - Import to remote
         │
         ▼
3. If remote DB has data:
   - Verify schema compatibility
   - Skip migration (join existing cluster)
         │
         ▼
4. Switch to remote driver
         │
         ▼
5. Local SQLite files preserved as backup
```

### Storage Backend Sync (Bidirectional)

**This section covers ALL storage transitions, not just the initial SQLite → Remote migration.**

The Migration Methods above describe the **initial migration** to cluster mode. This section describes:
- Migrating back from Remote → SQLite (leaving cluster)
- YAML config import/export for backup or migration
- All possible storage transitions

**Data always syncs TOWARD the new storage backend before switching.**

| From | To | Method | Sync Action |
|------|-----|--------|-------------|
| **SQLite → Remote** | Config file or Web UI | Export SQLite data → Import to remote DB → Switch to remote |
| **Remote → SQLite** | Web UI only | Export remote data → Import to SQLite files → Disconnect → Switch to SQLite |
| **SQLite → YAML** | CLI: `--maintenance backup` | Export `server.db` settings → Write to backup file |
| **YAML → SQLite** | CLI: `--maintenance restore` | Read backup → Import settings to `server.db` |
| **YAML → Remote** | CLI: `--maintenance restore` | Read backup → Import settings to remote DB |

#### Remote → SQLite (Downgrade to Local)

When switching from remote database back to local SQLite:

```
1. User selects "Switch to SQLite" in Web UI
         │
         ▼
2. Export ALL data from remote database
         │
         ▼
3. Create/update local SQLite files:
   - {data_dir}/db/server.db
   - {data_dir}/db/users.db
         │
         ▼
4. Import remote data to SQLite
         │
         ▼
5. Verify data integrity (row counts match)
         │
         ▼
6. Disconnect from remote database
         │
         ▼
7. Update config: driver: sqlite
         │
         ▼
8. Now using local SQLite (standalone mode)
```

**Use case:** Converting cluster node back to standalone instance.

#### SQLite ↔ YAML Sync

Settings can be stored in database OR config file. Sync between them:

**SQLite → YAML (Export settings to file):**

```
Admin Web UI: /admin/server/settings → "Export to YAML"
         │
         ▼
Read all settings from server.db
         │
         ▼
Write to server.yml (preserves comments, formatting)
         │
         ▼
Settings now in both DB and YAML (DB is source of truth)
```

**YAML → SQLite (Import settings from file):**

```
On startup: YAML file detected with changes
         │
         ▼
Read settings from server.yml
         │
         ▼
Import to server.db (overwrites DB values)
         │
         ▼
DB is now source of truth
```

#### Sync Priority (Source of Truth)

| Mode | Source of Truth | Behavior |
|------|-----------------|----------|
| **Running** | Database | DB values used, YAML ignored |
| **Startup (YAML changed)** | YAML | YAML imported to DB, then DB is source |
| **Startup (YAML unchanged)** | Database | DB values used |
| **Cluster** | Remote Database | All nodes read from shared DB |

### Mixed Mode (Heterogeneous Database Backends)

**Mixed Mode allows different nodes in a cluster to connect to different database backends.**

This is useful when:
- Migrating from one database to another (e.g., MySQL → PostgreSQL)
- Geographic distribution with local database preferences
- Testing new database backend before full migration

#### Mixed Mode Configuration

Each node specifies its own database connection:

**Node 1 (PostgreSQL):**
```yaml
server:
  database:
    driver: postgres
    host: pg.us-east.example.com
    port: 5432
    name: myapp
    username: myapp
    password: ${DB_PASSWORD}
```

**Node 2 (MariaDB):**
```yaml
server:
  database:
    driver: mysql
    host: maria.eu-west.example.com
    port: 3306
    name: myapp
    username: myapp
    password: ${DB_PASSWORD}
```

**Node 3 (PostgreSQL - different server):**
```yaml
server:
  database:
    driver: postgres
    host: pg.ap-south.example.com
    port: 5432
    name: myapp
    username: myapp
    password: ${DB_PASSWORD}
```

#### Mixed Mode Requirements

| Requirement | Description |
|-------------|-------------|
| **Valkey/Redis REQUIRED** | State synchronization between heterogeneous backends |
| **Schema compatibility** | All databases MUST have identical schema |
| **Data sync** | Application handles cross-database replication via Valkey |
| **Same schema version** | All nodes must run same application version |

#### Mixed Mode Diagram

```
┌─────────────────────────────────────────────────────────────────────┐
│                        CLUSTER NODES                                │
│                                                                     │
│  ┌──────────┐        ┌──────────┐        ┌──────────┐             │
│  │  Node 1  │        │  Node 2  │        │  Node 3  │             │
│  │ (US-East)│        │ (EU-West)│        │(AP-South)│             │
│  └────┬─────┘        └────┬─────┘        └────┬─────┘             │
│       │                   │                   │                    │
│       └───────────────────┼───────────────────┘                    │
│                           │                                         │
│                  ┌────────▼────────┐                               │
│                  │  Valkey/Redis   │  ← Sync layer (REQUIRED)      │
│                  │    Cluster      │                               │
│                  └────────┬────────┘                               │
│                           │                                         │
└───────────────────────────┼─────────────────────────────────────────┘
                            │
        ┌───────────────────┼───────────────────┐
        │                   │                   │
        ▼                   ▼                   ▼
┌──────────────┐   ┌──────────────┐   ┌──────────────┐
│  PostgreSQL  │   │   MariaDB    │   │  PostgreSQL  │
│  (US-East)   │   │  (EU-West)   │   │  (AP-South)  │
└──────────────┘   └──────────────┘   └──────────────┘
```

#### Mixed Mode Sync via Valkey

**All state changes are broadcast through Valkey/Redis:**

```
Node 1 writes user record
         │
         ▼
Local PostgreSQL INSERT
         │
         ▼
Publish to Valkey: "user.created" + payload
         │
         ├──────────────────────────────────────┐
         │                                      │
         ▼                                      ▼
Node 2 receives                          Node 3 receives
         │                                      │
         ▼                                      ▼
Local MariaDB INSERT                     Local PostgreSQL INSERT
```

**The application handles:**
- Publishing changes to Valkey after local writes
- Subscribing to changes from other nodes
- Applying remote changes to local database
- Conflict resolution (last-write-wins by timestamp)

### Node Management (NON-NEGOTIABLE)

**Simple node management via admin web UI. No CLI commands, no manual config.**

#### Adding a Node

**On existing node:**

1. Go to `/admin/server/nodes/add`
2. Click "Generate Token" button
3. Server generates:
   - Token: `node_{random_32_chars}`
   - URL: `{proto}://{fqdn}` (of this node)
4. Display token and URL to admin (copy buttons)

**On new server:**

1. Go to `/admin/server/nodes/add`
2. Enter:
   - URL from existing node
   - Token from existing node
3. Click "Join Cluster"
4. New node automatically:
   - Connects to existing node
   - Gets database connection details
   - Gets all configuration
   - Joins cluster

```
Existing Node                          New Node
     │                                      │
     ▼                                      │
/admin/server/nodes/add                     │
     │                                      │
     ▼                                      │
Generate Token                              │
  → node_abc123...                          │
  → https://node1.example.com               │
     │                                      │
     └──────── Share token + URL ──────────►│
                                            │
                                            ▼
                                   /admin/server/nodes/add
                                            │
                                            ▼
                                   Enter URL + Token
                                            │
                                            ▼
                                   Click "Join Cluster"
                                            │
                                            ▼
                                   Auto-configured!
```

#### Join Cluster Flow (Technical)

**Step-by-step process when new node joins cluster:**

```
NEW NODE                                    EXISTING NODE
    │                                            │
    │  1. POST /api/v1/cluster/join              │
    │     Body: { "token": "node_xxx" }          │
    │─────────────────────────────────────────►  │
    │                                            │
    │                                            ▼
    │                                   2. Validate token:
    │                                      - Token exists?
    │                                      - Not expired (15 min)?
    │                                      - Not already used?
    │                                      - Not in 90-day lockout?
    │                                            │
    │                                            ▼
    │                                   3. Mark token as used
    │                                            │
    │  4. Response: cluster bootstrap data       │
    │  ◄─────────────────────────────────────────│
    │                                            │
    ▼                                            │
5. Receive bootstrap data:                       │
   - Database connection (encrypted)             │
   - Encryption key for secrets                  │
   - Cluster ID                                  │
    │                                            │
    ▼                                            │
6. Connect to remote database                    │
    │                                            │
    ▼                                            │
7. Read all configuration from database          │
   - Server settings                             │
   - Branding/SEO                                │
   - SSL settings                                │
   - All other config                            │
    │                                            │
    ▼                                            │
8. Register self in nodes table                  │
   - node_id: {hostname}                         │
   - status: online                              │
   - joined_at: now()                            │
    │                                            │
    ▼                                            │
9. Write minimal server.yml                      │
   - Database connection only                    │
    │                                            │
    ▼                                            │
10. Start heartbeat                              │
    │                                            │
    ▼                                            │
11. Node is now part of cluster                  │
```

#### Bootstrap Data Structure

**Response from existing node (`POST /api/v1/cluster/join`):**

```json
{
  "success": true,
  "cluster": {
    "id": "cluster_abc123",
    "name": "MyApp Cluster"
  },
  "database": {
    "driver": "postgres",
    "host": "db.example.com",
    "port": 5432,
    "name": "myapp",
    "username": "myapp",
    "password_encrypted": "base64_encrypted_password",
    "sslmode": "require"
  },
  "encryption": {
    "key_encrypted": "base64_encrypted_key"
  },
  "node": {
    "suggested_id": "server-2"
  }
}
```

#### Security: Encrypted Transfer

**Sensitive data is encrypted during transfer using token-derived key:**

```go
// Token is used to derive encryption key for bootstrap data
func deriveKeyFromToken(token string) []byte {
    // Use Argon2id to derive encryption key from token
    salt := sha256.Sum256([]byte("cluster_join_" + token))
    return argon2.IDKey([]byte(token), salt[:16], 3, 64*1024, 4, 32)
}

// Existing node encrypts sensitive data
func encryptBootstrapData(data []byte, token string) []byte {
    key := deriveKeyFromToken(token)
    // AES-256-GCM encryption
    return aesGcmEncrypt(data, key)
}

// New node decrypts using same token
func decryptBootstrapData(encrypted []byte, token string) []byte {
    key := deriveKeyFromToken(token)
    return aesGcmDecrypt(encrypted, key)
}
```

**What's encrypted:**
- Database password
- Encryption key for secrets (TOTP secrets, etc.)

**What's NOT encrypted (not sensitive):**
- Database host/port/name
- Cluster ID
- Node suggestions

#### Database Tables for Clustering

**Nodes Table (in remote database):**

| Column | Type | Description |
|--------|------|-------------|
| `id` | String | Node ID (default: hostname) |
| `hostname` | String | Server hostname |
| `ip_address` | String | Node IP address |
| `version` | String | Application version |
| `status` | String | online, offline, degraded |
| `last_heartbeat` | Timestamp | Last heartbeat time |
| `joined_at` | Timestamp | When node joined cluster |
| `system_info` | JSON | CPU, memory, disk stats |

**Join Tokens Table (in remote database):**

| Column | Type | Description |
|--------|------|-------------|
| `id` | UUID | Primary key |
| `token_hash` | String | SHA-256 hash of token |
| `created_by` | String | Node ID that created token |
| `created_at` | Timestamp | Creation time |
| `expires_at` | Timestamp | Expiration (created_at + 15 min) |
| `used_at` | Timestamp | When token was used (NULL if unused) |
| `used_by` | String | Node ID that used token |
| `lockout_until` | Timestamp | Cannot reuse until (used_at + 90 days) |

#### Heartbeat

**Nodes send heartbeat every 30 seconds:**

```go
func startHeartbeat(ctx context.Context, db *sql.DB, nodeID string) {
    ticker := time.NewTicker(30 * time.Second)
    defer ticker.Stop()

    for {
        select {
        case <-ctx.Done():
            return
        case <-ticker.C:
            updateHeartbeat(db, nodeID)
        }
    }
}

func updateHeartbeat(db *sql.DB, nodeID string) {
    db.Exec(`
        UPDATE nodes
        SET last_heartbeat = NOW(),
            status = 'online',
            system_info = $1
        WHERE id = $2
    `, getSystemInfo(), nodeID)
}
```

**Node status determination:**

| Last Heartbeat | Status |
|----------------|--------|
| < 1 minute ago | online |
| 1-5 minutes ago | degraded |
| > 5 minutes ago | offline |

#### Error Handling

| Error | Response | Action |
|-------|----------|--------|
| Invalid token | 401 Unauthorized | Show error, ask to retry |
| Token expired | 401 Token Expired | Generate new token on existing node |
| Token already used | 401 Token Already Used | Generate new token |
| Token in lockout | 401 Token Locked | Wait 90 days or generate new token |
| Database connection failed | 500 Database Error | Show error, check DB settings |
| Network error | Connection Failed | Retry with backoff |

#### Token Rules

| Rule | Value |
|------|-------|
| Format | `node_{random_32_chars}` |
| Valid for | 15 minutes |
| Usage | One-time only |
| Reuse lockout | 90 days (prevents replay attacks) |

#### Removing a Node

**A node can only remove ITSELF from the cluster.**

1. Go to `/admin/server/nodes/remove` (on the node to remove)
2. Click "Remove from Cluster"
3. Confirmation modal: "Are you sure you want to remove {nodename} from the cluster?"
   - [Yes, Remove] [Cancel]
4. On confirmation:
   - Node disconnects from cluster
   - Node reverts to standalone mode (local SQLite)
   - Node creates fresh local databases
   - Other nodes see removal, adjust node count

**Cannot remove other nodes** - prevents accidental/malicious removal.

#### Viewing Nodes

**`/admin/server/nodes`** - Node list

| Column | Description |
|--------|-------------|
| Node Name | Hostname (clickable link) |
| Status | online, offline, degraded |
| Uptime | Time since last restart |
| Version | Application version |
| Last Seen | Last heartbeat time |

**`/admin/server/nodes/{node}`** - Node detail

| Section | Contents |
|---------|----------|
| **Info** | Node name, hostname, IP, version, uptime |
| **Status** | Connection status, last heartbeat |
| **System** | CPU usage, memory usage, disk usage |
| **Database** | Connection status, query latency |
| **Tor** | Hidden service status, .onion address |

#### Node Identity

| Setting | Default | Changeable |
|---------|---------|------------|
| Node ID | `{hostname}` | Yes, via `/admin/server/nodes/settings` |
| Display Name | `{hostname}` | Yes |

#### First Node Behavior

**Generating the first token automatically converts to cluster mode.**

```
Single Instance (SQLite)
         │
         ▼
Admin goes to /admin/server/nodes/add
         │
         ▼
Clicks "Generate Token"
         │
         ▼
Wizard prompts: "Enable cluster mode?"
  - Requires remote database connection
  - Enter PostgreSQL/MySQL details
         │
         ▼
On confirm:
  - Migrates local data to remote DB
  - Generates join token
  - Node is now cluster-ready
```

#### Admin Panel Routes

| Route | Description |
|-------|-------------|
| `/admin/server/nodes` | List all nodes |
| `/admin/server/nodes/add` | Add node (generate token OR join) |
| `/admin/server/nodes/remove` | Remove THIS node from cluster |
| `/admin/server/nodes/settings` | Node identity settings |
| `/admin/server/nodes/{node}` | View specific node details |

#### API Endpoints

| Endpoint | Method | Description |
|----------|--------|-------------|
| `/api/v1/admin/server/nodes` | GET | List all nodes |
| `/api/v1/admin/server/nodes/token` | POST | Generate join token |
| `/api/v1/admin/server/nodes/join` | POST | Join cluster with token |
| `/api/v1/admin/server/nodes/leave` | POST | Remove this node from cluster |
| `/api/v1/admin/server/nodes/{node}` | GET | Get node details |
| `/api/v1/admin/server/nodes/settings` | GET | Get node identity settings |
| `/api/v1/admin/server/nodes/settings` | PATCH | Update node identity |

### Supported Remote Databases

| Database | Driver | Pure Go | Notes |
|----------|--------|---------|-------|
| PostgreSQL | `github.com/lib/pq` | YES | Recommended for production |
| MySQL/MariaDB | `github.com/go-sql-driver/mysql` | YES | Widely supported |
| SQLite | `modernc.org/sqlite` | YES | Single instance only |

### Schema Migration

When using remote database, the same tables are created but with appropriate types:

| SQLite Type | PostgreSQL Type | MySQL Type |
|-------------|-----------------|------------|
| TEXT | TEXT | VARCHAR(255) / TEXT |
| INTEGER | INTEGER / BIGINT | INT / BIGINT |
| BOOLEAN | BOOLEAN | TINYINT(1) |
| TIMESTAMP | TIMESTAMPTZ | DATETIME |
| UUID | UUID | CHAR(36) |
| JSON | JSONB | JSON |

## Database Schema

### Server Database Tables (server.db)

#### Admin Credentials Table

**Stores server admin credentials - NEVER in config file.**

| Column | Type | Description |
|--------|------|-------------|
| `id` | INTEGER | Primary key (always 1 - single admin) |
| `username` | String | Admin username |
| `email` | String | Admin email |
| `password_hash` | String | Argon2id hash (PHC format) |
| `token_hash` | String | SHA-256 hash of API token |
| `token_prefix` | String | First 8 chars of token (for identification) |
| `totp_secret` | String | 2FA secret (encrypted, optional) |
| `totp_enabled` | Boolean | 2FA enabled |
| `created_at` | Timestamp | Account creation |
| `updated_at` | Timestamp | Last update |
| `last_login_at` | Timestamp | Last login |

**Notes:**
- Only ONE row ever exists (id=1)
- Created via setup wizard on first run
- Setup token displayed in console ONCE, used to access `/admin/server/setup`
- Admin password and API token created during setup wizard (user must copy)

#### Admin Sessions Table

| Column | Type | Description |
|--------|------|-------------|
| `id` | UUID | Primary key |
| `token_hash` | String | SHA-256 hash of session token |
| `ip_address` | String | Client IP |
| `user_agent` | String | Browser/client info |
| `location` | String | GeoIP location |
| `expires_at` | Timestamp | Session expiry |
| `created_at` | Timestamp | Session start |

#### Scheduler State Table

| Column | Type | Description |
|--------|------|-------------|
| `task_id` | String | Unique task identifier |
| `last_run` | Timestamp | Last execution time |
| `next_run` | Timestamp | Next scheduled time |
| `last_result` | String | success/failure |
| `last_error` | Text | Error message if failed |
| `run_count` | Integer | Total runs |
| `enabled` | Boolean | Task enabled |

### Users Database Tables (users.db)

#### Users Table

| Column | Type | Description |
|--------|------|-------------|
| `id` | UUID | Primary key |
| `email` | String | Unique, required |
| `password_hash` | String | Argon2id hash (PHC format) |
| `display_name` | String | Optional |
| `avatar_url` | String | Optional |
| `bio` | Text | Optional |
| `role` | String | User role |
| `email_verified` | Boolean | Email verified status |
| `approved` | Boolean | Admin approved (if required) |
| `disabled` | Boolean | Account disabled |
| `totp_secret` | String | 2FA secret (encrypted) |
| `totp_enabled` | Boolean | 2FA enabled |
| `timezone` | String | User timezone |
| `language` | String | User language |
| `created_at` | Timestamp | Account creation |
| `updated_at` | Timestamp | Last update |
| `last_login_at` | Timestamp | Last login |

#### User Tokens Table

| Column | Type | Description |
|--------|------|-------------|
| `id` | UUID | Primary key |
| `user_id` | UUID | Foreign key to users |
| `name` | String | User-defined label |
| `token_hash` | String | SHA-256 hash of API token |
| `token_prefix` | String | First 8 chars (for identification) |
| `scopes` | JSON | Optional permission scopes |
| `expires_at` | Timestamp | Optional expiration |
| `last_used_at` | Timestamp | Last usage |
| `created_at` | Timestamp | Creation time |

#### User Sessions Table

| Column | Type | Description |
|--------|------|-------------|
| `id` | UUID | Primary key |
| `user_id` | UUID | Foreign key to users |
| `token_hash` | String | SHA-256 hash of session token |
| `ip_address` | String | Client IP |
| `user_agent` | String | Browser/client info |
| `location` | String | GeoIP location |
| `expires_at` | Timestamp | Session expiry |
| `created_at` | Timestamp | Session start |

#### Invites Table

| Column | Type | Description |
|--------|------|-------------|
| `id` | UUID | Primary key |
| `code` | String | Unique invite code |
| `role` | String | Role for invited users |
| `max_uses` | Integer | Maximum uses (0 = unlimited) |
| `use_count` | Integer | Current use count |
| `expires_at` | Timestamp | Expiration |
| `created_by` | UUID | Admin who created |
| `created_at` | Timestamp | Creation time |

---


# PART 24: DATABASE & CLUSTER (NON-NEGOTIABLE)

## Database Schema

**ALL apps use `CREATE TABLE IF NOT EXISTS` for self-creating schema.**

| Feature | Description |
|---------|-------------|
| Self-creating | Tables created on startup if missing |
| Idempotent | Safe to run multiple times |
| Schema changes | Use `ALTER TABLE` inline when needed |
| No migrations table | Keep it simple |

See **Database Schema for Configuration** section in PART 5 for full table definitions.

## Cluster Support (NON-NEGOTIABLE)

**ALL apps MUST support cluster mode with config sync.**

### What Clustering Provides (Standard for ALL Apps)

| Feature | Description |
|---------|-------------|
| **Config Sync** | Change setting on one node → syncs to all nodes |
| **Session Sharing** | User sessions shared across nodes |
| **Distributed Locks** | Prevent duplicate task execution |
| **Primary Election** | One node handles cluster-wide tasks |
| **Health Monitoring** | Nodes monitor each other |

**This is the BASE functionality. Every project gets this.**

### Single Instance (Auto-detected)

- No external cache/database configured
- Uses local file/SQLite for state
- Fully functional, just not clustered

### Cluster Mode (Auto-detected)

- Auto-enabled when external cache or shared database detected
- Requires: PostgreSQL/MySQL + Valkey/Redis
- All nodes share same database and cache
- Config changes propagate automatically

### Cluster Heartbeat & Failure Handling

**Every cluster node sends heartbeats to detect failures.**

| Setting | Value | Description |
|---------|-------|-------------|
| Heartbeat interval | 30 seconds | How often nodes send heartbeats |
| Heartbeat timeout | 90 seconds | 3 missed heartbeats = node considered unresponsive |
| Degraded threshold | 90 seconds | Node marked as `degraded` |
| Offline threshold | 5 minutes | Node marked as `offline` |
| Removal threshold | Manual | Offline nodes require manual removal |

**Node States:**

| State | Meaning | Action |
|-------|---------|--------|
| `healthy` | Heartbeat received within 30 seconds | Normal operation |
| `degraded` | Heartbeat missed (30-90 seconds) | Logged, monitoring continues |
| `offline` | No heartbeat for 5+ minutes | Node excluded from load balancing |
| `removed` | Manually removed by admin | Node record deleted |

**Failure Detection Flow:**

```
Node A sends heartbeat every 30 seconds
         │
         ▼
Other nodes track "last_seen" timestamp
         │
         ▼
If now - last_seen > 90 seconds:
   Mark as "degraded", log warning
         │
         ▼
If now - last_seen > 5 minutes:
   Mark as "offline", exclude from cluster operations
         │
         ▼
Admin manually removes dead nodes via:
   /admin/server/cluster → Remove Node
```

**Primary Election:**

| Event | Action |
|-------|--------|
| Cluster starts | Node with lowest ID becomes primary |
| Primary goes offline | Next healthy node (by ID) becomes primary |
| Primary comes back | Remains secondary (no preemption) |
| Split-brain | Database is source of truth (latest write wins) |

**What Primary Node Handles:**

- Scheduled tasks (only primary runs cron jobs)
- Cluster-wide maintenance
- GeoIP/blocklist updates (once, shared via DB)

### Extended Node Functions (PER-PROJECT)

**Beyond config sync, what nodes DO varies by project.**

| App Type | Base (Config Sync) | Extended Node Function |
|----------|:------------------:|------------------------|
| Jokes API | ✓ | None - sync only |
| Quotes API | ✓ | None - sync only |
| Watchtower-type | ✓ | + Manage Docker hosts |
| DNS Server | ✓ | + HA failover |
| Monitoring App | ✓ | + Monitor remote servers |
| Proxmox-type | ✓ | + Manage VMs + HA failover |

**Extended functions are defined in the project's AI.md under "Node Functions".**

### High Availability (Specialized Apps Only)

**HA is NOT standard - only for apps that specifically require failover.**

| HA Requirement | Examples |
|----------------|----------|
| DNS failover | DNS servers, domain controllers |
| Service continuity | Proxmox, cPanel, critical infrastructure |
| Data redundancy | Database clusters, storage systems |

**If your app needs HA, define it in AI.md under "High Availability Requirements".**

Most apps (Jokes, Quotes, Airports, etc.) do NOT need HA - clustering with config sync is sufficient.

---


# PART 25: BACKUP & RESTORE (NON-NEGOTIABLE)

## Backup Command

```bash
casspeed --maintenance backup [filename]
```

### Backup Contents

| Content | Included | Notes |
|---------|----------|-------|
| `server.yml` | ✓ Always | Configuration file |
| `server.db` | ✓ Always | Main database (admin credentials, settings) |
| `users.db` | ✓ If exists | User database (multi-user mode) |
| `{config_dir}/templates/` | ✓ If exists | Custom email templates |
| `{config_dir}/themes/` | ✓ If exists | Custom themes |
| `{config_dir}/ssl/` | Optional | SSL certificates (flag: `--include-ssl`) |
| `{data_dir}/` | Optional | Data files (flag: `--include-data`) |

### Admin Credentials in Backup

**Yes, admin credentials are included in the backup (`server.db`).**

| Credential | Included | Format |
|------------|----------|--------|
| Admin username | ✓ | Plain text |
| Admin password | ✓ | Hashed (Argon2id) |
| Admin API token | ✓ | Hashed (SHA-256) |
| Admin 2FA secret | ✓ | Encrypted |
| Admin recovery keys | ✓ | Hashed |
| Additional admin accounts | ✓ | Same as above |
| OIDC/LDAP admin mappings | ✓ | Configuration only |

### Backup Format

- Single `.tar.gz` file (or `.tar.gz.enc` if encrypted)
- Filename: `casspeed_backup_YYYY-MM-DD_HHMMSS.tar.gz[.enc]`
- Includes manifest with version info
- Encrypted if backup password was set during setup

**Manifest (`manifest.json`):**
```json
{
  "version": "1.0.0",
  "created_at": "2025-01-15T10:30:00Z",
  "created_by": "administrator",
  "app_version": "1.2.3",
  "contents": [
    "server.yml",
    "server.db",
    "users.db",
    "templates/",
    "ssl/"
  ],
  "encrypted": true,
  "encryption_method": "AES-256-GCM",
  "checksum": "sha256:abc123..."
}
```

### Backup Encryption (Highly Recommended)

**If backup encryption password was set during setup, ALL backups are automatically encrypted.**

| Aspect | Details |
|--------|---------|
| Algorithm | AES-256-GCM |
| Key Derivation | Argon2id (password → encryption key) |
| File Extension | `.tar.gz.enc` |
| Password Storage | **NEVER stored** - admin must remember |

**How It Works:**
1. Backup creates `.tar.gz` archive in memory
2. Password is run through Argon2id to derive 256-bit key
3. Archive is encrypted with AES-256-GCM
4. Encrypted file saved as `.tar.gz.enc`
5. Unencrypted archive never touches disk

**Encryption Configuration:**

```yaml
server:
  backup:
    encryption:
      # true if password was set during setup
      enabled: true
      # Password is NEVER stored - derived on-demand
```

**Setting/Changing Backup Password:**

| Action | Location | Notes |
|--------|----------|-------|
| Set during setup | Setup wizard Step 4 | Recommended |
| Set later | `/admin/server/backup` | Click "Set Encryption Password" |
| Change password | `/admin/server/backup` | New backups use new password |
| Remove encryption | Not possible | Once enabled, cannot disable |

**Important:**
- Old backups encrypted with old password still need old password to restore
- Password hint can be stored (optional): "Hint: First pet's name + year"
- No password recovery - if lost, backups are unrecoverable

**CLI Backup with Encryption:**

```bash
# If encryption password set during setup:
casspeed --maintenance backup
# Prompts for password, creates encrypted backup

# Override with explicit password:
casspeed --maintenance backup --password "mypassword"

# Restore encrypted backup:
casspeed --maintenance restore backup.tar.gz.enc
# Prompts for password
```

**API Backup with Encryption:**

```
POST /api/v1/admin/server/backup
Content-Type: application/json

{
  "password": "backup-encryption-password"  // Required if encryption enabled
}
```

**Warning Shown if Encryption Not Enabled:**

```
┌─────────────────────────────────────────────────────────────────────┐
│  ⚠️  BACKUP ENCRYPTION NOT CONFIGURED                               │
│                                                                      │
│  Your backups are NOT encrypted. If someone gains access to your    │
│  backup files, they can read all data including admin credentials.  │
│                                                                      │
│  [Set Encryption Password]  [Remind Me Later]  [Don't Show Again]   │
└─────────────────────────────────────────────────────────────────────┘
```

Shown on:
- First backup if encryption not configured
- `/admin/server/backup` page (dismissable)

### Backup Retention (Max 4 by Default)

**Storage management: only keep the most recent backups.**

| Setting | Default | Description |
|---------|---------|-------------|
| `max_backups` | 4 | Maximum number of backups to keep |
| `retention_policy` | `count` | `count`, `day`, `week`, `month`, `year` |

**Retention Policies:**

| Policy | Behavior |
|--------|----------|
| `count` | Keep last N backups (default: 4) |
| `day` | Keep one backup per day for N days |
| `week` | Keep one backup per week for N weeks |
| `month` | Keep one backup per month for N months |
| `year` | Keep one backup per year for N years |

**Configuration:**

```yaml
server:
  backup:
    retention:
      # Maximum backups to keep (prevents storage bloat)
      max_backups: 4
      # Policy: count, day, week, month, year
      policy: count
      # Auto-delete old backups after creating new one
      auto_cleanup: true
```

**Backup Creation Flow:**

```
1. Create new backup
2. Verify backup integrity (checksum + test decrypt if encrypted)
3. If verification passes:
   - Count existing backups
   - If count >= max_backups:
     - Delete oldest backup(s) to stay under limit
4. If verification fails:
   - Delete failed backup
   - Alert admin
   - Do NOT delete any existing backups
```

**Verification (NON-NEGOTIABLE):**

Every backup is verified immediately after creation:

| Check | Description |
|-------|-------------|
| File exists | Backup file was written |
| Size > 0 | File is not empty |
| Checksum valid | SHA-256 matches manifest |
| Decrypt test | If encrypted, verify password works |
| Manifest readable | Can parse manifest.json |

**Only delete old backups if new backup passes ALL verification checks.**

**Admin UI:**

```
┌─────────────────────────────────────────────────────────────────────┐
│  BACKUP RETENTION                                                    │
├─────────────────────────────────────────────────────────────────────┤
│                                                                      │
│  Maximum backups to keep: [4    ▼]                                  │
│                                                                      │
│  Retention policy:                                                   │
│  (●) Keep last N backups                                            │
│  ( ) Keep daily backups for N days                                  │
│  ( ) Keep weekly backups for N weeks                                │
│  ( ) Keep monthly backups for N months                              │
│  ( ) Keep yearly backups for N years                                │
│                                                                      │
│  [✓] Auto-delete old backups after successful backup                │
│                                                                      │
│  Current storage: 45 MB (4 backups)                                 │
│                                                                      │
└─────────────────────────────────────────────────────────────────────┘
```

**Audit Events:**

| Event | Description | Logged Data |
|-------|-------------|-------------|
| `backup.retention_cleanup` | Old backups deleted | Deleted files, reason, remaining count |
| `backup.verification_failed` | Backup verification failed | Filename, check that failed |

## Restore Command

```bash
casspeed --maintenance restore <backup-file>
```

### Restore Behavior

| Scenario | Behavior |
|----------|----------|
| **Restore to same server** | Overwrites current config and database |
| **Restore to new server** | Primary admin must re-authenticate |
| **Version mismatch** | Warning shown, schema updates applied if needed |

### Primary Admin Re-Setup on Restore

**When restoring a backup to a NEW server, the primary admin must re-authenticate:**

```
Restore completed. Primary admin re-authentication required.

A new setup token has been generated:

  Setup Token: a1b2c3d4e5f67890abcdef1234567890

Go to: https://{fqdn}:{port}/admin

Enter the setup token to verify you are the server administrator.
Your existing password and settings will be preserved.
```

**Why Re-Authentication?**
- Prevents stolen backup from granting immediate admin access
- Verifies person restoring has server-level access (can see console)
- Preserves existing admin credentials (just requires re-verification)

**What is Preserved:**
- Admin username
- Admin password (still valid after re-auth)
- Admin 2FA settings
- Admin API token
- All configuration
- All user accounts

**What Requires Re-Setup:**
- Initial setup token verification (one-time)

### Additional Admins on Restore

| Admin Type | Restore Behavior |
|------------|------------------|
| **Primary Admin** | Must re-authenticate with setup token |
| **Additional Admins (local)** | Can log in immediately with existing credentials |
| **OIDC/LDAP Admins** | Can log in if OIDC/LDAP provider accessible |

## Admin Recovery Command

```bash
casspeed --maintenance setup
```

**Purpose:** Resets admin credentials and generates a new setup token. This is the ONLY way for a server admin to recover access if they have lost their password, API token, AND recovery keys.

### What It Does

| Action | Description |
|--------|-------------|
| **Clears admin password** | Admin password is set to null/empty |
| **Clears admin API token** | Admin API token is invalidated |
| **Generates new setup token** | One-time setup token displayed in console |
| **Preserves everything else** | User accounts, data, configuration unchanged |

### What It Does NOT Do

| Preserved | Description |
|-----------|-------------|
| **User accounts** | All user accounts remain intact |
| **User passwords** | No user credentials are modified |
| **User data** | All user data is preserved |
| **Configuration** | All settings except admin credentials |
| **Database** | No data is deleted or modified |
| **SSL certificates** | Certificates remain valid |

### Usage

```bash
# Stop the service first (recommended)
casspeed --service stop

# Run setup reset
casspeed --maintenance setup

# Output:
# ╔══════════════════════════════════════════════════════════════════╗
# ║                     ADMIN CREDENTIALS RESET                      ║
# ╠══════════════════════════════════════════════════════════════════╣
# ║  Admin password and API token have been cleared.                 ║
# ║                                                                  ║
# ║  NEW SETUP TOKEN (copy this now, shown ONCE):                    ║
# ║  ┌────────────────────────────────────────────────────────────┐  ║
# ║  │  a1b2c3d4e5f67890abcdef1234567890                          │  ║
# ║  └────────────────────────────────────────────────────────────┘  ║
# ║                                                                  ║
# ║  1. Start the service: casspeed --service start             ║
# ║  2. Go to: http://{fqdn}:{port}/admin                            ║
# ║  3. Enter the setup token above                                  ║
# ║  4. Create new admin account via setup wizard                    ║
# ╚══════════════════════════════════════════════════════════════════╝

# Start the service
casspeed --service start
```

### Security Considerations

| Consideration | Requirement |
|---------------|-------------|
| **Requires root/admin** | Must have console/SSH access to run binary |
| **Console access required** | Setup token only displayed in terminal |
| **One-time token** | Token expires after use or after 24 hours |
| **Logged** | Action logged to audit log (if available) |
| **Service should be stopped** | Recommended to stop service first |

### When to Use

| Scenario | Use `--maintenance setup` |
|----------|---------------------------|
| Admin forgot password | ✓ Yes |
| Admin lost API token | ✓ Yes |
| Admin lost recovery keys | ✓ Yes |
| Admin locked out of 2FA | ✓ Yes (only if no recovery keys) |
| User forgot password | ✗ No (use password reset) |
| User locked out | ✗ No (admin can help via UI) |
| Routine password change | ✗ No (use /admin/profile) |

### Recovery Flow

```
┌─────────────────────────────────────────────────────────────────┐
│                    ADMIN RECOVERY FLOW                          │
├─────────────────────────────────────────────────────────────────┤
│                                                                 │
│  Admin locked out (no password, no token, no recovery keys)     │
│                           │                                     │
│                           ▼                                     │
│  Server admin runs: casspeed --maintenance setup           │
│                           │                                     │
│                           ▼                                     │
│  Admin credentials cleared, new setup token generated           │
│                           │                                     │
│                           ▼                                     │
│  Admin visits /admin and enters setup token                     │
│                           │                                     │
│                           ▼                                     │
│  Setup wizard: Create new admin account                         │
│  (username, password, API token, 2FA optional)                  │
│                           │                                     │
│                           ▼                                     │
│  Admin access restored, new recovery keys issued                │
│                                                                 │
└─────────────────────────────────────────────────────────────────┘
```

---


# PART 26: EMAIL & NOTIFICATIONS (NON-NEGOTIABLE)

## Overview

**ALL projects MUST have customizable email templates.**

Email templates allow server admins to customize ALL notification messages, including account-related emails (password reset, email verification, login alerts, etc.). Default templates with sane defaults are embedded in the binary; custom templates are stored in `{config_dir}/templates/email/`.

**Key Points:**
- ALL email templates are fully customizable via the admin panel
- Account emails (password reset, verification, security alerts) follow the same customization pattern as server notification emails
- Each template has sensible defaults that work out-of-the-box
- Changes take effect immediately (live reload)

## Template Storage

| Type | Location |
|------|----------|
| Default templates | Embedded in binary (`src/templates/email/`) |
| Custom templates | `{config_dir}/templates/email/` |

**Behavior:**
- If custom template exists → use custom
- If not → fall back to embedded default
- Reset to default → delete custom file

## SMTP Requirement (NON-NEGOTIABLE)

**ALL emails require a valid and working SMTP server. No SMTP = No emails. Don't even try.**

| Rule | Description |
|------|-------------|
| **No SMTP configured** | Email functionality completely disabled |
| **SMTP configured but invalid** | Validate on save, reject invalid config |
| **SMTP configured and working** | Email functionality enabled |

**Behavior When No SMTP:**

| Feature | Behavior |
|---------|----------|
| Password reset | Feature hidden/disabled, show "Contact administrator" |
| Email verification | Skipped entirely (emails auto-verified) |
| Login alerts | Not sent, not attempted, not logged |
| Welcome email | Not sent, not attempted |
| Security alerts | Not sent, not attempted |
| All notifications | Not sent, not attempted |

**DO NOT:**
- ❌ Attempt to send emails without valid SMTP
- ❌ Queue emails hoping SMTP will be configured later
- ❌ Log "would have sent email" messages
- ❌ Show email-related options if SMTP not configured

**DO:**
- ✓ Check SMTP status once at startup and on config change
- ✓ Completely disable email features if no SMTP
- ✓ Hide email-dependent UI elements when SMTP unavailable
- ✓ Show clear message: "Email features require SMTP configuration"

**Admin Panel:**
- If SMTP not configured, show banner: "⚠️ SMTP not configured. Email features disabled. [Configure SMTP](/admin/server/email)"
- Email-dependent features (password reset link, etc.) hidden until SMTP configured
- Test email button validates SMTP actually works before enabling email features

## Default Templates

**Note:** Templates are defined for all functionality but are ONLY used when SMTP is configured. When SMTP is not configured:
- Templates exist but are never rendered or sent
- `email_verify` template is not used - email addresses are auto-verified
- All email-dependent features are hidden/disabled

| Template | Purpose | Account Email? |
|----------|---------|:--------------:|
| `welcome` | New user registration / admin setup | ✓ |
| `password_reset` | Password reset request | ✓ |
| `email_verify` | Email address verification | ✓ |
| `login_alert` | New login detected | ✓ |
| `security_alert` | Security event (failed logins, etc.) | ✓ |
| `mfa_reminder` | Gentle prompt to enable MFA (periodic) | ✓ |
| `2fa_enabled` | 2FA activated on account | ✓ |
| `2fa_disabled` | 2FA removed from account | ✓ |
| `password_changed` | Password was changed | ✓ |
| `backup_complete` | Backup finished successfully | ✗ |
| `backup_failed` | Backup error | ✗ |
| `ssl_expiring` | Certificate expiration warning | ✗ |
| `ssl_renewed` | Certificate renewed successfully | ✗ |
| `scheduler_error` | Scheduled task failed | ✗ |
| `breach_notification` | Data breach notification to affected users | ✓ |
| `breach_admin_alert` | Breach detected alert to server admins | ✗ |
| `test` | Test email | ✗ |

**Account Email (✓):** Must follow Account Email Requirements (visible link, disclaimer, etc.)

## Sane Defaults (NON-NEGOTIABLE)

**ALL email templates MUST have sensible defaults that work immediately without configuration.**

| Template | Default Subject | Default Behavior |
|----------|-----------------|------------------|
| `welcome` | `Welcome to {app_name}` | Sent to new users on registration (if enabled) and to admin on first setup |
| `password_reset` | `Password Reset Request - {app_name}` | 24-hour expiry, includes IP address |
| `email_verify` | `Verify Your Email - {app_name}` | 48-hour expiry |
| `login_alert` | `New Login Detected - {app_name}` | Includes IP, location (if GeoIP enabled), device |
| `security_alert` | `Security Alert - {app_name}` | Generic alert for various security events |
| `mfa_reminder` | `Secure Your Account - {app_name}` | Periodic reminder, includes setup link, dismissable |
| `2fa_enabled` | `Two-Factor Authentication Enabled - {app_name}` | Confirmation of 2FA activation |
| `2fa_disabled` | `Two-Factor Authentication Disabled - {app_name}` | Warning about 2FA removal |
| `password_changed` | `Your Password Was Changed - {app_name}` | Confirmation of password change |
| `backup_complete` | `Backup Complete - {app_name}` | Includes filename and size |
| `backup_failed` | `Backup Failed - {app_name}` | Includes error message |
| `ssl_expiring` | `SSL Certificate Expiring - {app_name}` | Sent 30, 14, 7, 3, 1 days before expiry |
| `ssl_renewed` | `SSL Certificate Renewed - {app_name}` | Confirmation of renewal |
| `scheduler_error` | `Scheduled Task Failed - {app_name}` | Includes task name and error |
| `breach_notification` | `Important Security Notice - {app_name}` | Compliance-aware, includes breach details, recommended actions |
| `breach_admin_alert` | `[{severity}] Security Breach Detected - {app_name}` | Immediate alert, includes detection details, action required |
| `test` | `Test Email - {app_name}` | Simple test message |

**Default Sender:**
- From Name: `{app_name}` (defaults to binary name if not set)
- From Address: `no-reply@{fqdn}` (defaults to `no-reply@localhost` if FQDN not set)
- Reply-To: `{admin_email}` (if set, otherwise omitted)

**Default Expiry Times:**
| Link Type | Default Expiry | Configurable? |
|-----------|----------------|---------------|
| Password reset | 24 hours | Yes |
| Email verification | 48 hours | Yes |
| Account recovery | 1 hour | Yes |
| Setup token | 24 hours | No (security) |

**MFA Reminder Schedule:**
| Recipient | First Reminder | Repeat | Stop When |
|-----------|----------------|--------|-----------|
| Server admin | 7 days after first login | Every 6 months | MFA enabled or dismissed permanently |
| Regular user | 7 days after registration | Every 6 months | MFA enabled or dismissed permanently |

- Reminders shown in-app (dismissable banner) - always works
- Email reminders only sent if SMTP is working (check `server.notifications.email.enabled`)
- User/admin can permanently dismiss reminders in settings
- Never more than one reminder per 6-month period
- Include one-click "Set up now" and "Don't remind me" links

**SMTP Check for Email Reminders:**
```go
// Check if email reminders can be sent
func canSendEmailReminder() bool {
    cfg := config.Get()
    return cfg.Server.Notifications.Email.Enabled &&
           cfg.Server.Notifications.Email.SMTP.Host != ""
}
```

## Template Format

Templates use simple `{variable}` syntax:

```
Subject: Your {app_name} backup completed
---
Hello,

Your backup completed successfully.

Filename: {filename}
Size: {size}
Time: {timestamp}

--
{app_name}
{app_url}
```

**Format Rules:**
- First line: `Subject: ...`
- Separator: `---` (three dashes on own line)
- Body: Plain text with variables
- Variables: `{variable_name}` syntax

## Global Variables (Available in All Templates)

| Variable | Description |
|----------|-------------|
| `{app_name}` | Application name/title |
| `{app_url}` | Application URL (full FQDN, e.g., `https://api.example.com`) |
| `{fqdn}` | Server FQDN only (e.g., `api.example.com`) |
| `{onion_url}` | Tor .onion URL (if enabled) |
| `{admin_email}` | Admin email address |
| `{recipient_email}` | Email address this message is being sent to |
| `{recipient_username}` | Username of the account (if applicable) |
| `{timestamp}` | Current date/time |
| `{year}` | Current year |

## Account Email Requirements (NON-NEGOTIABLE)

**ALL account-related emails MUST include:**

| Requirement | Description |
|-------------|-------------|
| **Why sent** | Clear explanation of why this email was sent |
| **Who it's for** | The recipient email address (visible in body) |
| **App identity** | App name AND full FQDN |
| **Visible link** | Plaintext URL (not just a button) - users can copy/paste |
| **Disclaimer** | "If you did not request this, ignore this message" (where applicable) |
| **No action if unsolicited** | Never include links that delete/modify without prior auth |

**Account-related emails include:**
- Welcome (user registration)
- Password reset
- Email verification
- Login alerts
- Security alerts
- 2FA changes
- Account recovery

### Example: User Welcome Email (Required Format)

```
Subject: Welcome to {app_name}
---
WELCOME TO {APP_NAME}

This email was sent to: {recipient_email}
From: {app_name} ({fqdn})

Hello {recipient_username},

Welcome to {app_name}! Your account has been created successfully.

To get started, log in at:

{login_url}

You can manage your profile and settings at:

{profile_url}

────────────────────────────────────────────────────────────────────────
GETTING STARTED

- Complete your profile
- Enable two-factor authentication for added security
- Explore the features available to you

If you have any questions, contact us at {admin_email}.
────────────────────────────────────────────────────────────────────────

--
{app_name}
{app_url}
```

### Example: Admin Welcome Email (Required Format)

```
Subject: Welcome to {app_name} - Admin Setup Complete
---
ADMIN SETUP COMPLETE

This email was sent to: {recipient_email}
From: {app_name} ({fqdn})

Congratulations! Your {app_name} instance is now configured.

Admin Panel: {admin_url}
Username: {admin_username}

────────────────────────────────────────────────────────────────────────
IMPORTANT NEXT STEPS

1. Log in to the admin panel and review your settings
2. Configure SMTP for email notifications
3. Enable SSL/TLS for secure connections
4. Set up regular backups
5. Enable two-factor authentication

Keep your admin credentials secure. If you lose access, use:
  casspeed --maintenance setup
────────────────────────────────────────────────────────────────────────

--
{app_name}
{app_url}
```

### Example: Password Reset Email (Required Format)

```
Subject: Password Reset Request - {app_name}
---
PASSWORD RESET REQUEST

This email was sent to: {recipient_email}
From: {app_name} ({fqdn})
Requested at: {timestamp}
Request IP: {ip}

Someone requested a password reset for the account associated with this
email address on {app_name} ({fqdn}).

To reset your password, visit the following link:

{reset_link}

This link expires in {expires}.

────────────────────────────────────────────────────────────────────────
⚠️  DID NOT REQUEST THIS?

If you did not request a password reset, you can safely ignore this email.
Your password will not be changed unless you click the link above.

No action is required on your part.
────────────────────────────────────────────────────────────────────────

--
{app_name}
{app_url}
```

### Example: Email Verification (Required Format)

```
Subject: Verify Your Email - {app_name}
---
EMAIL VERIFICATION

This email was sent to: {recipient_email}
From: {app_name} ({fqdn})
Sent at: {timestamp}

You (or someone) requested to add this email address to an account on
{app_name} ({fqdn}).

To verify this email address, visit the following link:

{verify_link}

This link expires in {expires}.

────────────────────────────────────────────────────────────────────────
⚠️  DID NOT REQUEST THIS?

If you did not request to add this email to an account, you can safely
ignore this email. No account will be created or linked.

No action is required on your part.
────────────────────────────────────────────────────────────────────────

--
{app_name}
{app_url}
```

### Example: Login Alert (Required Format)

```
Subject: New Login Detected - {app_name}
---
NEW LOGIN DETECTED

This alert was sent to: {recipient_email}
Account: {recipient_username}
From: {app_name} ({fqdn})

A new login was detected on your account:

  Time:     {time}
  IP:       {ip}
  Location: {location}
  Device:   {device}

If this was you, no action is required.

────────────────────────────────────────────────────────────────────────
⚠️  NOT YOU?

If you did not log in, your account may be compromised. Take action:

1. Change your password immediately:
   {app_url}/auth/password/forgot

2. Review your active sessions:
   {app_url}/settings/sessions

3. Enable 2FA if not already enabled:
   {app_url}/settings/security
────────────────────────────────────────────────────────────────────────

--
{app_name}
{app_url}
```

### Example: Security Alert (Required Format)

```
Subject: Security Alert - {app_name}
---
SECURITY ALERT

This alert was sent to: {recipient_email}
Account: {recipient_username}
From: {app_name} ({fqdn})
Time: {timestamp}

{event}

Details:
  Source IP: {ip}
  {details}

────────────────────────────────────────────────────────────────────────
⚠️  RECOMMENDED ACTIONS

If this activity was not you:

1. Change your password immediately:
   {app_url}/auth/password/forgot

2. Review account activity:
   {app_url}/settings/security

3. Contact support if needed:
   {admin_email}
────────────────────────────────────────────────────────────────────────

--
{app_name}
{app_url}
```

### Example: 2FA Disabled Alert (Required Format)

```
Subject: Two-Factor Authentication Disabled - {app_name}
---
2FA DISABLED

This alert was sent to: {recipient_email}
Account: {recipient_username}
From: {app_name} ({fqdn})
Time: {timestamp}

Two-factor authentication has been disabled on your account.

Method used: {method}
  (password, recovery key, or admin action)

────────────────────────────────────────────────────────────────────────
⚠️  DID NOT DO THIS?

If you did not disable 2FA, your account may be compromised:

1. Change your password immediately:
   {app_url}/auth/password/forgot

2. Re-enable 2FA:
   {app_url}/settings/security

3. Contact support:
   {admin_email}
────────────────────────────────────────────────────────────────────────

--
{app_name}
{app_url}
```

### Example: Password Changed Alert (Required Format)

```
Subject: Your Password Was Changed - {app_name}
---
PASSWORD CHANGED

This alert was sent to: {recipient_email}
Account: {recipient_username}
From: {app_name} ({fqdn})
Time: {timestamp}

The password for your account was successfully changed.

Method: {method}
IP Address: {ip}

If you made this change, no action is required.

────────────────────────────────────────────────────────────────────────
⚠️  DID NOT CHANGE YOUR PASSWORD?

If you did not change your password, your account may be compromised:

1. Reset your password immediately:
   {app_url}/auth/password/forgot

2. Review your account security:
   {app_url}/settings/security

3. Contact support:
   {admin_email}
────────────────────────────────────────────────────────────────────────

--
{app_name}
{app_url}
```

### Example: Breach Notification (Required Format)

```
Subject: Important Security Notice - {app_name}
---
IMPORTANT SECURITY NOTICE

This notice was sent to: {recipient_email}
Account: {recipient_username}
From: {app_name} ({fqdn})
Date: {timestamp}
Reference: {breach_id}

We are writing to inform you of a security incident that may have affected
your account on {app_name}.

────────────────────────────────────────────────────────────────────────
WHAT HAPPENED

{breach_summary}

Date discovered: {breach_date}
Incident type: {breach_type}
────────────────────────────────────────────────────────────────────────

────────────────────────────────────────────────────────────────────────
WHAT INFORMATION WAS INVOLVED

The following categories of data may have been affected:

{affected_data}
────────────────────────────────────────────────────────────────────────

────────────────────────────────────────────────────────────────────────
WHAT WE ARE DOING

We take the security of your information seriously. Upon discovering this
incident, we immediately:

- Secured affected systems and contained the incident
- Launched a comprehensive investigation
- Notified relevant authorities as required by law
- Enhanced our security measures to prevent future incidents

{notification_deadline}
────────────────────────────────────────────────────────────────────────

────────────────────────────────────────────────────────────────────────
WHAT YOU SHOULD DO

We recommend you take the following steps to protect your account:

{recommended_actions}

1. Change your password immediately:
   {app_url}/auth/password/forgot

2. Review your account activity:
   {app_url}/user/security

3. Enable two-factor authentication if not already enabled:
   {app_url}/user/security/2fa

4. Monitor your accounts for any suspicious activity
────────────────────────────────────────────────────────────────────────

────────────────────────────────────────────────────────────────────────
CONTACT INFORMATION

If you have questions or need assistance:

Email: {contact_email}
{contact_phone}
{dpo_contact}

Reference this ID in all communications: {breach_id}
────────────────────────────────────────────────────────────────────────

{regulatory_notice}

We sincerely apologize for any concern or inconvenience this may cause.
We remain committed to protecting your information and will continue to
take steps to enhance our security measures.

--
{app_name}
{app_url}
```

**Compliance-Specific Regulatory Notices:**

The `{regulatory_notice}` variable is automatically populated based on enabled compliance standards:

| Compliance | Regulatory Notice Content |
|------------|---------------------------|
| GDPR | "This notification is provided in accordance with Article 34 of the General Data Protection Regulation (GDPR). You have the right to lodge a complaint with your local data protection authority." |
| HIPAA | "This notification is provided in accordance with the HIPAA Breach Notification Rule (45 CFR §§ 164.400-414). For questions about your health information rights, contact the HHS Office for Civil Rights." |
| CCPA | "Under the California Consumer Privacy Act, you have the right to know what personal information was collected and to request deletion. Visit our privacy page for more information." |
| LGPD | "Esta notificação é fornecida de acordo com a Lei Geral de Proteção de Dados (LGPD). Você tem o direito de apresentar reclamação à ANPD (Autoridade Nacional de Proteção de Dados)." |
| PIPEDA | "This notification is provided in accordance with Canada's Personal Information Protection and Electronic Documents Act (PIPEDA). You may contact the Office of the Privacy Commissioner of Canada." |
| APPI | "This notification is provided in accordance with Japan's Act on the Protection of Personal Information. You may contact the Personal Information Protection Commission." |
| PDPA | "This notification is provided in accordance with Singapore's Personal Data Protection Act. You may contact the Personal Data Protection Commission." |

**When Multiple Standards Apply:** All applicable regulatory notices are included, with the most restrictive notification timeline met.

### Example: Breach Admin Alert (Required Format)

```
Subject: [{severity}] Security Breach Detected - {app_name}
---
🚨 SECURITY BREACH DETECTED

Server: {app_name} ({fqdn})
Time: {timestamp}
Breach ID: {breach_id}

────────────────────────────────────────────────────────────────────────
SEVERITY: {severity}
TYPE: {breach_type}
DETECTION: {detection_method}
────────────────────────────────────────────────────────────────────────

SUMMARY:
{breach_summary}

────────────────────────────────────────────────────────────────────────
DETAILS

Detection trigger: {trigger}
Source IP: {source_ip}
Affected scope: {affected_scope}
Estimated affected users: {affected_users}
Affected data categories: {affected_data}
────────────────────────────────────────────────────────────────────────

────────────────────────────────────────────────────────────────────────
AUTO-ACTIONS TAKEN

{auto_actions}
────────────────────────────────────────────────────────────────────────

────────────────────────────────────────────────────────────────────────
COMPLIANCE REQUIREMENTS

{compliance_requirements}

Notification deadline: {notify_deadline}
────────────────────────────────────────────────────────────────────────

────────────────────────────────────────────────────────────────────────
IMMEDIATE ACTION REQUIRED

1. Review breach details:
   {admin_url}/compliance/breaches/{breach_id}

2. Start investigation (if not auto-started):
   {admin_url}/compliance/breaches/{breach_id}/investigate

3. Assess containment status

4. Prepare user notifications if required
────────────────────────────────────────────────────────────────────────

This is an automated security alert from {app_name}.
Do not reply to this email.

--
{app_name} Security System
{app_url}
```

## Template-Specific Variables

**Note:** Account-related templates (marked ✓ above) also have access to `{recipient_email}`, `{recipient_username}`, and `{fqdn}` from global variables.

### welcome

**Two variants:** Admin welcome (first setup) and User welcome (registration).

**Admin Welcome Variables:**
| Variable | Description |
|----------|-------------|
| `{admin_url}` | Admin panel URL |
| `{admin_username}` | Initial admin username |

**User Welcome Variables:**
| Variable | Description |
|----------|-------------|
| `{recipient_username}` | New user's username |
| `{recipient_email}` | New user's email address |
| `{login_url}` | Login page URL |
| `{profile_url}` | User profile URL |

**When Sent:**
| Scenario | Template Used | Recipient |
|----------|---------------|-----------|
| First admin setup | Admin welcome | Server admin email |
| User registration (if enabled) | User welcome | New user's email |
| Admin creates user | User welcome | New user's email |
| User invited via invite code | User welcome | Invited user's email |

### password_reset
| Variable | Description |
|----------|-------------|
| `{reset_link}` | Password reset URL (full URL, visible in email) |
| `{expires}` | Link expiration time (e.g., "24 hours") |
| `{ip}` | Requesting IP address |

### email_verify
| Variable | Description |
|----------|-------------|
| `{verify_link}` | Email verification URL (full URL, visible in email) |
| `{expires}` | Link expiration time |

### login_alert
| Variable | Description |
|----------|-------------|
| `{ip}` | Login IP address |
| `{location}` | GeoIP location (if available) |
| `{device}` | User agent / device info |
| `{time}` | Login time |

### security_alert
| Variable | Description |
|----------|-------------|
| `{event}` | Security event type |
| `{ip}` | Source IP address |
| `{details}` | Event details |

### 2fa_enabled
| Variable | Description |
|----------|-------------|
| `{method}` | 2FA method enabled (TOTP, WebAuthn, etc.) |
| `{ip}` | IP address where 2FA was enabled |

### 2fa_disabled
| Variable | Description |
|----------|-------------|
| `{method}` | How 2FA was disabled (password, recovery key, admin) |
| `{ip}` | IP address where 2FA was disabled |

### password_changed
| Variable | Description |
|----------|-------------|
| `{ip}` | IP address where password was changed |
| `{method}` | How changed (direct, reset link, admin reset) |

### backup_complete / backup_failed
| Variable | Description |
|----------|-------------|
| `{filename}` | Backup filename |
| `{size}` | Backup file size |
| `{error}` | Error message (failed only) |

### ssl_expiring / ssl_renewed
| Variable | Description |
|----------|-------------|
| `{fqdn}` | Domain name on certificate |
| `{expires_in}` | Days until expiration |
| `{expiry_date}` | Expiration date |
| `{valid_until}` | New validity date (renewed only) |

### scheduler_error
| Variable | Description |
|----------|-------------|
| `{task_name}` | Failed task name |
| `{error}` | Error message |
| `{next_run}` | Next scheduled run |

### breach_notification

**Compliance-Aware Template:** This template automatically adjusts content based on enabled compliance standards.

| Variable | Description |
|----------|-------------|
| `{breach_id}` | Unique breach identifier for reference |
| `{breach_date}` | Date/time breach was discovered |
| `{breach_type}` | Type of breach (unauthorized access, data exposure, etc.) |
| `{affected_data}` | Categories of data potentially affected |
| `{breach_summary}` | Brief description of what happened |
| `{recommended_actions}` | List of recommended user actions |
| `{contact_email}` | Contact email for breach inquiries |
| `{contact_phone}` | Contact phone (if configured) |
| `{dpo_contact}` | Data Protection Officer contact (GDPR/LGPD) |
| `{regulatory_notice}` | Compliance-specific regulatory text (auto-generated) |
| `{notification_deadline}` | Compliance deadline met (e.g., "within 72 hours") |

### breach_admin_alert

**Sent to all server admins immediately when a breach is detected (automated or manual).**

| Variable | Description |
|----------|-------------|
| `{breach_id}` | Unique breach identifier |
| `{severity}` | Severity level (CRITICAL, HIGH, MEDIUM, LOW) |
| `{breach_type}` | Type of breach |
| `{breach_summary}` | Brief description |
| `{detection_method}` | How detected (automated/manual/external) |
| `{trigger}` | Specific detection trigger (e.g., "brute_force", "anomaly") |
| `{source_ip}` | Source IP address (if applicable) |
| `{affected_scope}` | Scope description (single user, multiple users, system-wide) |
| `{affected_users}` | Estimated number of affected users |
| `{affected_data}` | Data categories potentially affected |
| `{auto_actions}` | List of automated actions taken |
| `{compliance_requirements}` | Applicable compliance standards and their requirements |
| `{notify_deadline}` | Deadline for user notification (based on strictest standard) |
| `{admin_url}` | Admin panel URL |

## Admin Panel (/admin/server/email/templates)

| Element | Type | Description |
|---------|------|-------------|
| Template list | Table | All templates with status (default/custom) |
| Edit button | Button | Open template editor |
| Subject field | Text input | Editable subject line |
| Body editor | Textarea | Template body with syntax highlighting |
| Variable reference | Sidebar | Available variables for selected template |
| Preview button | Button | Render template with sample data |
| Send Test | Button | Send test email to specific address |
| Save button | Button | Save custom template |
| Reset to default | Button | Delete custom, restore embedded (confirmation required) |

**Editor Features:**
- Syntax highlighting for `{variables}`
- Variable autocomplete
- Live preview with sample data
- Validation (warn if unknown variables used)

### Template Preview

**Live preview renders the template with sample data as you edit.**

```
Email Template Editor (/admin/server/email/templates/password_reset)
┌─────────────────────────────────────────────────────────────┐
│  Template: password_reset                    [Default] [Custom]│
├─────────────────────────────────────────────────────────────┤
│                                                             │
│  Subject:                                                   │
│  ┌─────────────────────────────────────────────────────┐    │
│  │ Password Reset Request - {app_name}                 │    │
│  └─────────────────────────────────────────────────────┘    │
│                                                             │
│  Body:                              │  Available Variables: │
│  ┌────────────────────────────────┐ │  {app_name}           │
│  │ PASSWORD RESET REQUEST         │ │  {app_url}            │
│  │                                │ │  {fqdn}               │
│  │ This email was sent to:        │ │  {recipient_email}    │
│  │ {recipient_email}              │ │  {recipient_username} │
│  │ From: {app_name} ({fqdn})      │ │  {reset_link}         │
│  │                                │ │  {expires}            │
│  │ To reset your password:        │ │  {ip}                 │
│  │ {reset_link}                   │ │  {timestamp}          │
│  │                                │ │                       │
│  └────────────────────────────────┘ │  Click to insert ↑    │
│                                                             │
│  ─────────────────────────────────────────────────────────  │
│                                                             │
│  📧 Preview (with sample data):                              │
│  ┌─────────────────────────────────────────────────────┐    │
│  │ Subject: Password Reset Request - My App            │    │
│  │ ─────────────────────────────────────────────────── │    │
│  │ PASSWORD RESET REQUEST                              │    │
│  │                                                     │    │
│  │ This email was sent to: user@example.com            │    │
│  │ From: My App (app.example.com)                      │    │
│  │                                                     │    │
│  │ To reset your password:                             │    │
│  │ https://app.example.com/auth/reset/abc123...        │    │
│  └─────────────────────────────────────────────────────┘    │
│                                                             │
│  [Send Test Email]  [Reset to Default]  [Save]              │
└─────────────────────────────────────────────────────────────┘
```

**Sample Data for Preview:**
| Variable | Sample Value |
|----------|--------------|
| `{app_name}` | Current app name from config |
| `{app_url}` | Current app URL |
| `{fqdn}` | Current FQDN |
| `{recipient_email}` | `user@example.com` |
| `{recipient_username}` | `sampleuser` |
| `{reset_link}` | `https://{fqdn}/auth/reset/sample123...` |
| `{verify_link}` | `https://{fqdn}/auth/verify/sample123...` |
| `{expires}` | `24 hours` |
| `{ip}` | `192.168.1.100` |
| `{timestamp}` | Current timestamp |
| `{admin_email}` | Admin email from config |

### Send Test Email

**Send a test email to verify the template renders correctly.**

```
Send Test Email Dialog
┌─────────────────────────────────────────────────────────────┐
│  Send Test Email                                            │
├─────────────────────────────────────────────────────────────┤
│                                                             │
│  Template: password_reset                                   │
│                                                             │
│  Send to: [admin@example.com              ]                 │
│           (defaults to your admin email)                    │
│                                                             │
│  ⚠️ This will send a real email using current SMTP settings. │
│  The email will contain sample data, not real user data.    │
│                                                             │
│  [Cancel]  [Send Test]                                      │
└─────────────────────────────────────────────────────────────┘
```

**Test Email Rules:**
- Requires valid SMTP configuration
- Defaults to current admin's email address
- Can specify any email address
- Uses sample data (not real user data)
- Subject prefixed with `[TEST]` to identify test emails
- Test sends logged to audit log

**After Sending:**
```
┌─────────────────────────────────────────────────────────────┐
│  ✅ Test Email Sent                                          │
├─────────────────────────────────────────────────────────────┤
│                                                             │
│  Sent to: admin@example.com                                 │
│  Template: password_reset                                   │
│  Subject: [TEST] Password Reset Request - My App            │
│                                                             │
│  Check your inbox to verify the email looks correct.        │
│                                                             │
│  [Close]                                                    │
└─────────────────────────────────────────────────────────────┘
```

### Template Validation

**Templates are validated before saving:**

| Check | Error Message |
|-------|---------------|
| Unknown variable | `Unknown variable: {foo}. Did you mean {fqdn}?` |
| Missing required variable | `Account emails must include {recipient_email}` |
| Empty subject | `Subject cannot be empty` |
| Empty body | `Body cannot be empty` |
| Invalid syntax | `Invalid template syntax at line 5` |

**Warnings (non-blocking):**
- Using deprecated variables
- Very long subject line (>78 chars)
- Missing recommended sections (e.g., disclaimer for account emails)

## Notification Systems (NON-NEGOTIABLE)

**Two notification systems available. WebUI is always available. Email requires SMTP.**

| System | Availability | Use When |
|--------|--------------|----------|
| **WebUI (Toast/Banner)** | Always available | User is actively using the app |
| **Email** | Requires valid SMTP | User is away, needs permanent record, critical alerts |

## WebUI Notification System

**The WebUI has a built-in notification system for both server admins and users. This is ALWAYS available regardless of SMTP configuration.**

### How It Works

| Component | Description |
|-----------|-------------|
| **Toast** | Pop-up notifications in corner of screen |
| **Banner** | Persistent bar at top of page |
| **Notification Center** | Bell icon with history of notifications |
| **Badge Count** | Unread notification count on bell icon |

### Notification Center

**Both server admins and users have a notification center accessible via bell icon in the header.**

```
┌─────────────────────────────────────────────────────────────┐
│  Header                                    🔔 (3)  [User]   │
└─────────────────────────────────────────────────────────────┘
                                               │
                                               ▼
                              ┌────────────────────────────────┐
                              │  Notifications                 │
                              ├────────────────────────────────┤
                              │  🔴 SSL certificate expiring   │
                              │     in 3 days                  │
                              │     2 hours ago                │
                              ├────────────────────────────────┤
                              │  ✅ Backup completed           │
                              │     backup_2025-01-15.tar.gz   │
                              │     5 hours ago                │
                              ├────────────────────────────────┤
                              │  ⚠️ Login from new location    │
                              │     192.168.1.100 (New York)   │
                              │     Yesterday                  │
                              ├────────────────────────────────┤
                              │  [Mark all read]  [Clear all]  │
                              └────────────────────────────────┘
```

### WebUI Notification Types

| Type | Icon | Use For | Auto-dismiss |
|------|------|---------|--------------|
| `success` | ✅ | Completed actions, confirmations | 5 seconds |
| `info` | ℹ️ | Informational, status updates | 5 seconds |
| `warning` | ⚠️ | Non-critical issues, expiring items | 10 seconds |
| `error` | ❌ | Failures, critical issues | Manual dismiss |
| `security` | 🔒 | Security-related alerts | Manual dismiss |

### Toast vs Banner vs Notification Center

| Element | Use For | Behavior |
|---------|---------|----------|
| **Toast** | Immediate feedback for user actions | Auto-dismiss, stacks in corner |
| **Banner** | Persistent alerts requiring attention | Stays until dismissed or resolved |
| **Notification Center** | History of all notifications | Persists across sessions, stored in DB |

**When to Use Each:**

| Scenario | Toast | Banner | Center |
|----------|:-----:|:------:|:------:|
| Settings saved | ✓ | | |
| Form validation error | ✓ | | |
| Backup complete | ✓ | | ✓ |
| SSL expiring soon | | ✓ | ✓ |
| Update available | | ✓ | ✓ |
| Login from new IP | ✓ | | ✓ |
| Password changed | ✓ | | ✓ |
| SMTP not configured | | ✓ | |
| Scheduler task failed | ✓ | | ✓ |

## Server Admin Notifications

**Notifications shown to server admins in `/admin/*` routes.**

| Event | Toast | Banner | Center | Description |
|-------|:-----:|:------:|:------:|-------------|
| Settings saved | ✓ | | | Confirmation of config save |
| Config validation error | ✓ | | | Invalid config value |
| Backup started | ✓ | | | Backup in progress |
| Backup complete | ✓ | | ✓ | Backup finished |
| Backup failed | ✓ | | ✓ | Backup error |
| SSL expiring (7+ days) | | | ✓ | Warning in center only |
| SSL expiring (<3 days) | | ✓ | ✓ | Urgent banner |
| SSL renewed | ✓ | | ✓ | Certificate renewed |
| SSL renewal failed | ✓ | ✓ | ✓ | Critical - needs attention |
| Update available | | ✓ | ✓ | New version available |
| Scheduler task failed | ✓ | | ✓ | Task error |
| New admin login | | | ✓ | Another admin logged in |
| SMTP not configured | | ✓ | | Persistent warning |
| Database connection issue | | ✓ | ✓ | Critical warning |
| Disk space low | | ✓ | ✓ | System warning |
| GeoIP database outdated | | | ✓ | Update needed |
| Tor address ready | ✓ | | | Onion address generated |

## User Notifications (Multi-User Mode)

**Notifications shown to regular users in `/user/*` routes.**

| Event | Toast | Banner | Center | Description |
|-------|:-----:|:------:|:------:|-------------|
| Profile updated | ✓ | | | Settings saved |
| Password changed | ✓ | | ✓ | Security confirmation |
| Email verified | ✓ | | ✓ | Verification complete |
| 2FA enabled | ✓ | | ✓ | Security confirmation |
| 2FA disabled | ✓ | | ✓ | Security warning |
| Login from new IP | | | ✓ | Security notice |
| Login from new device | | | ✓ | Security notice |
| Session expired | ✓ | | | Re-login required |
| API token created | ✓ | | ✓ | Token generated |
| API token revoked | ✓ | | ✓ | Token deleted |
| Account suspended | | ✓ | | Admin action notice |
| Password reset required | | ✓ | | Admin-initiated reset |
| Recovery keys running low | | | ✓ | Only 1-2 keys left |

## Notification vs Email Decision Matrix

**WebUI notifications are ALWAYS used when the user is active. Email is ONLY used when:**
1. SMTP is configured AND working
2. The event warrants a permanent record OR
3. The user may be away and needs to be alerted

| Event | WebUI | Email | Reason |
|-------|:-----:|:-----:|--------|
| Settings saved | ✓ | ✗ | Immediate feedback only |
| Backup complete | ✓ | Optional | Quick confirmation |
| Backup failed | ✓ | ✓ | Critical - needs attention |
| SSL expiring (7+ days) | ✓ | ✗ | Warning, not urgent |
| SSL expiring (<3 days) | ✓ | ✓ | Urgent - needs action |
| SSL renewed | ✓ | ✗ | Informational |
| Login from new IP | ✓ | ✓ | Security - permanent record |
| Security alert | ✓ | ✓ | Critical - needs record |
| Scheduler task failed | ✓ | ✓ | Needs attention when away |
| Scheduler task success | ✗ | ✗ | No notification needed |
| Password changed | ✓ | ✓ | Security - confirmation |
| Token regenerated | ✓ | ✓ | Security - confirmation |
| 2FA enabled/disabled | ✓ | ✓ | Security - confirmation |
| Tor address regenerated | ✓ | ✗ | User initiated |
| Update available | ✓ | Optional | Informational |
| Update installed | ✓ | ✓ | Important change record |
| Welcome (new user) | ✓ | ✓ | Onboarding |
| Email verification | ✗ | ✓ | Requires email link |
| Password reset | ✗ | ✓ | Requires email link |

### Decision Logic

```
1. Is user actively using the app?
   → Always show WebUI notification (toast/center)

2. Is SMTP configured?
   → No: WebUI only, no email attempt
   → Yes: Continue to step 3

3. Is it critical (failure, security, urgent)?
   → Send email

4. Does user need a record when away?
   → Send email

5. Is it just confirmation of user action?
   → WebUI only (no email)

6. Is it routine success?
   → No notification needed
```

## Notification Storage

**WebUI notifications are stored in the database for persistence.**

| Storage | Server Admin | Regular User |
|---------|--------------|--------------|
| Table | `admin_notifications` | `user_notifications` |
| Retention | 30 days (configurable) | 30 days (configurable) |
| Max stored | 100 per admin | 100 per user |
| Sync | Real-time via WebSocket | Real-time via WebSocket |

**Notification Record:**
```json
{
  "id": "notif_01HQXYZ",
  "type": "warning",
  "title": "SSL Certificate Expiring",
  "message": "Certificate expires in 3 days",
  "link": "/admin/server/ssl",
  "read": false,
  "created_at": "2025-01-15T10:30:00Z"
}
```

## Sane Defaults

| Setting | Default | Description |
|---------|---------|-------------|
| Toast position | `top-right` | Corner for toast notifications |
| Toast duration | `5` seconds | Auto-dismiss time (0 = manual) |
| Error dismiss | `manual` | Errors require manual dismiss |
| Notification retention | `30` days | How long to keep in center |
| Max notifications | `100` | Per user/admin limit |
| Real-time updates | `enabled` | WebSocket for instant updates |

## Notification Preferences

**Both server admins and users can configure their notification preferences.**

### Admin Notification Preferences (`/admin/profile/notifications`)

| Category | Events | Default | Can Disable? |
|----------|--------|---------|--------------|
| **Security** | Login alerts, 2FA changes, password changes | All ON | No (required) |
| **Server** | SSL expiring, updates available, disk space | All ON | Yes |
| **Backup** | Backup complete, backup failed | Failed ON, Complete OFF | Yes |
| **Scheduler** | Task failed, task manual run | Failed ON | Yes |
| **Other Admins** | Admin login/logout | ON | Yes |

**Security notifications cannot be disabled** - these are critical for account security.

```
Admin Notification Preferences (/admin/profile/notifications)
┌─────────────────────────────────────────────────────────────┐
│  Notification Preferences                                   │
├─────────────────────────────────────────────────────────────┤
│                                                             │
│  🔒 Security (cannot be disabled)                           │
│     ☑ Login from new IP/device                              │
│     ☑ Password changed                                      │
│     ☑ 2FA enabled/disabled                                  │
│     ☑ API token regenerated                                 │
│                                                             │
│  ⚙️ Server                                          WebUI Email│
│     SSL certificate expiring                        [✓]  [✓] │
│     SSL certificate renewed                         [✓]  [ ] │
│     Update available                                [✓]  [ ] │
│     Disk space low                                  [✓]  [✓] │
│                                                             │
│  💾 Backup                                                   │
│     Backup completed                                [✓]  [ ] │
│     Backup failed                                   [✓]  [✓] │
│                                                             │
│  📅 Scheduler                                                │
│     Task failed                                     [✓]  [✓] │
│     Task manually triggered                         [✓]  [ ] │
│                                                             │
│  👥 Other Admins                                             │
│     Admin logged in                                 [✓]  [ ] │
│     Admin logged out                                [ ]  [ ] │
│                                                             │
│  [Save Preferences]                                         │
└─────────────────────────────────────────────────────────────┘
```

### User Notification Preferences (`/user/settings/notifications`)

| Category | Events | Default | Can Disable? |
|----------|--------|---------|--------------|
| **Security** | Login alerts, password changes, 2FA changes | All ON | No (required) |
| **Account** | Email verified, profile updated | All ON | Yes |
| **Sessions** | Session expired, new device | All ON | Partial |

```
User Notification Preferences (/user/settings/notifications)
┌─────────────────────────────────────────────────────────────┐
│  Notification Preferences                                   │
├─────────────────────────────────────────────────────────────┤
│                                                             │
│  🔒 Security (cannot be disabled)                           │
│     ☑ Login from new IP/device                              │
│     ☑ Password changed                                      │
│     ☑ 2FA enabled/disabled                                  │
│     ☑ Recovery key used                                     │
│                                                             │
│  👤 Account                                         WebUI Email│
│     Email verified                                  [✓]  [✓] │
│     Profile updated                                 [✓]  [ ] │
│                                                             │
│  🔑 Sessions                                                 │
│     Session expired                                 [✓]  [ ] │
│     Logged in from new device                       [✓]  [✓] │
│                                                             │
│  [Save Preferences]                                         │
└─────────────────────────────────────────────────────────────┘
```

### Preference Storage

| User Type | Storage | Key |
|-----------|---------|-----|
| Server Admin | `admin_preferences` table | `admin_id` |
| Regular User | `user_preferences` table | `user_id` |

**Preference Schema:**
```json
{
  "notifications": {
    "webui": {
      "backup_complete": true,
      "backup_failed": true,
      "ssl_expiring": true,
      "admin_login": true
    },
    "email": {
      "backup_complete": false,
      "backup_failed": true,
      "ssl_expiring": true,
      "admin_login": false
    }
  }
}
```

## Configuration

```yaml
server:
  notifications:
    # WebUI notifications (always enabled)
    webui:
      position: top-right
      # top-right, top-left, bottom-right, bottom-left
      duration: 5
      # seconds (0 = manual dismiss)

    # Email notifications
    # enabled is auto-set based on SMTP availability (no manual toggle)
    # All SMTP settings can be overridden via SMTP_* env vars
    email:
      smtp:
        # If empty: autodetect local SMTP on startup
        # If set: test connection on startup
        host: ""
        port: 587
        username: ""
        password: ""
        # TLS mode: auto, starttls, tls, none
        tls: auto
      from:
        # Default: app title
        name: ""
        # Default: no-reply@{fqdn}
        email: ""

      # Per-event email settings (override defaults)
      events:
        startup: false
        shutdown: false
        backup_complete: false
        backup_failed: true
        ssl_expiring: true
        ssl_renewed: false
        login_alert: true
        security_alert: true
        scheduler_error: true
        password_changed: true
        token_regenerated: true
        update_available: false
        update_installed: true
```

---


# PART 27: SCHEDULER (NON-NEGOTIABLE)

## Built-in Scheduler

**ALL projects MUST have a built-in scheduler that is ALWAYS RUNNING.**

### Core Requirements

| Requirement | Description |
|-------------|-------------|
| **Always Running** | Scheduler starts with application and runs until shutdown |
| **Persistent State** | Task state survives restarts (stored in server.db) |
| **Automatic Recovery** | Missed tasks run on startup if within catch-up window |
| **Cluster Aware** | Only one node runs each task in cluster mode |
| **No External Dependencies** | Built-in, no cron or external scheduler needed |

### Built-in Tasks (Required)

Every project MUST include these scheduled tasks:

| Task | Default Schedule | Purpose | Skippable |
|------|-----------------|---------|-----------|
| `ssl.renewal` | Daily at 03:00 | Renew `{config_dir}/ssl/letsencrypt/{fqdn}/` certs 7 days before expiry | No |
| `geoip.update` | Weekly (Sunday 03:00) | Download/update MaxMind GeoLite2 databases | Yes |
| `blocklist.update` | Daily at 04:00 | Download/update IP/domain blocklists | Yes |
| `cve.update` | Daily at 05:00 | Download/update CVE/security databases | Yes |
| `session.cleanup` | Hourly | Remove expired sessions | No |
| `token.cleanup` | Daily at 06:00 | Remove expired tokens | No |
| `log.rotation` | Daily at 00:00 | Rotate and compress old logs | No |
| `backup.auto` | Disabled by default | Automatic backups | Yes |
| `healthcheck.self` | Every 5 minutes | Self-health verification | No |
| `tor.health` | Every 10 minutes | Check Tor connectivity, restart if needed | No (when Tor installed) |
| `cluster.heartbeat` | Every 30 seconds | Cluster node heartbeat (cluster mode only) | No |

### Task Configuration

```yaml
server:
  scheduler:
    # Scheduler is ALWAYS running - no enable/disable setting
    # Individual tasks can be enabled/disabled below

    # Timezone for scheduled tasks (default: America/New_York)
    timezone: America/New_York

    # Catch-up window: run missed tasks if within this duration
    catch_up_window: 1h

    # Built-in tasks (can adjust schedule, cannot disable critical tasks)
    tasks:
      # Daily at 03:00 (after backup at 02:00)
      ssl_renewal:
        schedule: "0 3 * * *"
        enabled: true

      # Weekly Sunday at 03:00
      geoip_update:
        schedule: "0 3 * * 0"
        enabled: true

      # Daily at 04:00
      blocklist_update:
        schedule: "0 4 * * *"
        enabled: true
        retry_on_fail: true
        retry_delay: 1h

      # Daily at 05:00
      cve_update:
        schedule: "0 5 * * *"
        enabled: true
        retry_on_fail: true
        retry_delay: 1h

      # Every hour
      session_cleanup:
        schedule: "@hourly"
        enabled: true

      # Daily at 06:00
      token_cleanup:
        schedule: "0 6 * * *"
        enabled: true

      # Daily at midnight
      log_rotation:
        schedule: "0 0 * * *"
        enabled: true
        # Delete logs older than 30 days
        max_age: 30d
        # Rotate when log exceeds 100MB
        max_size: 100MB
        compress: true

      # Daily at 01:00 (disabled by default)
      backup_auto:
        schedule: "0 1 * * *"
        enabled: false
        # Keep max 4 backups (storage management)
        keep_count: 4

      # Every 5 minutes
      healthcheck_self:
        schedule: "@every 5m"
        enabled: true

      # Every 10 minutes (only runs if Tor installed)
      tor_health:
        schedule: "@every 10m"
        enabled: true
        # Auto-restart if unhealthy
        restart_on_fail: true
```

### Schedule Format

| Format | Example | Description |
|--------|---------|-------------|
| Cron | `0 2 * * *` | Standard cron (minute hour day month weekday) |
| `@hourly` | `@hourly` | Every hour at minute 0 |
| `@daily` | `@daily` | Every day at 00:00 |
| `@weekly` | `@weekly` | Every Sunday at 00:00 |
| `@monthly` | `@monthly` | First day of month at 00:00 |
| `@every Xm` | `@every 5m` | Every X minutes |
| `@every Xh` | `@every 2h` | Every X hours |

### Scheduler State (Persistent)

Task state is stored in `server.db`:

| Column | Type | Description |
|--------|------|-------------|
| `task_id` | String | Unique task identifier |
| `task_name` | String | Human-readable name |
| `schedule` | String | Cron/interval expression |
| `last_run` | Timestamp | When task last completed |
| `last_status` | String | success, failed, skipped |
| `last_error` | String | Error message if failed |
| `next_run` | Timestamp | Scheduled next execution |
| `run_count` | Integer | Total successful runs |
| `fail_count` | Integer | Total failed runs |
| `enabled` | Boolean | Is task enabled |
| `locked_by` | String | Node ID holding lock (cluster mode) |
| `locked_at` | Timestamp | When lock was acquired |

### Startup Behavior

```
Application Start
       │
       ▼
Load scheduler state from database
       │
       ▼
Check for missed tasks (within catch_up_window)
       │
       ├─► Found missed tasks
       │   │
       │   ▼
       │   Queue missed tasks for immediate execution
       │   (in order of original scheduled time)
       │
       ▼
Start scheduler loop
       │
       ▼
Scheduler runs continuously until shutdown
```

### Cluster Mode Task Distribution

In cluster mode, tasks are distributed to prevent duplicate execution:

| Task Type | Execution |
|-----------|-----------|
| **Global Tasks** | Run on ONE node only (leader election) |
| **Local Tasks** | Run on EVERY node |

**Global Tasks (run once per cluster):**
- `ssl.renewal`
- `geoip.update`
- `blocklist.update`
- `backup.auto`

**Local Tasks (run on each node):**
- `session.cleanup`
- `token.cleanup`
- `healthcheck.self`
- `cluster.heartbeat`

### Task Locking (Cluster Mode)

```
Task Ready to Run
       │
       ▼
Attempt to acquire lock in database
       │
       ├─► Lock acquired
       │   │
       │   ▼
       │   Execute task
       │   │
       │   ▼
       │   Release lock, update last_run
       │
       └─► Lock held by another node
           │
           ▼
           Skip execution (other node handling it)
```

**Lock timeout:** 5 minutes (auto-release if node dies during task)

### Task Execution Flow

```
Task Triggered (scheduled or manual)
       │
       ▼
Check if enabled
       │
       ├─► Disabled: Skip
       │
       ▼
Acquire lock (cluster mode)
       │
       ├─► Lock failed: Skip (another node running)
       │
       ▼
Execute task
       │
       ├─► Success
       │   │
       │   ▼
       │   Update: last_run, last_status=success, run_count++
       │   Log to audit log
       │
       └─► Failure
           │
           ▼
           Update: last_status=failed, last_error, fail_count++
           Log to audit log
           Send notification (if configured)
           Schedule retry (if retryable)
```

### Retry Policy

| Setting | Default | Description |
|---------|---------|-------------|
| `max_retries` | 3 | Maximum retry attempts |
| `retry_delay` | 5m | Delay between retries |
| `backoff` | exponential | Delay multiplier (5m, 10m, 20m) |

### Admin Panel (/admin/server/scheduler)

| Section | Contents |
|---------|----------|
| **Task List** | All tasks with status, next run, last run |
| **Task Detail** | Full history, logs, configuration |
| **Run Now** | Button to trigger immediate execution |
| **Enable/Disable** | Toggle for non-critical tasks |
| **History** | Last 100 executions per task |

**Task List Columns:**

| Column | Description |
|--------|-------------|
| Task Name | Human-readable name |
| Status | ● running, ✓ success, ✗ failed, ○ pending |
| Last Run | Timestamp and duration |
| Next Run | Scheduled time |
| Actions | Run Now, View History |

### API Endpoints

| Endpoint | Method | Description |
|----------|--------|-------------|
| `/api/v1/admin/server/scheduler` | GET | List all tasks |
| `/api/v1/admin/server/scheduler/{id}` | GET | Get task details |
| `/api/v1/admin/server/scheduler/{id}` | PATCH | Update task settings |
| `/api/v1/admin/server/scheduler/{id}/run` | POST | Run task immediately |
| `/api/v1/admin/server/scheduler/{id}/enable` | POST | Enable task |
| `/api/v1/admin/server/scheduler/{id}/disable` | POST | Disable task |
| `/api/v1/admin/server/scheduler/{id}/history` | GET | Get execution history |

### Shutdown Behavior

```
Shutdown Signal Received
       │
       ▼
Stop accepting new task executions
       │
       ▼
Wait for running tasks to complete (max 30 seconds)
       │
       ├─► Tasks completed
       │   │
       │   ▼
       │   Release all locks
       │
       └─► Timeout
           │
           ▼
           Force release locks
           Mark interrupted tasks for retry on next start
       │
       ▼
Save scheduler state to database
       │
       ▼
Shutdown complete
```

### Implementation Requirements

1. **Use Go's time/ticker** - No external cron libraries required
2. **Database-backed state** - All state in server.db, survives restarts
3. **Graceful shutdown** - Complete running tasks, release locks
4. **Cluster-safe** - Distributed locking for global tasks
5. **Audit logging** - All task executions logged
6. **Notifications** - Failed tasks trigger notifications (if configured)

---


# PART 28: GEOIP (NON-NEGOTIABLE)

## Overview

**ALL projects MUST have built-in GeoIP support using sapics/ip-location-db.**

GeoIP databases are NEVER embedded - they are downloaded on first run and updated via scheduler.

## Configuration

```yaml
server:
  geoip:
    enabled: true

    # Directory for downloaded MMDB files
    dir: "{config_dir}/security/geoip"

    # Update schedule (handled by scheduler, see PART 26)
    # Default: weekly on Sunday 03:00

    # Block countries by ISO 3166-1 alpha-2 code
    deny_countries: []

    # Which databases to download and use
    # All use MMDB format, IPv4 and IPv6 support
    databases:
      # ASN lookup - AS number and organization name
      asn: true
      # Country lookup - country code (ISO 3166-1)
      country: true
      # City lookup - city, region, postal, coordinates, timezone
      city: true
      # WHOIS lookup - registrant info combined with ASN
      whois: true
```

## Database Sources (ip-location-db)

All databases from [sapics/ip-location-db](https://github.com/sapics/ip-location-db) - no API key required.

| Database | File | CDN URL |
|----------|------|---------|
| ASN | `asn.mmdb` | `https://cdn.jsdelivr.net/npm/@ip-location-db/asn-mmdb/asn.mmdb` |
| Country | `country.mmdb` | `https://cdn.jsdelivr.net/npm/@ip-location-db/geo-whois-asn-country-mmdb/geo-whois-asn-country.mmdb` |
| City | `city.mmdb` | `https://cdn.jsdelivr.net/npm/@ip-location-db/dbip-city-mmdb/dbip-city-ipv4.mmdb` |
| WHOIS | `whois.mmdb` | `https://cdn.jsdelivr.net/npm/@ip-location-db/geo-whois-asn-country-mmdb/geo-whois-asn-country.mmdb` |

**Database Contents:**

| Database | Fields Available |
|----------|------------------|
| ASN | `autonomous_system_number`, `autonomous_system_organization` |
| Country | `country_code` (ISO 3166-1 alpha-2) |
| City | `city`, `region`, `postal_code`, `latitude`, `longitude`, `timezone` |
| WHOIS | `registrant_org`, `asn`, `country_code` (combined lookup) |

## Admin Panel (/admin/server/network/geoip)

| Element | Type | Description |
|---------|------|-------------|
| Enable GeoIP | Toggle | Turn GeoIP on/off |
| Deny countries | Tag input | ISO 3166-1 alpha-2 codes to block |
| ASN database | Toggle | Enable ASN lookups |
| Country database | Toggle | Enable country lookups |
| City database | Toggle | Enable city lookups |
| WHOIS database | Toggle | Enable WHOIS lookups |
| Last update | Read-only | When databases were last updated |
| Update now | Button | Force immediate update |

---


# PART 29: METRICS (NON-NEGOTIABLE)

## Overview

**ALL projects MUST have built-in Prometheus-compatible metrics support for production monitoring.**

| Feature | Description |
|---------|-------------|
| Format | Prometheus text exposition format |
| Endpoint | `/metrics` (configurable) |
| Authentication | Optional bearer token |
| Library | `github.com/prometheus/client_golang` |

## Configuration

```yaml
server:
  metrics:
    enabled: true
    endpoint: /metrics

    # Include system metrics (CPU, memory, disk, goroutines)
    include_system: true

    # Include Go runtime metrics
    include_runtime: true

    # Optional Bearer token for authentication
    token: ""

    # Histogram buckets for request duration (seconds)
    duration_buckets: [0.001, 0.005, 0.01, 0.025, 0.05, 0.1, 0.25, 0.5, 1, 2.5, 5, 10]

    # Histogram buckets for request size (bytes)
    size_buckets: [100, 1000, 10000, 100000, 1000000, 10000000]
```

## Metrics Categories

| Category | Metrics | Description |
|----------|---------|-------------|
| **HTTP** | Requests, duration, size, status codes | Request-level metrics |
| **Database** | Queries, duration, connections, errors | Database performance |
| **Cache** | Hits, misses, evictions, size | Cache effectiveness |
| **Scheduler** | Tasks run, duration, failures | Background task health |
| **System** | CPU, memory, disk, goroutines | System resources |
| **Business** | Users, sessions, API calls | Application-specific |

## Metrics Implementation

### Core Metrics Package

```go
// src/server/metrics/metrics.go
package metrics

import (
    "github.com/prometheus/client_golang/prometheus"
    "github.com/prometheus/client_golang/prometheus/promauto"
)

var (
    // HTTP metrics
    HTTPRequestsTotal = promauto.NewCounterVec(
        prometheus.CounterOpts{
            Name: "casspeed_http_requests_total",
            Help: "Total number of HTTP requests",
        },
        []string{"method", "path", "status"},
    )

    HTTPRequestDuration = promauto.NewHistogramVec(
        prometheus.HistogramOpts{
            Name:    "casspeed_http_request_duration_seconds",
            Help:    "HTTP request duration in seconds",
            Buckets: []float64{0.001, 0.005, 0.01, 0.025, 0.05, 0.1, 0.25, 0.5, 1, 2.5, 5, 10},
        },
        []string{"method", "path"},
    )

    HTTPRequestSize = promauto.NewHistogramVec(
        prometheus.HistogramOpts{
            Name:    "casspeed_http_request_size_bytes",
            Help:    "HTTP request size in bytes",
            Buckets: []float64{100, 1000, 10000, 100000, 1000000, 10000000},
        },
        []string{"method", "path"},
    )

    HTTPResponseSize = promauto.NewHistogramVec(
        prometheus.HistogramOpts{
            Name:    "casspeed_http_response_size_bytes",
            Help:    "HTTP response size in bytes",
            Buckets: []float64{100, 1000, 10000, 100000, 1000000, 10000000},
        },
        []string{"method", "path"},
    )

    HTTPActiveRequests = promauto.NewGauge(
        prometheus.GaugeOpts{
            Name: "casspeed_http_active_requests",
            Help: "Number of active HTTP requests",
        },
    )

    // Database metrics
    DBQueriesTotal = promauto.NewCounterVec(
        prometheus.CounterOpts{
            Name: "casspeed_db_queries_total",
            Help: "Total number of database queries",
        },
        []string{"operation", "table"},
    )

    DBQueryDuration = promauto.NewHistogramVec(
        prometheus.HistogramOpts{
            Name:    "casspeed_db_query_duration_seconds",
            Help:    "Database query duration in seconds",
            Buckets: []float64{0.0001, 0.0005, 0.001, 0.005, 0.01, 0.05, 0.1, 0.5, 1},
        },
        []string{"operation", "table"},
    )

    DBConnectionsOpen = promauto.NewGauge(
        prometheus.GaugeOpts{
            Name: "casspeed_db_connections_open",
            Help: "Number of open database connections",
        },
    )

    DBConnectionsInUse = promauto.NewGauge(
        prometheus.GaugeOpts{
            Name: "casspeed_db_connections_in_use",
            Help: "Number of database connections in use",
        },
    )

    DBErrors = promauto.NewCounterVec(
        prometheus.CounterOpts{
            Name: "casspeed_db_errors_total",
            Help: "Total number of database errors",
        },
        []string{"operation", "error_type"},
    )

    // Cache metrics
    CacheHits = promauto.NewCounterVec(
        prometheus.CounterOpts{
            Name: "casspeed_cache_hits_total",
            Help: "Total number of cache hits",
        },
        []string{"cache"},
    )

    CacheMisses = promauto.NewCounterVec(
        prometheus.CounterOpts{
            Name: "casspeed_cache_misses_total",
            Help: "Total number of cache misses",
        },
        []string{"cache"},
    )

    CacheEvictions = promauto.NewCounterVec(
        prometheus.CounterOpts{
            Name: "casspeed_cache_evictions_total",
            Help: "Total number of cache evictions",
        },
        []string{"cache"},
    )

    CacheSize = promauto.NewGaugeVec(
        prometheus.GaugeOpts{
            Name: "casspeed_cache_size",
            Help: "Current cache size (items)",
        },
        []string{"cache"},
    )

    CacheBytes = promauto.NewGaugeVec(
        prometheus.GaugeOpts{
            Name: "casspeed_cache_bytes",
            Help: "Current cache size (bytes)",
        },
        []string{"cache"},
    )

    // Scheduler metrics
    SchedulerTasksTotal = promauto.NewCounterVec(
        prometheus.CounterOpts{
            Name: "casspeed_scheduler_tasks_total",
            Help: "Total number of scheduled tasks executed",
        },
        []string{"task", "status"},
    )

    SchedulerTaskDuration = promauto.NewHistogramVec(
        prometheus.HistogramOpts{
            Name:    "casspeed_scheduler_task_duration_seconds",
            Help:    "Scheduled task duration in seconds",
            Buckets: []float64{0.1, 0.5, 1, 5, 10, 30, 60, 300, 600},
        },
        []string{"task"},
    )

    SchedulerTasksRunning = promauto.NewGaugeVec(
        prometheus.GaugeOpts{
            Name: "casspeed_scheduler_tasks_running",
            Help: "Number of currently running scheduled tasks",
        },
        []string{"task"},
    )

    SchedulerLastRun = promauto.NewGaugeVec(
        prometheus.GaugeOpts{
            Name: "casspeed_scheduler_last_run_timestamp",
            Help: "Timestamp of last task run",
        },
        []string{"task"},
    )

    // Authentication metrics
    AuthAttempts = promauto.NewCounterVec(
        prometheus.CounterOpts{
            Name: "casspeed_auth_attempts_total",
            Help: "Total authentication attempts",
        },
        []string{"method", "status"},
    )

    AuthSessionsActive = promauto.NewGauge(
        prometheus.GaugeOpts{
            Name: "casspeed_auth_sessions_active",
            Help: "Number of active sessions",
        },
    )

    // Business metrics
    UsersTotal = promauto.NewGauge(
        prometheus.GaugeOpts{
            Name: "casspeed_users_total",
            Help: "Total number of registered users",
        },
    )

    UsersActive = promauto.NewGauge(
        prometheus.GaugeOpts{
            Name: "casspeed_users_active",
            Help: "Number of users active in last 24 hours",
        },
    )

    APITokensActive = promauto.NewGauge(
        prometheus.GaugeOpts{
            Name: "casspeed_api_tokens_active",
            Help: "Number of active API tokens",
        },
    )

    // Application info
    AppInfo = promauto.NewGaugeVec(
        prometheus.GaugeOpts{
            Name: "casspeed_app_info",
            Help: "Application information",
        },
        []string{"version", "commit", "build_date", "go_version"},
    )

    AppUptime = promauto.NewGauge(
        prometheus.GaugeOpts{
            Name: "casspeed_app_uptime_seconds",
            Help: "Application uptime in seconds",
        },
    )

    AppStartTime = promauto.NewGauge(
        prometheus.GaugeOpts{
            Name: "casspeed_app_start_timestamp",
            Help: "Application start timestamp",
        },
    )
)

// Init initializes application info metrics
func Init(version, commit, buildDate string) {
    AppInfo.WithLabelValues(version, commit, buildDate, runtime.Version()).Set(1)
    AppStartTime.SetToCurrentTime()
}
```

### Metrics Middleware

```go
// src/server/middleware_metrics.go
package server

import (
    "net/http"
    "strconv"
    "time"

    "github.com/casapps/casspeed/src/server/metrics"
)

// metricsMiddleware records HTTP metrics for all requests
func (s *Server) metricsMiddleware(next http.Handler) http.Handler {
    if !s.config.Metrics.Enabled {
        return next
    }

    return http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {
        start := time.Now()

        // Track active requests
        metrics.HTTPActiveRequests.Inc()
        defer metrics.HTTPActiveRequests.Dec()

        // Get normalized path (remove IDs for cardinality control)
        path := normalizePath(r.URL.Path)

        // Record request size
        if r.ContentLength > 0 {
            metrics.HTTPRequestSize.WithLabelValues(r.Method, path).Observe(float64(r.ContentLength))
        }

        // Wrap response writer
        rw := &metricsResponseWriter{ResponseWriter: w, status: http.StatusOK}

        // Process request
        next.ServeHTTP(rw, r)

        // Record metrics
        duration := time.Since(start).Seconds()
        status := strconv.Itoa(rw.status)

        metrics.HTTPRequestsTotal.WithLabelValues(r.Method, path, status).Inc()
        metrics.HTTPRequestDuration.WithLabelValues(r.Method, path).Observe(duration)
        metrics.HTTPResponseSize.WithLabelValues(r.Method, path).Observe(float64(rw.size))
    })
}

type metricsResponseWriter struct {
    http.ResponseWriter
    status int
    size   int
}

func (rw *metricsResponseWriter) WriteHeader(status int) {
    rw.status = status
    rw.ResponseWriter.WriteHeader(status)
}

func (rw *metricsResponseWriter) Write(b []byte) (int, error) {
    n, err := rw.ResponseWriter.Write(b)
    rw.size += n
    return n, err
}

// normalizePath normalizes URL path for consistent metric labels
// Replaces dynamic segments (UUIDs, IDs) with placeholders
func normalizePath(path string) string {
    // Replace UUIDs
    path = uuidRegex.ReplaceAllString(path, ":id")
    // Replace numeric IDs
    path = numericIDRegex.ReplaceAllString(path, ":id")
    return path
}

var (
    uuidRegex      = regexp.MustCompile(`[0-9a-f]{8}-[0-9a-f]{4}-[0-9a-f]{4}-[0-9a-f]{4}-[0-9a-f]{12}`)
    numericIDRegex = regexp.MustCompile(`/\d+(?:/|$)`)
)
```

### Database Metrics Wrapper

```go
// src/server/store/metrics.go
package store

import (
    "context"
    "database/sql"
    "time"

    "github.com/casapps/casspeed/src/server/metrics"
)

// MetricsDB wraps sql.DB with metrics
type MetricsDB struct {
    *sql.DB
}

func (m *MetricsDB) QueryContext(ctx context.Context, query string, args ...any) (*sql.Rows, error) {
    start := time.Now()
    rows, err := m.DB.QueryContext(ctx, query, args...)
    duration := time.Since(start).Seconds()

    op, table := parseQuery(query)
    metrics.DBQueriesTotal.WithLabelValues(op, table).Inc()
    metrics.DBQueryDuration.WithLabelValues(op, table).Observe(duration)

    if err != nil {
        metrics.DBErrors.WithLabelValues(op, classifyError(err)).Inc()
    }
    return rows, err
}

func (m *MetricsDB) ExecContext(ctx context.Context, query string, args ...any) (sql.Result, error) {
    start := time.Now()
    result, err := m.DB.ExecContext(ctx, query, args...)
    duration := time.Since(start).Seconds()

    op, table := parseQuery(query)
    metrics.DBQueriesTotal.WithLabelValues(op, table).Inc()
    metrics.DBQueryDuration.WithLabelValues(op, table).Observe(duration)

    if err != nil {
        metrics.DBErrors.WithLabelValues(op, classifyError(err)).Inc()
    }
    return result, err
}

// UpdateConnectionMetrics updates connection pool metrics
func (m *MetricsDB) UpdateConnectionMetrics() {
    stats := m.DB.Stats()
    metrics.DBConnectionsOpen.Set(float64(stats.OpenConnections))
    metrics.DBConnectionsInUse.Set(float64(stats.InUse))
}

func parseQuery(query string) (operation, table string) {
    // Simple query parsing for metrics labels
    query = strings.TrimSpace(strings.ToUpper(query))
    parts := strings.Fields(query)
    if len(parts) == 0 {
        return "unknown", "unknown"
    }

    operation = parts[0]
    switch operation {
    case "SELECT", "DELETE":
        for i, p := range parts {
            if p == "FROM" && i+1 < len(parts) {
                return strings.ToLower(operation), strings.ToLower(parts[i+1])
            }
        }
    case "INSERT":
        for i, p := range parts {
            if p == "INTO" && i+1 < len(parts) {
                return "insert", strings.ToLower(parts[i+1])
            }
        }
    case "UPDATE":
        if len(parts) > 1 {
            return "update", strings.ToLower(parts[1])
        }
    }
    return strings.ToLower(operation), "unknown"
}

func classifyError(err error) string {
    errStr := err.Error()
    switch {
    case strings.Contains(errStr, "connection"):
        return "connection"
    case strings.Contains(errStr, "timeout"):
        return "timeout"
    case strings.Contains(errStr, "constraint"):
        return "constraint"
    case strings.Contains(errStr, "duplicate"):
        return "duplicate"
    default:
        return "other"
    }
}
```

### Cache Metrics Wrapper

```go
// src/server/cache/metrics.go
package cache

import (
    "time"

    "github.com/casapps/casspeed/src/server/metrics"
)

// MetricsCache wraps a cache with metrics
type MetricsCache struct {
    cache Cache
    name  string
}

func NewMetricsCache(cache Cache, name string) *MetricsCache {
    return &MetricsCache{cache: cache, name: name}
}

func (m *MetricsCache) Get(key string) (any, bool) {
    value, found := m.cache.Get(key)
    if found {
        metrics.CacheHits.WithLabelValues(m.name).Inc()
    } else {
        metrics.CacheMisses.WithLabelValues(m.name).Inc()
    }
    return value, found
}

func (m *MetricsCache) Set(key string, value any, ttl time.Duration) {
    m.cache.Set(key, value, ttl)
    m.updateSizeMetrics()
}

func (m *MetricsCache) Delete(key string) {
    m.cache.Delete(key)
    m.updateSizeMetrics()
}

func (m *MetricsCache) OnEviction(key string, value any) {
    metrics.CacheEvictions.WithLabelValues(m.name).Inc()
}

func (m *MetricsCache) updateSizeMetrics() {
    stats := m.cache.Stats()
    metrics.CacheSize.WithLabelValues(m.name).Set(float64(stats.Items))
    metrics.CacheBytes.WithLabelValues(m.name).Set(float64(stats.Bytes))
}
```

### Scheduler Metrics

```go
// src/scheduler/metrics.go
package scheduler

import (
    "time"

    "github.com/casapps/casspeed/src/server/metrics"
)

// RecordTaskStart records when a task starts
func RecordTaskStart(taskName string) {
    metrics.SchedulerTasksRunning.WithLabelValues(taskName).Inc()
}

// RecordTaskEnd records when a task ends
func RecordTaskEnd(taskName string, duration time.Duration, err error) {
    metrics.SchedulerTasksRunning.WithLabelValues(taskName).Dec()
    metrics.SchedulerTaskDuration.WithLabelValues(taskName).Observe(duration.Seconds())
    metrics.SchedulerLastRun.WithLabelValues(taskName).SetToCurrentTime()

    status := "success"
    if err != nil {
        status = "error"
    }
    metrics.SchedulerTasksTotal.WithLabelValues(taskName, status).Inc()
}
```

### System Metrics Collector

```go
// src/server/metrics/system.go
package metrics

import (
    "runtime"
    "time"

    "github.com/prometheus/client_golang/prometheus"
    "github.com/prometheus/client_golang/prometheus/promauto"
    "github.com/shirou/gopsutil/v3/cpu"
    "github.com/shirou/gopsutil/v3/disk"
    "github.com/shirou/gopsutil/v3/mem"
)

var (
    // System metrics
    SystemCPUUsage = promauto.NewGauge(
        prometheus.GaugeOpts{
            Name: "casspeed_system_cpu_usage_percent",
            Help: "Current CPU usage percentage",
        },
    )

    SystemMemoryUsage = promauto.NewGauge(
        prometheus.GaugeOpts{
            Name: "casspeed_system_memory_usage_percent",
            Help: "Current memory usage percentage",
        },
    )

    SystemMemoryUsed = promauto.NewGauge(
        prometheus.GaugeOpts{
            Name: "casspeed_system_memory_used_bytes",
            Help: "Memory used in bytes",
        },
    )

    SystemMemoryTotal = promauto.NewGauge(
        prometheus.GaugeOpts{
            Name: "casspeed_system_memory_total_bytes",
            Help: "Total memory in bytes",
        },
    )

    SystemDiskUsage = promauto.NewGaugeVec(
        prometheus.GaugeOpts{
            Name: "casspeed_system_disk_usage_percent",
            Help: "Disk usage percentage",
        },
        []string{"path"},
    )

    SystemDiskUsed = promauto.NewGaugeVec(
        prometheus.GaugeOpts{
            Name: "casspeed_system_disk_used_bytes",
            Help: "Disk used in bytes",
        },
        []string{"path"},
    )

    SystemDiskTotal = promauto.NewGaugeVec(
        prometheus.GaugeOpts{
            Name: "casspeed_system_disk_total_bytes",
            Help: "Total disk in bytes",
        },
        []string{"path"},
    )

    // Go runtime metrics
    GoGoroutines = promauto.NewGauge(
        prometheus.GaugeOpts{
            Name: "casspeed_go_goroutines",
            Help: "Number of goroutines",
        },
    )

    GoMemAlloc = promauto.NewGauge(
        prometheus.GaugeOpts{
            Name: "casspeed_go_mem_alloc_bytes",
            Help: "Bytes allocated and in use",
        },
    )

    GoMemSys = promauto.NewGauge(
        prometheus.GaugeOpts{
            Name: "casspeed_go_mem_sys_bytes",
            Help: "Bytes obtained from system",
        },
    )

    GoGCRuns = promauto.NewCounter(
        prometheus.CounterOpts{
            Name: "casspeed_go_gc_runs_total",
            Help: "Total number of GC runs",
        },
    )

    GoGCPauseTotal = promauto.NewCounter(
        prometheus.CounterOpts{
            Name: "casspeed_go_gc_pause_total_seconds",
            Help: "Total GC pause time in seconds",
        },
    )
)

// SystemCollector collects system metrics periodically
type SystemCollector struct {
    dataDir  string
    interval time.Duration
    stop     chan struct{}
    lastGC   uint32
}

func NewSystemCollector(dataDir string, interval time.Duration) *SystemCollector {
    return &SystemCollector{
        dataDir:  dataDir,
        interval: interval,
        stop:     make(chan struct{}),
    }
}

func (c *SystemCollector) Start() {
    go c.collect()
}

func (c *SystemCollector) Stop() {
    close(c.stop)
}

func (c *SystemCollector) collect() {
    ticker := time.NewTicker(c.interval)
    defer ticker.Stop()

    for {
        select {
        case <-ticker.C:
            c.collectCPU()
            c.collectMemory()
            c.collectDisk()
            c.collectRuntime()
        case <-c.stop:
            return
        }
    }
}

func (c *SystemCollector) collectCPU() {
    if percent, err := cpu.Percent(0, false); err == nil && len(percent) > 0 {
        SystemCPUUsage.Set(percent[0])
    }
}

func (c *SystemCollector) collectMemory() {
    if vmem, err := mem.VirtualMemory(); err == nil {
        SystemMemoryUsage.Set(vmem.UsedPercent)
        SystemMemoryUsed.Set(float64(vmem.Used))
        SystemMemoryTotal.Set(float64(vmem.Total))
    }
}

func (c *SystemCollector) collectDisk() {
    if usage, err := disk.Usage(c.dataDir); err == nil {
        SystemDiskUsage.WithLabelValues(c.dataDir).Set(usage.UsedPercent)
        SystemDiskUsed.WithLabelValues(c.dataDir).Set(float64(usage.Used))
        SystemDiskTotal.WithLabelValues(c.dataDir).Set(float64(usage.Total))
    }
}

func (c *SystemCollector) collectRuntime() {
    var m runtime.MemStats
    runtime.ReadMemStats(&m)

    GoGoroutines.Set(float64(runtime.NumGoroutine()))
    GoMemAlloc.Set(float64(m.Alloc))
    GoMemSys.Set(float64(m.Sys))

    // Track GC runs (delta since last collection)
    if m.NumGC > c.lastGC {
        GoGCRuns.Add(float64(m.NumGC - c.lastGC))
        c.lastGC = m.NumGC
    }

    // Total GC pause time
    GoGCPauseTotal.Add(float64(m.PauseTotalNs) / 1e9)
}
```

### Metrics Handler

```go
// src/server/handler/metrics.go
package handler

import (
    "net/http"

    "github.com/prometheus/client_golang/prometheus/promhttp"
)

// MetricsHandler returns the Prometheus metrics handler with optional auth
func MetricsHandler(token string) http.Handler {
    handler := promhttp.Handler()

    if token == "" {
        return handler
    }

    // Wrap with bearer token authentication
    return http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {
        auth := r.Header.Get("Authorization")
        if auth != "Bearer "+token {
            http.Error(w, "Unauthorized", http.StatusUnauthorized)
            return
        }
        handler.ServeHTTP(w, r)
    })
}
```

### Uptime Updater

```go
// src/server/metrics/uptime.go
package metrics

import (
    "time"
)

var startTime = time.Now()

// StartUptimeUpdater updates uptime metric periodically
func StartUptimeUpdater() {
    go func() {
        ticker := time.NewTicker(1 * time.Second)
        defer ticker.Stop()

        for range ticker.C {
            AppUptime.Set(time.Since(startTime).Seconds())
        }
    }()
}
```

## Metrics Endpoint Output

```
# HELP casspeed_http_requests_total Total number of HTTP requests
# TYPE casspeed_http_requests_total counter
casspeed_http_requests_total{method="GET",path="/api/v1/users",status="200"} 1523
casspeed_http_requests_total{method="POST",path="/api/v1/users",status="201"} 42

# HELP casspeed_http_request_duration_seconds HTTP request duration in seconds
# TYPE casspeed_http_request_duration_seconds histogram
casspeed_http_request_duration_seconds_bucket{method="GET",path="/api/v1/users",le="0.01"} 1400
casspeed_http_request_duration_seconds_bucket{method="GET",path="/api/v1/users",le="0.1"} 1520
casspeed_http_request_duration_seconds_bucket{method="GET",path="/api/v1/users",le="+Inf"} 1523
casspeed_http_request_duration_seconds_sum{method="GET",path="/api/v1/users"} 12.456
casspeed_http_request_duration_seconds_count{method="GET",path="/api/v1/users"} 1523

# HELP casspeed_db_connections_open Number of open database connections
# TYPE casspeed_db_connections_open gauge
casspeed_db_connections_open 5

# HELP casspeed_cache_hits_total Total number of cache hits
# TYPE casspeed_cache_hits_total counter
casspeed_cache_hits_total{cache="sessions"} 8234
casspeed_cache_hits_total{cache="users"} 1523

# HELP casspeed_app_info Application information
# TYPE casspeed_app_info gauge
casspeed_app_info{version="1.2.3",commit="abc123",build_date="2025-01-15",go_version="go1.23"} 1

# HELP casspeed_app_uptime_seconds Application uptime in seconds
# TYPE casspeed_app_uptime_seconds gauge
casspeed_app_uptime_seconds 86423.5
```

## Alerting Rules (Prometheus)

```yaml
# alerts.yml - Example Prometheus alerting rules
groups:
  - name: casspeed_alerts
    rules:
      # High error rate
      - alert: HighErrorRate
        expr: |
          sum(rate(casspeed_http_requests_total{status=~"5.."}[5m]))
          / sum(rate(casspeed_http_requests_total[5m])) > 0.05
        for: 5m
        labels:
          severity: critical
        annotations:
          summary: "High error rate (> 5%)"
          description: "Error rate is {{ $value | humanizePercentage }}"

      # High latency
      - alert: HighLatency
        expr: |
          histogram_quantile(0.95, rate(casspeed_http_request_duration_seconds_bucket[5m])) > 1
        for: 5m
        labels:
          severity: warning
        annotations:
          summary: "High p95 latency (> 1s)"
          description: "p95 latency is {{ $value | humanizeDuration }}"

      # Database connection pool exhausted
      - alert: DBConnectionPoolExhausted
        expr: |
          casspeed_db_connections_in_use / casspeed_db_connections_open > 0.9
        for: 5m
        labels:
          severity: warning
        annotations:
          summary: "Database connection pool > 90% used"

      # High memory usage
      - alert: HighMemoryUsage
        expr: casspeed_system_memory_usage_percent > 90
        for: 10m
        labels:
          severity: warning
        annotations:
          summary: "Memory usage > 90%"

      # Disk space low
      - alert: DiskSpaceLow
        expr: casspeed_system_disk_usage_percent > 85
        for: 5m
        labels:
          severity: warning
        annotations:
          summary: "Disk usage > 85%"

      # Application down
      - alert: ApplicationDown
        expr: up{job="casspeed"} == 0
        for: 1m
        labels:
          severity: critical
        annotations:
          summary: "casspeed is down"

      # Goroutine leak
      - alert: GoroutineLeak
        expr: |
          casspeed_go_goroutines > 1000
          and increase(casspeed_go_goroutines[1h]) > 100
        for: 30m
        labels:
          severity: warning
        annotations:
          summary: "Possible goroutine leak"
          description: "Goroutines: {{ $value }}"

      # Scheduler task failing
      - alert: SchedulerTaskFailing
        expr: |
          increase(casspeed_scheduler_tasks_total{status="error"}[1h]) > 3
        for: 0m
        labels:
          severity: warning
        annotations:
          summary: "Scheduler task {{ $labels.task }} failing"
```

## Grafana Dashboard

```json
{
  "title": "CASSPEED Metrics",
  "panels": [
    {
      "title": "Request Rate",
      "type": "graph",
      "targets": [
        {"expr": "sum(rate(casspeed_http_requests_total[5m]))"}
      ]
    },
    {
      "title": "Error Rate",
      "type": "graph",
      "targets": [
        {"expr": "sum(rate(casspeed_http_requests_total{status=~\"5..\"}[5m])) / sum(rate(casspeed_http_requests_total[5m]))"}
      ]
    },
    {
      "title": "Latency (p50, p95, p99)",
      "type": "graph",
      "targets": [
        {"expr": "histogram_quantile(0.50, rate(casspeed_http_request_duration_seconds_bucket[5m]))", "legendFormat": "p50"},
        {"expr": "histogram_quantile(0.95, rate(casspeed_http_request_duration_seconds_bucket[5m]))", "legendFormat": "p95"},
        {"expr": "histogram_quantile(0.99, rate(casspeed_http_request_duration_seconds_bucket[5m]))", "legendFormat": "p99"}
      ]
    },
    {
      "title": "Active Requests",
      "type": "stat",
      "targets": [
        {"expr": "casspeed_http_active_requests"}
      ]
    },
    {
      "title": "Database Connections",
      "type": "graph",
      "targets": [
        {"expr": "casspeed_db_connections_open", "legendFormat": "open"},
        {"expr": "casspeed_db_connections_in_use", "legendFormat": "in_use"}
      ]
    },
    {
      "title": "Cache Hit Rate",
      "type": "graph",
      "targets": [
        {"expr": "sum(rate(casspeed_cache_hits_total[5m])) / (sum(rate(casspeed_cache_hits_total[5m])) + sum(rate(casspeed_cache_misses_total[5m])))"}
      ]
    },
    {
      "title": "Memory Usage",
      "type": "gauge",
      "targets": [
        {"expr": "casspeed_system_memory_usage_percent"}
      ]
    },
    {
      "title": "Goroutines",
      "type": "graph",
      "targets": [
        {"expr": "casspeed_go_goroutines"}
      ]
    },
    {
      "title": "Uptime",
      "type": "stat",
      "targets": [
        {"expr": "casspeed_app_uptime_seconds"}
      ]
    }
  ]
}
```

## Admin Panel (/admin/server/metrics)

| Element | Type | Description |
|---------|------|-------------|
| Enable metrics | Toggle | Turn metrics on/off |
| Endpoint | Text input | Metrics endpoint path (default: /metrics) |
| Include system metrics | Toggle | Include CPU/memory/disk |
| Include runtime metrics | Toggle | Include Go runtime stats |
| Authentication token | Text input | Bearer token (empty = no auth) |
| Prometheus URL | Info | Display scrape URL for Prometheus config |

---


# PART 30: TOR HIDDEN SERVICE (NON-NEGOTIABLE)

## Overview

**ALL projects MUST have built-in Tor hidden service support.**

Tor integration uses **external Tor binary** via `github.com/cretz/bine`. This maintains `CGO_ENABLED=0` compatibility for static binaries while providing full Tor hidden service functionality.

## Configuration

```yaml
server:
  tor:
    # Path to Tor binary (auto-detected if empty)
    binary: ""
    # Data directory for this instance's Tor data
    # Default: {data_dir}/tor/
    data_dir: ""
```

**Notes:**
- Uses external Tor binary (not embedded) for CGO_ENABLED=0 compatibility
- **Auto-enabled if tor binary is installed** - no enable flag needed
- Binary manages its OWN Tor instance (not system Tor)
- When binary stops, its Tor instance stops (clean shutdown)
- .onion address derived from keys in `{data_dir}/tor/site/`
- Completely isolated from any system Tor installation

## Tor Process Management (NON-NEGOTIABLE)

**The application MUST start its OWN dedicated Tor process. NEVER use system Tor.**

This prevents conflicts with any existing Tor installation on the system.

```
1. Find Tor binary:
   ├─ Check config `server.tor.binary` path
   ├─ Check PATH for `tor` executable
   ├─ Check common locations:
   │   ├─ Linux: /usr/bin/tor, /usr/local/bin/tor
   │   ├─ macOS: /usr/local/bin/tor, /opt/homebrew/bin/tor
   │   ├─ Windows: C:\Program Files\Tor\tor.exe
   │   └─ BSD: /usr/local/bin/tor
   └─ NOT FOUND: Log warning, disable Tor features, continue without Tor

2. Start DEDICATED Tor process:
   ├─ Use application's own DataDir: `{data_dir}/tor/`
   ├─ Use random available ControlPort (not 9051)
   ├─ Disable SocksPort (server-only, not browsing)
   ├─ Completely isolated from system Tor
   ├─ Wait for bootstrap completion
   └─ Create hidden service via ADD_ONION

3. On application shutdown:
   └─ Terminate the dedicated Tor process
```

### Why Dedicated Tor Process?

| Reason | Description |
|--------|-------------|
| **No conflicts** | System Tor uses 9050/9051, we use random ports |
| **Isolation** | Our DataDir is separate from system Tor |
| **Clean shutdown** | We control the process lifecycle |
| **No permissions issues** | Don't need access to system Tor control |
| **Predictable behavior** | Always same configuration |

## Implementation

### Library

Use `github.com/cretz/bine` (pure Go, CGO_ENABLED=0 compatible):

```go
import (
    "github.com/cretz/bine/tor"
)

func startDedicatedTor(ctx context.Context, localPort int) (*tor.Tor, *tor.OnionService, error) {
    // Start OUR OWN Tor process - completely separate from system Tor
    t, err := tor.Start(ctx, &tor.StartConf{
        // Our own data directory - isolated from system Tor
        DataDir: paths.GetDataDir() + "/tor",

        // Let bine pick available ports (avoids conflict with system Tor 9050/9051)
        // These are set automatically to available ports
        NoAutoSocksPort: false,

        // Optional: specify path if not in PATH
        // ExePath: "/usr/bin/tor",

        // Debug output (development only)
        // DebugWriter: os.Stderr,
    })
    if err != nil {
        return nil, nil, fmt.Errorf("failed to start dedicated tor: %w", err)
    }

    // Wait for Tor to bootstrap
    dialCtx, cancel := context.WithTimeout(ctx, 3*time.Minute)
    defer cancel()
    if err := t.EnableNetwork(dialCtx, true); err != nil {
        t.Close()
        return nil, nil, fmt.Errorf("failed to enable tor network: %w", err)
    }

    // Create hidden service
    onion, err := t.Listen(ctx, &tor.ListenConf{
        RemotePorts: []int{80},
        LocalPort:   localPort,
    })
    if err != nil {
        t.Close()
        return nil, nil, fmt.Errorf("failed to create onion service: %w", err)
    }

    // onion.ID contains the .onion address (without .onion suffix)
    log.Printf("Tor hidden service started: %s.onion", onion.ID)
    return t, onion, nil
}

// Shutdown cleanly terminates our dedicated Tor process
func shutdownTor(t *tor.Tor) error {
    if t != nil {
        return t.Close()
    }
    return nil
}
```

### Port Allocation

| Port | System Tor | Our Tor |
|------|------------|---------|
| SocksPort | 9050 | 0 (disabled - server only) |
| ControlPort | 9051 | Random available |
| DataDir | `/var/lib/tor` | `{data_dir}/tor/` |

**bine automatically selects available ControlPort**, ensuring no conflict with system Tor. SocksPort is disabled since we're running as a hidden service server, not browsing through Tor.

### Tor Configuration Optimizations (NON-NEGOTIABLE)

**Tor is used ONLY for hidden services. Optimize accordingly.**

```go
// Optimized torrc settings for hidden-service-only mode
func getTorConfig() string {
    return `
# Hidden service only - not a relay or exit
SocksPort 0
# No SOCKS proxy needed - we're server only

# Disable unused features
ExitRelay 0
ExitPolicy reject *:*
# Never act as exit node

# Don't relay traffic for others
ORPort 0
DirPort 0

# Reduce circuit building (we only need service circuits)
MaxCircuitDirtiness 600
# Keep circuits longer

# Reduce bandwidth for Tor overhead
BandwidthRate 1 MB
BandwidthBurst 2 MB

# Hidden service optimizations
HiddenServiceSingleHopMode 0
# Keep full anonymity (3 hops)

# Faster startup
FetchDirInfoEarly 1
FetchDirInfoExtraEarly 1

# Reduce memory usage
DisableDebuggerAttachment 1
`
}
```

| Setting | Value | Reason |
|---------|-------|--------|
| `SocksPort 0` | Disabled | Not browsing, server only |
| `ExitRelay 0` | Disabled | Not an exit node |
| `ORPort 0` | Disabled | Not relaying traffic |
| `DirPort 0` | Disabled | Not a directory server |
| `ExitPolicy reject *:*` | Block all | Extra safety |
| `MaxCircuitDirtiness 600` | 10 minutes | Keep circuits longer |

### Tor Process Lifecycle (NON-NEGOTIABLE)

**The application MUST fully manage the Tor process lifecycle.**

| Event | Action |
|-------|--------|
| **App Start** | Find Tor binary → Start dedicated Tor process → Wait for bootstrap → Create hidden service |
| **App Running** | Monitor Tor process, restart if crashed |
| **App Shutdown** | Terminate Tor process gracefully (SIGTERM) |
| **App Crash** | Tor process should terminate (child process dies with parent) |
| **SIGTERM/SIGINT** | Graceful shutdown: stop Tor, then exit |
| **SIGHUP** | Reload config, restart Tor if settings changed |

### Tor Restart Triggers (NON-NEGOTIABLE)

**Tor MUST be restarted when these events occur:**

| Trigger | Action | Notes |
|---------|--------|-------|
| **Regenerate .onion address** | Stop Tor → Delete keys → Start Tor | New random address |
| **Apply vanity address** | Stop Tor → Replace keys → Start Tor | Use generated vanity keys |
| **Import external keys** | Stop Tor → Replace keys → Start Tor | Use imported keys |
| **Start Tor** | Start Tor | Manual start (auto-starts on boot if installed) |
| **Stop Tor** | Stop Tor | Manual stop (temporary, restarts on reboot) |
| **Tor process crash** | Restart Tor | Auto-recovery |
| **Tor unresponsive** | Stop Tor → Start Tor | Health check failed |
| **Config change** | Stop Tor → Start Tor | Settings changed |

### Restart Implementation

```go
// TorManager handles all Tor lifecycle operations
type TorManager struct {
    mu        sync.Mutex
    tor       *tor.Tor
    onion     *tor.OnionService
    dataDir   string
    localPort int
    ctx       context.Context
    cancel    context.CancelFunc
}

// Restart stops and starts Tor (used for config changes, recovery)
func (tm *TorManager) Restart() error {
    tm.mu.Lock()
    defer tm.mu.Unlock()

    // Stop existing
    if tm.tor != nil {
        tm.tor.Close()
        tm.tor = nil
        tm.onion = nil
    }

    // Start fresh
    return tm.startLocked()
}

// RegenerateAddress creates a new random .onion address
func (tm *TorManager) RegenerateAddress() (string, error) {
    tm.mu.Lock()
    defer tm.mu.Unlock()

    // Stop Tor
    if tm.tor != nil {
        tm.tor.Close()
        tm.tor = nil
        tm.onion = nil
    }

    // Delete existing keys
    keysDir := filepath.Join(tm.dataDir, "site")
    if err := os.RemoveAll(keysDir); err != nil {
        return "", fmt.Errorf("failed to remove old keys: %w", err)
    }

    // Start Tor - new keys will be generated
    if err := tm.startLocked(); err != nil {
        return "", err
    }

    return tm.onion.ID + ".onion", nil
}

// ApplyKeys stops Tor, replaces keys, and restarts
func (tm *TorManager) ApplyKeys(privateKey []byte) (string, error) {
    tm.mu.Lock()
    defer tm.mu.Unlock()

    // Stop Tor
    if tm.tor != nil {
        tm.tor.Close()
        tm.tor = nil
        tm.onion = nil
    }

    // Write new keys
    keysDir := filepath.Join(tm.dataDir, "site")
    os.MkdirAll(keysDir, 0700)
    keyPath := filepath.Join(keysDir, "hs_ed25519_secret_key")
    if err := os.WriteFile(keyPath, privateKey, 0600); err != nil {
        return "", fmt.Errorf("failed to write key: %w", err)
    }

    // Start Tor with new keys
    if err := tm.startLocked(); err != nil {
        return "", err
    }

    return tm.onion.ID + ".onion", nil
}

// SetEnabled enables or disables Tor
func (tm *TorManager) SetEnabled(enabled bool) error {
    tm.mu.Lock()
    defer tm.mu.Unlock()

    if enabled {
        if tm.tor == nil {
            return tm.startLocked()
        }
    } else {
        if tm.tor != nil {
            tm.tor.Close()
            tm.tor = nil
            tm.onion = nil
        }
    }
    return nil
}
```

### Signal Handling with Tor

```go
func main() {
    ctx, cancel := context.WithCancel(context.Background())
    defer cancel()

    // Start Tor
    torProcess, onion, err := startDedicatedTor(ctx, localPort)
    if err != nil {
        log.Printf("Warning: Tor disabled - %v", err)
        // Continue without Tor
    }

    // Handle shutdown signals
    // NOTE: Use signal package's setupSignalHandler() for proper cross-platform support
    // This is simplified - actual implementation uses platform-specific signal_*.go files
    sigChan := make(chan os.Signal, 1)
    registerShutdownSignals(sigChan) // See signal/signal_unix.go and signal_windows.go

    go func() {
        <-sigChan
        log.Println("Shutting down...")

        // Stop Tor FIRST
        if torProcess != nil {
            log.Println("Stopping Tor process...")
            torProcess.Close()
        }

        // Then cancel context for other goroutines
        cancel()
    }()

    // Run server...
}
```

### Tor Process Monitoring

```go
// Monitor Tor and restart if it crashes
func monitorTor(ctx context.Context, torProcess *tor.Tor, restartFunc func() (*tor.Tor, error)) {
    ticker := time.NewTicker(30 * time.Second)
    defer ticker.Stop()

    for {
        select {
        case <-ctx.Done():
            return
        case <-ticker.C:
            // Check if Tor is still responsive
            if torProcess != nil {
                // Ping control connection
                if _, err := torProcess.Control.GetInfo("version"); err != nil {
                    log.Println("Tor process unresponsive, restarting...")
                    torProcess.Close()
                    newTor, err := restartFunc()
                    if err != nil {
                        log.Printf("Failed to restart Tor: %v", err)
                    } else {
                        torProcess = newTor
                    }
                }
            }
        }
    }
}
```

### Binary Size

No impact on binary size - Tor is external. Application binary remains small and static.

### Data Storage

| Data | Location |
|------|----------|
| Tor data directory | `{data_dir}/tor/` |
| Hidden service keys | `{data_dir}/tor/site/` |
| Tor process PID | `{data_dir}/tor/tor.pid` |

## Admin Panel

### /admin/server/tor (Web UI)

| Element | Type | Description |
|---------|------|-------------|
| Tor Service | Toggle switch | Start/Stop hidden service (auto-starts on boot) |
| Status | Indicator | ● Connected / ○ Disconnected / ⚠ Error |
| .onion Address | Read-only text | Full address with copy button |
| Regenerate Address | Button | Creates new random .onion (requires confirmation modal) |
| Vanity Prefix | Text input | Desired prefix (max 6 characters) |
| Generate Vanity | Button | Starts background generation |
| Vanity Status | Progress indicator | Shows when generating in background |
| Import Keys | File upload | Import externally generated keys |

**Status Card Example:**
```
┌─────────────────────────────────────────────────────────┐
│ Tor Hidden Service                                      │
│                                                         │
│ Status: ● Connected                                     │
│ Address: abcd1234...wxyz.onion                  [Copy]  │
│                                                         │
│ [Regenerate Address]                                    │
├─────────────────────────────────────────────────────────┤
│ Vanity Address                                          │
│                                                         │
│ Prefix: [______] (max 6 chars)  [Generate]              │
│                                                         │
│ ⏳ Generating: "jokes" - 2h 15m elapsed...              │
│    [Cancel]                                             │
├─────────────────────────────────────────────────────────┤
│ Import External Keys                      [Import Keys] │
│ ⓘ Help: How to generate longer vanity addresses        │
└─────────────────────────────────────────────────────────┘
```

### Vanity Address Generation

**Built-in generation (max 6 characters):**

| Prefix Length | Approximate Time |
|---------------|------------------|
| 1-4 chars | Seconds to minutes |
| 5 chars | Minutes to hours |
| 6 chars | Hours to days |

**Behavior:**
- Generation runs in background
- Current .onion address remains active while generating
- Notification sent when vanity address is ready
- User clicks notification or "Apply" button to activate
- Old keys deleted, new vanity keys activated
- Tor restarts with new address

### External Vanity Generation (7+ characters)

For prefixes longer than 6 characters, use external tools with GPU acceleration. The admin panel includes documentation (expandable help section):

**Using mkp224o (CPU):**
```bash
# Install
git clone https://github.com/cathugger/mkp224o
cd mkp224o && ./autogen.sh && ./configure && make

# Generate (example: 7-char prefix "myapp12")
./mkp224o -d ./keys myapp12

# Output: ./keys/myapp12xxxxx.onion/
#   ├── hostname        # Your .onion address
#   ├── hs_ed25519_public_key
#   └── hs_ed25519_secret_key
```

**Using mkp224o (GPU - much faster):**
```bash
# With CUDA support
./configure --enable-cuda
make

# Generate
./mkp224o -d ./keys myapp12
```

**Importing keys:**
1. Generate keys using mkp224o or similar tool
2. In admin panel, click "Import Keys"
3. Upload `hs_ed25519_secret_key` file (or zip containing both key files)
4. Confirm to replace current address
5. Tor restarts with imported keys

**Time estimates for longer prefixes:**

| Prefix Length | CPU Time | GPU Time |
|---------------|----------|----------|
| 7 chars | Days to weeks | Hours to days |
| 8 chars | Weeks to months | Days to weeks |
| 9+ chars | Months to years | Weeks to months |

**Security Notes:**
- .onion address shown only after admin authentication
- "Regenerate Address" requires confirmation modal (destructive - old address stops working)
- Address regeneration logged to audit log
- Imported keys should be generated on a trusted machine
- Delete source key files after successful import

### API Endpoints

**See PART 22 for full API route definitions under `/api/v1/admin/server/tor/`**

### Response Format

```json
{
  "enabled": true,
  "status": "connected",
  "onion_address": "abcd1234efgh5678ijkl9012mnop3456qrst7890uvwx.onion",
  "uptime": "2d 5h 30m"
}
```

## Behavior

| Scenario | Behavior |
|----------|----------|
| First run | Tor starts, generates .onion address, saves to config |
| Subsequent runs | Tor starts, uses existing .onion address |
| Disabled in config | Tor does not start, no .onion available |
| Regenerate address | Old keys deleted, new .onion generated, config updated |
| Network issues | Tor retries connection automatically |

## CLI

The `--status` command includes Tor and cluster status:

### Single Instance

```
$ myapp --status

Server Status: Running
  Port: 8080
  Mode: production
  Uptime: 2d 5h 30m

Node: standalone
Cluster: disabled

Tor Hidden Service: Connected
  Address: abcd1234...wxyz.onion
```

### Cluster Mode

```
$ myapp --status

Server Status: Running
  Port: 8080
  Mode: production
  Uptime: 2d 5h 30m

Node: node-abc123
  Hostname: server-1.example.com

Cluster: connected
  Status: healthy
  Nodes: 3
  Database: postgres://db.example.com/myapp

Tor Hidden Service: Connected
  Address: abcd1234...wxyz.onion
```

### Status Fields

| Field | Description |
|-------|-------------|
| Node | Node ID (standalone or unique ID) |
| Hostname | Server hostname |
| Cluster | disabled, connected, degraded, disconnected |
| Nodes | Number of nodes in cluster |
| Database | Database connection info (driver://host/db) |

---


# PART 31: ERROR HANDLING & CACHING (NON-NEGOTIABLE)

## Error Handling

### User-Facing Errors

- Clear, actionable messages
- No stack traces in production
- Appropriate HTTP status codes
- Consistent format

### Error Codes

**Standard error codes mapped to HTTP status codes:**

| Code | HTTP | Description |
|------|------|-------------|
| `ERR_BAD_REQUEST` | 400 | Malformed request syntax |
| `ERR_VALIDATION` | 400 | Input validation failed |
| `ERR_UNAUTHORIZED` | 401 | Authentication required |
| `ERR_SESSION_EXPIRED` | 401 | Session has expired |
| `ERR_SESSION_INVALID` | 401 | Invalid session token |
| `ERR_2FA_REQUIRED` | 401 | Two-factor authentication required |
| `ERR_2FA_INVALID` | 401 | Invalid 2FA code |
| `ERR_FORBIDDEN` | 403 | Permission denied |
| `ERR_ACCOUNT_LOCKED` | 403 | Account temporarily locked |
| `ERR_NOT_FOUND` | 404 | Resource not found |
| `ERR_METHOD_NOT_ALLOWED` | 405 | HTTP method not supported |
| `ERR_CONFLICT` | 409 | Resource already exists or version conflict |
| `ERR_UNPROCESSABLE` | 422 | Semantic validation error |
| `ERR_RATE_LIMIT` | 429 | Rate limit exceeded |
| `ERR_INTERNAL` | 500 | Server error |
| `ERR_SERVICE_UNAVAILABLE` | 503 | Maintenance mode or overloaded |

## Caching

See **PART 17: SERVER CONFIGURATION** for full Valkey/Redis setup.

### Cache Drivers

| Driver | Mode | Notes |
|--------|------|-------|
| `memory` | Single instance | Default, in-process |
| `valkey` | Single/Cluster | Preferred for production |
| `redis` | Single/Cluster | Full support |

### HTTP Cache Headers

| Content Type | Header |
|--------------|--------|
| Static assets | `Cache-Control: max-age=31536000, immutable` |
| API responses | `Cache-Control: no-cache` or short TTL |
| HTML pages | `Cache-Control: no-store` |
| Authenticated | `Cache-Control: private, no-store` |

---


# PART 32: I18N & A11Y (NON-NEGOTIABLE)

## Internationalization (i18n)

- UTF-8 everywhere
- Accept-Language header respected
- Default: English (en)
- Extensible translation system

## Accessibility (a11y)

| Requirement | Description |
|-------------|-------------|
| WCAG 2.1 AA | Compliance required |
| Keyboard | Full navigation |
| Screen readers | Full support |
| ARIA labels | Proper usage |
| Color contrast | Proper ratios |
| Focus indicators | Visible |

---


# PART 33: READTHEDOCS DOCUMENTATION (NON-NEGOTIABLE)

## Overview

**Every project MUST have documentation hosted on ReadTheDocs.**

**CRITICAL:** The `docs/` directory is **ONLY** for ReadTheDocs files (MkDocs documentation). **NEVER** put other files in `docs/` - use `src/` for source code, `scripts/` for scripts, etc.

Documentation uses MkDocs Material theme with built-in light/dark/auto switching that matches the project-wide theme system.

| Attribute | Value |
|-----------|-------|
| Documentation engine | MkDocs (Markdown-based) |
| Theme | MkDocs Material with palette toggle (light/dark/auto) |
| Default theme | Dark theme |
| Hosting | ReadTheDocs |
| URL format | `https://casapps-casspeed.readthedocs.io` |
| Source directory | `docs/` (ONLY ReadTheDocs files) |

**Theme Support:**
- **Dark theme** (default) - Dark color scheme (see `docs/stylesheets/dark.css`)
- **Light theme** - Light color scheme (see `docs/stylesheets/light.css`)
- **Auto theme** - Follows system preference
- User can toggle between themes via UI button
- Preference persisted in browser localStorage
- Consistent with project-wide theme system

## Required Files

### Project Root Files

| File | Purpose |
|------|---------|
| `mkdocs.yml` | MkDocs configuration |
| `.readthedocs.yaml` | ReadTheDocs build configuration |

### Documentation Directory (`docs/`)

| File | Required | Purpose |
|------|:--------:|---------|
| `index.md` | ✓ | Documentation homepage |
| `installation.md` | ✓ | Installation guide (Docker, binary, systemd) |
| `configuration.md` | ✓ | Configuration reference (all settings) |
| `api.md` | ✓ | API documentation (endpoints, formats) |
| `cli.md` | If applicable | CLI reference (flags, commands) |
| `admin.md` | ✓ | Admin panel guide |
| `development.md` | ✓ | Development/contributing guide |
| `stylesheets/dark.css` | Optional | Dark theme customization |
| `stylesheets/light.css` | Optional | Light theme customization |
| `requirements.txt` | ✓ | Python dependencies for MkDocs |

## mkdocs.yml Template (NON-NEGOTIABLE)

```yaml
site_name: CASSPEED
site_url: https://casapps-casspeed.readthedocs.io
site_description: "{Project description}"
site_author: casapps

repo_name: casapps/casspeed
repo_url: https://github.com/casapps/casspeed
edit_uri: edit/main/docs/

theme:
  name: material
  palette:
    # Light/Dark/Auto theme toggle
    - media: "(prefers-color-scheme)"
      toggle:
        icon: material/brightness-auto
        name: Switch to light mode
    - media: "(prefers-color-scheme: light)"
      scheme: default
      primary: indigo
      accent: indigo
      toggle:
        icon: material/brightness-7
        name: Switch to dark mode
    - media: "(prefers-color-scheme: dark)"
      scheme: slate
      primary: deep purple
      accent: purple
      toggle:
        icon: material/brightness-4
        name: Switch to auto mode
  features:
    - navigation.instant
    - navigation.tracking
    - navigation.tabs
    - navigation.sections
    - navigation.expand
    - navigation.top
    - search.suggest
    - search.highlight
    - content.code.copy
    - content.action.edit
  font:
    text: Roboto
    code: Roboto Mono
  icon:
    repo: fontawesome/brands/github

extra_css:
  - stylesheets/dark.css
  - stylesheets/light.css

plugins:
  - search
  - minify:
      minify_html: true

markdown_extensions:
  - abbr
  - admonition
  - attr_list
  - def_list
  - footnotes
  - meta
  - md_in_html
  - tables
  - toc:
      permalink: true
      toc_depth: 3
  - pymdownx.arithmatex:
      generic: true
  - pymdownx.betterem:
      smart_enable: all
  - pymdownx.caret
  - pymdownx.details
  - pymdownx.emoji:
      emoji_index: !!python/name:material.extensions.emoji.twemoji
      emoji_generator: !!python/name:material.extensions.emoji.to_svg
  - pymdownx.highlight:
      anchor_linenums: true
      line_spans: __span
      pygments_lang_class: true
  - pymdownx.inlinehilite
  - pymdownx.keys
  - pymdownx.magiclink:
      repo_url_shorthand: true
      user: casapps
      repo: casspeed
  - pymdownx.mark
  - pymdownx.smartsymbols
  - pymdownx.superfences:
      custom_fences:
        - name: mermaid
          class: mermaid
          format: !!python/name:pymdownx.superfences.fence_code_format
  - pymdownx.tabbed:
      alternate_style: true
  - pymdownx.tasklist:
      custom_checkbox: true
  - pymdownx.tilde

nav:
  - Home: index.md
  - Getting Started:
    - Installation: installation.md
    - Configuration: configuration.md
  - Usage:
    - API Reference: api.md
    - CLI Reference: cli.md
    - Admin Panel: admin.md
  - Development:
    - Contributing: development.md

extra:
  social:
    - icon: fontawesome/brands/github
      link: https://github.com/casapps/casspeed
  generator: false
```

## .readthedocs.yaml Template (NON-NEGOTIABLE)

```yaml
# ReadTheDocs configuration
# https://docs.readthedocs.io/en/stable/config-file/v2.html

version: 2

build:
  os: ubuntu-22.04
  tools:
    python: "3.11"

mkdocs:
  configuration: mkdocs.yml

python:
  install:
    - requirements: docs/requirements.txt
```

## docs/requirements.txt (NON-NEGOTIABLE)

```
mkdocs>=1.5.0
mkdocs-material>=9.5.0
mkdocs-minify-plugin>=0.7.0
pymdown-extensions>=10.0
```

## Theme CSS Files (OPTIONAL)

**Note:** MkDocs Material includes built-in light/dark/auto theme toggle. The CSS files below are OPTIONAL for additional customization.

### Dark Theme CSS

**File:** `docs/stylesheets/dark.css`

```css
/* Dark Theme Customization for MkDocs Material (OPTIONAL) */
/* MkDocs Material's built-in 'slate' scheme already provides a dark theme */
/* This file adds additional dark theme customization */

:root {
  /* Dark theme color palette */
  --dark-bg: #282a36;
  --dark-bg-alt: #44475a;
  --dark-text: #f8f8f2;
  --dark-text-muted: #6272a4;
  --dark-accent-cyan: #8be9fd;
  --dark-accent-green: #50fa7b;
  --dark-accent-orange: #ffb86c;
  --dark-accent-pink: #ff79c6;
  --dark-accent-purple: #bd93f9;
  --dark-accent-red: #ff5555;
  --dark-accent-yellow: #f1fa8c;
}

/* Apply dark theme customization */
[data-md-color-scheme="slate"] {
  --md-default-bg-color: var(--dark-bg);
  --md-default-fg-color: var(--dark-text);
  --md-default-fg-color--light: var(--dark-text-muted);
  --md-default-fg-color--lighter: var(--dark-bg-alt);
  --md-default-fg-color--lightest: var(--dark-bg-alt);

  --md-primary-fg-color: var(--dark-accent-purple);
  --md-primary-fg-color--light: var(--dark-accent-pink);
  --md-primary-fg-color--dark: var(--dark-accent-purple);
  --md-primary-bg-color: var(--dark-text);
  --md-primary-bg-color--light: var(--dark-text);

  --md-accent-fg-color: var(--dark-accent-pink);
  --md-accent-fg-color--transparent: rgba(255, 121, 198, 0.1);
  --md-accent-bg-color: var(--dark-accent-pink);

  --md-code-fg-color: var(--dark-text);
  --md-code-bg-color: var(--dark-bg-alt);

  --md-code-hl-color: rgba(255, 184, 108, 0.2);
  --md-code-hl-number-color: var(--dark-accent-purple);
  --md-code-hl-special-color: var(--dark-accent-pink);
  --md-code-hl-function-color: var(--dark-accent-green);
  --md-code-hl-constant-color: var(--dark-accent-purple);
  --md-code-hl-keyword-color: var(--dark-accent-pink);
  --md-code-hl-string-color: var(--dark-accent-yellow);
  --md-code-hl-name-color: var(--dark-text);
  --md-code-hl-operator-color: var(--dark-accent-pink);
  --md-code-hl-punctuation-color: var(--dark-text);
  --md-code-hl-comment-color: var(--dark-text-muted);
  --md-code-hl-generic-color: var(--dark-text);
  --md-code-hl-variable-color: var(--dark-text);

  --md-typeset-color: var(--dark-text);
  --md-typeset-a-color: var(--dark-accent-cyan);

  --md-typeset-kbd-color: var(--dark-text);
  --md-typeset-kbd-accent-color: var(--dark-bg-alt);
  --md-typeset-kbd-border-color: var(--dark-text-muted);

  --md-typeset-mark-color: rgba(241, 250, 140, 0.3);

  --md-typeset-table-color: var(--dark-bg-alt);

  --md-admonition-fg-color: var(--dark-text);
  --md-admonition-bg-color: var(--dark-bg-alt);

  --md-footer-bg-color: var(--dark-bg-alt);
  --md-footer-bg-color--dark: var(--dark-bg);
}

/* Navigation and sidebar */
[data-md-color-scheme="slate"] .md-nav__link {
  color: var(--dark-text);
}

[data-md-color-scheme="slate"] .md-nav__link:hover {
  color: var(--dark-accent-cyan);
}

[data-md-color-scheme="slate"] .md-nav__link--active {
  color: var(--dark-accent-pink);
}

/* Search */
[data-md-color-scheme="slate"] .md-search__input {
  background-color: var(--dark-bg-alt);
  color: var(--dark-text);
}

[data-md-color-scheme="slate"] .md-search__input::placeholder {
  color: var(--dark-text-muted);
}

/* Tables */
[data-md-color-scheme="slate"] .md-typeset table:not([class]) th {
  background-color: var(--dark-bg-alt);
  color: var(--dark-accent-purple);
}

[data-md-color-scheme="slate"] .md-typeset table:not([class]) tr:hover {
  background-color: rgba(68, 71, 90, 0.5);
}

/* Code blocks */
[data-md-color-scheme="slate"] .highlight {
  background-color: var(--dark-bg-alt);
}

[data-md-color-scheme="slate"] code {
  background-color: var(--dark-bg-alt);
  color: var(--dark-text);
}

/* Admonitions */
[data-md-color-scheme="slate"] .md-typeset .admonition,
[data-md-color-scheme="slate"] .md-typeset details {
  border-color: var(--dark-accent-purple);
  background-color: var(--dark-bg-alt);
}

[data-md-color-scheme="slate"] .md-typeset .admonition-title,
[data-md-color-scheme="slate"] .md-typeset summary {
  background-color: rgba(189, 147, 249, 0.1);
}

/* Note admonition */
[data-md-color-scheme="slate"] .md-typeset .admonition.note,
[data-md-color-scheme="slate"] .md-typeset details.note {
  border-color: var(--dark-accent-cyan);
}

[data-md-color-scheme="slate"] .md-typeset .note > .admonition-title,
[data-md-color-scheme="slate"] .md-typeset .note > summary {
  background-color: rgba(139, 233, 253, 0.1);
}

/* Warning admonition */
[data-md-color-scheme="slate"] .md-typeset .admonition.warning,
[data-md-color-scheme="slate"] .md-typeset details.warning {
  border-color: var(--dark-accent-orange);
}

[data-md-color-scheme="slate"] .md-typeset .warning > .admonition-title,
[data-md-color-scheme="slate"] .md-typeset .warning > summary {
  background-color: rgba(255, 184, 108, 0.1);
}

/* Danger/Error admonition */
[data-md-color-scheme="slate"] .md-typeset .admonition.danger,
[data-md-color-scheme="slate"] .md-typeset .admonition.error,
[data-md-color-scheme="slate"] .md-typeset details.danger,
[data-md-color-scheme="slate"] .md-typeset details.error {
  border-color: var(--dark-accent-red);
}

[data-md-color-scheme="slate"] .md-typeset .danger > .admonition-title,
[data-md-color-scheme="slate"] .md-typeset .error > .admonition-title,
[data-md-color-scheme="slate"] .md-typeset .danger > summary,
[data-md-color-scheme="slate"] .md-typeset .error > summary {
  background-color: rgba(255, 85, 85, 0.1);
}

/* Tip/Success admonition */
[data-md-color-scheme="slate"] .md-typeset .admonition.tip,
[data-md-color-scheme="slate"] .md-typeset .admonition.success,
[data-md-color-scheme="slate"] .md-typeset details.tip,
[data-md-color-scheme="slate"] .md-typeset details.success {
  border-color: var(--dark-accent-green);
}

[data-md-color-scheme="slate"] .md-typeset .tip > .admonition-title,
[data-md-color-scheme="slate"] .md-typeset .success > .admonition-title,
[data-md-color-scheme="slate"] .md-typeset .tip > summary,
[data-md-color-scheme="slate"] .md-typeset .success > summary {
  background-color: rgba(80, 250, 123, 0.1);
}
```

### Light Theme CSS

**File:** `docs/stylesheets/light.css`

```css
/* Light Theme Customization for MkDocs Material (OPTIONAL) */
/* MkDocs Material's built-in 'default' scheme already provides a light theme */
/* This file adds additional light theme customization */

:root {
  /* Light theme color palette */
  --light-bg: #ffffff;
  --light-bg-alt: #f5f5f5;
  --light-bg-elevated: #e0e0e0;
  --light-text: #1a1a1a;
  --light-text-muted: #666666;
  --light-accent-blue: #0066cc;
  --light-accent-green: #008000;
  --light-accent-orange: #ff8c00;
  --light-accent-red: #cc0000;
  --light-accent-purple: #6600cc;
  --light-accent-teal: #008080;
}

/* Apply light theme customization */
[data-md-color-scheme="default"] {
  --md-default-bg-color: var(--light-bg);
  --md-default-fg-color: var(--light-text);
  --md-default-fg-color--light: var(--light-text-muted);
  --md-default-fg-color--lighter: var(--light-bg-elevated);
  --md-default-fg-color--lightest: var(--light-bg-alt);

  --md-primary-fg-color: var(--light-accent-purple);
  --md-primary-fg-color--light: var(--light-accent-blue);
  --md-primary-fg-color--dark: var(--light-accent-purple);
  --md-primary-bg-color: var(--light-bg);
  --md-primary-bg-color--light: var(--light-bg-alt);

  --md-accent-fg-color: var(--light-accent-blue);
  --md-accent-fg-color--transparent: rgba(0, 102, 204, 0.1);
  --md-accent-bg-color: var(--light-accent-blue);

  --md-code-fg-color: var(--light-text);
  --md-code-bg-color: var(--light-bg-alt);

  --md-typeset-a-color: var(--light-accent-blue);
  --md-typeset-mark-color: rgba(255, 235, 59, 0.5);
}

/* Navigation */
[data-md-color-scheme="default"] .md-nav__link:hover {
  color: var(--light-accent-blue);
}

[data-md-color-scheme="default"] .md-nav__link--active {
  color: var(--light-accent-purple);
}

/* Admonitions */
[data-md-color-scheme="default"] .md-typeset .admonition.note,
[data-md-color-scheme="default"] .md-typeset details.note {
  border-color: var(--light-accent-blue);
}

[data-md-color-scheme="default"] .md-typeset .admonition.warning,
[data-md-color-scheme="default"] .md-typeset details.warning {
  border-color: var(--light-accent-orange);
}

[data-md-color-scheme="default"] .md-typeset .admonition.danger,
[data-md-color-scheme="default"] .md-typeset .admonition.error,
[data-md-color-scheme="default"] .md-typeset details.danger,
[data-md-color-scheme="default"] .md-typeset details.error {
  border-color: var(--light-accent-red);
}

[data-md-color-scheme="default"] .md-typeset .admonition.tip,
[data-md-color-scheme="default"] .md-typeset .admonition.success,
[data-md-color-scheme="default"] .md-typeset details.tip,
[data-md-color-scheme="default"] .md-typeset details.success {
  border-color: var(--light-accent-green);
}
```

## Documentation Templates

### docs/index.md

```markdown
# CASSPEED

{Brief project description}

## Quick Start

```bash
# Docker
docker run -p 64580:80 ghcr.io/casapps/casspeed:latest

# Binary
./casspeed-linux-amd64 --config server.yml
```

## Features

- {Feature 1}
- {Feature 2}
- {Feature 3}

## Documentation

- [Installation](installation.md) - How to install and run
- [Configuration](configuration.md) - All configuration options
- [API Reference](api.md) - REST API, Swagger, GraphQL
- [Admin Panel](admin.md) - Web UI administration
- [Development](development.md) - Contributing guide

## Links

- [GitHub Repository](https://github.com/casapps/casspeed)
- [Live Demo](https://casspeed.casapps.us) (if applicable)
- [API Documentation](/openapi) (Swagger UI)
- [GraphQL Playground](/graphql)

## License

MIT - See [LICENSE.md](https://github.com/casapps/casspeed/blob/main/LICENSE.md)
```

### docs/installation.md

```markdown
# Installation

## Docker (Recommended)

```bash
docker run -d \
  --name casspeed \
  -p 64580:80 \
  -v casspeed-data:/data \
  ghcr.io/casapps/casspeed:latest
```

## Binary

Download from [releases](https://github.com/casapps/casspeed/releases):

```bash
# Linux AMD64
wget https://github.com/casapps/casspeed/releases/latest/download/casspeed-linux-amd64
chmod +x casspeed-linux-amd64
./casspeed-linux-amd64
```

## Systemd Service

```bash
sudo ./casspeed --service install
sudo systemctl start casspeed
sudo systemctl enable casspeed
```

## Configuration

See [Configuration](configuration.md) for all options.
```

### docs/configuration.md

```markdown
# Configuration

## Config File

Default location: `/etc/casspeed/server.yml`

```yaml
server:
  address: 0.0.0.0
  port: 80

database:
  type: sqlite
  path: /data/db/server.db

# ... (all configuration options)
```

## Environment Variables

All settings can be overridden via environment:

```bash
CASSPEED_SERVER_PORT=8080
CASSPEED_DATABASE_TYPE=postgres
```

## Admin Panel

All settings are configurable via the web UI at `/admin`.
```

### docs/api.md

```markdown
# API Reference

## REST API

Base URL: `/api/v1/`

### Endpoints

| Endpoint | Method | Description |
|----------|--------|-------------|
| `/api/v1/healthz` | GET | Health check |
| `/api/v1/{resource}` | GET | List resources |

## Swagger UI

Interactive API documentation: [/openapi](/openapi)

## GraphQL

GraphQL playground: [/graphql](/graphql)

### Schema

```graphql
# ... (GraphQL schema)
```
```

### docs/admin.md

```markdown
# Admin Panel

## Access

- URL: `/admin`
- First-run setup wizard creates admin account
- Session-based authentication

## Features

- Server configuration
- User management
- Database management
- Backup/restore
- SSL/TLS management
- Monitoring & logs

## Admin API

Programmatic access via `/api/v1/admin/` with bearer token authentication.
```

### docs/development.md

```markdown
# Development Guide

## Prerequisites

- Go 1.21+
- Make
- Docker (optional)

## Build

```bash
git clone https://github.com/casapps/casspeed
cd casspeed
make build
```

## Run Locally

```bash
./binaries/casspeed --config server.yml --debug
```

## Testing

```bash
make test
```

## Contributing

1. Fork the repository
2. Create feature branch
3. Make changes
4. Run tests
5. Submit pull request

## Code Style

- Follow Go standard formatting
- Add tests for new features
- Update documentation
```

---

## Project-Specific Customization

**The theme colors defined above are DEFAULT values.** Individual projects MAY customize colors to match their branding, but MUST:

- Maintain WCAG AA contrast ratios (4.5:1 minimum)
- Keep both light and dark themes readable
- Update `docs/stylesheets/dark.css` and `docs/stylesheets/light.css` accordingly
- Document color choices in project's AI.md file

**Example project-specific customization:**
- Change accent colors to match project branding
- Adjust background shades for better contrast
- Add project logo colors to palette
- Ensure all changes work in BOTH themes

---

# PART 34: CLI CLIENT (PER-PROJECT)

## Overview

**CLI client is a PER-PROJECT determination.** Not all projects require a CLI client.

When a project includes a CLI client, it provides a terminal-based interface for interacting with the server. The CLI supports both standard command-line usage and an interactive TUI (Terminal User Interface) mode.

| Attribute | Value |
|-----------|-------|
| Default binary name | `casspeed-cli` |
| Versioning | Same as main application |
| Build | Part of same Makefile (`make build` produces both binaries) |
| Config location | `~/.config/casspeed/cli.yml` |

## Binary Naming Rules

**Same rules as server binary (see PART 6):**

- CLI client binary can be renamed by users
- Show ACTUAL binary name in user-facing places:
  - `--help` and `--version` output
  - Error messages, usage examples
- Hardcode `casspeed-cli` for:
  - User-Agent header (server uses this to identify client type)
  - Default config path uses `casspeed` not binary name

```go
// Get actual binary name for display
binaryName := filepath.Base(os.Args[0])

// Hardcoded for User-Agent (never changes)
const projectName = "jokes"  // compiled in via -ldflags
userAgent := fmt.Sprintf("%s-cli/%s", projectName, version)
```

## Modes

### Standard CLI Mode

Traditional command-line interface with commands, subcommands, and flags:

```bash
# Examples
jokes-cli get random
jokes-cli search --query "programming" --limit 10
jokes-cli list --output json
airports-cli lookup JFK
quotes-cli random --category motivation
```

### TUI Mode (Interactive)

Full terminal user interface with menus, panels, and keyboard navigation:

```bash
# Launch TUI
jokes-cli --tui
jokes-cli tui

# TUI provides:
# - Interactive menus
# - Search with live results
# - Keyboard shortcuts
# - Visual data display
```

**TUI Library:** Use `github.com/charmbracelet/bubbletea` for TUI implementation.

## Configuration

### Config File Location

| OS | Path |
|----|------|
| Linux | `~/.config/casspeed/cli.yml` |
| macOS | `~/.config/casspeed/cli.yml` |
| Windows | `%APPDATA%\casspeed\cli.yml` |

### Config Structure

```yaml
# CLI client configuration
server:
  # Server address (FQDN or IP:port)
  # Default: official site if defined for project, otherwise empty
  address: "https://api.example.com"

  # API token for authenticated requests (optional)
  token: ""

  # Request timeout in seconds
  timeout: 30

# Output preferences
output:
  # Default format: json, table, plain
  format: table

  # Colorize output (auto, always, never)
  color: auto

# TUI preferences
tui:
  # Theme: default, minimal, compact
  theme: default

  # Show help hints in TUI
  show_hints: true
```

### Default Server Address

| Scenario | `server.address` Default |
|----------|--------------------------|
| Project has official site | Official site URL (e.g., `https://jokes.example.com`) |
| No official site defined | Empty (must be configured by user) |

**Official site is defined in the project's AI.md specification.**

## Standard Flags (NON-NEGOTIABLE)

**ALL CLI clients MUST support these flags:**

| Flag | Short | Description |
|------|-------|-------------|
| `--help` | `-h` | Show help (same format as server `--help`) |
| `--version` | `-v` | Show version (same format as server `--version`) |
| `--server` | | Server address (overrides config) |
| `--token` | | API token (overrides config) |
| `--output` | | Output format: json, table, plain |
| `--config` | | Path to config file |
| `--no-color` | | Disable colored output |
| `--timeout` | | Request timeout in seconds |
| `--debug` | | Enable debug output |
| `--tui` | | Launch TUI mode |

**Short Flag Rule:** Only `-h` (help) and `-v` (version) may have short flags. All other flags use long form only.

### --help Output

**Note:** Examples show default name `jokes-cli`. Actual output uses `filepath.Base(os.Args[0])` - whatever the binary is named.

```bash
$ jokes-cli --help
jokes-cli v1.2.3 - CLI client for Jokes API

Usage:
  jokes-cli [command] [flags]

Commands:
  random      Get a random joke
  search      Search jokes
  categories  List categories
  get         Get joke by ID
  config      Manage configuration
  tui         Launch interactive TUI
  version     Show version information

Flags:
  -s, --server string    Server address (default: config or https://jokes.example.com)
  -t, --token string     API token for authentication
  -o, --output string    Output format: json, table, plain (default: table)
  -c, --config string    Path to config file
      --no-color         Disable colored output
      --timeout int      Request timeout in seconds (default: 30)
      --tui              Launch TUI mode
  -h, --help             Show help
  -v, --version          Show version

Use "jokes-cli [command] --help" for more information about a command.
```

**If user renames binary:**
```bash
$ myjokes --help
myjokes v1.2.3 - CLI client for Jokes API   # Shows actual name

Usage:
  myjokes [command] [flags]                   # Shows actual name
...
```

### --version Output

**MUST match server `--version` format. Shows ACTUAL binary name:**

```bash
$ jokes-cli --version
jokes-cli v1.2.3 (abc1234) built 2025-01-15

# If renamed:
$ myjokes --version
myjokes v1.2.3 (abc1234) built 2025-01-15   # Shows actual name
```

Same format as server:
```bash
$ jokes --version
jokes v1.2.3 (abc1234) built 2025-01-15
```

## Standard Commands (NON-NEGOTIABLE)

**ALL CLI clients MUST have these commands:**

| Command | Description |
|---------|-------------|
| `config` | Manage configuration |
| `config show` | Display current configuration |
| `config set <key> <value>` | Set configuration value |
| `config get <key>` | Get configuration value |
| `config init` | Create default config file |
| `version` | Show version information |
| `tui` | Launch TUI mode |

### Config Command Examples

```bash
# Initialize config file
jokes-cli config init

# Set server address
jokes-cli config set server.address https://jokes.example.com

# Set API token
jokes-cli config set server.token abc123

# Set default output format
jokes-cli config set output.format json

# Show current config
jokes-cli config show

# Get specific value
jokes-cli config get server.address
```

## Authentication

**Authentication requirements are PROJECT-DEPENDENT and ROUTE-DEPENDENT.**

| Auth Type | When Used |
|-----------|-----------|
| None | Public endpoints (e.g., `GET /api/v1/jokes/random`) |
| API Token | Protected endpoints, user-specific data |
| Session | Admin operations (if CLI supports admin features) |

**Token Storage:**
- Stored in `cli.yml` under `server.token`
- Can be overridden with `--token` flag
- Environment variable: `CASSPEED_CLI_TOKEN`

**Priority (highest to lowest):**
1. `--token` flag
2. `CASSPEED_CLI_TOKEN` environment variable
3. `server.token` in config file

## HTTP Client Identity (NON-NEGOTIABLE)

### User-Agent Rule

**The CLI binary can be renamed by users, but the User-Agent MUST always use the original project name.**

| Aspect | Uses Filename | Uses Original Name |
|--------|---------------|-------------------|
| Display in `--help` | ✓ | |
| Display in `--version` | ✓ | |
| Error messages | ✓ | |
| Config file path | ✓ | |
| **User-Agent header** | | ✓ |

**Why?** The server uses User-Agent to identify client types for:
- Client-specific rate limits
- Client-specific settings/features
- Analytics and usage tracking
- Version compatibility checks

### User-Agent Format

```
casspeed-cli/{version}
```

**Examples:**

| Binary Name | User-Agent Header |
|-------------|-------------------|
| `jokes-cli` | `jokes-cli/1.2.3` |
| `my-jokes` (renamed) | `jokes-cli/1.2.3` |
| `jk` (renamed) | `jokes-cli/1.2.3` |
| `airports-cli` | `airports-cli/1.2.3` |
| `apt` (renamed) | `airports-cli/1.2.3` |

### Implementation

The project name is compiled into the binary at build time:

```go
// Set at build time via -ldflags
var (
    ProjectName = "jokes"      // Original project name (compiled in)
    Version     = "1.2.3"
)

// GetUserAgent returns the fixed User-Agent regardless of binary name
func GetUserAgent() string {
    return fmt.Sprintf("%s-cli/%s", ProjectName, Version)
}

// GetBinaryName returns the actual executable name (for display)
func GetBinaryName() string {
    return filepath.Base(os.Args[0])
}
```

**Build command:**
```bash
go build -ldflags "-X main.ProjectName=jokes -X main.Version=1.2.3" -o jokes-cli src/client
```

### Server-Side Client Detection

The server can use the User-Agent to apply client-specific behavior:

```go
func getClientType(r *http.Request) string {
    ua := r.Header.Get("User-Agent")
    if strings.HasPrefix(ua, ProjectName+"-cli/") {
        return "cli"
    }
    if strings.Contains(ua, "Mozilla") || strings.Contains(ua, "Chrome") {
        return "browser"
    }
    return "api"
}
```

## Output Formats

### JSON

```bash
$ jokes-cli get random --output json
{
  "id": "abc123",
  "text": "Why do programmers prefer dark mode? Because light attracts bugs.",
  "category": "programming"
}
```

### Table

```bash
$ jokes-cli list --output table
┌──────────┬─────────────────────────────────────────────┬─────────────┐
│ ID       │ Text                                        │ Category    │
├──────────┼─────────────────────────────────────────────┼─────────────┤
│ abc123   │ Why do programmers prefer dark mode?...     │ programming │
│ def456   │ A SQL query walks into a bar...             │ programming │
│ ghi789   │ There are 10 types of people...             │ programming │
└──────────┴─────────────────────────────────────────────┴─────────────┘
```

### Plain

```bash
$ jokes-cli get random --output plain
Why do programmers prefer dark mode? Because light attracts bugs.
```

## Project-Specific Commands

Each project defines its own commands based on its API:

```bash
# Jokes project
jokes-cli random
jokes-cli search --query "programming"
jokes-cli categories

# Airports project
airports-cli lookup JFK
airports-cli search --city "New York"
airports-cli nearby --lat 40.7128 --lon -74.0060

# Quotes project
quotes-cli random
quotes-cli random --category motivation
quotes-cli search --author "Einstein"
```

## Build Integration

### Makefile Targets

```makefile
# Build both server and CLI (if src/client exists)
build:
	CGO_ENABLED=0 go build -o binaries/casspeed src
	@if [ -d "src/client" ]; then \
		CGO_ENABLED=0 go build -o binaries/casspeed-cli src/client; \
	fi

# Build CLI only
build-cli:
	CGO_ENABLED=0 go build -o binaries/casspeed-cli src/client

# Release builds (8 platforms)
release:
	# Server binaries
	GOOS=linux GOARCH=amd64 CGO_ENABLED=0 go build -o dist/casspeed-linux-amd64 src
	GOOS=linux GOARCH=arm64 CGO_ENABLED=0 go build -o dist/casspeed-linux-arm64 src
	# ... (other platforms)

	# CLI binaries (if src/client exists)
	@if [ -d "src/client" ]; then \
		GOOS=linux GOARCH=amd64 CGO_ENABLED=0 go build -o dist/casspeed-linux-amd64-cli src/client; \
		GOOS=linux GOARCH=arm64 CGO_ENABLED=0 go build -o dist/casspeed-linux-arm64-cli src/client; \
	fi
	# ... (other platforms)
```

### Directory Structure

```
casspeed/
├── src/                    # Server application
│   ├── main.go
│   ├── config/
│   ├── server/
│   ├── ...
│   └── client/             # CLI client (if project has CLI)
│       ├── main.go
│       ├── cmd/            # Command implementations
│       │   ├── root.go
│       │   ├── config.go
│       │   ├── version.go
│       │   └── {project-specific}.go
│       ├── tui/            # TUI implementation
│       │   ├── app.go
│       │   ├── views/
│       │   └── components/
│       └── api/            # API client library
│           └── client.go
├── go.mod
├── Makefile
└── ...
```

## TUI Requirements

### Minimum Features

| Feature | Required |
|---------|----------|
| Keyboard navigation | ✓ |
| Search/filter | ✓ |
| Help screen (?) | ✓ |
| Quit (q/Ctrl+C) | ✓ |
| Responsive layout | ✓ |
| Error display | ✓ |

### Recommended Libraries

| Library | Purpose |
|---------|---------|
| `github.com/charmbracelet/bubbletea` | TUI framework |
| `github.com/charmbracelet/bubbles` | TUI components |
| `github.com/charmbracelet/lipgloss` | TUI styling |

### TUI Theme

**TUI MUST use dark theme color scheme to match server frontend.**

```go
// Dark theme colors for TUI
var (
    Background = lipgloss.Color("#282a36")
    Foreground = lipgloss.Color("#f8f8f2")
    Selection  = lipgloss.Color("#44475a")
    Comment    = lipgloss.Color("#6272a4")
    Cyan       = lipgloss.Color("#8be9fd")
    Green      = lipgloss.Color("#50fa7b")
    Orange     = lipgloss.Color("#ffb86c")
    Pink       = lipgloss.Color("#ff79c6")
    Purple     = lipgloss.Color("#bd93f9")
    Red        = lipgloss.Color("#ff5555")
    Yellow     = lipgloss.Color("#f1fa8c")
)
```

## Error Handling

### Exit Codes

| Code | Meaning |
|------|---------|
| 0 | Success |
| 1 | General error |
| 2 | Configuration error |
| 3 | Connection error |
| 4 | Authentication error |
| 5 | Not found |
| 64 | Usage error (bad arguments) |

### Error Messages

```bash
# Connection error
$ jokes-cli random
Error: cannot connect to server at https://jokes.example.com
  Check your network connection and server address.
  Use --server to specify a different server.

# Auth error
$ jokes-cli admin users --token invalid
Error: authentication failed
  Your API token is invalid or expired.
  Use 'jokes-cli config set server.token <token>' to update.

# Not found
$ jokes-cli get abc123
Error: joke not found: abc123
```

## Version Command

```bash
$ jokes-cli version
jokes-cli v1.2.3

Server: https://jokes.example.com
Server Version: v1.2.3 (compatible)

Build Info:
  Go: go1.21.0
  OS/Arch: linux/amd64
  Commit: abc123
  Date: 2025-01-15
```

**Version compatibility check:** CLI queries server `/api/v1/version` and warns if versions differ significantly.

## Determining If Project Needs CLI

**Add CLI client to project if ANY of these apply:**

| Criterion | Example |
|-----------|---------|
| Data lookup/search use case | airports, zipcodes, countries |
| Power users benefit from terminal access | developers, sysadmins |
| Scripting/automation valuable | CI/CD integration, batch operations |
| Offline-friendly interactions | cached data, local operations |

**Skip CLI client if:**
- Project is purely web-based with no terminal use case
- API is too simple (single endpoint)
- Target audience doesn't use terminal

---


# PART 35: CUSTOM DOMAINS (OPTIONAL PER-PROJECT)

## Overview

**Custom domains is an OPTIONAL feature that allows users or organizations to use their own domains with the application.** Not all projects need this feature.

| Attribute | Description |
|-----------|-------------|
| Feature type | Optional, per-project |
| Scope | User-owned or Org-owned domains |
| SSL | Automatic via Let's Encrypt DNS-01 |
| Verification | TXT record ownership verification |

### When to Include This Feature

| Include | Skip | Reason |
|---------|------|--------|
| Linktree clone | Weather API | Users want branded links (myname.com) |
| Blog platform | Jokes API | Users publish under own domain |
| SaaS application | GeoIP service | Customers need branded instances |
| URL shortener | Pastebin | Users want custom short domains |
| E-commerce platform | Timezone API | Merchants want branded stores |

**Rule of thumb:** If users/orgs will publicly share content or services, they likely want custom domains. If the app is just an API or utility, skip this feature.

**Use cases (when included):**
- Blog platform: `myblog.example.com` → user's blog
- API service: `api.acme-corp.com` → org's API endpoint
- SaaS: `app.customer.com` → customer's branded instance
- Linktree: `links.myname.com` → user's link page

## Feature Configuration

**Enable custom domains in `server.yml`:**

```yaml
server:
  features:
    custom_domains:
      # Enable custom domain support
      enabled: false

      # Limit per user (0 = unlimited)
      max_domains_per_user: 5

      # Limit per org (0 = unlimited)
      max_domains_per_org: 20

      # Require SSL for all custom domains
      require_ssl: true

      # Allow apex domains (example.com)
      allow_apex: true

      # Allow subdomains (sub.example.com)
      allow_subdomain: true

      # Allow wildcard domains (*.example.com)
      allow_wildcard: false

      # Verification token TTL (24 hours)
      verification_ttl: 86400

      # Renew SSL certs N days before expiry
      ssl_renewal_days: 7

      # Reserved domains that cannot be used
      reserved:
        - "localhost"
        - "*.local"
        - "*.test"
        - "*.example"
        - "*.invalid"

      # Blocked patterns (regex)
      # Government/military/education TLDs
      blocked_patterns:
        - ".*\\.(gov|mil|edu)$"
```

**Environment variable override:**

```bash
CUSTOM_DOMAINS_ENABLED=true
CUSTOM_DOMAINS_MAX_PER_USER=5
CUSTOM_DOMAINS_MAX_PER_ORG=20
```

## Database Schema

**Tables in users.db:**

```sql
-- ----------------------------------------------------------------------------
-- Custom Domains
-- ----------------------------------------------------------------------------
CREATE TABLE IF NOT EXISTS custom_domains (
    id                  INTEGER PRIMARY KEY AUTOINCREMENT,

    -- Ownership
    owner_type          TEXT NOT NULL,                      -- user, org
    owner_id            INTEGER NOT NULL,                   -- FK to users or orgs

    -- Domain info
    domain              TEXT NOT NULL UNIQUE,               -- The custom domain
    is_apex             INTEGER NOT NULL DEFAULT 0,         -- Is apex domain (no subdomain)
    is_wildcard         INTEGER NOT NULL DEFAULT 0,         -- Is wildcard (*.example.com)

    -- Verification (domain must resolve to server IP)
    verification_status TEXT NOT NULL DEFAULT 'pending',    -- pending, verified, failed
    verified_at         INTEGER,                            -- When domain was verified
    verified_ip         TEXT,                               -- IP that domain resolved to
    last_check_at       INTEGER,                            -- Last verification check
    check_count         INTEGER NOT NULL DEFAULT 0,         -- Number of verification attempts

    -- SSL Configuration
    ssl_enabled         INTEGER NOT NULL DEFAULT 0,
    ssl_status          TEXT NOT NULL DEFAULT 'none',       -- none, pending, active, expired, error
    ssl_challenge       TEXT,                               -- http-01, tls-alpn-01, dns-01
    ssl_provider        TEXT,                               -- DNS provider (only for dns-01)
    ssl_credentials     TEXT,                               -- Encrypted provider credentials (only for dns-01)
    ssl_cert_pem        TEXT,                               -- Encrypted certificate (PEM)
    ssl_key_pem         TEXT,                               -- Encrypted private key (PEM)
    ssl_issued_at       INTEGER,
    ssl_expires_at      INTEGER,
    ssl_last_error      TEXT,                               -- Last SSL error message

    -- Status
    status              TEXT NOT NULL DEFAULT 'pending',    -- pending, active, suspended, error
    suspended_reason    TEXT,                               -- Why domain was suspended

    -- Timestamps
    created_at          INTEGER NOT NULL DEFAULT (strftime('%s', 'now')),
    updated_at          INTEGER NOT NULL DEFAULT (strftime('%s', 'now'))
);

CREATE UNIQUE INDEX IF NOT EXISTS idx_custom_domains_domain ON custom_domains(domain);
CREATE INDEX IF NOT EXISTS idx_custom_domains_owner ON custom_domains(owner_type, owner_id);
CREATE INDEX IF NOT EXISTS idx_custom_domains_status ON custom_domains(status);
CREATE INDEX IF NOT EXISTS idx_custom_domains_ssl_expires ON custom_domains(ssl_expires_at);

-- ----------------------------------------------------------------------------
-- Custom Domain Audit Log
-- ----------------------------------------------------------------------------
CREATE TABLE IF NOT EXISTS custom_domain_audit (
    id              INTEGER PRIMARY KEY AUTOINCREMENT,
    domain_id       INTEGER NOT NULL REFERENCES custom_domains(id) ON DELETE CASCADE,
    action          TEXT NOT NULL,                          -- created, verified, ssl_issued, suspended, deleted
    actor_type      TEXT NOT NULL,                          -- user, org, admin, system
    actor_id        INTEGER,
    details         TEXT,                                   -- JSON details
    created_at      INTEGER NOT NULL DEFAULT (strftime('%s', 'now'))
);

CREATE INDEX IF NOT EXISTS idx_domain_audit_domain ON custom_domain_audit(domain_id);
```

## Domain Resolution Flow

**How incoming requests are routed to custom domains:**

```
Incoming Request: https://api.customer.com/path
   │
   ├─► Extract Host header: api.customer.com
   │
   ├─► Check custom_domains table for matching domain
   │   │
   │   ├─► Not found → 404 or redirect to main domain
   │   │
   │   ├─► Found but status != 'active' → Show domain status page
   │   │
   │   └─► Found and active → Continue
   │
   ├─► Check SSL certificate valid
   │   │
   │   ├─► Expired/missing → Attempt renewal or show error
   │   │
   │   └─► Valid → Serve with custom domain's cert
   │
   └─► Route request to owner's resources
       │
       ├─► User-owned: Route to user's content/namespace
       │
       └─► Org-owned: Route to org's resources/namespace
```

**Go Implementation:**

```go
// DomainResolver handles custom domain routing
type DomainResolver struct {
    db       *sql.DB
    cache    *cache.Cache  // Cache domain lookups
    cacheTTL time.Duration
}

// Resolve looks up a custom domain and returns routing info
func (r *DomainResolver) Resolve(host string) (*CustomDomain, error) {
    // Check cache first
    if cached, ok := r.cache.Get(host); ok {
        return cached.(*CustomDomain), nil
    }

    // Query database
    var domain CustomDomain
    err := r.db.QueryRow(`
        SELECT id, owner_type, owner_id, domain, status, ssl_enabled,
               ssl_cert_pem, ssl_key_pem, ssl_expires_at
        FROM custom_domains
        WHERE domain = ? AND status = 'active'
    `, host).Scan(
        &domain.ID, &domain.OwnerType, &domain.OwnerID, &domain.Domain,
        &domain.Status, &domain.SSLEnabled, &domain.SSLCertPEM,
        &domain.SSLKeyPEM, &domain.SSLExpiresAt,
    )

    if err == sql.ErrNoRows {
        return nil, ErrDomainNotFound
    }
    if err != nil {
        return nil, err
    }

    // Cache result
    r.cache.Set(host, &domain, r.cacheTTL)

    return &domain, nil
}

// Middleware for custom domain handling
func CustomDomainMiddleware(resolver *DomainResolver) func(http.Handler) http.Handler {
    return func(next http.Handler) http.Handler {
        return http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {
            host := r.Host

            // Skip if it's the main application domain
            if host == config.MainDomain {
                next.ServeHTTP(w, r)
                return
            }

            // Resolve custom domain
            domain, err := resolver.Resolve(host)
            if err == ErrDomainNotFound {
                http.Error(w, "Domain not found", http.StatusNotFound)
                return
            }
            if err != nil {
                http.Error(w, "Internal error", http.StatusInternalServerError)
                return
            }

            // Add domain context
            ctx := context.WithValue(r.Context(), CustomDomainKey, domain)
            next.ServeHTTP(w, r.WithContext(ctx))
        })
    }
}
```

## Web Routes

### User Domain Management (`/user/domains/`)

| Path | Description |
|------|-------------|
| `/user/domains` | List user's custom domains |
| `/user/domains/add` | Add new custom domain form |
| `/user/domains/{domain}` | Domain details and management |
| `/user/domains/{domain}/dns` | DNS configuration instructions |
| `/user/domains/{domain}/ssl` | SSL configuration |
| `/user/domains/{domain}/verify` | Trigger verification |
| `/user/domains/{domain}/delete` | Delete confirmation |

### Org Domain Management (`/org/{slug}/domains/`)

| Path | Description |
|------|-------------|
| `/org/{slug}/domains` | List org's custom domains |
| `/org/{slug}/domains/add` | Add new custom domain form |
| `/org/{slug}/domains/{domain}` | Domain details and management |
| `/org/{slug}/domains/{domain}/dns` | DNS configuration instructions |
| `/org/{slug}/domains/{domain}/ssl` | SSL configuration |
| `/org/{slug}/domains/{domain}/verify` | Trigger verification |
| `/org/{slug}/domains/{domain}/delete` | Delete confirmation |

### Admin Domain Management (`/admin/server/domains/`)

| Path | Description |
|------|-------------|
| `/admin/server/domains` | List all custom domains |
| `/admin/server/domains/{domain}` | View/manage any domain |
| `/admin/server/domains/{domain}/suspend` | Suspend domain |
| `/admin/server/domains/{domain}/unsuspend` | Unsuspend domain |
| `/admin/server/domains/{domain}/delete` | Force delete domain |

## API Routes

### User Domain API (`/api/v1/user/domains/`)

| Route | Method | Description |
|-------|--------|-------------|
| `/api/v1/user/domains` | GET | List user's domains |
| `/api/v1/user/domains` | POST | Add new domain |
| `/api/v1/user/domains/{domain}` | GET | Get domain details |
| `/api/v1/user/domains/{domain}` | DELETE | Remove domain |
| `/api/v1/user/domains/{domain}/verify` | POST | Trigger verification |
| `/api/v1/user/domains/{domain}/dns` | GET | Get DNS records to configure |
| `/api/v1/user/domains/{domain}/ssl` | GET | Get SSL status |
| `/api/v1/user/domains/{domain}/ssl` | POST | Configure SSL (provider + credentials) |
| `/api/v1/user/domains/{domain}/ssl/renew` | POST | Force SSL renewal |

### Org Domain API (`/api/v1/org/{slug}/domains/`)

Same routes as user, scoped to organization.

### Admin Domain API (`/api/v1/admin/server/domains/`)

| Route | Method | Description |
|-------|--------|-------------|
| `/api/v1/admin/server/domains` | GET | List all domains (paginated) |
| `/api/v1/admin/server/domains/{domain}` | GET | Get any domain details |
| `/api/v1/admin/server/domains/{domain}` | DELETE | Force delete any domain |
| `/api/v1/admin/server/domains/{domain}/suspend` | POST | Suspend domain |
| `/api/v1/admin/server/domains/{domain}/unsuspend` | POST | Unsuspend domain |
| `/api/v1/admin/server/domains/{domain}/ssl/renew` | POST | Force SSL renewal |

## Verification Flow

**Verification is simple: the custom domain must resolve to the server's public IP or FQDN.**

### Step 1: User Adds Domain

```
POST /api/v1/user/domains
{
  "domain": "api.mycompany.com"
}

Response:
{
  "success": true,
  "domain": {
    "id": 123,
    "domain": "api.mycompany.com",
    "status": "pending",
    "verification_status": "pending",
    "dns_instructions": {
      "target": "custom.yourapp.com",
      "target_ips": ["203.0.113.50", "2001:db8::1"],
      "instructions": "Add a CNAME record pointing to custom.yourapp.com, or A/AAAA records pointing to the IPs above."
    }
  }
}
```

### Step 2: User Configures DNS

User adds ONE of these at their DNS provider:

```
; Option 1: CNAME (recommended for subdomains)
api.mycompany.com.          300  IN  CNAME  custom.yourapp.com.

; Option 2: A/AAAA records (required for apex domains)
mycompany.com.              300  IN  A      203.0.113.50
mycompany.com.              300  IN  AAAA   2001:db8::1
```

### Step 3: User Triggers Verification

```
POST /api/v1/user/domains/api.mycompany.com/verify

Response (success):
{
  "success": true,
  "domain": {
    "domain": "api.mycompany.com",
    "verification_status": "verified",
    "verified_at": "2025-01-15T10:30:00Z",
    "status": "active",
    "resolved_to": "203.0.113.50"
  }
}

Response (failed - wrong IP):
{
  "success": false,
  "error": "Domain does not resolve to this server",
  "code": "ERR_DNS_MISMATCH",
  "details": {
    "expected": ["203.0.113.50", "2001:db8::1"],
    "got": ["198.51.100.25"],
    "hint": "DNS propagation can take up to 48 hours"
  }
}
```

### Verification Logic

```go
func (s *DomainService) Verify(domainID int64) (*VerifyResult, error) {
    domain, err := s.GetByID(domainID)
    if err != nil {
        return nil, err
    }

    // Get server's public IPs
    serverIPs := s.getServerPublicIPs()

    // Resolve the custom domain
    ips, err := net.LookupIP(domain.Domain)
    if err != nil {
        return &VerifyResult{
            Success: false,
            Error:   "DNS lookup failed",
            Code:    "ERR_DNS_LOOKUP",
        }, nil
    }

    // Check if any resolved IP matches server IP
    matched := false
    var resolvedIPs []string
    for _, ip := range ips {
        resolvedIPs = append(resolvedIPs, ip.String())
        for _, serverIP := range serverIPs {
            if ip.Equal(serverIP) {
                matched = true
                break
            }
        }
    }

    if !matched {
        return &VerifyResult{
            Success: false,
            Error:   "Domain does not resolve to this server",
            Code:    "ERR_DNS_MISMATCH",
            Details: map[string]interface{}{
                "expected": serverIPs,
                "got":      resolvedIPs,
            },
        }, nil
    }

    // Mark as verified
    domain.VerificationStatus = "verified"
    domain.VerifiedAt = time.Now().Unix()
    domain.Status = "active"

    if err := s.Update(domain); err != nil {
        return nil, err
    }

    // Log audit event
    s.audit.Log(domain.ID, "verified", domain.OwnerType, domain.OwnerID, nil)

    return &VerifyResult{Success: true, ResolvedTo: resolvedIPs[0]}, nil
}

// getServerPublicIPs returns all public IPs the server is reachable on
// Uses cached external IP discovery (refreshed every 12 hours)
func (s *DomainService) getServerPublicIPs() []net.IP {
    var ips []net.IP

    // From DOMAIN env var / configured FQDN
    if fqdn := config.GetFQDN(); fqdn != "" {
        if resolved, err := net.LookupIP(fqdn); err == nil {
            ips = append(ips, resolved...)
        }
    }

    // From external IP discovery (works in containers)
    // This is cached and refreshed every 12 hours by scheduler
    if cached := s.cache.Get("server_public_ips"); cached != nil {
        ips = append(ips, cached.([]net.IP)...)
    }

    return ips
}

// discoverPublicIPs discovers our public IP addresses
// Called on startup and every 12 hours (hardcoded, sensible interval)
// Safe to expose in /healthz - same info available via `dig`
func discoverPublicIPs() ([]net.IP, error) {
    var ips []net.IP

    // IPv4: Always use external lookup (containers/NAT hide real IP)
    ipv4Services := []string{
        "https://api.ipify.org",
        "https://ifconfig.me/ip",
        "https://icanhazip.com",
        "https://checkip.amazonaws.com",
    }

    for _, url := range ipv4Services {
        if ip := fetchIP(url); ip != nil && ip.To4() != nil {
            ips = append(ips, ip)
            break
        }
    }

    // IPv6: Check local interfaces first for global addresses
    if globalIPv6 := getLocalGlobalIPv6(); globalIPv6 != nil {
        ips = append(ips, globalIPv6)
    }

    if len(ips) == 0 {
        return nil, errors.New("failed to discover public IP")
    }

    return ips, nil
}

// getLocalGlobalIPv6 returns the first global unicast IPv6 address from local interfaces
func getLocalGlobalIPv6() net.IP {
    ifaces, err := net.Interfaces()
    if err != nil {
        return nil
    }

    for _, iface := range ifaces {
        // Skip loopback and down interfaces
        if iface.Flags&net.FlagLoopback != 0 || iface.Flags&net.FlagUp == 0 {
            continue
        }

        addrs, err := iface.Addrs()
        if err != nil {
            continue
        }

        for _, addr := range addrs {
            var ip net.IP
            switch v := addr.(type) {
            case *net.IPNet:
                ip = v.IP
            case *net.IPAddr:
                ip = v.IP
            }

            // Must be IPv6 (not IPv4) and global unicast (not link-local, not ULA)
            if ip != nil && ip.To4() == nil && ip.IsGlobalUnicast() && !isULA(ip) {
                return ip
            }
        }
    }
    return nil
}

// isULA checks if IP is a Unique Local Address (fc00::/7)
func isULA(ip net.IP) bool {
    return len(ip) == net.IPv6len && (ip[0]&0xfe) == 0xfc
}

func fetchIP(url string) net.IP {
    client := &http.Client{Timeout: 5 * time.Second}
    resp, err := client.Get(url)
    if err != nil {
        return nil
    }
    defer resp.Body.Close()

    body, err := io.ReadAll(io.LimitReader(resp.Body, 64))
    if err != nil {
        return nil
    }

    return net.ParseIP(strings.TrimSpace(string(body)))
}
```

## SSL Challenge Types

**Three ACME challenge types are supported for custom domain SSL:**

| Challenge | Requirements | Best For |
|-----------|--------------|----------|
| **HTTP-01** | Port 80 accessible | Direct server access |
| **TLS-ALPN-01** | Port 443 accessible | Behind reverse proxy (recommended) |
| **DNS-01** | DNS API credentials | Wildcard certs, firewalled servers |

### Challenge Selection Logic

```go
func (s *DomainService) selectChallengeType(domain *CustomDomain) string {
    // If user explicitly configured DNS provider, use DNS-01
    if domain.SSLProvider != "" {
        return "dns-01"
    }

    // If domain is wildcard, must use DNS-01
    if domain.IsWildcard {
        return "dns-01"
    }

    // Try TLS-ALPN-01 first (works behind reverse proxy)
    // This is preferred because it uses port 443 which is usually available
    if s.canUseTLSALPN() {
        return "tls-alpn-01"
    }

    // Fall back to HTTP-01
    if s.canUseHTTP() {
        return "http-01"
    }

    // Must configure DNS provider
    return "dns-01"
}
```

## SSL Configuration Flow

### Automatic SSL (HTTP-01 / TLS-ALPN-01)

**For verified domains, SSL can be issued automatically without user configuration:**

```
POST /api/v1/user/domains/api.mycompany.com/ssl
{
  "challenge": "auto"   // or "http-01", "tls-alpn-01"
}

Response:
{
  "success": true,
  "domain": {
    "domain": "api.mycompany.com",
    "ssl_status": "active",
    "ssl_challenge": "tls-alpn-01",
    "ssl_issued_at": "2025-01-15T10:30:00Z",
    "ssl_expires_at": "2025-04-15T10:30:00Z"
  }
}
```

**TLS-ALPN-01 behind reverse proxy:**

The server handles the ACME TLS-ALPN-01 challenge on port 443. This works behind a reverse proxy as long as the proxy forwards TLS connections for the custom domain to the backend.

### DNS-01 (Manual Configuration)

**For wildcards or when HTTP/TLS challenges aren't available:**

```
POST /api/v1/user/domains/api.mycompany.com/ssl
{
  "challenge": "dns-01",
  "provider": "cloudflare",
  "credentials": {
    "api_token": "cf_xxx..."
  }
}
```

The system validates credentials, encrypts them, and stores for reuse.

### Certificate Issuance

```go
func (s *DomainService) issueCertificate(domain *CustomDomain) error {
    // Create ACME client
    acmeClient := acme.NewClient(acme.Config{
        Email:   s.config.LetsEncryptEmail,
        Staging: s.config.LetsEncryptStaging,
    })

    var cert, key []byte
    var err error

    switch domain.SSLChallenge {
    case "http-01":
        // HTTP-01: Serve challenge on /.well-known/acme-challenge/
        cert, key, err = acmeClient.ObtainCertificateHTTP(domain.Domain)

    case "tls-alpn-01":
        // TLS-ALPN-01: Handle ALPN challenge on port 443
        cert, key, err = acmeClient.ObtainCertificateTLSALPN(domain.Domain)

    case "dns-01":
        // DNS-01: Use configured DNS provider
        creds, err := s.decryptCredentials(domain.SSLCredentials)
        if err != nil {
            return s.setSSLError(domain, err)
        }
        dnsProvider, err := dns.NewProvider(domain.SSLProvider, creds)
        if err != nil {
            return s.setSSLError(domain, err)
        }
        cert, key, err = acmeClient.ObtainCertificateDNS(domain.Domain, dnsProvider)
    }

    if err != nil {
        return s.setSSLError(domain, err)
    }

    // Encrypt and store certificate
    domain.SSLCertPEM = s.encrypt(cert)
    domain.SSLKeyPEM = s.encrypt(key)
    domain.SSLIssuedAt = time.Now().Unix()
    domain.SSLExpiresAt = extractExpiry(cert)
    domain.SSLStatus = "active"
    domain.SSLEnabled = true

    // Clear cache to pick up new cert
    s.cache.Delete(domain.Domain)

    return s.Update(domain)
}
```

### Challenge Endpoints

**HTTP-01 Challenge Handler:**

```go
// Serves ACME HTTP-01 challenges for all custom domains
// Route: GET /.well-known/acme-challenge/{token}
func (s *Server) handleACMEChallenge(w http.ResponseWriter, r *http.Request) {
    token := chi.URLParam(r, "token")
    host := r.Host

    // Look up challenge response for this domain + token
    response, err := s.acmeStore.GetChallenge(host, token)
    if err != nil {
        http.NotFound(w, r)
        return
    }

    w.Header().Set("Content-Type", "text/plain")
    w.Write([]byte(response))
}
```

**TLS-ALPN-01 requires TLS config that handles the ACME-TLS/1 protocol.**

## Scheduled Tasks

**Add to scheduler configuration:**

**System task (hardcoded, not configurable):**
- `public_ip_refresh` - Runs on startup and every 12 hours
- IPv4: External lookup (containers/NAT hide real IP)
- IPv6: Check local interfaces for global unicast address

```yaml
server:
  scheduler:
    tasks:
      custom_domain_verification:
        enabled: true
        schedule: "*/15 * * * *"        # Every 15 minutes
        description: "Retry pending domain verifications"

      custom_domain_ssl_renewal:
        enabled: true
        schedule: "0 4 * * *"           # Daily at 4:00 AM
        description: "Renew expiring custom domain SSL certs"
        renew_before: 7d

      custom_domain_cleanup:
        enabled: true
        schedule: "0 5 * * *"           # Daily at 5:00 AM
        description: "Remove unverified domains after TTL"
```

**Public IP in /healthz:**

The discovered public IPs are safe to include in `/healthz` - same info anyone can get with `dig {fqdn}`.
- IPv4: From external lookup (needed for containers/NAT)
- IPv6: From local interface if global unicast address exists

```json
{
  "status": "healthy",
  "version": "1.0.0",
  "public_ips": {
    "ipv4": "203.0.113.50",
    "ipv6": "2001:db8::1",
    "last_checked": "2025-01-15T10:00:00Z"
  }
}
```

## Error Handling

| Error Code | HTTP | Description |
|------------|------|-------------|
| `ERR_DOMAIN_EXISTS` | 409 | Domain already registered |
| `ERR_DOMAIN_RESERVED` | 400 | Domain is reserved/blocked |
| `ERR_DOMAIN_LIMIT` | 400 | Max domains limit reached |
| `ERR_DOMAIN_INVALID` | 400 | Invalid domain format |
| `ERR_DOMAIN_NOT_FOUND` | 404 | Domain not found |
| `ERR_DOMAIN_NOT_VERIFIED` | 400 | Domain not yet verified |
| `ERR_DOMAIN_SUSPENDED` | 403 | Domain is suspended |
| `ERR_DNS_LOOKUP` | 400 | DNS lookup failed |
| `ERR_DNS_MISMATCH` | 400 | Domain does not resolve to server IP |
| `ERR_SSL_PROVIDER` | 400 | Invalid DNS provider for SSL |
| `ERR_SSL_CREDENTIALS` | 400 | DNS credentials validation failed |
| `ERR_SSL_CHALLENGE` | 400 | ACME challenge failed |
| `ERR_SSL_ISSUANCE` | 500 | Certificate issuance failed |

## Admin Controls

**Server admins can:**

| Action | Description |
|--------|-------------|
| View all domains | List all custom domains across users/orgs |
| Suspend domain | Disable a domain (shows suspension page) |
| Unsuspend domain | Re-enable a suspended domain |
| Force delete | Remove any domain immediately |
| Force SSL renewal | Trigger certificate renewal |
| View audit log | See all domain actions |

**Suspension reasons:**

| Reason | Description |
|--------|-------------|
| `abuse` | Domain used for abuse/spam |
| `tos_violation` | Terms of service violation |
| `billing` | Payment issue (if applicable) |
| `security` | Security concern |
| `admin_request` | Manual admin action |

## WebUI Components

### Domain List Page

```
┌─────────────────────────────────────────────────────────────────┐
│ Custom Domains                                    [+ Add Domain] │
├─────────────────────────────────────────────────────────────────┤
│ Domain                    │ Status   │ SSL      │ Actions       │
├───────────────────────────┼──────────┼──────────┼───────────────┤
│ api.mycompany.com        │ ✅ Active │ 🔒 Valid │ [Manage]      │
│ blog.example.org         │ ⏳ Pending│ ⚠️ None  │ [Verify][DNS] │
│ old.domain.com           │ ❌ Error  │ ❌ Error │ [Fix][Delete] │
└─────────────────────────────────────────────────────────────────┘
```

### DNS Configuration Page

```
┌─────────────────────────────────────────────────────────────────┐
│ DNS Configuration for api.mycompany.com                         │
├─────────────────────────────────────────────────────────────────┤
│ Add these records at your DNS provider:                         │
│                                                                 │
│ ┌─────────────────────────────────────────────────────────────┐ │
│ │ Type: TXT                                                   │ │
│ │ Name: _verify.api.mycompany.com                            │ │
│ │ Value: verify_abc123def456                       [Copy]    │ │
│ │ Status: ✅ Verified                                         │ │
│ └─────────────────────────────────────────────────────────────┘ │
│                                                                 │
│ ┌─────────────────────────────────────────────────────────────┐ │
│ │ Type: CNAME                                                 │ │
│ │ Name: api.mycompany.com                                    │ │
│ │ Value: custom.yourapp.com                        [Copy]    │ │
│ │ Status: ⏳ Pending                                          │ │
│ └─────────────────────────────────────────────────────────────┘ │
│                                                                 │
│ [Check DNS Records]                                             │
│                                                                 │
│ ℹ️ DNS changes can take up to 48 hours to propagate.            │
└─────────────────────────────────────────────────────────────────┘
```

### SSL Configuration Page

```
┌─────────────────────────────────────────────────────────────────┐
│ SSL Configuration for api.mycompany.com                         │
├─────────────────────────────────────────────────────────────────┤
│ SSL Status: 🔒 Active                                           │
│ Certificate: Let's Encrypt                                      │
│ Expires: 2025-04-15 (in 90 days)                               │
│                                                                 │
│ DNS Provider: Cloudflare                                        │
│ Credentials: ✅ Valid (last checked: 2 hours ago)               │
│                                                                 │
│ [Renew Now] [Change Provider]                                   │
└─────────────────────────────────────────────────────────────────┘

OR (if not configured):

┌─────────────────────────────────────────────────────────────────┐
│ SSL Configuration for api.mycompany.com                         │
├─────────────────────────────────────────────────────────────────┤
│ SSL Status: ⚠️ Not Configured                                   │
│                                                                 │
│ To enable SSL, we need access to your DNS provider to complete │
│ the ACME DNS-01 challenge.                                      │
│                                                                 │
│ DNS Provider: [Cloudflare          ▼]                           │
│                                                                 │
│ ┌─────────────────────────────────────────────────────────────┐ │
│ │ API Token: [________________________________]               │ │
│ │                                                             │ │
│ │ ℹ️ Create a token with Zone:DNS:Edit permission             │ │
│ └─────────────────────────────────────────────────────────────┘ │
│                                                                 │
│ [Validate & Enable SSL]                                         │
│                                                                 │
│ 🔒 Credentials are encrypted and stored securely.               │
└─────────────────────────────────────────────────────────────────┘
```

## Implementation Checklist

When implementing custom domains for a project:

- [ ] Add feature flag to configuration
- [ ] Create database tables (custom_domains, custom_domain_records, custom_domain_audit)
- [ ] Implement domain resolver middleware
- [ ] Create user web routes (/user/domains/*)
- [ ] Create user API routes (/api/v1/user/domains/*)
- [ ] Create org web/API routes (if orgs supported)
- [ ] Create admin management routes
- [ ] Implement DNS verification
- [ ] Implement SSL issuance via ACME DNS-01
- [ ] Add scheduled tasks (verification retry, SSL renewal, cleanup)
- [ ] Add domain caching
- [ ] Add rate limiting for domain operations
- [ ] Create WebUI pages
- [ ] Update README.md if project uses custom domains

---


# PART 36: PROJECT-SPECIFIC SECTIONS

**This section defines WHAT your project does (business logic, intent, unique features), NOT HOW to implement it.**

## ⚠️ CRITICAL: Business Logic Only

**PARTS 1-35 define HOW to build (standards, patterns, structure).**
**PART 36 defines WHAT this project does (business logic, unique features).**

**PART 36 should contain:**
- ✓ Business purpose and intent
- ✓ Unique data structures and models
- ✓ Business rules and validation logic
- ✓ Data sources and content
- ✓ Special algorithms or logic
- ✓ Project-specific features

**PART 36 should NOT contain:**
- ✗ Route implementation details (follow PART 20: API Structure)
- ✗ HTML/CSS/frontend patterns (follow PART 17: Web Frontend)
- ✗ Config file format/structure (follow PART 5: Configuration)
- ✗ Database table schemas (follow PART 24: Database)
- ✗ Authentication patterns (follow PART 23: User Management)
- ✗ Testing approaches (follow PART 13: Testing)

**Rule: AI reads PART 36 for business logic, then implements using standards from PARTS 1-35.**

---

## Project Business Purpose

**Purpose:** Provide a free, self-hosted network speed testing solution as an alternative to speedtest.net

**Target Users:**
- Home lab enthusiasts monitoring their network performance over time
- Network administrators needing internal bandwidth testing capabilities
- Privacy-conscious users who want self-hosted network testing without tracking
- Organizations requiring on-premises speed test infrastructure
- System administrators automating bandwidth monitoring via CLI

**Unique Value:**
- Complete self-hosted solution with no external dependencies for testing
- Historical test results with graphical visualization of trends
- Both web interface and CLI client for different use cases
- No advertisements, tracking, or artificial feature limitations
- Multi-threaded testing for accurate high-bandwidth measurements
- Real-time progress indicators during tests
- Latency, jitter, and packet loss measurements
- Support for concurrent testing from multiple clients

## Business Logic & Rules

**Speed Test Rules:**
- Download test: Multi-threaded downloads with random data generation
- Upload test: Multi-threaded uploads with random data
- Ping test: Multiple ICMP or HTTP ping measurements for latency
- Test duration: Configurable (default: 10 seconds per direction)
- Thread count: Auto-scaled based on connection speed detection (1-16 threads)
- Data chunk size: Dynamic sizing based on bandwidth (prevents memory issues)
- Minimum test interval: 5 seconds between tests (prevent abuse)
- Maximum concurrent tests per IP: 3 (prevent server overload)

**Result Storage:**
- Test results stored in SQLite database per user/IP
- Fields: timestamp, download_mbps, upload_mbps, ping_ms, jitter_ms, packet_loss_percent, client_ip, user_agent
- Retention: Configurable (default: 90 days, 0 = unlimited)
- Anonymous mode: Tests without user account (stored by IP hash)
- Registered mode: Tests stored in user account history

**Validation:**
- Download/upload speed: Must be > 0 and < 100,000 Mbps (sanity check)
- Ping: Must be > 0ms and < 10,000ms
- Jitter: Must be >= 0ms
- Packet loss: 0-100 percent
- Test ID: UUID v4 format
- Client IP: Valid IPv4 or IPv6 address

**Privacy:**
- IP addresses hashed with salt before storage (privacy mode)
- User-agent stored for compatibility tracking
- No geolocation or tracking cookies
- Results only accessible by creator (or server admin)
- Option to delete individual or all test results

## Data Models

```go
// SpeedTest represents a single speed test result
type SpeedTest struct {
    ID            string    `json:"id"`              // UUID v4
    Timestamp     time.Time `json:"timestamp"`       // When test was run
    DownloadMbps  float64   `json:"download_mbps"`   // Download speed in Mbps
    UploadMbps    float64   `json:"upload_mbps"`     // Upload speed in Mbps
    PingMs        float64   `json:"ping_ms"`         // Average ping in milliseconds
    JitterMs      float64   `json:"jitter_ms"`       // Ping jitter in milliseconds
    PacketLoss    float64   `json:"packet_loss"`     // Packet loss percentage (0-100)
    ClientIPHash  string    `json:"-"`               // Hashed client IP (not exposed via API)
    UserAgent     string    `json:"user_agent"`      // Client user agent
    ServerID      string    `json:"server_id"`       // Which server ran the test (clustering)
    UserID        string    `json:"user_id,omitempty"` // Optional: user account ID
}

// TestProgress represents real-time test progress (WebSocket updates)
type TestProgress struct {
    TestID      string  `json:"test_id"`
    Stage       string  `json:"stage"`        // "ping", "download", "upload", "complete"
    Progress    float64 `json:"progress"`     // 0.0-1.0 percentage
    CurrentSpeed float64 `json:"current_speed"` // Current Mbps during download/upload
    Message     string  `json:"message"`      // Status message
}

// TestSummary represents aggregated test statistics
type TestSummary struct {
    TotalTests    int     `json:"total_tests"`
    AvgDownload   float64 `json:"avg_download_mbps"`
    AvgUpload     float64 `json:"avg_upload_mbps"`
    AvgPing       float64 `json:"avg_ping_ms"`
    MaxDownload   float64 `json:"max_download_mbps"`
    MaxUpload     float64 `json:"max_upload_mbps"`
    MinPing       float64 `json:"min_ping_ms"`
    DateRange     string  `json:"date_range"`
}

// ServerInfo represents speed test server information
type ServerInfo struct {
    ServerID   string `json:"server_id"`
    Name       string `json:"name"`
    Location   string `json:"location"`
    Host       string `json:"host"`
    Country    string `json:"country"`
    Sponsor    string `json:"sponsor,omitempty"`
}
```

## Data Sources

**Speed Test Data Generation:**
- Random data generated on-the-fly for download tests (no static files)
- Zero-buffer data sink for upload tests (discarded immediately)
- Data patterns: Compressible and non-compressible options (test compression impact)

**Test Results Storage:**
- SQLite database: `{datadir}/db/speedtest.db`
- Schema automatically created on first run
- Automatic migrations on version updates
- No external data sources (fully self-contained)

**Configuration:**
- server.yml: Server configuration (test parameters, limits, retention)
- Embedded defaults in binary (no config file required for basic operation)

**Update Strategy:**
- Database: Runtime writes for test results
- Configuration: Hot-reload supported (no restart required)
- No embedded data files (all data is user-generated test results)

## Project-Specific Endpoints Summary

**Implementation of these endpoints MUST follow PART 20 (API Structure) and PART 17 (Web Frontend) rules.**

**Speedtest Endpoints:**

**Core Test Endpoints:**
- **Start test:** Initialize a new speed test and return test ID
- **Test download:** Multi-threaded download speed measurement
- **Test upload:** Multi-threaded upload speed measurement  
- **Test ping:** Latency and jitter measurement
- **Test status:** Real-time progress updates (WebSocket or SSE)
- **Get result:** Retrieve completed test result by ID

**Results Management:**
- **List results:** Paginated list of test history (by user/IP)
- **Get statistics:** Aggregated stats (averages, min/max, trends)
- **Delete result:** Remove specific test result
- **Delete all results:** Clear all test history for user
- **Export results:** Download test history as CSV/JSON

**Server Information:**
- **Server info:** Get server details (name, location, capabilities)
- **Server list:** List available test servers (multi-server support)

**Business Behavior:**

**Test Execution:**
- Tests run in stages: ping → download → upload
- Each stage reports progress via WebSocket/SSE
- Download test: Server sends random data, client measures receipt speed
- Upload test: Client sends data, server measures and discards
- Ping test: Multiple round-trip measurements (min 10 samples)
- Thread scaling: Starts with 1 thread, adds threads if speed plateaus
- Timeout: 60 seconds total per test (prevents hung tests)

**Result Storage:**
- Immediate storage after each test completes
- Results indexed by timestamp and user/IP hash
- Privacy mode: IP addresses hashed, no PII stored
- Retention: Auto-delete results older than configured days (default 90)

**Rate Limiting:**
- Maximum 3 concurrent tests per IP address
- Minimum 5 second interval between tests from same IP
- Configurable via server.yml (admins can adjust limits)

**Multi-Server Support (Optional):**
- Each server has unique ID and metadata
- Clients can select preferred test server
- Results tagged with server_id for comparison
- Server list API provides available servers

## Extended Node Functions (If Applicable)

**Not applicable for casspeed.**

This project only requires standard clustering (config sync). Speed test servers do not manage external nodes.

## High Availability Requirements (If Applicable)

**Not applicable for casspeed.**

Speed testing does not require HA. Clustering provides config sync and distributed capacity, but no automatic failover is needed. Users can manually choose different servers if one is unavailable.

## Notes

**Architecture Decisions:**
- Multi-threaded testing is critical for accurate high-bandwidth measurements (single-thread limited by TCP window)
- WebSocket or SSE for real-time progress (better UX than polling)
- SQLite sufficient for test history (low write volume, simple queries)
- Privacy-first: IP hashing prevents identifying users from logs
- No external test servers required (fully self-contained)

**CLI Client Considerations:**
- CLI client is REQUIRED (not optional per PART 34) for server-side automated testing
- CLI should support same test workflow: run test, view history, export results
- Useful for cron jobs, monitoring scripts, and headless servers

**Performance Considerations:**
- Random data generation must be fast (use crypto/rand or similar)
- Upload data should be discarded without buffering (prevent memory bloat)
- Thread pool management to prevent resource exhaustion
- Rate limiting essential to prevent DoS

**Future Enhancements:**
- IPv6 vs IPv4 comparison testing
- MTU discovery and path analysis
- Visual traceroute integration
- Speed test scheduling (automated recurring tests)
- Comparison against public speedtest.net results

---

# FINAL CHECKPOINT: COMPLIANCE CHECKLIST

---

## FOR AI ASSISTANTS (STRICT RULES)

**These rules are NON-NEGOTIABLE. Violation is unacceptable.**

### Document Rules

- [ ] **AI.md is the ONLY project specification** - nothing else
- [ ] **AI.md does NOT exist in projects** - it lives only in apimgr repo
- [ ] **NEVER reference AI.md** - projects don't have it, don't need it
- [ ] If AI.md missing, ask human to create it (or create from AI.md in apimgr)
- [ ] Keep AI.md in sync with PROJECT STATE
- [ ] Migrate old files: `CLAUDE.md`, `SPEC.md` → merge into `AI.md`, DELETE old files
- [ ] Use TODO.AI.md for tasks when more than 2 items

### Behavior Rules

- [ ] **NEVER assume or guess** - ask questions when unclear
- [ ] **NEVER skip steps** - follow specifications exactly
- [ ] **NEVER add features not requested** - implement what is specified
- [ ] **NEVER use deprecated patterns** - check the spec for current standards
- [ ] **ALWAYS verify before modifying** - read existing code first
- [ ] **ALWAYS use exact naming** - config paths, routes, file names as specified
- [ ] **ALWAYS check cross-references** - ensure consistency across sections

### Code Rules

- [ ] CGO_ENABLED=0 - no exceptions, static binaries only
- [ ] No external runtime dependencies - everything embedded
- [ ] Use ONLY approved libraries (see PART 5)
- [ ] Follow exact config paths: `server.xxx`, not variations
- [ ] Follow exact route patterns: `/api/v1/admin/server/xxx`
- [ ] Token prefixes: `adm_` (admin), `key_` (API key), `ses_` (session)
- [ ] Setup token: 32 hex chars, no dashes

### When Starting Work

1. Read AI.md completely - this is the ONLY project specification
2. Read TODO.AI.md for current tasks (if exists)
3. Identify the specific task/section
4. Check for cross-references to other sections
5. Ask clarifying questions BEFORE implementing
6. Implement exactly as specified
7. Verify consistency with related sections
8. Update TODO.AI.md when tasks complete

**Note:** AI.md does NOT exist in projects. AI.md IS the spec.

---

## FOR HUMANS (PROJECT CHECKLIST)

### Project Files

- [ ] `AI.md` - Complete project specification (required, THE spec)
- [ ] `TODO.AI.md` - Task tracking (when needed)
- [ ] `README.md` - User documentation (required)
- [ ] `LICENSE.md` - License file (required)
- [ ] `Makefile` - Build targets (required)
- [ ] `Dockerfile` - Container build (required)
- [ ] `go.mod` / `go.sum` - Go modules (required)
- [ ] `.github/workflows/` or `.gitea/workflows/` - CI/CD (required)

**Note:** No AI.md, SPEC.md, or CLAUDE.md in projects. Only AI.md.

### Development

- [ ] All 4 OSes: Linux, macOS, BSD, Windows
- [ ] Both architectures: AMD64, ARM64
- [ ] CGO_ENABLED=0 for static binaries
- [ ] Single binary with embedded assets
- [ ] No external runtime dependencies

### Configuration

- [ ] Config file: `server.yml` (not .yaml)
- [ ] Environment variables: `CASSPEED_xxx`
- [ ] CLI flags override env, env overrides file
- [ ] Boolean accepts: true/false, yes/no, 1/0, on/off
- [ ] Sane defaults for everything

### Frontend

- [ ] Frontend required for ALL projects
- [ ] Project-wide theme system: light/dark/auto (dark is default)
- [ ] Themes apply everywhere: web UI, admin, Swagger, GraphQL, ReadTheDocs
- [ ] NO inline CSS - external stylesheets only
- [ ] NO JavaScript alerts - use toast notifications
- [ ] Mobile-first responsive design
- [ ] WCAG 2.1 AA accessibility (both light and dark themes)

### API

- [ ] REST API at `/api/v1/`
- [ ] Swagger UI at `/openapi`
- [ ] OpenAPI spec at `/openapi.json` (JSON only, no YAML)
- [ ] GraphQL at `/graphql` (synced with REST)
- [ ] Health check at `/healthz`

### Admin Panel

- [ ] Web UI at `/admin` (session auth)
- [ ] API at `/api/v1/admin/` (bearer token auth)
- [ ] First-run setup wizard
- [ ] All settings configurable via UI

### Server CLI

- [ ] `--help`, `--version` - no privileges needed
- [ ] `--status` - show running status
- [ ] `--config` - specify config file
- [ ] `--service` - install/start/stop/restart/uninstall
- [ ] `--maintenance` - backup/restore/setup
- [ ] `--update` - check/yes/branch

### Database

- [ ] SQLite for local/single-node (default)
- [ ] PostgreSQL/MySQL for cluster mode
- [ ] Self-creating schema (CREATE TABLE IF NOT EXISTS)
- [ ] Automatic migrations on startup

### Scheduler

- [ ] Built-in scheduler (always running)
- [ ] Backup: 02:00 daily
- [ ] SSL renewal: 03:00 daily
- [ ] GeoIP update: 03:00 Sunday
- [ ] Session cleanup: hourly
- [ ] Cluster-aware task locking

### Backup & Restore

- [ ] Automatic daily backups (configurable)
- [ ] Encrypted backups (AES-256-GCM)
- [ ] Max 4 backups retained (default)
- [ ] Restore via CLI: `--maintenance restore`

### Email & Notifications

- [ ] SMTP required for email features
- [ ] No SMTP = email features disabled (not hidden errors)
- [ ] Customizable email templates
- [ ] WebUI notifications always available

### SSL/TLS

- [ ] Let's Encrypt support (HTTP-01, TLS-ALPN-01, DNS-01)
- [ ] Manual certificate support
- [ ] Auto-renewal via scheduler
- [ ] HSTS when SSL enabled

### Security

- [ ] All security headers (CSP, X-Frame-Options, etc.)
- [ ] Rate limiting enabled
- [ ] Audit logging
- [ ] 2FA support (TOTP, WebAuthn)
- [ ] Session management

### Logging

- [ ] access.log, server.log, error.log, audit.log, security.log
- [ ] Configurable formats and rotation
- [ ] Audit log: JSON only, daily rotation

### Build & Deploy

- [ ] Makefile: build, release, docker, test
- [ ] CI/CD: release, beta, daily, docker workflows
- [ ] 8 platform builds (4 OS × 2 arch)
- [ ] Docker: Alpine base, tini init, non-root user

### Documentation

- [ ] `docs/` directory ONLY for ReadTheDocs (MkDocs) - nothing else
- [ ] `mkdocs.yml` in project root
- [ ] `.readthedocs.yaml` in project root
- [ ] `docs/requirements.txt` with dependencies
- [ ] MkDocs Material theme with light/dark/auto toggle (dark default)
- [ ] `docs/stylesheets/dark.css` (OPTIONAL for dark theme customization)
- [ ] `docs/stylesheets/light.css` (OPTIONAL for light theme customization)
- [ ] Required pages: index, installation, configuration, api, admin, development
- [ ] ReadTheDocs URL: `https://casapps-casspeed.readthedocs.io`
- [ ] Documentation badge in README.md

### CLI Client (if applicable)

- [ ] Binary: `casspeed-cli`
- [ ] Same version as server
- [ ] Standard CLI + TUI modes
- [ ] Config: `~/.config/casspeed/cli.yml`
- [ ] Dark theme for TUI (matching project theme)
- [ ] Built alongside server

### Tor (if tor binary installed)

- [ ] Auto-enabled when tor binary found
- [ ] Dedicated tor process (not system tor)
- [ ] .onion address management
- [ ] Vanity address generation

### Optional Features

- [ ] Custom domains (per-project decision)
- [ ] Multi-user mode (per-project decision)
- [ ] Organizations (per-project decision)
- [ ] Cluster mode (when HA needed)

---

**END OF SPECIFICATION**

**ALL sections marked NON-NEGOTIABLE must be implemented exactly as specified.**

**When in doubt:**
- **AI:** Re-read AI.md and TODO.AI.md. Ask questions. Never assume.
- **Humans:** Re-read AI.md. Update TODO.AI.md. Ask AI to clarify.

---

# APPENDIX A: INTEGRATION NOTES

# Integration Notes for Existing Projects

**Use this prompt when integrating this specification into an EXISTING project.**

---

## Prompt for AI Assistants

When integrating this specification into an existing project:

### Phase 1: Assessment (Read-Only)

1. **Read the entire AI.md specification** (this file)
2. **Read the existing project codebase** - understand current structure
3. **Identify gaps** between current state and specification requirements
4. **Create TODO.AI.md** with comprehensive task list organized by priority:
   - **Critical (P0)**: Security issues, data loss risks, broken functionality
   - **High (P1)**: Missing NON-NEGOTIABLE requirements
   - **Medium (P2)**: Structural improvements, standardization
   - **Low (P3)**: Nice-to-have features, documentation improvements

### Phase 2: Planning

1. **Do NOT start making changes yet**
2. **Review TODO.AI.md with the human** - get approval on priorities
3. **Ask clarifying questions:**
   - Are there existing features that should be preserved?
   - Are there breaking changes acceptable?
   - What is the migration timeline (can it be done incrementally)?
   - Are there production systems that need careful migration?
4. **Create a migration plan** for each major change
5. **Identify risks** - data migration, API breaking changes, downtime requirements

### Phase 3: Incremental Implementation

**NEVER attempt to fix everything at once. Work incrementally:**

1. **Start with Critical (P0) items**
   - Security vulnerabilities
   - Data integrity issues
   - Broken functionality

2. **Then High (P1) NON-NEGOTIABLE items**
   - Work in small, testable increments
   - One subsystem at a time
   - Ensure each change is tested before moving on

3. **Then Medium (P2) improvements**
   - Structural reorganization
   - Standardization of patterns

4. **Finally Low (P3) enhancements**
   - Documentation
   - Nice-to-have features

### Phase 4: Validation

After each significant change:

1. **Test thoroughly** - verify nothing broke
2. **Update TODO.AI.md** - mark items complete
3. **Update AI.md** - reflect current project state
4. **Document breaking changes** - if any
5. **Get human approval** before proceeding to next phase

---

## Common Integration Patterns

### Pattern 1: File Structure Migration

**If project has non-standard structure:**

1. Create new `src/` directory structure per spec
2. Move files incrementally (one package at a time)
3. Update imports after each move
4. Test after each move
5. Delete old structure only when new structure is fully working

### Pattern 2: Configuration Migration

**If project uses different config format:**

1. Keep old config format working alongside new format
2. Add config migration utility: `--migrate-config old.conf new.yml`
3. Warn users about old format deprecation
4. Provide migration guide in docs
5. Eventually remove old format support (with proper notice)

### Pattern 3: API Versioning

**If project has existing API that doesn't match spec:**

1. Implement new spec-compliant API at `/api/v2/`
2. Keep old API at `/api/v1/` with deprecation warnings
3. Add migration guide for API consumers
4. Set deprecation timeline
5. Eventually remove old API version

### Pattern 4: Database Schema Migration

**If project has existing database:**

1. **NEVER break existing data**
2. Create migration scripts in `src/migration/`
3. Use proper migration tool or SQL migration files
4. Test migrations on backup data first
5. Provide rollback capability
6. Document breaking schema changes

---

## Critical Rules for Integration

| Rule | Description |
|------|-------------|
| **NEVER break production** | Integration should be incremental and safe |
| **NEVER lose data** | Migrations must preserve all existing data |
| **NEVER remove features** | Unless explicitly approved by human |
| **ALWAYS test** | Every change must be tested before proceeding |
| **ALWAYS backup** | Before major structural changes |
| **ALWAYS document** | Breaking changes, migrations, deprecations |
| **ALWAYS ask** | When unsure about preserving existing behavior |

---

## Red Flags (Stop and Ask Human)

Stop immediately and ask the human if you encounter:

- Existing data that might be lost
- Breaking API changes affecting external users
- Configuration changes requiring manual migration
- File structure changes affecting deployed systems
- Security changes that might break authentication
- Database schema changes without clear migration path
- Removal of features currently in use

---

## Integration Checklist

Before starting integration:

- [ ] Have you read the ENTIRE AI.md specification?
- [ ] Have you read and understood the existing codebase?
- [ ] Have you created a comprehensive TODO.AI.md with prioritized tasks?
- [ ] Have you reviewed the TODO.AI.md with the human?
- [ ] Have you identified all risks and breaking changes?
- [ ] Have you planned for data migration (if needed)?
- [ ] Have you planned for incremental rollout?
- [ ] Do you have a rollback plan for each major change?

**If you answered NO to any of the above, DO NOT START IMPLEMENTATION.**

---

## Example TODO.AI.md for Integration

```markdown
# Integration Tasks for casspeed

## Critical (P0) - Do First

- [ ] Fix SQL injection vulnerability in user search (line 234)
- [ ] Add missing input validation on admin endpoints
- [ ] Fix session management security issue

## High (P1) - NON-NEGOTIABLE Requirements

### File Structure
- [ ] Create src/ directory structure per spec
- [ ] Move main.go to src/main.go
- [ ] Create src/config/ package
- [ ] Create src/server/ package
- [ ] Create src/swagger/ package (NEW)
- [ ] Create src/graphql/ package (NEW)
- [ ] Update all imports

### Configuration
- [ ] Migrate config.json to server.yml format
- [ ] Add environment variable support
- [ ] Add CLI flag overrides
- [ ] Create migration utility

### API
- [ ] Add Swagger/OpenAPI support (NEW)
- [ ] Add GraphQL support (NEW)
- [ ] Ensure REST API matches spec patterns

## Medium (P2) - Standardization

- [ ] Standardize error handling per spec
- [ ] Add comprehensive logging per spec
- [ ] Implement project-wide theme system (light/dark/auto)
- [ ] Add health check endpoint format per spec

## Low (P3) - Documentation

- [ ] Create docs/ directory for ReadTheDocs
- [ ] Write docs/index.md
- [ ] Write docs/installation.md
- [ ] Configure mkdocs.yml
```

---

## Remember

**Integration is a PROCESS, not a single change.**

- Work incrementally
- Test continuously
- Document everything
- Get approval at each phase
- Preserve existing functionality unless explicitly changing it
- NEVER rush integration to "get it done faster"

---

---

# APPENDIX B: BOOTSTRAP NOTES

# Bootstrap Notes for New Projects

**Use this prompt when creating a NEW project from scratch.**

---

## Prompt for AI Assistants

When bootstrapping a new project from this specification:

### Phase 1: Project Initialization

1. **Confirm project details:**
   - Project name: `casspeed`
   - Organization: `casapps`
   - Description: What does this project do?
   - Primary purpose: What problem does it solve?

2. **Create directory structure:**
   ```bash
   mkdir -p casspeed
   cd casspeed

   # Create all required directories
   mkdir -p src/{config,server,swagger,graphql,mode,paths,ssl,scheduler,service,admin}
   mkdir -p src/server/{handler,service,model,store,template}
   mkdir -p docker/rootfs/usr/local/bin
   mkdir -p docs/stylesheets
   mkdir -p tests
   mkdir -p scripts
   mkdir -p .github/workflows
   ```

3. **Create AI.md from AI.md:**
   - Copy AI.md from apimgr repo
   - Replace all `CASSPEED` with actual project name
   - Replace all `casspeed` with actual project name
   - Replace all `casapps` with actual organization
   - Fill in PROJECT DESCRIPTION section
   - Fill in PART 36: PROJECT-SPECIFIC SECTIONS
   - Save as AI.md

4. **Create foundational files:**
   ```bash
   # Required files
   touch README.md
   touch LICENSE.md
   touch Makefile
   touch Jenkinsfile
   touch release.txt
   touch TODO.AI.md
   touch .gitignore

   # Docker files
   touch docker/Dockerfile
   touch docker/docker-compose.yml
   touch docker/docker-compose.dev.yml
   touch docker/docker-compose.test.yml
   touch docker/rootfs/usr/local/bin/entrypoint.sh

   # ReadTheDocs files
   touch mkdocs.yml
   touch .readthedocs.yaml
   touch docs/index.md
   touch docs/installation.md
   touch docs/configuration.md
   touch docs/api.md
   touch docs/admin.md
   touch docs/development.md
   touch docs/requirements.txt
   touch docs/stylesheets/dark.css
   touch docs/stylesheets/light.css

   # CI/CD
   touch .github/workflows/release.yml
   touch .github/workflows/beta.yml
   touch .github/workflows/daily.yml
   touch .github/workflows/docker.yml
   ```

### Phase 2: Core Implementation Order

**Implement in this specific order for best results:**

#### Step 1: Basic Structure (PARTS 1-5)

1. **Initialize Go module:**
   ```bash
   go mod init github.com/casapps/casspeed
   ```

2. **Create src/main.go** - Minimal entry point
3. **Create src/config/config.go** - Configuration loading
4. **Create src/mode/mode.go** - Application mode detection
5. **Create src/paths/paths.go** - Path resolution

**Test:** Binary should compile and show version

#### Step 2: Server Foundation (PARTS 6-10)

1. **Create src/server/server.go** - HTTP server setup
2. **Create src/server/handler/health.go** - Health check
3. **Add CLI flags** per PART 6 specification
4. **Add service support** per PART 9
5. **Create Makefile** per PART 11

**Test:** Server starts and responds to `/healthz`

#### Step 3: Docker & CI/CD (PARTS 11-14)

1. **Create docker/Dockerfile** - Multi-stage build
2. **Create docker-compose files** - Production, dev, test
3. **Create entrypoint.sh** - Container initialization
4. **Create .github/workflows/** - All CI/CD workflows
5. **Create Makefile targets** - build, docker, release

**Test:** Docker build succeeds, container runs

#### Step 4: Web Frontend (PART 16)

1. **Create src/server/template/** - HTML templates
2. **Embed templates in server.go**
3. **Implement theme system** (light/dark/auto)
4. **Create homepage route** - `/` endpoint
5. **Test responsive design**

**Test:** Homepage loads with working theme toggle

#### Step 5: Admin Panel (PART 18)

1. **Create src/admin/admin.go** - Admin package
2. **Create admin templates** - UI pages
3. **Create admin handlers** - Routes and logic
4. **Implement first-run setup wizard**
5. **Add all admin configuration pages**

**Test:** Admin panel accessible at `/admin`

#### Step 6: API Layer (PART 19)

1. **Create src/server/handler/api.go** - REST API handlers
2. **Create src/swagger/swagger.go** - OpenAPI/Swagger
3. **Create src/graphql/graphql.go** - GraphQL API
4. **Ensure all three APIs are in sync**
5. **Apply theme to Swagger/GraphQL UIs**

**Test:** All three APIs work (REST, Swagger, GraphQL)

#### Step 7: Core Features (PARTS 20-28)

Implement in order:
1. **PART 20:** SSL/TLS & Let's Encrypt
2. **PART 21:** Security & Logging
3. **PART 22:** User Management
4. **PART 23:** Database & Cluster
5. **PART 24:** Backup & Restore
6. **PART 25:** Email & Notifications
7. **PART 26:** Scheduler
8. **PART 27:** GeoIP
9. **PART 28:** Metrics

**Test after each part:** Verify the feature works before moving to next

#### Step 8: Optional Features (PARTS 29-34)

Implement as needed:
1. **PART 29:** Tor Hidden Service (if tor installed)
2. **PART 30:** Error Handling & Caching
3. **PART 31:** I18N & A11Y
4. **PART 34:** CLI Client (if applicable)
5. **PART 35:** Custom Domains (if applicable)

#### Step 9: Documentation (PART 33)

1. **Create all docs/*.md files**
2. **Configure mkdocs.yml**
3. **Configure .readthedocs.yaml**
4. **Add docs/requirements.txt**
5. **Create theme CSS files**
6. **Test local MkDocs build:** `mkdocs serve`

**Test:** Documentation builds and deploys to ReadTheDocs

#### Step 10: Project-Specific (PART 36)

1. **Fill in PART 36 in AI.md** - Define project-specific endpoints, data, config
2. **Implement project-specific features**
3. **Add project-specific tests**
4. **Update documentation with project specifics**

**Test:** All project-specific functionality works

### Phase 3: Polish & Release

1. **Run full test suite** - Ensure everything works
2. **Build all 8 platforms** - Verify cross-platform builds
3. **Test Docker images** - All compose files work
4. **Complete README.md** - Production-first documentation
5. **Complete LICENSE.md** - Include all embedded licenses
6. **Final compliance check** - Review FINAL CHECKPOINT checklist
7. **Create initial release** - Tag v0.1.0

---

## Bootstrap Checklist

### Before You Start

- [ ] Have you read the ENTIRE AI.md specification?
- [ ] Do you understand the project purpose and scope?
- [ ] Have you confirmed all project details (name, org, description)?
- [ ] Have you asked clarifying questions about project-specific requirements?

### Foundation (Must Complete First)

- [ ] Directory structure created per spec
- [ ] AI.md created and customized
- [ ] go.mod initialized
- [ ] .gitignore created with proper rules
- [ ] Basic src/main.go exists
- [ ] src/config/config.go exists
- [ ] Project compiles successfully

### Core Features (In Order)

- [ ] Server starts and responds to requests
- [ ] Health check endpoint works
- [ ] CLI flags work per spec
- [ ] Configuration loading works (file, env, flags)
- [ ] Logging configured properly
- [ ] Admin panel accessible
- [ ] First-run setup wizard works
- [ ] REST API endpoints defined
- [ ] Swagger UI accessible at /openapi
- [ ] GraphQL accessible at /graphql
- [ ] All three APIs in sync

### Infrastructure

- [ ] Docker builds successfully
- [ ] Docker Compose files work (prod, dev, test)
- [ ] CI/CD workflows configured
- [ ] Automated builds work
- [ ] Multi-platform builds work (8 platforms)

### Documentation

- [ ] README.md complete
- [ ] LICENSE.md complete with embedded licenses
- [ ] docs/ directory structure created
- [ ] All required .md files in docs/
- [ ] mkdocs.yml configured
- [ ] ReadTheDocs configured
- [ ] Documentation builds successfully

### Final Validation

- [ ] All NON-NEGOTIABLE requirements met
- [ ] All FINAL CHECKPOINT items checked
- [ ] No TODO items marked as critical/blocker
- [ ] All tests pass
- [ ] All 8 platform builds succeed
- [ ] Docker images build and run
- [ ] Documentation published

---

## Common Mistakes When Bootstrapping

| Mistake | Why It's Wrong | Correct Approach |
|---------|----------------|------------------|
| Starting with project-specific features | Wastes time if foundation is wrong | Build foundation first (config, server, admin) |
| Skipping admin panel | Hard to configure without UI | Build admin panel early |
| Implementing all APIs at once | Easy to get out of sync | Start with REST, then add Swagger, then GraphQL |
| Not testing incrementally | Find bugs too late | Test after each major component |
| Hardcoding values | Makes project inflexible | Use configuration from day 1 |
| Skipping documentation | Users can't use the project | Write docs as you build |
| Building for one platform only | Fails CI/CD | Test multi-platform early |
| Ignoring theme system | Hard to retrofit later | Implement themes from start |

---

## Time-Saving Tips

1. **Use existing projects as reference:**
   - Look at jokes, quotes, or other apimgr projects
   - Copy patterns that match the spec
   - Adapt to your project's needs

2. **Leverage templates:**
   - Use spec templates for Docker, CI/CD, configs
   - Don't reinvent - copy and customize

3. **Build iteratively:**
   - Get basic version working first
   - Add features incrementally
   - Test continuously

4. **Focus on NON-NEGOTIABLE items first:**
   - Optional features can wait
   - Core requirements must be solid

---

## Success Criteria

A successfully bootstrapped project should:

✅ Compile to a single static binary for all 8 platforms
✅ Run in Docker with proper configuration
✅ Have working web UI with theme support (light/dark/auto)
✅ Have working admin panel with all config options
✅ Expose REST, Swagger, AND GraphQL APIs (all in sync)
✅ Have comprehensive documentation on ReadTheDocs
✅ Pass all CI/CD workflows
✅ Follow every NON-NEGOTIABLE requirement in AI.md
✅ Be ready for v0.1.0 release

---

## Getting Help

When stuck:

1. **Re-read the relevant PART** in AI.md
2. **Check existing projects** in apimgr for working examples
3. **Ask specific questions** about unclear requirements
4. **Propose solutions** for human review

**NEVER guess or assume** - always ask when uncertain.

---
